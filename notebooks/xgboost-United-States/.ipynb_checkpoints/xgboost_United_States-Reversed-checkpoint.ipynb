{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PISA 2022 Amazon SageMaker XGBoost\n",
    "Supervised Learning with Gradient Boosted Trees: A Binary Prediction Problem With Unbalanced Classes\n",
    "\n",
    "More info on SageMaker Immersion Day: [Workshop Link](https://catalog.us-east-1.prod.workshops.aws/workshops/63069e26-921c-4ce1-9cc7-dd882ff62575/en-US/lab2-model-training/pro-code)\n",
    "\n",
    "\n",
    "## Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Change country name below!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_name = 'United_States'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_name_edited = country_name.replace(\"_\", \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cell 02\n",
    "import sagemaker\n",
    "bucket=sagemaker.Session().default_bucket()\n",
    "prefix = 'sagemaker/xgboost-'+country_name_edited\n",
    " \n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's bring in the Python libraries that we'll use throughout the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cell 03\n",
    "import numpy as np                                # For matrix operations and numerical processing\n",
    "import pandas as pd                               # For munging tabular data\n",
    "import matplotlib.pyplot as plt                   # For charts and visualizations\n",
    "from IPython.display import Image                 # For displaying images in the notebook\n",
    "from IPython.display import display               # For displaying outputs in the notebook\n",
    "from time import gmtime, strftime                 # For labeling SageMaker models, endpoints, etc.\n",
    "import sys                                        # For writing outputs to notebook\n",
    "import math                                       # For ceiling function\n",
    "import json                                       # For parsing hosting outputs\n",
    "import os                                         # For manipulating filepath names\n",
    "import sagemaker \n",
    "import zipfile     # Amazon SageMaker's Python SDK provides many helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download PISA 2022 Prepared Dataset\n",
    "\n",
    "This is our dataset output from our cleaned notebook [here](https://7z4vtvpqcoxouiu.studio.us-west-2.sagemaker.aws/jupyterlab/default/lab/tree/RTC%3Amids-capstone/notebooks/eda/Data_merging.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# cell 06\n",
    "\n",
    "# Define local file path\n",
    "local_file_path = \"PISA_cleaned_dataset.csv\"  # Change as needed\n",
    "\n",
    "# Define S3 details\n",
    "bucket_name = \"sagemaker-us-west-2-986030204467\"\n",
    "file_key = \"capstone/testfiles/PISA_cleaned_dataset.csv\"\n",
    "\n",
    "# Check if the file exists locally\n",
    "if os.path.exists(local_file_path):\n",
    "    print(\"üìÇ Loading data from local file...\")\n",
    "    data = pd.read_csv(local_file_path, usecols=None)\n",
    "    \n",
    "else:\n",
    "    print(\"‚òÅÔ∏è Downloading data from S3...\")\n",
    "    \n",
    "    # Create S3 client\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "\n",
    "    # Download the file from S3\n",
    "    response = s3_client.get_object(Bucket=bucket_name, Key=file_key)\n",
    "\n",
    "    # Read the file into pandas DataFrame\n",
    "    data = pd.read_csv(response[\"Body\"], usecols=None)\n",
    "\n",
    "    # Save a local copy for future use\n",
    "    data.to_csv(local_file_path, index=False)\n",
    "    print(f\"‚úÖ File saved locally as {local_file_path}\")\n",
    "\n",
    "# Display first few rows\n",
    "#data.head()\n",
    "\n",
    "pd.set_option('display.max_columns', 500)     # Make sure we can see all of the columns\n",
    "pd.set_option('display.max_rows', 20)         # Keep the output on one page\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download dictionary of the variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the file from S3\n",
    "s3_client = boto3.client(\"s3\")\n",
    "dictionary_file = s3_client.get_object(Bucket=bucket_name, Key=\"capstone/testfiles/Variable_dictionary.csv\")\n",
    "\n",
    "# Read the file into pandas DataFrame\n",
    "dictionary = pd.read_csv(dictionary_file[\"Body\"], usecols=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset the data to a specific COUNTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = data[data['CNT'] == country_name]\n",
    "print(model_data.shape)\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take out additional variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of columns to drop\n",
    "columns_to_remove = [\"CNTSCHID\", \"CNTSTUID\", \"OECD\",\n",
    "    \"HOMEPOS\", \"RELATST\", \"BELONG\", \"BULLIED\", \"FEELSAFE\", \"SCHRISK\", \"PERSEVAGR\", \"CURIOAGR\", \n",
    "    \"COOPAGR\", \"EMPATAGR\", \"ASSERAGR\", \"STRESAGR\", \"EMOCOAGR\", \"GROSAGR\", \"INFOSEEK\", \"FAMSUP\", \n",
    "    \"DISCLIM\", \"TEACHSUP\", \"COGACRCO\", \"COGACMCO\", \"EXPOFA\", \"EXPO21ST\", \"MATHEFF\", \"MATHEF21\", \n",
    "    \"FAMCON\", \"ANXMAT\", \"MATHPERS\", \"CREATEFF\", \"CREATSCH\", \"CREATFAM\", \"CREATAS\", \"CREATOOS\", \n",
    "    \"CREATOP\", \"OPENART\", \"IMAGINE\", \"SCHSUST\", \"LEARRES\", \"PROBSELF\", \"FAMSUPSL\", \"FEELLAH\", \n",
    "    \"SDLEFF\", \"ICTRES\", \"FLSCHOOL\", \"FLMULTSB\", \"FLFAMILY\", \"ACCESSFP\", \"FLCONFIN\", \"FLCONICT\", \n",
    "    \"ACCESSFA\", \"ATTCONFM\", \"FRINFLFM\", \"ICTSCH\", \"ICTHOME\", \"ICTQUAL\", \"ICTSUBJ\", \"ICTENQ\", \n",
    "    \"ICTFEED\", \"ICTOUT\", \"ICTWKDY\", \"ICTWKEND\", \"ICTREG\", \"ICTINFO\", \"ICTEFFIC\", \"BODYIMA\", \n",
    "    \"SOCONPA\", \"LIFESAT\", \"PSYCHSYM\", \"SOCCON\", \"EXPWB\", \"CURSUPP\", \"PQMIMP\", \"PQMCAR\", \n",
    "    \"PARINVOL\", \"PQSCHOOL\", \"PASCHPOL\", \"ATTIMMP\", \"CREATHME\", \"CREATACT\", \"CREATOPN\", \n",
    "    \"CREATOR\", \"SCHAUTO\", \"TCHPART\", \"EDULEAD\", \"INSTLEAD\", \"ENCOURPG\", \"DIGDVPOL\", \"TEAFDBK\", \n",
    "    \"MTTRAIN\", \"DMCVIEWS\", \"NEGSCLIM\", \"STAFFSHORT\", \"EDUSHORT\", \"STUBEHA\", \"TEACHBEHA\", \n",
    "    \"STDTEST\", \"TDTEST\", \"ALLACTIV\", \"BCREATSC\", \"CREENVSC\", \"ACTCRESC\", \"OPENCUL\", \n",
    "    \"PROBSCRI\", \"SCPREPBP\", \"SCPREPAP\", \"DIGPREP\", \n",
    "    \"ESCS\", \"BMMJ1\", \"BFMJ2\", \"EFFORT1\", \"EFFORT2\", \"Option_UH\", \"SC209Q04JA\", \"SC209Q05JA\", \"SC209Q06JA\"\n",
    "]\n",
    "\n",
    "# Drop the columns above\n",
    "model_data = model_data.drop(columns=columns_to_remove, errors='ignore')  # `errors='ignore'` prevents errors if a column isn't found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_data.shape)\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker's XGBoost container expects data in the libSVM or CSV data format.  **Note that the first column must be the target variable and the CSV should not include headers.**  Although repetitive, it's easiest to do this after the train|validation|test split rather than before.  This avoids any misalignment issues due to random reordering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new variable called MATH_Behind\n",
    "* `MATH_Behind`: Is the student falling behind in Math (average of 10 Math plausible values < 420.07)?\n",
    "* 1 means the student is falling behind in Math\n",
    "* This will make evaluation metrics like Precision and Recall more meaningful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new variable\n",
    "model_data[\"MATH_Behind\"] = 1 - model_data[\"MATH_Proficient\"]\n",
    "\n",
    "# Drop the MATH_Proficient variable\n",
    "model_data = model_data.drop(columns=[\"MATH_Proficient\"], errors='ignore')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns to bring 'MATH_Behind' first\n",
    "new_order = ['MATH_Behind'] + [col for col in model_data.columns if col != 'MATH_Behind']\n",
    "model_data = model_data[new_order]\n",
    "\n",
    "# Check the shape after dropping\n",
    "print(model_data.shape)\n",
    "\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll randomly split the data into 3 uneven groups.  **The model will be trained on 70% of data, it will then be evaluated on 15% of data to give us an estimate of the accuracy we hope to have on \"new\" data, and 15% will be held back as a final testing dataset which will be used later on.**\n",
    "\n",
    "A seed is included in the code so the splits can be replicated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cell 12\n",
    "# Randomly sort the data then split out first 70%, second 15%, and last 15%\n",
    "train_data, validation_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data)), int(0.85 * len(model_data))])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows in FULL dataset:\", model_data.shape[0])\n",
    "\n",
    "train_data_percent = round(train_data.shape[0]/model_data.shape[0] * 100, 0)\n",
    "print(\"Number of rows in TRAINING dataset:\", train_data.shape[0], \",\", train_data_percent, \"%\")\n",
    "\n",
    "validation_data_percent = round(validation_data.shape[0]/model_data.shape[0] * 100, 0)\n",
    "print(\"Number of rows in VALIDATION dataset:\", validation_data.shape[0], \",\", validation_data_percent, \"%\")\n",
    "\n",
    "test_data_percent = round(test_data.shape[0]/model_data.shape[0] * 100, 0)\n",
    "print(\"Number of rows in TEST dataset:\", test_data.shape[0], \",\", test_data_percent, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop country names from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cell 13\n",
    "#pd.concat([train_data['y_yes'], train_data.drop(['y_no', 'y_yes'], axis=1)], axis=1).to_csv('train.csv', index=False, header=False)\n",
    "#pd.concat([validation_data['y_yes'], validation_data.drop(['y_no', 'y_yes'], axis=1)], axis=1).to_csv('validation.csv', index=False, header=False)# Drop non-numeric columns (e.g., country names or IDs that are not numeric)\n",
    "\n",
    "# Drop string variables (Country names)\n",
    "non_numeric_columns = train_data.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "train_data = train_data.drop(columns=non_numeric_columns)\n",
    "validation_data = validation_data.drop(columns=non_numeric_columns)\n",
    "test_data = test_data.drop(columns=non_numeric_columns)\n",
    "\n",
    "# Save train dataset \n",
    "train_data.to_csv('train.csv', index=False, header=False)\n",
    "\n",
    "# Save validation dataset \n",
    "validation_data.to_csv('validation.csv', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data - Saved to S3 as CSV\n",
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data - Saved to S3 as CSV\n",
    "print(validation_data.shape)\n",
    "validation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data - NOT SAVED TO S3\n",
    "print(test_data.shape)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll copy the file to S3 for Amazon SageMaker's managed training to pickup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cell 14\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training \n",
    "\n",
    "At a high level, gradient boosted trees works by combining predictions from many simple models, each of which tries to address the weaknesses of the previous models.  By doing this the collection of simple models can actually outperform large, complex models.  Other Amazon SageMaker notebooks elaborate on gradient boosting trees further and how they differ from similar algorithms.\n",
    "\n",
    "`xgboost` is an extremely popular, open-source package for gradient boosted trees.  It is computationally powerful, fully featured, and has been successfully used in many machine learning competitions.  Let's start with a simple `xgboost` model, trained using Amazon SageMaker's managed, distributed training framework.\n",
    "\n",
    "First we'll need to specify the ECR container location for Amazon SageMaker's implementation of XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 15\n",
    "container = sagemaker.image_uris.retrieve(region=boto3.Session().region_name, framework='xgboost', version='latest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, because we're training with the CSV file format, we'll create `s3_input`s that our training function can use as a pointer to the files in S3, which also specify that the content type is CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 16\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/validation/'.format(bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll need to specify training parameters to the estimator.  This includes:\n",
    "1. The `xgboost` algorithm container\n",
    "1. The IAM role to use\n",
    "1. Training instance type and count\n",
    "1. S3 location for output data\n",
    "1. Algorithm hyperparameters\n",
    "\n",
    "And then a `.fit()` function which specifies:\n",
    "1. S3 location for output data.  In this case we have both a training and validation set which are passed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 17\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    instance_count=1, \n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.set_hyperparameters(# seed=42,       # Random seed (turned off because we are using a different seed per iteration)  \n",
    "                        seed_per_iteration=True,   # Different seed for each boosting iteration, can prevent overfitting\n",
    "                        early_stopping_rounds=10,   # Stop if AUC doesn‚Äôt improve for 10 rounds\n",
    "                        objective='binary:logistic',\n",
    "                        eval_metric='aucpr', # AUCPR is better than AUC-ROC when the outcome is not balanced (maximizing this will make the model good at detecting positives)\n",
    "                        num_round=100,   # Number of boosting rounds for training                    \n",
    "                        eta=0.05,   # Learning rate, lower value is more robust to overfitting but requires more boosting rounds\n",
    "                        max_depth=5,   # Deeper trees can model more complex patterns but may overfit\n",
    "                        min_child_weight=10,   # Higher value ensures leaf nodes have sufficient samples, preventing overfitting\n",
    "                        gamma=4,    # Higher values make it harder to partition a leaf node, making the algorithm more conservative\n",
    "                        subsample=0.8,   # Fraction of training instances to use for each boosting round, < 1 can prevent overfitting\n",
    "                        alpha=5   # L1 regularization term on weights, higher value leads to more regularization                       \n",
    "                        )\n",
    "\n",
    "# xgb.fit({'train': s3_input_train, 'validation': s3_input_validation}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use auto-tuning to find best hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker automatic model tuning, also known as hyperparameter tuning, finds the best version of a model by running many training jobs on your dataset using the algorithm and ranges of hyperparameters that you specify. It then chooses the hyperparameter values that result in a model that performs the best, as measured by a metric that you choose.\n",
    "For example, suppose that you want to solve a binary classification problem on this marketing dataset. Your goal is to maximize the area under the curve (auc) metric of the algorithm by training an XGBoost Algorithm model. You don't know which values of the eta, alpha, min_child_weight, and max_depth hyperparameters to use to train the best model. To find the best values for these hyperparameters, you can specify ranges of values that Amazon SageMaker hyperparameter tuning searches to find the combination of values that results in the training job that performs the best as measured by the objective metric that you chose. Hyperparameter tuning launches training jobs that use hyperparameter values in the ranges that you specified, and returns the training job with highest auc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "hyperparameter_ranges = {'num_round': IntegerParameter(50, 300),\n",
    "                         'eta': ContinuousParameter(0.01, 0.1),\n",
    "                         'max_depth': IntegerParameter(3, 6),\n",
    "                         'min_child_weight': IntegerParameter(5, 20),\n",
    "                         'gamma': IntegerParameter(1, 10),     \n",
    "                         'subsample': ContinuousParameter(0.7, 1.0),\n",
    "                         'alpha': IntegerParameter(1, 10),\n",
    "                         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(estimator=xgb,\n",
    "                            objective_metric_name='validation:auc',\n",
    "                            hyperparameter_ranges=hyperparameter_ranges,\n",
    "                            max_jobs=20,  \n",
    "                            max_parallel_jobs=5)\n",
    "\n",
    "# May need to adjust number of jobs depending on budget!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 26\n",
    "boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 27\n",
    "# Return the best training job name\n",
    "best_training_job = tuner.best_training_job()\n",
    "print(best_training_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out hyperparameters of BEST model\n",
    "response = boto3.client('sagemaker').describe_training_job(TrainingJobName=best_training_job)\n",
    "best_hyperparameters = response[\"HyperParameters\"]\n",
    "\n",
    "best_num_round = int(best_hyperparameters[\"num_round\"])\n",
    "best_eta = float(best_hyperparameters[\"eta\"])\n",
    "best_max_depth = int(best_hyperparameters[\"max_depth\"])\n",
    "best_min_child_weight = int(best_hyperparameters[\"min_child_weight\"])\n",
    "best_gamma = int(best_hyperparameters[\"gamma\"])\n",
    "best_subsample = float(best_hyperparameters[\"subsample\"])\n",
    "best_alpha = int(best_hyperparameters[\"alpha\"])\n",
    "\n",
    "print(\"BEST num_round: \", best_num_round)\n",
    "print(\"BEST eta: \", round(best_eta, 2))\n",
    "print(\"BEST max_depth: \", best_max_depth)\n",
    "print(\"BEST min_child_weight: \", best_min_child_weight)\n",
    "print(\"BEST gamma: \", best_gamma)\n",
    "print(\"BEST subsample: \", round(best_subsample, 2))\n",
    "print(\"BEST alpha: \", best_alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model (the best model identified by HyperparameterTuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 28\n",
    "tuner_predictor = tuner.deploy(initial_instance_count=1,\n",
    "                           instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 29\n",
    "# Create a serializer\n",
    "tuner_predictor.serializer = sagemaker.serializers.CSVSerializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 20\n",
    "def predict(data, predictor, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, predictor.predict(array).decode('utf-8')])\n",
    "    return np.fromstring(predictions[1:], sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 30\n",
    "# Make predictions\n",
    "predictions = predict(test_data.drop(['MATH_Behind'], axis=1).to_numpy(),tuner_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance (This model has all of the predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 31\n",
    "\n",
    "# Generate the confusion matrix (ensure predictions are rounded appropriately)\n",
    "cm = pd.crosstab(index=test_data['MATH_Behind'], \n",
    "                 columns=np.round(predictions), \n",
    "                 rownames=['actuals'], \n",
    "                 colnames=['predictions'])\n",
    "print(cm)\n",
    "\n",
    "# Extract values from the confusion matrix\n",
    "# Assuming that:\n",
    "# - actual class 0 is negative\n",
    "# - actual class 1 is positive\n",
    "TN = cm.loc[0.0, 0.0]\n",
    "FP = cm.loc[0.0, 1.0]\n",
    "FN = cm.loc[1.0, 0.0]\n",
    "TP = cm.loc[1.0, 1.0]\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN) * 100\n",
    "\n",
    "# Calculate Precision (for the positive class)\n",
    "precision = TP / (TP + FP) * 100 if (TP + FP) > 0 else 0\n",
    "\n",
    "# Calculate Recall (for the positive class)\n",
    "recall = TP / (TP + FN) * 100 if (TP + FN) > 0 else 0\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# Calculate Specificity (True Negative Rate)\n",
    "specificity = TN / (TN + FP) * 100 if (TN + FP) > 0 else 0\n",
    "\n",
    "# Print out the calculated metrics\n",
    "print(\"\\n Accuracy: {:.2f}\".format(accuracy))\n",
    "print(\"\\n Precision: {:.2f}\".format(precision))\n",
    "print(\"\\n Recall: {:.2f}\".format(recall))\n",
    "print(\"\\n F1 Score: {:.2f}\".format(f1_score))\n",
    "print(\"\\n Specificity: {:.2f}\".format(specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 33\n",
    "# Clean up\n",
    "tuner_predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain the trained model using Clarify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "model_name = \"Clarify-{}-{}\".format(country_name_edited, datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\"))\n",
    "\n",
    "best_model = sagemaker.estimator.Estimator.attach(best_training_job)  # Attach the best training job\n",
    "\n",
    "model = best_model.create_model(name=model_name)  # Create a model from the best job\n",
    "\n",
    "container_def = model.prepare_container_def()\n",
    "\n",
    "session.create_model(model_name, role, container_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test_data.drop([\"MATH_Behind\"], axis=1)\n",
    "test_target = test_data[\"MATH_Behind\"]\n",
    "test_features.to_csv(\"test_features.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import clarify\n",
    "\n",
    "clarify_processor = clarify.SageMakerClarifyProcessor(\n",
    "    role=role, instance_count=1, instance_type=\"ml.m5.2xlarge\", sagemaker_session=session\n",
    ")\n",
    "\n",
    "model_config = clarify.ModelConfig(\n",
    "    model_name=model_name,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    accept_type=\"text/csv\",\n",
    "    content_type=\"text/csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "# Download data from S3 to local instance\n",
    "local_path = S3Downloader.download('s3://{}/{}/train'.format(bucket, prefix), './tmp/train_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and sample\n",
    "full_data = pd.read_csv('./tmp/train_data/train.csv', header=None)\n",
    "n = min(3000, len(full_data))  # Should we decrease this? It takes a long time to run\n",
    "sampled_data = full_data.sample(n=n)  # If full_data has less than 1500, use full sample\n",
    "\n",
    "# Save sampled data back to S3\n",
    "sampled_path = 'sampled_train_data.csv'\n",
    "sampled_data.to_csv(sampled_path, index=False)\n",
    "\n",
    "from sagemaker.s3 import S3Uploader\n",
    "sampled_s3_uri = S3Uploader.upload(sampled_path, 's3://{}/{}/sampled_train'.format(bucket, prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sampled_data.shape)\n",
    "sampled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_config = clarify.SHAPConfig(\n",
    "    baseline=[test_features.iloc[0].values.tolist()],\n",
    "    num_samples=3000,  \n",
    "    agg_method=\"mean_abs\",\n",
    "    save_local_shap_values=True\n",
    ")\n",
    "\n",
    "explainability_output_path = \"s3://{}/{}/clarify-explainability\".format(bucket, prefix)\n",
    "\n",
    "explainability_data_config = clarify.DataConfig(\n",
    "    #s3_data_input_path='s3://{}/{}/train'.format(bucket, prefix),\n",
    "    s3_data_input_path=sampled_s3_uri,\n",
    "    s3_output_path=explainability_output_path,\n",
    "    label='MATH_Behind',\n",
    "    headers=train_data.columns.to_list(),\n",
    "    dataset_type=\"text/csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set logging level for 'sagemaker.clarify' to WARNING (hides INFO messages)\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"sagemaker.clarify\").setLevel(logging.WARNING)\n",
    "\n",
    "clarify_processor.run_explainability(\n",
    "    data_config=explainability_data_config,\n",
    "    model_config=model_config,\n",
    "    explainability_config=shap_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model again with the top 20 predictors\n",
    "#### Get the list of top 20 predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your actual bucket name and prefix used in explainability_output_path\n",
    "# bucket = \"your-bucket-name\"\n",
    "# prefix = \"your-prefix\"  # e.g., the folder structure used in your explainability_output_path\n",
    "\n",
    "# Construct the S3 key for the output file\n",
    "key = f\"{prefix}/clarify-explainability/analysis.json\"\n",
    "\n",
    "# Initialize boto3 client for S3 and download the JSON report\n",
    "s3 = boto3.client(\"s3\")\n",
    "response = s3.get_object(Bucket=bucket, Key=key)\n",
    "content = response[\"Body\"].read().decode(\"utf-8\")\n",
    "report = json.loads(content)\n",
    "\n",
    "# Navigate to the global SHAP values dictionary\n",
    "global_shap = report[\"explanations\"][\"kernel_shap\"][\"label0\"][\"global_shap_values\"]\n",
    "\n",
    "# Sort the items by the SHAP value in descending order and take the top 20\n",
    "top_20 = sorted(global_shap.items(), key=lambda item: item[1], reverse=True)[:20]\n",
    "\n",
    "# Extract just the feature names\n",
    "top_20_features = [feature for feature, value in top_20]\n",
    "\n",
    "# Print\n",
    "print(\"Top 20 features with the highest mean absolute SHAP values:\")\n",
    "for feature in top_20_features:\n",
    "    print(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a subset of the training dataset (with only 20 predictors)\n",
    "variables_to_keep = [\"MATH_Behind\"] + top_20_features\n",
    "train_data_small = train_data[variables_to_keep]\n",
    "print(train_data_small.shape)\n",
    "train_data_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train dataset \n",
    "train_data_small.to_csv('train_small.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train_small/train_small.csv')).upload_file('train_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a subset of the validation dataset (with only 20 predictors)\n",
    "validation_data_small = validation_data[variables_to_keep]\n",
    "print(validation_data_small.shape)\n",
    "validation_data_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation dataset \n",
    "validation_data_small.to_csv('validation_small.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation_small/validation_small.csv')).upload_file('validation_small.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model using the hyperparameters from the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 15\n",
    "container = sagemaker.image_uris.retrieve(region=boto3.Session().region_name, framework='xgboost', version='latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 16\n",
    "s3_input_train_small = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/train_small'.format(bucket, prefix), content_type='csv')\n",
    "s3_input_validation_small = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/validation_small/'.format(bucket, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cell 17\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "xgb_small = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    instance_count=1, \n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess)\n",
    "\n",
    "xgb_small.set_hyperparameters(# seed=42,       # Random seed (turned off because we are using a different seed per iteration)  \n",
    "                        seed_per_iteration=True,   # Different seed for each boosting iteration, can prevent overfitting\n",
    "                        early_stopping_rounds=10,   # Stop if AUC doesn‚Äôt improve for 10 rounds\n",
    "                        objective='binary:logistic',\n",
    "                        eval_metric='aucpr',\n",
    "                        num_round=best_num_round,   # Number of boosting rounds for training                    \n",
    "                        eta=best_eta,   # Learning rate, lower value is more robust to overfitting but requires more boosting rounds\n",
    "                        max_depth=best_max_depth,   # Deeper trees can model more complex patterns but may overfit\n",
    "                        min_child_weight=best_min_child_weight,   # Higher value ensures leaf nodes have sufficient samples, preventing overfitting\n",
    "                        gamma=best_gamma,    # Higher values make it harder to partition a leaf node, making the algorithm more conservative\n",
    "                        subsample=best_subsample,   # Fraction of training instances to use for each boosting round, < 1 can prevent overfitting\n",
    "                        alpha=best_alpha   # L1 regularization term on weights, higher value leads to more regularization                       \n",
    "                        )\n",
    "\n",
    "xgb_small.fit({'train': s3_input_train_small, 'validation': s3_input_validation_small}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model\n",
    "Now that we've trained the `xgboost` algorithm on our data, let's deploy a model that's hosted behind a real-time endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 18\n",
    "xgb_small_predictor = xgb_small.deploy(initial_instance_count=1,\n",
    "                           instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance (This model has only the top 20 predictors)\n",
    "First we'll need to determine how we pass data into and receive data from our endpoint.  Our data is currently stored as NumPy arrays in memory of our notebook instance.  To send it in an HTTP POST request, we'll serialize it as a CSV string and then decode the resulting CSV.\n",
    "\n",
    "*Note: For inference with CSV format, SageMaker XGBoost requires that the data does NOT include the target variable.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 19\n",
    "xgb_small_predictor.serializer = sagemaker.serializers.CSVSerializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use a simple function to:\n",
    "1. Loop over our test dataset\n",
    "1. Split it into mini-batches of rows \n",
    "1. Convert those mini-batches to CSV string payloads (notice, we drop the target variable from our dataset first)\n",
    "1. Retrieve mini-batch predictions by invoking the XGBoost endpoint\n",
    "1. Collect predictions and convert from the CSV output our model provides into a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_small = test_data[variables_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 20\n",
    "\n",
    "# Use the updated target variable and drop it from test data\n",
    "predictions_small = predict(test_data_small.drop(['MATH_Behind'], axis=1).to_numpy(), xgb_small_predictor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll check our confusion matrix to see how well we predicted versus actuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 21\n",
    "\n",
    "# Generate the confusion matrix (ensure predictions are rounded appropriately)\n",
    "cm = pd.crosstab(index=test_data_small['MATH_Behind'], \n",
    "                 columns=np.round(predictions_small), \n",
    "                 rownames=['actuals'], \n",
    "                 colnames=['predictions'])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Extract values from the confusion matrix\n",
    "# Assuming that:\n",
    "# - actual class 0 is negative\n",
    "# - actual class 1 is positive\n",
    "TN = cm.loc[0.0, 0.0]\n",
    "FP = cm.loc[0.0, 1.0]\n",
    "FN = cm.loc[1.0, 0.0]\n",
    "TP = cm.loc[1.0, 1.0]\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN) * 100\n",
    "\n",
    "# Calculate Precision (for the positive class)\n",
    "precision = TP / (TP + FP) * 100 if (TP + FP) > 0 else 0\n",
    "\n",
    "# Calculate Recall (for the positive class)\n",
    "recall = TP / (TP + FN) * 100 if (TP + FN) > 0 else 0\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# Calculate Specificity (True Negative Rate)\n",
    "specificity = TN / (TN + FP) * 100 if (TN + FP) > 0 else 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note that because there is some element of randomness in the algorithm's subsample, your results may differ slightly from the text written above._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 22\n",
    "# Clean up\n",
    "xgb_small_predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of students not proficient in Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proficient_n = (model_data['MATH_Behind'] == 0).sum()\n",
    "not_proficient_n = (model_data['MATH_Behind'] == 1).sum()\n",
    "not_proficient_p = round( not_proficient_n / (not_proficient_n + proficient_n) * 100, 1)\n",
    "\n",
    "#print(\"Students who are proficient: \", proficient_n)\n",
    "print(\"Students who are NOT proficient: \", not_proficient_n, \"(\", not_proficient_p, \"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n Accuracy: {:.2f}\".format(accuracy))\n",
    "print(\"\\n Precision: {:.2f}\".format(precision))\n",
    "print(\"\\n Recall: {:.2f}\".format(recall))\n",
    "print(\"\\n F1 Score: {:.2f}\".format(f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 20 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Filter the DataFrame to only include rows where Variable_name is in top_20_features\n",
    "top_20_dictionary = dictionary[dictionary[\"Variable_name\"].isin(top_20_features)]\n",
    "top_20_table = top_20_dictionary.set_index(\"Variable_name\").loc[top_20_features].reset_index()\n",
    "display(Markdown(top_20_table.to_markdown()))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
