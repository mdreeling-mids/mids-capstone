{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RkCcUTUBabv1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPSS Loader and Editor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepares our SPSS file using these standards (https://docs.google.com/document/d/1LZ_i9fHxzdG6w6_Ie7i7wYuiAET9Ubc-SEA3mEiOSDs/edit?tab=t.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook loads an SPSS file and then allows the user to change it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyreadstat\n",
      "  Using cached pyreadstat-1.2.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from pyreadstat) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2.0->pyreadstat) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2.0->pyreadstat) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2.0->pyreadstat) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2.0->pyreadstat) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadstat) (1.17.0)\n",
      "Using cached pyreadstat-1.2.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "Installing collected packages: pyreadstat\n",
      "Successfully installed pyreadstat-1.2.8\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# Mount Google Drive\n",
    "# drive.mount('/content/drive')\n",
    "!pip install pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Edit STUDENT IBM SPSS File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading data from local file... PISA_2022_Background_questionnaire_edited.SAV\n",
      "Load completed\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "import pyreadstat\n",
    "\n",
    "# Define local file path\n",
    "#local_file_path_student_miss = \"/content/drive/My Drive/PISA_2022_Background_questionnaire_STUDENT_filtered_recode_miss.csv\"\n",
    "local_file_path_student_miss = \"PISA_2022_Background_questionnaire_edited.SAV\"  # Change as needed\n",
    "\n",
    "# Define S3 details\n",
    "bucket_name = \"sagemaker-us-west-2-986030204467\"\n",
    "file_key = \"capstone/testfiles/PISA_2022_Background_questionnaire_edited.SAV\"\n",
    "\n",
    "# AWS credentials are usually stored in ~/.aws/credentials or IAM roles (if running on AWS services)\n",
    "s3_client = boto3.client(\"s3\")\n",
    "\n",
    "# Check if the file exists locally\n",
    "if os.path.exists(local_file_path_student_miss):\n",
    "    print(f\"üìÇ Loading data from local file... {local_file_path_student_miss}\")\n",
    "    student_dataset, student_meta = pyreadstat.read_sav(local_file_path_student_miss)\n",
    "    print(\"Load completed\")\n",
    "else:\n",
    "    print(\"‚òÅÔ∏è Downloading data from S3...\")\n",
    "    \n",
    "    # Create S3 client\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "\n",
    "    # Download the file from S3\n",
    "    response = s3_client.get_object(Bucket=bucket_name, Key=file_key)\n",
    "\n",
    "    # Read the file into pandas DataFrame\n",
    "    student_dataset, student_meta = pyreadstat.read_sav(response[\"Body\"])\n",
    "\n",
    "    # Save a local copy for future use\n",
    "    student_dataset.to_sav(local_file_path_student_miss, index=False)\n",
    "    print(f\"‚úÖ File saved locally as {local_file_path_student_miss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add -999 as a Categorical Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a categorical column is 'missing' in SPSS, we need to make is something that is NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = student_dataset.select_dtypes(include=['category']).columns\n",
    "\n",
    "# Add -999 as a new category\n",
    "for col in categorical_cols:\n",
    "    student_dataset[col] = student_dataset[col].cat.add_categories([-999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace all NaN's with -999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV's need the 'missing values' from SAV to be 'something', we will use -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now replace NaN with -999\n",
    "student_dataset.fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check a few variables to see if they now have -999's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -999.0\n",
       "1   -999.0\n",
       "2      6.0\n",
       "3   -999.0\n",
       "4   -999.0\n",
       "5   -999.0\n",
       "6   -999.0\n",
       "7   -999.0\n",
       "8   -999.0\n",
       "9   -999.0\n",
       "Name: ST021Q01TA, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_dataset['ST021Q01TA'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LANGTEST_PAQ has a lot of 'System Missing' variables which are .'s (dots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -999.0\n",
       "1   -999.0\n",
       "2   -999.0\n",
       "3   -999.0\n",
       "4   -999.0\n",
       "5   -999.0\n",
       "6   -999.0\n",
       "7   -999.0\n",
       "8   -999.0\n",
       "9   -999.0\n",
       "Name: LANGTEST_PAQ, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_dataset['LANGTEST_PAQ'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      5.0\n",
       "1   -999.0\n",
       "2   -999.0\n",
       "3      3.0\n",
       "4      3.0\n",
       "5      3.0\n",
       "6      5.0\n",
       "7      1.0\n",
       "8   -999.0\n",
       "9   -999.0\n",
       "Name: ST322Q01JA, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_dataset['ST322Q01JA'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ST322Q01JA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613718</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613719</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613731</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613739</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613743</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39491 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ST322Q01JA\n",
       "19             6.0\n",
       "21             6.0\n",
       "36             6.0\n",
       "53             6.0\n",
       "72             6.0\n",
       "...            ...\n",
       "613718         6.0\n",
       "613719         6.0\n",
       "613731         6.0\n",
       "613739         6.0\n",
       "613743         6.0\n",
       "\n",
       "[39491 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_dataset.loc[student_dataset['ST322Q01JA'].isin([6, 6.0]), ['ST322Q01JA']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edit the file and remove unneeded columns per Selenes XLSX sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we use "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Download Student Variables Inclusion/Exclusion Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Google Sheets export URL\n",
    "# Variables to include - Students.xlsx\n",
    "sheet_url = \"https://docs.google.com/spreadsheets/d/1rb0AVCWQAEQ-c5vYfKn1aHtmK9bjvq3u/export?format=xlsx\"\n",
    "\n",
    "# Read the Excel file directly from the URL\n",
    "xls = pd.ExcelFile(sheet_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Check Dataframe Shape before editing (should have 1280 columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(613744, 1280)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use XLS Sheet to Include/Exclude Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Exclude sheet\n",
    "exclude_df = pd.read_excel(xls, sheet_name=\"Exclude\")\n",
    "\n",
    "# Read the main data sheet (assuming it's the first sheet)\n",
    "include_df = pd.read_excel(xls, sheet_name=xls.sheet_names[0])\n",
    "\n",
    "# Filter columns to keep based on the Exclude sheet conditions\n",
    "columns_to_keep = exclude_df[\n",
    "    (exclude_df[\"Include\"] == \"x\") & (exclude_df[\"Reason for exclusion\"] == \"Can use WLE\")\n",
    "][\"NAME\"].tolist()\n",
    "\n",
    "# Identify columns where \"Include\" = 'O' and add them to columns_to_keep\n",
    "columns_to_keep += include_df[\n",
    "    (include_df[\"Include\"] == \"o\") & (include_df[\"Reasons for inclusion\"] != \"WLE\")\n",
    "][\"NAME\"].tolist()\n",
    "\n",
    "# Filter dataframe columns\n",
    "df_filtered = student_dataset[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ST322Q01JA': 39491,\n",
       " 'ST322Q02JA': 25559,\n",
       " 'ST322Q03JA': 17624,\n",
       " 'ST322Q04JA': 41568,\n",
       " 'ST322Q06JA': 51716,\n",
       " 'ST322Q07JA': 37880,\n",
       " 'LANGN': 0,\n",
       " 'IC184Q01JA': 13423,\n",
       " 'IC184Q02JA': 12960,\n",
       " 'IC184Q03JA': 23619,\n",
       " 'IC184Q04JA': 30010,\n",
       " 'WB161Q01HA': 12339}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_nullables_before(df, include_df):\n",
    "    \"\"\"\n",
    "    Count occurrences of nullable values before replacement.\n",
    "\n",
    "    :param df: Pandas DataFrame (student dataset)\n",
    "    :param include_df: DataFrame containing the 'Include' sheet\n",
    "    :return: Dictionary with counts of nullable values per column\n",
    "    \"\"\"\n",
    "    count_dict = {}\n",
    "\n",
    "    for _, row in include_df.iterrows():\n",
    "        col = row['NAME']\n",
    "        nullables = parse_nullable_values(row['nullables'])\n",
    "\n",
    "        if pd.notna(col) and pd.notna(row['nullables']) and col in df.columns:\n",
    "            count_dict[col] = df[col].isin(nullables).sum()\n",
    "\n",
    "    return count_dict\n",
    "\n",
    "# Count nullables before replacement\n",
    "nullables_before = count_nullables_before(student_dataset, include_df)\n",
    "nullables_before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Replace all 'other nullables' with -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_nullable_values(value):\n",
    "    \"\"\"Convert nullable column values into lists.\"\"\"\n",
    "    if pd.isna(value):  # If NaN, return empty list\n",
    "        return []\n",
    "    if isinstance(value, str):  # Check if the value is a string (like '998,999')\n",
    "        return [int(v.strip()) for v in value.split(\",\")]  # Convert CSV string to list of ints\n",
    "    return [value]  # If it's a single number, wrap it in a list\n",
    "\n",
    "def replace_values_with_neg999(df, include_df):\n",
    "    \"\"\"\n",
    "    Replace specified nullable values in columns based on 'Include' sheet.\n",
    "\n",
    "    :param df: Pandas DataFrame (student dataset)\n",
    "    :param include_df: DataFrame containing the 'Include' sheet\n",
    "    :return: Modified DataFrame\n",
    "    \"\"\"\n",
    "    # Build dictionary of columns and their nullable values\n",
    "    replace_dict = {\n",
    "        row['NAME']: parse_nullable_values(row['nullables'])\n",
    "        for _, row in include_df.iterrows()\n",
    "        if pd.notna(row['NAME']) and pd.notna(row['nullables'])  # Ensure columns and nullables are valid\n",
    "    }\n",
    "\n",
    "    # Apply replacements using .loc to avoid SettingWithCopyWarning\n",
    "    for col, values in replace_dict.items():\n",
    "        if col in df.columns:\n",
    "            df.loc[:, col] = df[col].replace(values, -999)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply replacements based on 'Include' sheet\n",
    "df_filtered = replace_values_with_neg999(df_filtered, include_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ST322Q01JA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613730</th>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613735</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613737</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613739</th>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613743</th>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51716 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ST322Q01JA\n",
       "19          -999.0\n",
       "21          -999.0\n",
       "36          -999.0\n",
       "37          -999.0\n",
       "52             5.0\n",
       "...            ...\n",
       "613730      -999.0\n",
       "613735         1.0\n",
       "613737         5.0\n",
       "613739      -999.0\n",
       "613743      -999.0\n",
       "\n",
       "[51716 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.loc[student_dataset['ST322Q06JA'].isin([6, 6.0]), ['ST322Q01JA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ST322Q01JA': 166041,\n",
       " 'ST322Q02JA': 167654,\n",
       " 'ST322Q03JA': 168714,\n",
       " 'ST322Q04JA': 168657,\n",
       " 'ST322Q06JA': 168887,\n",
       " 'ST322Q07JA': 168107,\n",
       " 'LANGN': 0,\n",
       " 'IC184Q01JA': 284814,\n",
       " 'IC184Q02JA': 286654,\n",
       " 'IC184Q03JA': 285610,\n",
       " 'IC184Q04JA': 286157,\n",
       " 'WB161Q01HA': 495107}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_neg999_after(df, include_df, nullables_before):\n",
    "    \"\"\"\n",
    "    Count occurrences of -999 after replacement, but only for columns that had nullables before.\n",
    "\n",
    "    :param df: Pandas DataFrame (student dataset)\n",
    "    :param include_df: DataFrame containing the 'Include' sheet\n",
    "    :param nullables_before: Dictionary of nullable counts before replacement\n",
    "    :return: Dictionary with counts of -999 per column (only for nullables)\n",
    "    \"\"\"\n",
    "    count_dict = {}\n",
    "\n",
    "    for col in nullables_before.keys():  # Only check columns that had nullables before\n",
    "        if col in df.columns:\n",
    "            count_dict[col] = (df[col] == -999).sum()\n",
    "\n",
    "    return count_dict\n",
    "\n",
    "# Count -999 occurrences after replacement (only for columns that had nullables before)\n",
    "neg999_after = count_neg999_after(student_dataset, include_df, nullables_before)\n",
    "neg999_after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Check Dataframe Shape AFTER editing (should have 735 columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(613744, 735)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remap Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the country code to name mapping\n",
    "country_mapping = {\n",
    "    \"ALB\": \"Albania\", \"ARE\": \"United_Arab_Emirates\", \"ARG\": \"Argentina\", \"AUS\": \"Australia\",\n",
    "    \"AUT\": \"Austria\", \"BEL\": \"Belgium\", \"BGR\": \"Bulgaria\", \"BRA\": \"Brazil\", \"BRN\": \"Brunei_Darussalam\",\n",
    "    \"CAN\": \"Canada\", \"CHE\": \"Switzerland\", \"CHL\": \"Chile\", \"COL\": \"Colombia\", \"CRI\": \"Costa_Rica\",\n",
    "    \"CZE\": \"Czech_Republic\", \"DEU\": \"Germany\", \"DNK\": \"Denmark\", \"DOM\": \"Dominican_Republic\",\n",
    "    \"ESP\": \"Spain\", \"EST\": \"Estonia\", \"FIN\": \"Finland\", \"FRA\": \"France\", \"GBR\": \"United_Kingdom\",\n",
    "    \"GEO\": \"Georgia\", \"GRC\": \"Greece\", \"GTM\": \"Guatemala\", \"HRV\": \"Croatia\", \"HUN\": \"Hungary\",\n",
    "    \"IDN\": \"Indonesia\", \"IRL\": \"Ireland\", \"ISL\": \"Iceland\", \"ISR\": \"Israel\", \"ITA\": \"Italy\",\n",
    "    \"JAM\": \"Jamaica\", \"JOR\": \"Jordan\", \"JPN\": \"Japan\", \"KAZ\": \"Kazakhstan\", \"KHM\": \"Cambodia\",\n",
    "    \"KOR\": \"Korea\", \"KSV\": \"Kosovo\", \"LTU\": \"Lithuania\", \"LVA\": \"Latvia\", \"MAR\": \"Morocco\",\n",
    "    \"MDA\": \"Republic_of_Moldova\", \"MEX\": \"Mexico\", \"MKD\": \"North_Macedonia\", \"MLT\": \"Malta\",\n",
    "    \"MNE\": \"Montenegro\", \"MNG\": \"Mongolia\", \"MYS\": \"Malaysia\", \"NLD\": \"Netherlands\", \"NOR\": \"Norway\",\n",
    "    \"NZL\": \"New_Zealand\", \"PAN\": \"Panama\", \"PER\": \"Peru\", \"PHL\": \"Philippines\", \"POL\": \"Poland\",\n",
    "    \"PRT\": \"Portugal\", \"PRY\": \"Paraguay\", \"PSE\": \"Palestinian_Authority\", \"QAT\": \"Qatar\",\n",
    "    \"QCY\": \"Cyprus\", \"ROU\": \"Romania\", \"SAU\": \"Saudi_Arabia\", \"SGP\": \"Singapore\", \"SLV\": \"El_Salvador\",\n",
    "    \"SRB\": \"Serbia\", \"SVK\": \"Slovak_Republic\", \"SVN\": \"Slovenia\", \"SWE\": \"Sweden\", \"TAP\": \"Taiwan\",\n",
    "    \"THA\": \"Thailand\", \"TUR\": \"T√ºrkiye\", \"URY\": \"Uruguay\", \"USA\": \"United_States\", \"UZB\": \"Uzbekistan\",\n",
    "    \"VNM\": \"Vietnam\"\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'CNT' column\n",
    "student_dataset.loc[:, \"CNT\"] = student_dataset[\"CNT\"].replace(country_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Albania', 'QAZ', 'Argentina', 'Australia', 'Austria', 'Belgium',\n",
       "       'Brazil', 'Brunei_Darussalam', 'Bulgaria', 'Cambodia', 'Canada',\n",
       "       'Chile', 'Taiwan', 'Colombia', 'Costa_Rica', 'Croatia',\n",
       "       'Czech_Republic', 'Denmark', 'Dominican_Republic', 'El_Salvador',\n",
       "       'Estonia', 'Finland', 'France', 'Georgia', 'Palestinian_Authority',\n",
       "       'Germany', 'Greece', 'Guatemala', 'HKG', 'Hungary', 'Iceland',\n",
       "       'Indonesia', 'Ireland', 'Israel', 'Italy', 'Kosovo', 'Jamaica',\n",
       "       'Japan', 'Kazakhstan', 'Jordan', 'Korea', 'Latvia', 'Lithuania',\n",
       "       'MAC', 'Malaysia', 'Malta', 'Mexico', 'Mongolia',\n",
       "       'Republic_of_Moldova', 'Montenegro', 'Morocco', 'Netherlands',\n",
       "       'New_Zealand', 'Norway', 'Panama', 'Paraguay', 'Peru',\n",
       "       'Philippines', 'Poland', 'Portugal', 'Qatar', 'Romania',\n",
       "       'Saudi_Arabia', 'Serbia', 'Singapore', 'Slovak_Republic',\n",
       "       'Vietnam', 'Slovenia', 'Spain', 'Sweden', 'Switzerland',\n",
       "       'Thailand', 'United_Arab_Emirates', 'T√ºrkiye', 'QUR',\n",
       "       'North_Macedonia', 'United_Kingdom', 'United_States', 'Uruguay',\n",
       "       'Uzbekistan'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_dataset[\"CNT\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ST250Q01JA</th>\n",
       "      <th>ST250Q02JA</th>\n",
       "      <th>ST250Q03JA</th>\n",
       "      <th>ST250Q04JA</th>\n",
       "      <th>ST250Q05JA</th>\n",
       "      <th>ST250D06JA</th>\n",
       "      <th>ST250D07JA</th>\n",
       "      <th>ST251Q01JA</th>\n",
       "      <th>ST251Q02JA</th>\n",
       "      <th>ST251Q03JA</th>\n",
       "      <th>...</th>\n",
       "      <th>WB177Q02HA</th>\n",
       "      <th>WB177Q03HA</th>\n",
       "      <th>WB177Q04HA</th>\n",
       "      <th>WB032Q01NA</th>\n",
       "      <th>WB032Q02NA</th>\n",
       "      <th>WB031Q01NA</th>\n",
       "      <th>EXERPRAC</th>\n",
       "      <th>STUBMI</th>\n",
       "      <th>WORKPAY</th>\n",
       "      <th>WORKHOME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>9999997</td>\n",
       "      <td>9999997</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9999997</td>\n",
       "      <td>9999997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9999997</td>\n",
       "      <td>9999997</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9999997</td>\n",
       "      <td>9999997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9999997</td>\n",
       "      <td>9999997</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 735 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ST250Q01JA  ST250Q02JA  ST250Q03JA  ST250Q04JA  ST250Q05JA ST250D06JA  \\\n",
       "0      -999.0         1.0      -999.0      -999.0      -999.0    9999997   \n",
       "1         2.0         2.0         2.0         1.0         2.0    9999997   \n",
       "2         1.0         1.0         1.0         1.0         1.0    9999997   \n",
       "3         1.0         1.0         2.0         1.0         1.0    9999997   \n",
       "4         1.0         1.0         1.0         1.0         1.0    9999997   \n",
       "\n",
       "  ST250D07JA  ST251Q01JA  ST251Q02JA  ST251Q03JA  ...  WB177Q02HA  WB177Q03HA  \\\n",
       "0    9999997      -999.0      -999.0      -999.0  ...      -999.0      -999.0   \n",
       "1    9999997         1.0         2.0         1.0  ...      -999.0      -999.0   \n",
       "2    9999997         2.0         3.0         3.0  ...      -999.0      -999.0   \n",
       "3    9999997         1.0         1.0         1.0  ...      -999.0      -999.0   \n",
       "4    9999997         3.0         1.0         2.0  ...      -999.0      -999.0   \n",
       "\n",
       "   WB177Q04HA WB032Q01NA WB032Q02NA  WB031Q01NA  EXERPRAC  STUBMI  WORKPAY  \\\n",
       "0      -999.0     -999.0     -999.0      -999.0       0.0  -999.0      0.0   \n",
       "1      -999.0     -999.0     -999.0      -999.0    -999.0  -999.0   -999.0   \n",
       "2      -999.0     -999.0     -999.0      -999.0    -999.0  -999.0      0.0   \n",
       "3      -999.0     -999.0     -999.0      -999.0      10.0  -999.0      0.0   \n",
       "4      -999.0     -999.0     -999.0      -999.0       2.0  -999.0      0.0   \n",
       "\n",
       "   WORKHOME  \n",
       "0      10.0  \n",
       "1    -999.0  \n",
       "2       0.0  \n",
       "3      10.0  \n",
       "4       4.0  \n",
       "\n",
       "[5 rows x 735 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove non-nationally representative countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the values to remove\n",
    "remove_countries = [\"QUR\", \"HKG\", \"MAC\", \"QAZ\"]\n",
    "\n",
    "# Filter out the unwanted rows\n",
    "df_filtered = df_filtered[~df_filtered[\"CNT\"].isin(remove_countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(591857, 735)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out our new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv('student_filtered_and_edited.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
