{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PISA 2022 Amazon SageMaker Linear Learner\n",
    "\n",
    "More info on SageMaker Immersion Day: [Workshop Link](https://catalog.us-east-1.prod.workshops.aws/workshops/63069e26-921c-4ce1-9cc7-dd882ff62575/en-US/lab2-model-training/pro-code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Change country name below!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_name = 'United_States'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_name_edited = country_name.replace(\"_\", \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "isConfigCell": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# cell 02\n",
    "import sagemaker\n",
    "bucket=sagemaker.Session().default_bucket()\n",
    "prefix = 'sagemaker/linear_learner-'+country_name_edited\n",
    " \n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's bring in the Python libraries that we'll use throughout the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cell 03\n",
    "import numpy as np                                # For matrix operations and numerical processing\n",
    "import pandas as pd                               # For munging tabular data\n",
    "import matplotlib.pyplot as plt                   # For charts and visualizations\n",
    "from IPython.display import Image                 # For displaying images in the notebook\n",
    "from IPython.display import display               # For displaying outputs in the notebook\n",
    "from time import gmtime, strftime                 # For labeling SageMaker models, endpoints, etc.\n",
    "import sys                                        # For writing outputs to notebook\n",
    "import math                                       # For ceiling function\n",
    "import json                                       # For parsing hosting outputs\n",
    "import os                                         # For manipulating filepath names\n",
    "import sagemaker \n",
    "import zipfile     # Amazon SageMaker's Python SDK provides many helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download PISA 2022 Prepared Dataset\n",
    "\n",
    "This is our dataset output from our cleaned notebook [here](https://7z4vtvpqcoxouiu.studio.us-west-2.sagemaker.aws/jupyterlab/default/lab/tree/RTC%3Amids-capstone/notebooks/eda/Data_merging.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Loading data from local file...\n",
      "CPU times: user 55.9 s, sys: 5.62 s, total: 1min 1s\n",
      "Wall time: 1min 5s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNT</th>\n",
       "      <th>CNTSCHID</th>\n",
       "      <th>CNTSTUID</th>\n",
       "      <th>MATH_Proficient</th>\n",
       "      <th>SISCO</th>\n",
       "      <th>ST250Q01JA</th>\n",
       "      <th>ST250Q02JA</th>\n",
       "      <th>ST250Q03JA</th>\n",
       "      <th>ST250Q04JA</th>\n",
       "      <th>ST250Q05JA</th>\n",
       "      <th>ST251Q01JA</th>\n",
       "      <th>ST251Q02JA</th>\n",
       "      <th>ST251Q03JA</th>\n",
       "      <th>ST251Q04JA</th>\n",
       "      <th>ST251Q06JA</th>\n",
       "      <th>ST251Q07JA</th>\n",
       "      <th>ST253Q01JA</th>\n",
       "      <th>ST254Q01JA</th>\n",
       "      <th>ST254Q02JA</th>\n",
       "      <th>ST254Q03JA</th>\n",
       "      <th>ST254Q04JA</th>\n",
       "      <th>ST254Q05JA</th>\n",
       "      <th>ST254Q06JA</th>\n",
       "      <th>ST255Q01JA</th>\n",
       "      <th>ST256Q01JA</th>\n",
       "      <th>ST256Q02JA</th>\n",
       "      <th>ST256Q03JA</th>\n",
       "      <th>ST256Q06JA</th>\n",
       "      <th>ST256Q07JA</th>\n",
       "      <th>ST256Q08JA</th>\n",
       "      <th>ST256Q09JA</th>\n",
       "      <th>ST256Q10JA</th>\n",
       "      <th>ST267Q01JA</th>\n",
       "      <th>ST267Q02JA</th>\n",
       "      <th>ST267Q03JA</th>\n",
       "      <th>ST267Q04JA</th>\n",
       "      <th>ST267Q05JA</th>\n",
       "      <th>ST267Q06JA</th>\n",
       "      <th>ST267Q07JA</th>\n",
       "      <th>ST267Q08JA</th>\n",
       "      <th>ST034Q01TA</th>\n",
       "      <th>ST034Q02TA</th>\n",
       "      <th>ST034Q03TA</th>\n",
       "      <th>ST034Q04TA</th>\n",
       "      <th>ST034Q05TA</th>\n",
       "      <th>ST034Q06TA</th>\n",
       "      <th>ST038Q03NA</th>\n",
       "      <th>ST038Q04NA</th>\n",
       "      <th>ST038Q05NA</th>\n",
       "      <th>ST038Q06NA</th>\n",
       "      <th>ST038Q07NA</th>\n",
       "      <th>ST038Q08NA</th>\n",
       "      <th>ST038Q09JA</th>\n",
       "      <th>ST038Q10JA</th>\n",
       "      <th>ST038Q11JA</th>\n",
       "      <th>ST265Q01JA</th>\n",
       "      <th>ST265Q02JA</th>\n",
       "      <th>ST265Q03JA</th>\n",
       "      <th>ST265Q04JA</th>\n",
       "      <th>ST266Q01JA</th>\n",
       "      <th>ST266Q02JA</th>\n",
       "      <th>ST266Q03JA</th>\n",
       "      <th>ST266Q04JA</th>\n",
       "      <th>ST266Q05JA</th>\n",
       "      <th>ST307Q01JA</th>\n",
       "      <th>ST307Q02JA</th>\n",
       "      <th>ST307Q03JA</th>\n",
       "      <th>ST307Q04JA</th>\n",
       "      <th>ST307Q05JA</th>\n",
       "      <th>ST307Q06JA</th>\n",
       "      <th>ST307Q07JA</th>\n",
       "      <th>ST307Q08JA</th>\n",
       "      <th>ST307Q09JA</th>\n",
       "      <th>ST307Q10JA</th>\n",
       "      <th>ST301Q01JA</th>\n",
       "      <th>ST301Q02JA</th>\n",
       "      <th>ST301Q03JA</th>\n",
       "      <th>ST301Q04JA</th>\n",
       "      <th>ST301Q05JA</th>\n",
       "      <th>ST301Q06JA</th>\n",
       "      <th>ST301Q07JA</th>\n",
       "      <th>ST301Q08JA</th>\n",
       "      <th>ST301Q09JA</th>\n",
       "      <th>ST301Q10JA</th>\n",
       "      <th>ST343Q01JA</th>\n",
       "      <th>ST343Q02JA</th>\n",
       "      <th>ST343Q03JA</th>\n",
       "      <th>ST343Q04JA</th>\n",
       "      <th>ST343Q05JA</th>\n",
       "      <th>ST343Q06JA</th>\n",
       "      <th>ST343Q07JA</th>\n",
       "      <th>ST343Q08JA</th>\n",
       "      <th>ST343Q09JA</th>\n",
       "      <th>ST343Q10JA</th>\n",
       "      <th>ST311Q01JA</th>\n",
       "      <th>ST311Q02JA</th>\n",
       "      <th>ST311Q03JA</th>\n",
       "      <th>ST311Q04JA</th>\n",
       "      <th>ST311Q05JA</th>\n",
       "      <th>ST311Q06JA</th>\n",
       "      <th>ST311Q07JA</th>\n",
       "      <th>ST311Q08JA</th>\n",
       "      <th>ST311Q09JA</th>\n",
       "      <th>ST311Q10JA</th>\n",
       "      <th>ST305Q01JA</th>\n",
       "      <th>ST305Q02JA</th>\n",
       "      <th>ST305Q03JA</th>\n",
       "      <th>ST305Q04JA</th>\n",
       "      <th>ST305Q05JA</th>\n",
       "      <th>ST305Q06JA</th>\n",
       "      <th>ST305Q07JA</th>\n",
       "      <th>ST305Q08JA</th>\n",
       "      <th>ST305Q09JA</th>\n",
       "      <th>ST305Q10JA</th>\n",
       "      <th>ST345Q01JA</th>\n",
       "      <th>ST345Q02JA</th>\n",
       "      <th>ST345Q03JA</th>\n",
       "      <th>ST345Q04JA</th>\n",
       "      <th>ST345Q05JA</th>\n",
       "      <th>ST345Q06JA</th>\n",
       "      <th>ST345Q07JA</th>\n",
       "      <th>ST345Q08JA</th>\n",
       "      <th>ST345Q09JA</th>\n",
       "      <th>ST345Q10JA</th>\n",
       "      <th>ST313Q01JA</th>\n",
       "      <th>ST313Q02JA</th>\n",
       "      <th>ST313Q03JA</th>\n",
       "      <th>ST313Q04JA</th>\n",
       "      <th>ST313Q05JA</th>\n",
       "      <th>ST313Q06JA</th>\n",
       "      <th>ST313Q07JA</th>\n",
       "      <th>ST313Q08JA</th>\n",
       "      <th>ST313Q09JA</th>\n",
       "      <th>ST313Q10JA</th>\n",
       "      <th>ST263Q02JA</th>\n",
       "      <th>ST263Q04JA</th>\n",
       "      <th>ST263Q06JA</th>\n",
       "      <th>ST263Q08JA</th>\n",
       "      <th>ST273Q01JA</th>\n",
       "      <th>ST273Q02JA</th>\n",
       "      <th>ST273Q03JA</th>\n",
       "      <th>ST273Q04JA</th>\n",
       "      <th>ST273Q05JA</th>\n",
       "      <th>ST273Q06JA</th>\n",
       "      <th>ST273Q07JA</th>\n",
       "      <th>ST270Q01JA</th>\n",
       "      <th>ST270Q02JA</th>\n",
       "      <th>ST270Q03JA</th>\n",
       "      <th>ST270Q04JA</th>\n",
       "      <th>ST285Q01JA</th>\n",
       "      <th>ST285Q02JA</th>\n",
       "      <th>ST285Q03JA</th>\n",
       "      <th>ST285Q04JA</th>\n",
       "      <th>ST285Q05JA</th>\n",
       "      <th>ST285Q06JA</th>\n",
       "      <th>ST285Q07JA</th>\n",
       "      <th>ST285Q08JA</th>\n",
       "      <th>ST285Q09JA</th>\n",
       "      <th>ST283Q01JA</th>\n",
       "      <th>ST283Q02JA</th>\n",
       "      <th>ST283Q03JA</th>\n",
       "      <th>ST283Q04JA</th>\n",
       "      <th>ST283Q05JA</th>\n",
       "      <th>ST283Q06JA</th>\n",
       "      <th>ST283Q07JA</th>\n",
       "      <th>ST283Q08JA</th>\n",
       "      <th>ST283Q09JA</th>\n",
       "      <th>ST275Q01WA</th>\n",
       "      <th>ST275Q02WA</th>\n",
       "      <th>ST275Q03WA</th>\n",
       "      <th>ST275Q04WA</th>\n",
       "      <th>ST275Q05WA</th>\n",
       "      <th>ST275Q06WA</th>\n",
       "      <th>ST275Q07WA</th>\n",
       "      <th>ST275Q08WA</th>\n",
       "      <th>ST275Q09WA</th>\n",
       "      <th>ST276Q01JA</th>\n",
       "      <th>ST276Q02JA</th>\n",
       "      <th>ST276Q03JA</th>\n",
       "      <th>ST276Q04JA</th>\n",
       "      <th>ST276Q05JA</th>\n",
       "      <th>ST276Q06JA</th>\n",
       "      <th>ST276Q07JA</th>\n",
       "      <th>ST276Q08JA</th>\n",
       "      <th>ST276Q09JA</th>\n",
       "      <th>ST276Q10JA</th>\n",
       "      <th>ST290Q01WA</th>\n",
       "      <th>ST290Q02WA</th>\n",
       "      <th>ST290Q03WA</th>\n",
       "      <th>ST290Q04WA</th>\n",
       "      <th>ST290Q05WA</th>\n",
       "      <th>ST290Q06WA</th>\n",
       "      <th>ST290Q07WA</th>\n",
       "      <th>ST290Q08WA</th>\n",
       "      <th>ST290Q09WA</th>\n",
       "      <th>ST291Q01JA</th>\n",
       "      <th>ST291Q02JA</th>\n",
       "      <th>ST291Q03JA</th>\n",
       "      <th>ST291Q04JA</th>\n",
       "      <th>ST291Q05JA</th>\n",
       "      <th>ST291Q06JA</th>\n",
       "      <th>ST291Q07JA</th>\n",
       "      <th>ST291Q08JA</th>\n",
       "      <th>ST291Q09JA</th>\n",
       "      <th>ST291Q10JA</th>\n",
       "      <th>ST289Q01WA</th>\n",
       "      <th>ST289Q02JA</th>\n",
       "      <th>ST289Q04JA</th>\n",
       "      <th>ST289Q05WA</th>\n",
       "      <th>ST289Q06JA</th>\n",
       "      <th>ST289Q07JA</th>\n",
       "      <th>ST289Q08WA</th>\n",
       "      <th>ST289Q09WA</th>\n",
       "      <th>ST289Q10WA</th>\n",
       "      <th>ST289Q14JA</th>\n",
       "      <th>ST293Q01JA</th>\n",
       "      <th>ST293Q02JA</th>\n",
       "      <th>ST293Q03JA</th>\n",
       "      <th>ST293Q05JA</th>\n",
       "      <th>ST293Q06JA</th>\n",
       "      <th>ST293Q07JA</th>\n",
       "      <th>ST293Q08JA</th>\n",
       "      <th>ST293Q09JA</th>\n",
       "      <th>ST292Q01JA</th>\n",
       "      <th>ST292Q02JA</th>\n",
       "      <th>ST292Q03JA</th>\n",
       "      <th>ST292Q04JA</th>\n",
       "      <th>ST292Q05JA</th>\n",
       "      <th>ST292Q06JA</th>\n",
       "      <th>ST334Q01JA</th>\n",
       "      <th>ST334Q02JA</th>\n",
       "      <th>ST334Q03JA</th>\n",
       "      <th>ST334Q04JA</th>\n",
       "      <th>ST334Q05JA</th>\n",
       "      <th>ST334Q06JA</th>\n",
       "      <th>ST334Q07JA</th>\n",
       "      <th>ST334Q08JA</th>\n",
       "      <th>ST334Q09JA</th>\n",
       "      <th>ST334Q10JA</th>\n",
       "      <th>ST335Q01JA</th>\n",
       "      <th>ST335Q02JA</th>\n",
       "      <th>ST335Q03JA</th>\n",
       "      <th>ST335Q05JA</th>\n",
       "      <th>ST335Q06JA</th>\n",
       "      <th>ST335Q07JA</th>\n",
       "      <th>ST336Q01JA</th>\n",
       "      <th>ST336Q03JA</th>\n",
       "      <th>ST336Q04JA</th>\n",
       "      <th>ST336Q05JA</th>\n",
       "      <th>ST336Q06JA</th>\n",
       "      <th>...</th>\n",
       "      <th>ST349Q01JA_2</th>\n",
       "      <th>ST349Q01JA_3</th>\n",
       "      <th>ST349Q01JA_4</th>\n",
       "      <th>ST349Q01JA_0</th>\n",
       "      <th>LANGN_105</th>\n",
       "      <th>LANGN_108</th>\n",
       "      <th>LANGN_118</th>\n",
       "      <th>LANGN_140</th>\n",
       "      <th>LANGN_148</th>\n",
       "      <th>LANGN_150</th>\n",
       "      <th>LANGN_156</th>\n",
       "      <th>LANGN_200</th>\n",
       "      <th>LANGN_204</th>\n",
       "      <th>LANGN_232</th>\n",
       "      <th>LANGN_273</th>\n",
       "      <th>LANGN_313</th>\n",
       "      <th>LANGN_316</th>\n",
       "      <th>LANGN_322</th>\n",
       "      <th>LANGN_329</th>\n",
       "      <th>LANGN_344</th>\n",
       "      <th>LANGN_351</th>\n",
       "      <th>LANGN_415</th>\n",
       "      <th>LANGN_463</th>\n",
       "      <th>LANGN_493</th>\n",
       "      <th>LANGN_496</th>\n",
       "      <th>LANGN_500</th>\n",
       "      <th>LANGN_520</th>\n",
       "      <th>LANGN_531</th>\n",
       "      <th>LANGN_602</th>\n",
       "      <th>LANGN_606</th>\n",
       "      <th>LANGN_615</th>\n",
       "      <th>LANGN_621</th>\n",
       "      <th>LANGN_625</th>\n",
       "      <th>LANGN_640</th>\n",
       "      <th>LANGN_641</th>\n",
       "      <th>LANGN_663</th>\n",
       "      <th>LANGN_669</th>\n",
       "      <th>LANGN_670</th>\n",
       "      <th>LANGN_800</th>\n",
       "      <th>LANGN_801</th>\n",
       "      <th>LANGN_802</th>\n",
       "      <th>LANGN_804</th>\n",
       "      <th>LANGN_805</th>\n",
       "      <th>LANGN_806</th>\n",
       "      <th>LANGN_807</th>\n",
       "      <th>LANGN_808</th>\n",
       "      <th>LANGN_865</th>\n",
       "      <th>LANGN_892</th>\n",
       "      <th>LANGN_895</th>\n",
       "      <th>LANGN_917</th>\n",
       "      <th>SC177Q01JA_1</th>\n",
       "      <th>SC177Q01JA_2</th>\n",
       "      <th>SC177Q01JA_3</th>\n",
       "      <th>SC177Q02JA_1</th>\n",
       "      <th>SC177Q02JA_2</th>\n",
       "      <th>SC177Q02JA_3</th>\n",
       "      <th>SC177Q03JA_1</th>\n",
       "      <th>SC177Q03JA_2</th>\n",
       "      <th>SC177Q03JA_3</th>\n",
       "      <th>MATHEXC_0</th>\n",
       "      <th>MATHEXC_1</th>\n",
       "      <th>MATHEXC_2</th>\n",
       "      <th>MATHEXC_3</th>\n",
       "      <th>SCHLTYPE_1</th>\n",
       "      <th>SCHLTYPE_2</th>\n",
       "      <th>SCHLTYPE_3</th>\n",
       "      <th>LANGN_121</th>\n",
       "      <th>LANGN_130</th>\n",
       "      <th>LANGN_137</th>\n",
       "      <th>LANGN_170</th>\n",
       "      <th>LANGN_244</th>\n",
       "      <th>LANGN_258</th>\n",
       "      <th>LANGN_263</th>\n",
       "      <th>LANGN_264</th>\n",
       "      <th>LANGN_266</th>\n",
       "      <th>LANGN_317</th>\n",
       "      <th>LANGN_340</th>\n",
       "      <th>LANGN_369</th>\n",
       "      <th>LANGN_381</th>\n",
       "      <th>LANGN_404</th>\n",
       "      <th>LANGN_420</th>\n",
       "      <th>LANGN_449</th>\n",
       "      <th>LANGN_467</th>\n",
       "      <th>LANGN_494</th>\n",
       "      <th>LANGN_495</th>\n",
       "      <th>LANGN_514</th>\n",
       "      <th>LANGN_523</th>\n",
       "      <th>LANGN_529</th>\n",
       "      <th>LANGN_540</th>\n",
       "      <th>LANGN_547</th>\n",
       "      <th>LANGN_600</th>\n",
       "      <th>LANGN_607</th>\n",
       "      <th>LANGN_618</th>\n",
       "      <th>LANGN_619</th>\n",
       "      <th>LANGN_630</th>\n",
       "      <th>LANGN_635</th>\n",
       "      <th>LANGN_650</th>\n",
       "      <th>LANGN_661</th>\n",
       "      <th>LANGN_673</th>\n",
       "      <th>LANGN_674</th>\n",
       "      <th>LANGN_809</th>\n",
       "      <th>LANGN_810</th>\n",
       "      <th>LANGN_811</th>\n",
       "      <th>LANGN_812</th>\n",
       "      <th>LANGN_813</th>\n",
       "      <th>LANGN_814</th>\n",
       "      <th>LANGN_815</th>\n",
       "      <th>LANGN_816</th>\n",
       "      <th>LANGN_818</th>\n",
       "      <th>LANGN_832</th>\n",
       "      <th>LANGN_868</th>\n",
       "      <th>LANGN_870</th>\n",
       "      <th>LANGN_920</th>\n",
       "      <th>LANGN_921</th>\n",
       "      <th>LANGN_113</th>\n",
       "      <th>LANGN_147</th>\n",
       "      <th>LANGN_275</th>\n",
       "      <th>LANGN_286</th>\n",
       "      <th>LANGN_363</th>\n",
       "      <th>LANGN_422</th>\n",
       "      <th>LANGN_434</th>\n",
       "      <th>LANGN_442</th>\n",
       "      <th>LANGN_471</th>\n",
       "      <th>LANGN_611</th>\n",
       "      <th>LANGN_614</th>\n",
       "      <th>LANGN_624</th>\n",
       "      <th>LANGN_642</th>\n",
       "      <th>LANGN_675</th>\n",
       "      <th>LANGN_676</th>\n",
       "      <th>LANGN_677</th>\n",
       "      <th>LANGN_678</th>\n",
       "      <th>LANGN_817</th>\n",
       "      <th>LANGN_819</th>\n",
       "      <th>LANGN_821</th>\n",
       "      <th>LANGN_823</th>\n",
       "      <th>LANGN_824</th>\n",
       "      <th>LANGN_825</th>\n",
       "      <th>LANGN_826</th>\n",
       "      <th>LANGN_827</th>\n",
       "      <th>LANGN_828</th>\n",
       "      <th>LANGN_885</th>\n",
       "      <th>LANGN_896</th>\n",
       "      <th>LANGN_916</th>\n",
       "      <th>LANGN_112</th>\n",
       "      <th>LANGN_154</th>\n",
       "      <th>LANGN_202</th>\n",
       "      <th>LANGN_246</th>\n",
       "      <th>LANGN_254</th>\n",
       "      <th>LANGN_272</th>\n",
       "      <th>LANGN_301</th>\n",
       "      <th>LANGN_325</th>\n",
       "      <th>LANGN_338</th>\n",
       "      <th>LANGN_358</th>\n",
       "      <th>LANGN_371</th>\n",
       "      <th>LANGN_375</th>\n",
       "      <th>LANGN_383</th>\n",
       "      <th>LANGN_409</th>\n",
       "      <th>LANGN_428</th>\n",
       "      <th>LANGN_465</th>\n",
       "      <th>LANGN_517</th>\n",
       "      <th>LANGN_527</th>\n",
       "      <th>LANGN_561</th>\n",
       "      <th>LANGN_562</th>\n",
       "      <th>LANGN_563</th>\n",
       "      <th>LANGN_565</th>\n",
       "      <th>LANGN_566</th>\n",
       "      <th>LANGN_567</th>\n",
       "      <th>LANGN_601</th>\n",
       "      <th>LANGN_622</th>\n",
       "      <th>LANGN_623</th>\n",
       "      <th>LANGN_628</th>\n",
       "      <th>LANGN_631</th>\n",
       "      <th>LANGN_831</th>\n",
       "      <th>LANGN_833</th>\n",
       "      <th>LANGN_836</th>\n",
       "      <th>LANGN_837</th>\n",
       "      <th>LANGN_838</th>\n",
       "      <th>LANGN_839</th>\n",
       "      <th>LANGN_840</th>\n",
       "      <th>LANGN_841</th>\n",
       "      <th>LANGN_845</th>\n",
       "      <th>LANGN_872</th>\n",
       "      <th>LANGN_873</th>\n",
       "      <th>LANGN_881</th>\n",
       "      <th>LANGN_890</th>\n",
       "      <th>LANGN_897</th>\n",
       "      <th>LANGN_898</th>\n",
       "      <th>LANGN_899</th>\n",
       "      <th>LANGN_900</th>\n",
       "      <th>LANGN_901</th>\n",
       "      <th>LANGN_902</th>\n",
       "      <th>LANGN_903</th>\n",
       "      <th>LANGN_904</th>\n",
       "      <th>LANGN_905</th>\n",
       "      <th>LANGN_906</th>\n",
       "      <th>LANGN_907</th>\n",
       "      <th>LANGN_908</th>\n",
       "      <th>LANGN_909</th>\n",
       "      <th>LANGN_910</th>\n",
       "      <th>LANGN_911</th>\n",
       "      <th>LANGN_912</th>\n",
       "      <th>LANGN_913</th>\n",
       "      <th>LANGN_914</th>\n",
       "      <th>LANGN_918</th>\n",
       "      <th>LANGN_919</th>\n",
       "      <th>LANGN_160</th>\n",
       "      <th>LANGN_327</th>\n",
       "      <th>LANGN_451</th>\n",
       "      <th>LANGN_474</th>\n",
       "      <th>LANGN_503</th>\n",
       "      <th>LANGN_608</th>\n",
       "      <th>LANGN_627</th>\n",
       "      <th>LANGN_639</th>\n",
       "      <th>LANGN_668</th>\n",
       "      <th>LANGN_842</th>\n",
       "      <th>LANGN_843</th>\n",
       "      <th>LANGN_844</th>\n",
       "      <th>LANGN_846</th>\n",
       "      <th>LANGN_849</th>\n",
       "      <th>LANGN_850</th>\n",
       "      <th>LANGN_851</th>\n",
       "      <th>LANGN_852</th>\n",
       "      <th>LANGN_861</th>\n",
       "      <th>LANGN_879</th>\n",
       "      <th>LANGN_133</th>\n",
       "      <th>LANGN_195</th>\n",
       "      <th>LANGN_237</th>\n",
       "      <th>LANGN_379</th>\n",
       "      <th>LANGN_382</th>\n",
       "      <th>LANGN_472</th>\n",
       "      <th>LANGN_492</th>\n",
       "      <th>LANGN_555</th>\n",
       "      <th>LANGN_605</th>\n",
       "      <th>LANGN_616</th>\n",
       "      <th>LANGN_626</th>\n",
       "      <th>LANGN_634</th>\n",
       "      <th>LANGN_648</th>\n",
       "      <th>LANGN_662</th>\n",
       "      <th>LANGN_665</th>\n",
       "      <th>LANGN_666</th>\n",
       "      <th>LANGN_667</th>\n",
       "      <th>LANGN_829</th>\n",
       "      <th>LANGN_854</th>\n",
       "      <th>LANGN_855</th>\n",
       "      <th>LANGN_857</th>\n",
       "      <th>LANGN_859</th>\n",
       "      <th>LANGN_860</th>\n",
       "      <th>LANGN_866</th>\n",
       "      <th>LANGN_877</th>\n",
       "      <th>LANGN_922</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>800282.0</td>\n",
       "      <td>800001.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>800115.0</td>\n",
       "      <td>800002.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>800242.0</td>\n",
       "      <td>800003.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>800245.0</td>\n",
       "      <td>800005.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albania</td>\n",
       "      <td>800285.0</td>\n",
       "      <td>800006.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591852</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>86000120.0</td>\n",
       "      <td>86007488.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591853</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>86000140.0</td>\n",
       "      <td>86007489.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591854</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>86000024.0</td>\n",
       "      <td>86007490.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591855</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>86000174.0</td>\n",
       "      <td>86007491.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591856</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>86000123.0</td>\n",
       "      <td>86007492.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>591857 rows Ã— 1121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               CNT    CNTSCHID    CNTSTUID  MATH_Proficient  SISCO  \\\n",
       "0          Albania    800282.0    800001.0              0.0    NaN   \n",
       "1          Albania    800115.0    800002.0              0.0    NaN   \n",
       "2          Albania    800242.0    800003.0              0.0    NaN   \n",
       "3          Albania    800245.0    800005.0              0.0    1.0   \n",
       "4          Albania    800285.0    800006.0              1.0    1.0   \n",
       "...            ...         ...         ...              ...    ...   \n",
       "591852  Uzbekistan  86000120.0  86007488.0              0.0    1.0   \n",
       "591853  Uzbekistan  86000140.0  86007489.0              0.0    NaN   \n",
       "591854  Uzbekistan  86000024.0  86007490.0              0.0    1.0   \n",
       "591855  Uzbekistan  86000174.0  86007491.0              0.0    NaN   \n",
       "591856  Uzbekistan  86000123.0  86007492.0              0.0    NaN   \n",
       "\n",
       "        ST250Q01JA  ST250Q02JA  ST250Q03JA  ST250Q04JA  ST250Q05JA  \\\n",
       "0              NaN         1.0         NaN         NaN         NaN   \n",
       "1              2.0         2.0         2.0         1.0         2.0   \n",
       "2              1.0         1.0         1.0         1.0         1.0   \n",
       "3              1.0         1.0         2.0         1.0         1.0   \n",
       "4              1.0         1.0         1.0         1.0         1.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         1.0         1.0         1.0         1.0         1.0   \n",
       "591853         1.0         2.0         1.0         1.0         2.0   \n",
       "591854         1.0         2.0         1.0         2.0         2.0   \n",
       "591855         1.0         1.0         1.0         2.0         1.0   \n",
       "591856         1.0         2.0         1.0         2.0         1.0   \n",
       "\n",
       "        ST251Q01JA  ST251Q02JA  ST251Q03JA  ST251Q04JA  ST251Q06JA  \\\n",
       "0              NaN         NaN         NaN         NaN         4.0   \n",
       "1              1.0         2.0         1.0         1.0         1.0   \n",
       "2              2.0         3.0         3.0         3.0         2.0   \n",
       "3              1.0         1.0         1.0         1.0         1.0   \n",
       "4              3.0         1.0         2.0         3.0         1.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         2.0         1.0         2.0         2.0         1.0   \n",
       "591853         2.0         1.0         2.0         3.0         1.0   \n",
       "591854         1.0         2.0         2.0         2.0         1.0   \n",
       "591855         4.0         1.0         3.0         2.0         1.0   \n",
       "591856         1.0         1.0         2.0         2.0         1.0   \n",
       "\n",
       "        ST251Q07JA  ST253Q01JA  ST254Q01JA  ST254Q02JA  ST254Q03JA  \\\n",
       "0              NaN         8.0         NaN         NaN         NaN   \n",
       "1              1.0         2.0         2.0         1.0         1.0   \n",
       "2              2.0         8.0         2.0         2.0         1.0   \n",
       "3              1.0         2.0         2.0         2.0         1.0   \n",
       "4              4.0         7.0         2.0         2.0         2.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         2.0         4.0         2.0         2.0         2.0   \n",
       "591853         1.0         1.0         NaN         NaN         NaN   \n",
       "591854         4.0         5.0         3.0         1.0         1.0   \n",
       "591855         1.0         8.0         2.0         2.0         2.0   \n",
       "591856         3.0         6.0         2.0         1.0         2.0   \n",
       "\n",
       "        ST254Q04JA  ST254Q05JA  ST254Q06JA  ST255Q01JA  ST256Q01JA  \\\n",
       "0              NaN         4.0         NaN         4.0         NaN   \n",
       "1              1.0         1.0         1.0         2.0         NaN   \n",
       "2              4.0         2.0         NaN         4.0         2.0   \n",
       "3              1.0         1.0         1.0         2.0         2.0   \n",
       "4              1.0         1.0         3.0         2.0         1.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         2.0         2.0         2.0         1.0         NaN   \n",
       "591853         NaN         NaN         NaN         2.0         4.0   \n",
       "591854         1.0         2.0         2.0         3.0         2.0   \n",
       "591855         1.0         1.0         2.0         4.0         NaN   \n",
       "591856         2.0         1.0         4.0         3.0         4.0   \n",
       "\n",
       "        ST256Q02JA  ST256Q03JA  ST256Q06JA  ST256Q07JA  ST256Q08JA  \\\n",
       "0              3.0         3.0         NaN         NaN         3.0   \n",
       "1              NaN         NaN         2.0         NaN         NaN   \n",
       "2              2.0         2.0         2.0         2.0         2.0   \n",
       "3              1.0         1.0         1.0         2.0         1.0   \n",
       "4              2.0         1.0         2.0         2.0         1.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         NaN         NaN         NaN         NaN         NaN   \n",
       "591853         1.0         1.0         2.0         1.0         1.0   \n",
       "591854         2.0         2.0         3.0         1.0         2.0   \n",
       "591855         3.0         3.0         2.0         1.0         2.0   \n",
       "591856         2.0         2.0         2.0         2.0         2.0   \n",
       "\n",
       "        ST256Q09JA  ST256Q10JA  ST267Q01JA  ST267Q02JA  ST267Q03JA  \\\n",
       "0              NaN         NaN         4.0         4.0         NaN   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              2.0         2.0         NaN         NaN         NaN   \n",
       "3              2.0         2.0         4.0         NaN         NaN   \n",
       "4              2.0         2.0         4.0         NaN         3.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         NaN         NaN         4.0         NaN         4.0   \n",
       "591853         2.0         2.0         1.0         NaN         NaN   \n",
       "591854         2.0         4.0         NaN         NaN         NaN   \n",
       "591855         4.0         4.0         4.0         4.0         NaN   \n",
       "591856         3.0         3.0         NaN         2.0         4.0   \n",
       "\n",
       "        ST267Q04JA  ST267Q05JA  ST267Q06JA  ST267Q07JA  ST267Q08JA  \\\n",
       "0              1.0         3.0         3.0         NaN         NaN   \n",
       "1              1.0         3.0         3.0         3.0         1.0   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              1.0         NaN         4.0         4.0         1.0   \n",
       "4              1.0         4.0         NaN         NaN         1.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         3.0         NaN         2.0         2.0         NaN   \n",
       "591853         3.0         3.0         3.0         NaN         NaN   \n",
       "591854         2.0         3.0         3.0         3.0         1.0   \n",
       "591855         NaN         4.0         4.0         NaN         1.0   \n",
       "591856         3.0         NaN         3.0         3.0         NaN   \n",
       "\n",
       "        ST034Q01TA  ST034Q02TA  ST034Q03TA  ST034Q04TA  ST034Q05TA  \\\n",
       "0              3.0         1.0         3.0         3.0         2.0   \n",
       "1              4.0         2.0         NaN         3.0         1.0   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              4.0         2.0         2.0         NaN         2.0   \n",
       "4              4.0         NaN         2.0         4.0         2.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         3.0         2.0         4.0         2.0         4.0   \n",
       "591853         3.0         2.0         2.0         3.0         2.0   \n",
       "591854         3.0         2.0         2.0         NaN         2.0   \n",
       "591855         4.0         1.0         3.0         NaN         2.0   \n",
       "591856         4.0         2.0         1.0         NaN         2.0   \n",
       "\n",
       "        ST034Q06TA  ST038Q03NA  ST038Q04NA  ST038Q05NA  ST038Q06NA  \\\n",
       "0              NaN         1.0         1.0         1.0         1.0   \n",
       "1              4.0         1.0         4.0         NaN         3.0   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              4.0         3.0         1.0         1.0         1.0   \n",
       "4              4.0         1.0         1.0         1.0         1.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         NaN         1.0         1.0         1.0         1.0   \n",
       "591853         NaN         1.0         1.0         1.0         1.0   \n",
       "591854         3.0         1.0         1.0         1.0         1.0   \n",
       "591855         4.0         1.0         1.0         1.0         1.0   \n",
       "591856         4.0         1.0         1.0         1.0         1.0   \n",
       "\n",
       "        ST038Q07NA  ST038Q08NA  ST038Q09JA  ST038Q10JA  ST038Q11JA  \\\n",
       "0              1.0         1.0         1.0         1.0         1.0   \n",
       "1              1.0         2.0         1.0         1.0         1.0   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              1.0         3.0         1.0         3.0         1.0   \n",
       "4              1.0         1.0         1.0         1.0         1.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         1.0         1.0         1.0         1.0         1.0   \n",
       "591853         1.0         1.0         1.0         1.0         1.0   \n",
       "591854         1.0         1.0         2.0         1.0         1.0   \n",
       "591855         1.0         1.0         1.0         1.0         1.0   \n",
       "591856         1.0         2.0         1.0         1.0         1.0   \n",
       "\n",
       "        ST265Q01JA  ST265Q02JA  ST265Q03JA  ST265Q04JA  ST266Q01JA  \\\n",
       "0              1.0         1.0         1.0         1.0         2.0   \n",
       "1              1.0         1.0         1.0         1.0         NaN   \n",
       "2              1.0         1.0         1.0         NaN         2.0   \n",
       "3              2.0         2.0         2.0         2.0         2.0   \n",
       "4              1.0         1.0         1.0         1.0         2.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         1.0         1.0         1.0         2.0         2.0   \n",
       "591853         2.0         2.0         2.0         2.0         2.0   \n",
       "591854         1.0         1.0         2.0         2.0         2.0   \n",
       "591855         1.0         1.0         1.0         1.0         2.0   \n",
       "591856         2.0         2.0         2.0         2.0         2.0   \n",
       "\n",
       "        ST266Q02JA  ST266Q03JA  ST266Q04JA  ST266Q05JA  ST307Q01JA  \\\n",
       "0              2.0         2.0         2.0         2.0         NaN   \n",
       "1              1.0         NaN         NaN         NaN         NaN   \n",
       "2              2.0         2.0         2.0         2.0         NaN   \n",
       "3              2.0         2.0         2.0         2.0         5.0   \n",
       "4              2.0         2.0         2.0         2.0         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         2.0         2.0         2.0         2.0         4.0   \n",
       "591853         2.0         2.0         2.0         2.0         4.0   \n",
       "591854         2.0         2.0         2.0         2.0         NaN   \n",
       "591855         2.0         2.0         2.0         2.0         5.0   \n",
       "591856         2.0         2.0         2.0         2.0         NaN   \n",
       "\n",
       "        ST307Q02JA  ST307Q03JA  ST307Q04JA  ST307Q05JA  ST307Q06JA  \\\n",
       "0              NaN         NaN         NaN         NaN         NaN   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              NaN         5.0         NaN         NaN         3.0   \n",
       "4              4.0         4.0         NaN         4.0         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         4.0         4.0         NaN         NaN         2.0   \n",
       "591853         NaN         NaN         2.0         2.0         NaN   \n",
       "591854         2.0         4.0         2.0         NaN         NaN   \n",
       "591855         NaN         NaN         5.0         5.0         NaN   \n",
       "591856         4.0         4.0         2.0         4.0         NaN   \n",
       "\n",
       "        ST307Q07JA  ST307Q08JA  ST307Q09JA  ST307Q10JA  ST301Q01JA  \\\n",
       "0              NaN         NaN         NaN         NaN         NaN   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              3.0         NaN         5.0         NaN         2.0   \n",
       "4              NaN         NaN         5.0         1.0         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         NaN         NaN         5.0         NaN         NaN   \n",
       "591853         1.0         2.0         NaN         NaN         NaN   \n",
       "591854         2.0         4.0         NaN         NaN         4.0   \n",
       "591855         2.0         NaN         NaN         1.0         NaN   \n",
       "591856         NaN         NaN         NaN         1.0         5.0   \n",
       "\n",
       "        ST301Q02JA  ST301Q03JA  ST301Q04JA  ST301Q05JA  ST301Q06JA  \\\n",
       "0              NaN         1.0         5.0         5.0         5.0   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              3.0         NaN         3.0         2.0         NaN   \n",
       "4              5.0         3.0         NaN         NaN         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         4.0         4.0         NaN         NaN         4.0   \n",
       "591853         NaN         NaN         4.0         4.0         4.0   \n",
       "591854         NaN         2.0         4.0         NaN         4.0   \n",
       "591855         NaN         1.0         NaN         5.0         5.0   \n",
       "591856         NaN         NaN         NaN         4.0         5.0   \n",
       "\n",
       "        ST301Q07JA  ST301Q08JA  ST301Q09JA  ST301Q10JA  ST343Q01JA  \\\n",
       "0              NaN         1.0         NaN         NaN         NaN   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              NaN         NaN         NaN         5.0         5.0   \n",
       "4              2.0         2.0         5.0         NaN         4.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         NaN         2.0         4.0         NaN         NaN   \n",
       "591853         NaN         NaN         4.0         4.0         NaN   \n",
       "591854         NaN         NaN         NaN         4.0         4.0   \n",
       "591855         5.0         NaN         NaN         5.0         5.0   \n",
       "591856         4.0         NaN         5.0         NaN         5.0   \n",
       "\n",
       "        ST343Q02JA  ST343Q03JA  ST343Q04JA  ST343Q05JA  ST343Q06JA  \\\n",
       "0              1.0         5.0         NaN         1.0         NaN   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              3.0         NaN         1.0         NaN         NaN   \n",
       "4              NaN         NaN         4.0         NaN         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         NaN         4.0         2.0         NaN         NaN   \n",
       "591853         2.0         4.0         NaN         NaN         4.0   \n",
       "591854         NaN         NaN         4.0         NaN         4.0   \n",
       "591855         NaN         5.0         NaN         NaN         5.0   \n",
       "591856         NaN         NaN         NaN         NaN         4.0   \n",
       "\n",
       "        ST343Q07JA  ST343Q08JA  ST343Q09JA  ST343Q10JA  ST311Q01JA  \\\n",
       "0              1.0         5.0         NaN         NaN         1.0   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              3.0         NaN         5.0         NaN         4.0   \n",
       "4              2.0         5.0         5.0         NaN         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         2.0         4.0         NaN         2.0         2.0   \n",
       "591853         2.0         NaN         NaN         2.0         2.0   \n",
       "591854         2.0         NaN         NaN         4.0         4.0   \n",
       "591855         1.0         4.0         NaN         NaN         1.0   \n",
       "591856         1.0         NaN         4.0         2.0         NaN   \n",
       "\n",
       "        ST311Q02JA  ST311Q03JA  ST311Q04JA  ST311Q05JA  ST311Q06JA  \\\n",
       "0              NaN         5.0         NaN         NaN         NaN   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              NaN         4.0         NaN         1.0         4.0   \n",
       "4              4.0         4.0         4.0         NaN         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         NaN         4.0         4.0         NaN         NaN   \n",
       "591853         2.0         NaN         3.0         NaN         NaN   \n",
       "591854         4.0         4.0         NaN         NaN         2.0   \n",
       "591855         1.0         NaN         NaN         NaN         4.0   \n",
       "591856         4.0         5.0         4.0         2.0         4.0   \n",
       "\n",
       "        ST311Q07JA  ST311Q08JA  ST311Q09JA  ST311Q10JA  ST305Q01JA  \\\n",
       "0              1.0         5.0         NaN         5.0         NaN   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              NaN         5.0         NaN         NaN         4.0   \n",
       "4              NaN         4.0         4.0         NaN         3.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         NaN         2.0         NaN         2.0         NaN   \n",
       "591853         NaN         2.0         NaN         2.0         2.0   \n",
       "591854         NaN         NaN         2.0         NaN         NaN   \n",
       "591855         1.0         NaN         5.0         NaN         5.0   \n",
       "591856         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST305Q02JA  ST305Q03JA  ST305Q04JA  ST305Q05JA  ST305Q06JA  \\\n",
       "0              NaN         2.0         NaN         2.0         4.0   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              5.0         NaN         NaN         4.0         NaN   \n",
       "4              NaN         3.0         3.0         3.0         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         2.0         2.0         NaN         NaN         4.0   \n",
       "591853         NaN         NaN         2.0         NaN         NaN   \n",
       "591854         2.0         NaN         2.0         2.0         NaN   \n",
       "591855         NaN         5.0         NaN         NaN         NaN   \n",
       "591856         NaN         4.0         4.0         NaN         4.0   \n",
       "\n",
       "        ST305Q07JA  ST305Q08JA  ST305Q09JA  ST305Q10JA  ST345Q01JA  \\\n",
       "0              2.0         NaN         NaN         3.0         NaN   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              NaN         NaN         4.0         4.0         NaN   \n",
       "4              NaN         NaN         5.0         NaN         4.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         2.0         NaN         4.0         NaN         2.0   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         NaN         NaN         4.0         2.0         4.0   \n",
       "591855         4.0         NaN         5.0         5.0         1.0   \n",
       "591856         NaN         4.0         NaN         4.0         NaN   \n",
       "\n",
       "        ST345Q02JA  ST345Q03JA  ST345Q04JA  ST345Q05JA  ST345Q06JA  \\\n",
       "0              5.0         3.0         3.0         NaN         NaN   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              4.0         4.0         NaN         NaN         NaN   \n",
       "4              3.0         NaN         3.0         4.0         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         NaN         NaN         2.0         2.0         NaN   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         NaN         NaN         NaN         4.0         4.0   \n",
       "591855         NaN         1.0         1.0         NaN         NaN   \n",
       "591856         4.0         NaN         2.0         NaN         4.0   \n",
       "\n",
       "        ST345Q07JA  ST345Q08JA  ST345Q09JA  ST345Q10JA  ST313Q01JA  \\\n",
       "0              5.0         NaN         NaN         3.0         5.0   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              4.0         4.0         NaN         4.0         4.0   \n",
       "4              NaN         NaN         4.0         NaN         5.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         2.0         2.0         NaN         NaN         4.0   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         2.0         NaN         NaN         2.0         4.0   \n",
       "591855         NaN         5.0         1.0         NaN         NaN   \n",
       "591856         NaN         NaN         4.0         4.0         4.0   \n",
       "\n",
       "        ST313Q02JA  ST313Q03JA  ST313Q04JA  ST313Q05JA  ST313Q06JA  \\\n",
       "0              NaN         NaN         NaN         5.0         NaN   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              NaN         NaN         4.0         NaN         4.0   \n",
       "4              NaN         4.0         NaN         3.0         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         4.0         NaN         NaN         4.0         5.0   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         4.0         NaN         2.0         4.0         NaN   \n",
       "591855         1.0         1.0         NaN         NaN         1.0   \n",
       "591856         NaN         4.0         NaN         NaN         NaN   \n",
       "\n",
       "        ST313Q07JA  ST313Q08JA  ST313Q09JA  ST313Q10JA  ST263Q02JA  \\\n",
       "0              NaN         3.0         5.0         3.0         4.0   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              4.0         4.0         NaN         NaN         3.0   \n",
       "4              NaN         NaN         4.0         4.0         3.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         NaN         NaN         5.0         NaN         4.0   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         NaN         NaN         2.0         NaN         3.0   \n",
       "591855         NaN         1.0         NaN         1.0         1.0   \n",
       "591856         NaN         4.0         4.0         4.0         3.0   \n",
       "\n",
       "        ST263Q04JA  ST263Q06JA  ST263Q08JA  ST273Q01JA  ST273Q02JA  \\\n",
       "0              3.0         3.0         4.0         NaN         4.0   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         4.0         NaN   \n",
       "3              3.0         2.0         4.0         1.0         4.0   \n",
       "4              3.0         3.0         3.0         4.0         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         2.0         2.0         2.0         4.0         NaN   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         2.0         3.0         3.0         NaN         3.0   \n",
       "591855         2.0         1.0         1.0         4.0         NaN   \n",
       "591856         3.0         2.0         3.0         4.0         3.0   \n",
       "\n",
       "        ST273Q03JA  ST273Q04JA  ST273Q05JA  ST273Q06JA  ST273Q07JA  \\\n",
       "0              NaN         4.0         4.0         3.0         3.0   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              1.0         4.0         1.0         1.0         NaN   \n",
       "3              4.0         NaN         4.0         NaN         4.0   \n",
       "4              3.0         3.0         NaN         3.0         4.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         4.0         NaN         4.0         4.0         4.0   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         NaN         2.0         4.0         4.0         4.0   \n",
       "591855         4.0         NaN         4.0         4.0         4.0   \n",
       "591856         NaN         4.0         4.0         NaN         3.0   \n",
       "\n",
       "        ST270Q01JA  ST270Q02JA  ST270Q03JA  ST270Q04JA  ST285Q01JA  \\\n",
       "0              1.0         1.0         1.0         1.0         NaN   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              1.0         1.0         1.0         1.0         1.0   \n",
       "4              1.0         1.0         2.0         3.0         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         1.0         1.0         1.0         1.0         NaN   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         1.0         1.0         2.0         1.0         1.0   \n",
       "591855         1.0         1.0         1.0         1.0         1.0   \n",
       "591856         1.0         1.0         1.0         1.0         1.0   \n",
       "\n",
       "        ST285Q02JA  ST285Q03JA  ST285Q04JA  ST285Q05JA  ST285Q06JA  \\\n",
       "0              NaN         5.0         NaN         NaN         1.0   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              NaN         NaN         1.0         NaN         2.0   \n",
       "4              NaN         3.0         3.0         3.0         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         5.0         NaN         NaN         5.0         5.0   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         NaN         4.0         5.0         NaN         5.0   \n",
       "591855         NaN         5.0         5.0         NaN         NaN   \n",
       "591856         5.0         NaN         NaN         5.0         5.0   \n",
       "\n",
       "        ST285Q07JA  ST285Q08JA  ST285Q09JA  ST283Q01JA  ST283Q02JA  \\\n",
       "0              5.0         5.0         5.0         5.0         5.0   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              4.0         NaN         3.0         2.0         3.0   \n",
       "4              NaN         4.0         4.0         4.0         3.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         5.0         NaN         5.0         5.0         5.0   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         NaN         NaN         5.0         4.0         NaN   \n",
       "591855         NaN         5.0         5.0         NaN         NaN   \n",
       "591856         5.0         NaN         NaN         NaN         5.0   \n",
       "\n",
       "        ST283Q03JA  ST283Q04JA  ST283Q05JA  ST283Q06JA  ST283Q07JA  \\\n",
       "0              5.0         NaN         NaN         NaN         NaN   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              2.0         3.0         NaN         NaN         NaN   \n",
       "4              NaN         3.0         NaN         NaN         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         5.0         NaN         5.0         NaN         NaN   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         NaN         NaN         4.0         4.0         NaN   \n",
       "591855         NaN         NaN         5.0         5.0         5.0   \n",
       "591856         5.0         5.0         NaN         NaN         NaN   \n",
       "\n",
       "        ST283Q08JA  ST283Q09JA  ST275Q01WA  ST275Q02WA  ST275Q03WA  \\\n",
       "0              5.0         5.0         NaN         4.0         4.0   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              2.0         NaN         3.0         NaN         2.0   \n",
       "4              4.0         5.0         4.0         3.0         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         NaN         5.0         2.0         NaN         2.0   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         4.0         4.0         NaN         4.0         4.0   \n",
       "591855         3.0         5.0         NaN         3.0         2.0   \n",
       "591856         5.0         5.0         1.0         2.0         2.0   \n",
       "\n",
       "        ST275Q04WA  ST275Q05WA  ST275Q06WA  ST275Q07WA  ST275Q08WA  \\\n",
       "0              2.0         NaN         2.0         NaN         2.0   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              NaN         3.0         NaN         2.0         3.0   \n",
       "4              NaN         NaN         3.0         3.0         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         2.0         2.0         NaN         2.0         NaN   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         NaN         1.0         2.0         NaN         NaN   \n",
       "591855         NaN         NaN         2.0         1.0         2.0   \n",
       "591856         NaN         NaN         NaN         1.0         NaN   \n",
       "\n",
       "        ST275Q09WA  ST276Q01JA  ST276Q02JA  ST276Q03JA  ST276Q04JA  \\\n",
       "0              NaN         NaN         NaN         1.0         NaN   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              NaN         NaN         2.0         NaN         2.0   \n",
       "4              3.0         3.0         NaN         NaN         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         NaN         4.0         NaN         NaN         4.0   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         1.0         1.0         2.0         NaN         NaN   \n",
       "591855         NaN         2.0         2.0         NaN         NaN   \n",
       "591856         1.0         NaN         1.0         1.0         NaN   \n",
       "\n",
       "        ST276Q05JA  ST276Q06JA  ST276Q07JA  ST276Q08JA  ST276Q09JA  \\\n",
       "0              1.0         NaN         1.0         NaN         1.0   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              2.0         2.0         NaN         NaN         NaN   \n",
       "4              NaN         3.0         NaN         3.0         3.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         4.0         NaN         4.0         NaN         4.0   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         NaN         3.0         NaN         1.0         1.0   \n",
       "591855         NaN         2.0         NaN         2.0         NaN   \n",
       "591856         2.0         NaN         NaN         NaN         1.0   \n",
       "\n",
       "        ST276Q10JA  ST290Q01WA  ST290Q02WA  ST290Q03WA  ST290Q04WA  \\\n",
       "0              1.0         2.0         NaN         NaN         2.0   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              2.0         NaN         2.0         NaN         2.0   \n",
       "4              4.0         1.0         NaN         NaN         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         NaN         NaN         NaN         4.0         4.0   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         NaN         NaN         3.0         3.0         NaN   \n",
       "591855         2.0         3.0         3.0         NaN         3.0   \n",
       "591856         2.0         NaN         2.0         NaN         NaN   \n",
       "\n",
       "        ST290Q05WA  ST290Q06WA  ST290Q07WA  ST290Q08WA  ST290Q09WA  \\\n",
       "0              2.0         NaN         NaN         2.0         2.0   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         4.0         NaN         NaN   \n",
       "3              NaN         NaN         2.0         2.0         2.0   \n",
       "4              2.0         3.0         4.0         3.0         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         4.0         4.0         NaN         NaN         4.0   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         4.0         NaN         3.0         NaN         4.0   \n",
       "591855         3.0         NaN         3.0         NaN         NaN   \n",
       "591856         2.0         2.0         NaN         2.0         NaN   \n",
       "\n",
       "        ST291Q01JA  ST291Q02JA  ST291Q03JA  ST291Q04JA  ST291Q05JA  \\\n",
       "0              NaN         NaN         3.0         NaN         3.0   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              NaN         NaN         4.0         4.0         4.0   \n",
       "4              3.0         NaN         2.0         3.0         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         4.0         4.0         NaN         NaN         4.0   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         3.0         NaN         3.0         3.0         3.0   \n",
       "591855         4.0         4.0         4.0         NaN         NaN   \n",
       "591856         2.0         1.0         NaN         NaN         NaN   \n",
       "\n",
       "        ST291Q06JA  ST291Q07JA  ST291Q08JA  ST291Q09JA  ST291Q10JA  \\\n",
       "0              NaN         NaN         NaN         NaN         NaN   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         4.0   \n",
       "3              4.0         4.0         NaN         NaN         NaN   \n",
       "4              NaN         4.0         NaN         4.0         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         4.0         NaN         NaN         NaN         4.0   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         NaN         NaN         4.0         NaN         NaN   \n",
       "591855         4.0         NaN         4.0         NaN         NaN   \n",
       "591856         2.0         NaN         1.0         2.0         NaN   \n",
       "\n",
       "        ST289Q01WA  ST289Q02JA  ST289Q04JA  ST289Q05WA  ST289Q06JA  \\\n",
       "0              NaN         NaN         NaN         NaN         NaN   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              NaN         NaN         4.0         4.0         NaN   \n",
       "4              NaN         5.0         4.0         4.0         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         NaN         NaN         5.0         5.0         NaN   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         NaN         4.0         NaN         4.0         NaN   \n",
       "591855         NaN         NaN         NaN         NaN         NaN   \n",
       "591856         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST289Q07JA  ST289Q08WA  ST289Q09WA  ST289Q10WA  ST289Q14JA  \\\n",
       "0              NaN         NaN         NaN         NaN         NaN   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              3.0         NaN         NaN         4.0         NaN   \n",
       "4              NaN         NaN         4.0         4.0         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         5.0         5.0         NaN         NaN         NaN   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         NaN         4.0         NaN         NaN         4.0   \n",
       "591855         NaN         NaN         NaN         NaN         NaN   \n",
       "591856         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST293Q01JA  ST293Q02JA  ST293Q03JA  ST293Q05JA  ST293Q06JA  \\\n",
       "0              NaN         NaN         2.0         4.0         5.0   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              3.0         3.0         NaN         NaN         NaN   \n",
       "4              NaN         NaN         3.0         3.0         3.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         5.0         NaN         5.0         5.0         NaN   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         2.0         NaN         NaN         5.0         4.0   \n",
       "591855         NaN         NaN         NaN         NaN         NaN   \n",
       "591856         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST293Q07JA  ST293Q08JA  ST293Q09JA  ST292Q01JA  ST292Q02JA  \\\n",
       "0              NaN         5.0         NaN         1.0         3.0   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         5.0         NaN         NaN         NaN   \n",
       "3              3.0         NaN         4.0         NaN         1.0   \n",
       "4              NaN         4.0         4.0         2.0         2.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         5.0         NaN         5.0         2.0         2.0   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         NaN         NaN         4.0         NaN         3.0   \n",
       "591855         NaN         NaN         NaN         NaN         NaN   \n",
       "591856         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST292Q03JA  ST292Q04JA  ST292Q05JA  ST292Q06JA  ST334Q01JA  \\\n",
       "0              3.0         3.0         1.0         NaN         NaN   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         4.0         NaN   \n",
       "3              2.0         3.0         2.0         3.0         NaN   \n",
       "4              NaN         3.0         3.0         4.0         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         2.0         2.0         2.0         NaN         NaN   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         3.0         3.0         3.0         3.0         NaN   \n",
       "591855         NaN         NaN         NaN         NaN         NaN   \n",
       "591856         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST334Q02JA  ST334Q03JA  ST334Q04JA  ST334Q05JA  ST334Q06JA  \\\n",
       "0              4.0         NaN         4.0         4.0         4.0   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         NaN   \n",
       "3              2.0         NaN         3.0         NaN         NaN   \n",
       "4              1.0         2.0         2.0         NaN         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         4.0         NaN         4.0         NaN         4.0   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         NaN         NaN         3.0         3.0         3.0   \n",
       "591855         NaN         NaN         NaN         NaN         NaN   \n",
       "591856         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST334Q07JA  ST334Q08JA  ST334Q09JA  ST334Q10JA  ST335Q01JA  \\\n",
       "0              NaN         NaN         4.0         NaN         1.0   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         4.0         NaN   \n",
       "3              2.0         3.0         2.0         NaN         2.0   \n",
       "4              NaN         4.0         3.0         NaN         3.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         4.0         4.0         NaN         NaN         3.0   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         NaN         NaN         2.0         3.0         3.0   \n",
       "591855         NaN         NaN         NaN         NaN         NaN   \n",
       "591856         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST335Q02JA  ST335Q03JA  ST335Q05JA  ST335Q06JA  ST335Q07JA  \\\n",
       "0              NaN         3.0         2.0         4.0         4.0   \n",
       "1              NaN         NaN         NaN         NaN         NaN   \n",
       "2              NaN         NaN         NaN         NaN         4.0   \n",
       "3              3.0         3.0         NaN         2.0         3.0   \n",
       "4              2.0         2.0         3.0         4.0         NaN   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "591852         3.0         3.0         3.0         NaN         3.0   \n",
       "591853         NaN         NaN         NaN         NaN         NaN   \n",
       "591854         3.0         3.0         3.0         3.0         NaN   \n",
       "591855         NaN         NaN         NaN         NaN         NaN   \n",
       "591856         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST336Q01JA  ST336Q03JA  ST336Q04JA  ST336Q05JA  ST336Q06JA  ...  \\\n",
       "0              3.0         3.0         3.0         4.0         4.0  ...   \n",
       "1              NaN         NaN         NaN         NaN         NaN  ...   \n",
       "2              NaN         4.0         NaN         NaN         NaN  ...   \n",
       "3              2.0         3.0         2.0         NaN         2.0  ...   \n",
       "4              2.0         2.0         2.0         3.0         NaN  ...   \n",
       "...            ...         ...         ...         ...         ...  ...   \n",
       "591852         3.0         NaN         3.0         3.0         3.0  ...   \n",
       "591853         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "591854         3.0         3.0         3.0         2.0         NaN  ...   \n",
       "591855         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "591856         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "\n",
       "        ST349Q01JA_2  ST349Q01JA_3  ST349Q01JA_4  ST349Q01JA_0  LANGN_105  \\\n",
       "0                  0             0             0             0          0   \n",
       "1                  0             0             0             0          0   \n",
       "2                  0             0             0             0          0   \n",
       "3                  0             0             0             0          0   \n",
       "4                  0             0             1             0          0   \n",
       "...              ...           ...           ...           ...        ...   \n",
       "591852             1             0             0             0          0   \n",
       "591853             0             0             0             0          0   \n",
       "591854             0             0             0             0          0   \n",
       "591855             0             0             0             0          0   \n",
       "591856             0             0             0             0          0   \n",
       "\n",
       "        LANGN_108  LANGN_118  LANGN_140  LANGN_148  LANGN_150  LANGN_156  \\\n",
       "0               0          0          1          0          0          0   \n",
       "1               0          0          1          0          0          0   \n",
       "2               0          0          1          0          0          0   \n",
       "3               0          0          1          0          0          0   \n",
       "4               0          0          1          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_200  LANGN_204  LANGN_232  LANGN_273  LANGN_313  LANGN_316  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_322  LANGN_329  LANGN_344  LANGN_351  LANGN_415  LANGN_463  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_493  LANGN_496  LANGN_500  LANGN_520  LANGN_531  LANGN_602  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_606  LANGN_615  LANGN_621  LANGN_625  LANGN_640  LANGN_641  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_663  LANGN_669  LANGN_670  LANGN_800  LANGN_801  LANGN_802  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_804  LANGN_805  LANGN_806  LANGN_807  LANGN_808  LANGN_865  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_892  LANGN_895  LANGN_917  SC177Q01JA_1  SC177Q01JA_2  \\\n",
       "0               0          0          0             0             0   \n",
       "1               0          0          0             0             0   \n",
       "2               0          0          0             0             0   \n",
       "3               0          0          0             0             0   \n",
       "4               0          0          0             1             0   \n",
       "...           ...        ...        ...           ...           ...   \n",
       "591852          0          0          0             1             0   \n",
       "591853          0          0          0             0             0   \n",
       "591854          0          0          0             1             0   \n",
       "591855          0          0          0             0             0   \n",
       "591856          0          0          0             1             0   \n",
       "\n",
       "        SC177Q01JA_3  SC177Q02JA_1  SC177Q02JA_2  SC177Q02JA_3  SC177Q03JA_1  \\\n",
       "0                  1             0             0             1             0   \n",
       "1                  0             0             0             0             0   \n",
       "2                  1             0             0             1             0   \n",
       "3                  1             0             0             1             0   \n",
       "4                  0             1             0             0             0   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "591852             0             1             0             0             0   \n",
       "591853             1             0             0             1             0   \n",
       "591854             0             0             0             1             0   \n",
       "591855             0             0             0             0             0   \n",
       "591856             0             0             0             1             0   \n",
       "\n",
       "        SC177Q03JA_2  SC177Q03JA_3  MATHEXC_0  MATHEXC_1  MATHEXC_2  \\\n",
       "0                  0             1          0          0          0   \n",
       "1                  0             0          0          0          0   \n",
       "2                  0             0          0          0          0   \n",
       "3                  0             0          0          0          0   \n",
       "4                  0             1          0          0          0   \n",
       "...              ...           ...        ...        ...        ...   \n",
       "591852             0             0          0          0          0   \n",
       "591853             0             1          0          0          0   \n",
       "591854             0             1          0          0          0   \n",
       "591855             0             0          0          0          0   \n",
       "591856             0             1          0          0          0   \n",
       "\n",
       "        MATHEXC_3  SCHLTYPE_1  SCHLTYPE_2  SCHLTYPE_3  LANGN_121  LANGN_130  \\\n",
       "0               1           0           0           1          0          0   \n",
       "1               0           0           0           1          0          0   \n",
       "2               1           0           0           1          0          0   \n",
       "3               1           0           0           1          0          0   \n",
       "4               0           0           0           1          0          0   \n",
       "...           ...         ...         ...         ...        ...        ...   \n",
       "591852          1           0           0           1          0          0   \n",
       "591853          1           0           0           1          0          0   \n",
       "591854          1           0           0           1          0          0   \n",
       "591855          1           0           0           1          0          0   \n",
       "591856          1           0           0           1          0          0   \n",
       "\n",
       "        LANGN_137  LANGN_170  LANGN_244  LANGN_258  LANGN_263  LANGN_264  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_266  LANGN_317  LANGN_340  LANGN_369  LANGN_381  LANGN_404  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_420  LANGN_449  LANGN_467  LANGN_494  LANGN_495  LANGN_514  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_523  LANGN_529  LANGN_540  LANGN_547  LANGN_600  LANGN_607  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_618  LANGN_619  LANGN_630  LANGN_635  LANGN_650  LANGN_661  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_673  LANGN_674  LANGN_809  LANGN_810  LANGN_811  LANGN_812  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_813  LANGN_814  LANGN_815  LANGN_816  LANGN_818  LANGN_832  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_868  LANGN_870  LANGN_920  LANGN_921  LANGN_113  LANGN_147  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_275  LANGN_286  LANGN_363  LANGN_422  LANGN_434  LANGN_442  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_471  LANGN_611  LANGN_614  LANGN_624  LANGN_642  LANGN_675  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          1          0          0          0          0          0   \n",
       "591853          1          0          0          0          0          0   \n",
       "591854          1          0          0          0          0          0   \n",
       "591855          1          0          0          0          0          0   \n",
       "591856          1          0          0          0          0          0   \n",
       "\n",
       "        LANGN_676  LANGN_677  LANGN_678  LANGN_817  LANGN_819  LANGN_821  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_823  LANGN_824  LANGN_825  LANGN_826  LANGN_827  LANGN_828  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_885  LANGN_896  LANGN_916  LANGN_112  LANGN_154  LANGN_202  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_246  LANGN_254  LANGN_272  LANGN_301  LANGN_325  LANGN_338  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_358  LANGN_371  LANGN_375  LANGN_383  LANGN_409  LANGN_428  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_465  LANGN_517  LANGN_527  LANGN_561  LANGN_562  LANGN_563  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_565  LANGN_566  LANGN_567  LANGN_601  LANGN_622  LANGN_623  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_628  LANGN_631  LANGN_831  LANGN_833  LANGN_836  LANGN_837  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_838  LANGN_839  LANGN_840  LANGN_841  LANGN_845  LANGN_872  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_873  LANGN_881  LANGN_890  LANGN_897  LANGN_898  LANGN_899  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_900  LANGN_901  LANGN_902  LANGN_903  LANGN_904  LANGN_905  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_906  LANGN_907  LANGN_908  LANGN_909  LANGN_910  LANGN_911  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_912  LANGN_913  LANGN_914  LANGN_918  LANGN_919  LANGN_160  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_327  LANGN_451  LANGN_474  LANGN_503  LANGN_608  LANGN_627  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_639  LANGN_668  LANGN_842  LANGN_843  LANGN_844  LANGN_846  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_849  LANGN_850  LANGN_851  LANGN_852  LANGN_861  LANGN_879  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_133  LANGN_195  LANGN_237  LANGN_379  LANGN_382  LANGN_472  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_492  LANGN_555  LANGN_605  LANGN_616  LANGN_626  LANGN_634  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_648  LANGN_662  LANGN_665  LANGN_666  LANGN_667  LANGN_829  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_854  LANGN_855  LANGN_857  LANGN_859  LANGN_860  LANGN_866  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               0          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "3               0          0          0          0          0          0   \n",
       "4               0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "591852          0          0          0          0          0          0   \n",
       "591853          0          0          0          0          0          0   \n",
       "591854          0          0          0          0          0          0   \n",
       "591855          0          0          0          0          0          0   \n",
       "591856          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_877  LANGN_922  \n",
       "0               0          0  \n",
       "1               0          0  \n",
       "2               0          0  \n",
       "3               0          0  \n",
       "4               0          0  \n",
       "...           ...        ...  \n",
       "591852          0          0  \n",
       "591853          0          0  \n",
       "591854          0          0  \n",
       "591855          0          0  \n",
       "591856          0          0  \n",
       "\n",
       "[591857 rows x 1121 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# cell 06\n",
    "\n",
    "# Define local file path\n",
    "local_file_path = \"../eda/with-wle-latent/new_PISA_cleaned_dataset.csv\"  # Change as needed\n",
    "\n",
    "# Define S3 details\n",
    "bucket_name = \"sagemaker-us-west-2-986030204467\"\n",
    "file_key = \"capstone/testfiles/new_PISA_cleaned_dataset.csv\"\n",
    "\n",
    "# Check if the file exists locally\n",
    "if os.path.exists(local_file_path):\n",
    "    print(\"ðŸ“‚ Loading data from local file...\")\n",
    "    data = pd.read_csv(local_file_path, usecols=None)\n",
    "    \n",
    "else:\n",
    "    print(\"â˜ï¸ Downloading data from S3...\")\n",
    "    \n",
    "    # Create S3 client\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "\n",
    "    # Download the file from S3\n",
    "    response = s3_client.get_object(Bucket=bucket_name, Key=file_key)\n",
    "\n",
    "    # Read the file into pandas DataFrame\n",
    "    data = pd.read_csv(response[\"Body\"], usecols=None)\n",
    "\n",
    "    # Save a local copy for future use\n",
    "    data.to_csv(local_file_path, index=False)\n",
    "    print(f\"âœ… File saved locally as {local_file_path}\")\n",
    "\n",
    "# Display first few rows\n",
    "#data.head()\n",
    "\n",
    "pd.set_option('display.max_columns', 500)     # Make sure we can see all of the columns\n",
    "pd.set_option('display.max_rows', 20)         # Keep the output on one page\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download dictionary for the variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the file from S3\n",
    "s3_client = boto3.client(\"s3\")\n",
    "dictionary_file = s3_client.get_object(Bucket=bucket_name, Key=\"capstone/testfiles/Variable_dictionary.csv\")\n",
    "\n",
    "# Read the file into pandas DataFrame\n",
    "dictionary = pd.read_csv(dictionary_file[\"Body\"], usecols=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset the data to a specific COUNTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4552, 1121)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNT</th>\n",
       "      <th>CNTSCHID</th>\n",
       "      <th>CNTSTUID</th>\n",
       "      <th>MATH_Proficient</th>\n",
       "      <th>SISCO</th>\n",
       "      <th>ST250Q01JA</th>\n",
       "      <th>ST250Q02JA</th>\n",
       "      <th>ST250Q03JA</th>\n",
       "      <th>ST250Q04JA</th>\n",
       "      <th>ST250Q05JA</th>\n",
       "      <th>ST251Q01JA</th>\n",
       "      <th>ST251Q02JA</th>\n",
       "      <th>ST251Q03JA</th>\n",
       "      <th>ST251Q04JA</th>\n",
       "      <th>ST251Q06JA</th>\n",
       "      <th>ST251Q07JA</th>\n",
       "      <th>ST253Q01JA</th>\n",
       "      <th>ST254Q01JA</th>\n",
       "      <th>ST254Q02JA</th>\n",
       "      <th>ST254Q03JA</th>\n",
       "      <th>ST254Q04JA</th>\n",
       "      <th>ST254Q05JA</th>\n",
       "      <th>ST254Q06JA</th>\n",
       "      <th>ST255Q01JA</th>\n",
       "      <th>ST256Q01JA</th>\n",
       "      <th>ST256Q02JA</th>\n",
       "      <th>ST256Q03JA</th>\n",
       "      <th>ST256Q06JA</th>\n",
       "      <th>ST256Q07JA</th>\n",
       "      <th>ST256Q08JA</th>\n",
       "      <th>ST256Q09JA</th>\n",
       "      <th>ST256Q10JA</th>\n",
       "      <th>ST267Q01JA</th>\n",
       "      <th>ST267Q02JA</th>\n",
       "      <th>ST267Q03JA</th>\n",
       "      <th>ST267Q04JA</th>\n",
       "      <th>ST267Q05JA</th>\n",
       "      <th>ST267Q06JA</th>\n",
       "      <th>ST267Q07JA</th>\n",
       "      <th>ST267Q08JA</th>\n",
       "      <th>ST034Q01TA</th>\n",
       "      <th>ST034Q02TA</th>\n",
       "      <th>ST034Q03TA</th>\n",
       "      <th>ST034Q04TA</th>\n",
       "      <th>ST034Q05TA</th>\n",
       "      <th>ST034Q06TA</th>\n",
       "      <th>ST038Q03NA</th>\n",
       "      <th>ST038Q04NA</th>\n",
       "      <th>ST038Q05NA</th>\n",
       "      <th>ST038Q06NA</th>\n",
       "      <th>ST038Q07NA</th>\n",
       "      <th>ST038Q08NA</th>\n",
       "      <th>ST038Q09JA</th>\n",
       "      <th>ST038Q10JA</th>\n",
       "      <th>ST038Q11JA</th>\n",
       "      <th>ST265Q01JA</th>\n",
       "      <th>ST265Q02JA</th>\n",
       "      <th>ST265Q03JA</th>\n",
       "      <th>ST265Q04JA</th>\n",
       "      <th>ST266Q01JA</th>\n",
       "      <th>ST266Q02JA</th>\n",
       "      <th>ST266Q03JA</th>\n",
       "      <th>ST266Q04JA</th>\n",
       "      <th>ST266Q05JA</th>\n",
       "      <th>ST307Q01JA</th>\n",
       "      <th>ST307Q02JA</th>\n",
       "      <th>ST307Q03JA</th>\n",
       "      <th>ST307Q04JA</th>\n",
       "      <th>ST307Q05JA</th>\n",
       "      <th>ST307Q06JA</th>\n",
       "      <th>ST307Q07JA</th>\n",
       "      <th>ST307Q08JA</th>\n",
       "      <th>ST307Q09JA</th>\n",
       "      <th>ST307Q10JA</th>\n",
       "      <th>ST301Q01JA</th>\n",
       "      <th>ST301Q02JA</th>\n",
       "      <th>ST301Q03JA</th>\n",
       "      <th>ST301Q04JA</th>\n",
       "      <th>ST301Q05JA</th>\n",
       "      <th>ST301Q06JA</th>\n",
       "      <th>ST301Q07JA</th>\n",
       "      <th>ST301Q08JA</th>\n",
       "      <th>ST301Q09JA</th>\n",
       "      <th>ST301Q10JA</th>\n",
       "      <th>ST343Q01JA</th>\n",
       "      <th>ST343Q02JA</th>\n",
       "      <th>ST343Q03JA</th>\n",
       "      <th>ST343Q04JA</th>\n",
       "      <th>ST343Q05JA</th>\n",
       "      <th>ST343Q06JA</th>\n",
       "      <th>ST343Q07JA</th>\n",
       "      <th>ST343Q08JA</th>\n",
       "      <th>ST343Q09JA</th>\n",
       "      <th>ST343Q10JA</th>\n",
       "      <th>ST311Q01JA</th>\n",
       "      <th>ST311Q02JA</th>\n",
       "      <th>ST311Q03JA</th>\n",
       "      <th>ST311Q04JA</th>\n",
       "      <th>ST311Q05JA</th>\n",
       "      <th>ST311Q06JA</th>\n",
       "      <th>ST311Q07JA</th>\n",
       "      <th>ST311Q08JA</th>\n",
       "      <th>ST311Q09JA</th>\n",
       "      <th>ST311Q10JA</th>\n",
       "      <th>ST305Q01JA</th>\n",
       "      <th>ST305Q02JA</th>\n",
       "      <th>ST305Q03JA</th>\n",
       "      <th>ST305Q04JA</th>\n",
       "      <th>ST305Q05JA</th>\n",
       "      <th>ST305Q06JA</th>\n",
       "      <th>ST305Q07JA</th>\n",
       "      <th>ST305Q08JA</th>\n",
       "      <th>ST305Q09JA</th>\n",
       "      <th>ST305Q10JA</th>\n",
       "      <th>ST345Q01JA</th>\n",
       "      <th>ST345Q02JA</th>\n",
       "      <th>ST345Q03JA</th>\n",
       "      <th>ST345Q04JA</th>\n",
       "      <th>ST345Q05JA</th>\n",
       "      <th>ST345Q06JA</th>\n",
       "      <th>ST345Q07JA</th>\n",
       "      <th>ST345Q08JA</th>\n",
       "      <th>ST345Q09JA</th>\n",
       "      <th>ST345Q10JA</th>\n",
       "      <th>ST313Q01JA</th>\n",
       "      <th>ST313Q02JA</th>\n",
       "      <th>ST313Q03JA</th>\n",
       "      <th>ST313Q04JA</th>\n",
       "      <th>ST313Q05JA</th>\n",
       "      <th>ST313Q06JA</th>\n",
       "      <th>ST313Q07JA</th>\n",
       "      <th>ST313Q08JA</th>\n",
       "      <th>ST313Q09JA</th>\n",
       "      <th>ST313Q10JA</th>\n",
       "      <th>ST263Q02JA</th>\n",
       "      <th>ST263Q04JA</th>\n",
       "      <th>ST263Q06JA</th>\n",
       "      <th>ST263Q08JA</th>\n",
       "      <th>ST273Q01JA</th>\n",
       "      <th>ST273Q02JA</th>\n",
       "      <th>ST273Q03JA</th>\n",
       "      <th>ST273Q04JA</th>\n",
       "      <th>ST273Q05JA</th>\n",
       "      <th>ST273Q06JA</th>\n",
       "      <th>ST273Q07JA</th>\n",
       "      <th>ST270Q01JA</th>\n",
       "      <th>ST270Q02JA</th>\n",
       "      <th>ST270Q03JA</th>\n",
       "      <th>ST270Q04JA</th>\n",
       "      <th>ST285Q01JA</th>\n",
       "      <th>ST285Q02JA</th>\n",
       "      <th>ST285Q03JA</th>\n",
       "      <th>ST285Q04JA</th>\n",
       "      <th>ST285Q05JA</th>\n",
       "      <th>ST285Q06JA</th>\n",
       "      <th>ST285Q07JA</th>\n",
       "      <th>ST285Q08JA</th>\n",
       "      <th>ST285Q09JA</th>\n",
       "      <th>ST283Q01JA</th>\n",
       "      <th>ST283Q02JA</th>\n",
       "      <th>ST283Q03JA</th>\n",
       "      <th>ST283Q04JA</th>\n",
       "      <th>ST283Q05JA</th>\n",
       "      <th>ST283Q06JA</th>\n",
       "      <th>ST283Q07JA</th>\n",
       "      <th>ST283Q08JA</th>\n",
       "      <th>ST283Q09JA</th>\n",
       "      <th>ST275Q01WA</th>\n",
       "      <th>ST275Q02WA</th>\n",
       "      <th>ST275Q03WA</th>\n",
       "      <th>ST275Q04WA</th>\n",
       "      <th>ST275Q05WA</th>\n",
       "      <th>ST275Q06WA</th>\n",
       "      <th>ST275Q07WA</th>\n",
       "      <th>ST275Q08WA</th>\n",
       "      <th>ST275Q09WA</th>\n",
       "      <th>ST276Q01JA</th>\n",
       "      <th>ST276Q02JA</th>\n",
       "      <th>ST276Q03JA</th>\n",
       "      <th>ST276Q04JA</th>\n",
       "      <th>ST276Q05JA</th>\n",
       "      <th>ST276Q06JA</th>\n",
       "      <th>ST276Q07JA</th>\n",
       "      <th>ST276Q08JA</th>\n",
       "      <th>ST276Q09JA</th>\n",
       "      <th>ST276Q10JA</th>\n",
       "      <th>ST290Q01WA</th>\n",
       "      <th>ST290Q02WA</th>\n",
       "      <th>ST290Q03WA</th>\n",
       "      <th>ST290Q04WA</th>\n",
       "      <th>ST290Q05WA</th>\n",
       "      <th>ST290Q06WA</th>\n",
       "      <th>ST290Q07WA</th>\n",
       "      <th>ST290Q08WA</th>\n",
       "      <th>ST290Q09WA</th>\n",
       "      <th>ST291Q01JA</th>\n",
       "      <th>ST291Q02JA</th>\n",
       "      <th>ST291Q03JA</th>\n",
       "      <th>ST291Q04JA</th>\n",
       "      <th>ST291Q05JA</th>\n",
       "      <th>ST291Q06JA</th>\n",
       "      <th>ST291Q07JA</th>\n",
       "      <th>ST291Q08JA</th>\n",
       "      <th>ST291Q09JA</th>\n",
       "      <th>ST291Q10JA</th>\n",
       "      <th>ST289Q01WA</th>\n",
       "      <th>ST289Q02JA</th>\n",
       "      <th>ST289Q04JA</th>\n",
       "      <th>ST289Q05WA</th>\n",
       "      <th>ST289Q06JA</th>\n",
       "      <th>ST289Q07JA</th>\n",
       "      <th>ST289Q08WA</th>\n",
       "      <th>ST289Q09WA</th>\n",
       "      <th>ST289Q10WA</th>\n",
       "      <th>ST289Q14JA</th>\n",
       "      <th>ST293Q01JA</th>\n",
       "      <th>ST293Q02JA</th>\n",
       "      <th>ST293Q03JA</th>\n",
       "      <th>ST293Q05JA</th>\n",
       "      <th>ST293Q06JA</th>\n",
       "      <th>ST293Q07JA</th>\n",
       "      <th>ST293Q08JA</th>\n",
       "      <th>ST293Q09JA</th>\n",
       "      <th>ST292Q01JA</th>\n",
       "      <th>ST292Q02JA</th>\n",
       "      <th>ST292Q03JA</th>\n",
       "      <th>ST292Q04JA</th>\n",
       "      <th>ST292Q05JA</th>\n",
       "      <th>ST292Q06JA</th>\n",
       "      <th>ST334Q01JA</th>\n",
       "      <th>ST334Q02JA</th>\n",
       "      <th>ST334Q03JA</th>\n",
       "      <th>ST334Q04JA</th>\n",
       "      <th>ST334Q05JA</th>\n",
       "      <th>ST334Q06JA</th>\n",
       "      <th>ST334Q07JA</th>\n",
       "      <th>ST334Q08JA</th>\n",
       "      <th>ST334Q09JA</th>\n",
       "      <th>ST334Q10JA</th>\n",
       "      <th>ST335Q01JA</th>\n",
       "      <th>ST335Q02JA</th>\n",
       "      <th>ST335Q03JA</th>\n",
       "      <th>ST335Q05JA</th>\n",
       "      <th>ST335Q06JA</th>\n",
       "      <th>ST335Q07JA</th>\n",
       "      <th>ST336Q01JA</th>\n",
       "      <th>ST336Q03JA</th>\n",
       "      <th>ST336Q04JA</th>\n",
       "      <th>ST336Q05JA</th>\n",
       "      <th>ST336Q06JA</th>\n",
       "      <th>...</th>\n",
       "      <th>ST349Q01JA_2</th>\n",
       "      <th>ST349Q01JA_3</th>\n",
       "      <th>ST349Q01JA_4</th>\n",
       "      <th>ST349Q01JA_0</th>\n",
       "      <th>LANGN_105</th>\n",
       "      <th>LANGN_108</th>\n",
       "      <th>LANGN_118</th>\n",
       "      <th>LANGN_140</th>\n",
       "      <th>LANGN_148</th>\n",
       "      <th>LANGN_150</th>\n",
       "      <th>LANGN_156</th>\n",
       "      <th>LANGN_200</th>\n",
       "      <th>LANGN_204</th>\n",
       "      <th>LANGN_232</th>\n",
       "      <th>LANGN_273</th>\n",
       "      <th>LANGN_313</th>\n",
       "      <th>LANGN_316</th>\n",
       "      <th>LANGN_322</th>\n",
       "      <th>LANGN_329</th>\n",
       "      <th>LANGN_344</th>\n",
       "      <th>LANGN_351</th>\n",
       "      <th>LANGN_415</th>\n",
       "      <th>LANGN_463</th>\n",
       "      <th>LANGN_493</th>\n",
       "      <th>LANGN_496</th>\n",
       "      <th>LANGN_500</th>\n",
       "      <th>LANGN_520</th>\n",
       "      <th>LANGN_531</th>\n",
       "      <th>LANGN_602</th>\n",
       "      <th>LANGN_606</th>\n",
       "      <th>LANGN_615</th>\n",
       "      <th>LANGN_621</th>\n",
       "      <th>LANGN_625</th>\n",
       "      <th>LANGN_640</th>\n",
       "      <th>LANGN_641</th>\n",
       "      <th>LANGN_663</th>\n",
       "      <th>LANGN_669</th>\n",
       "      <th>LANGN_670</th>\n",
       "      <th>LANGN_800</th>\n",
       "      <th>LANGN_801</th>\n",
       "      <th>LANGN_802</th>\n",
       "      <th>LANGN_804</th>\n",
       "      <th>LANGN_805</th>\n",
       "      <th>LANGN_806</th>\n",
       "      <th>LANGN_807</th>\n",
       "      <th>LANGN_808</th>\n",
       "      <th>LANGN_865</th>\n",
       "      <th>LANGN_892</th>\n",
       "      <th>LANGN_895</th>\n",
       "      <th>LANGN_917</th>\n",
       "      <th>SC177Q01JA_1</th>\n",
       "      <th>SC177Q01JA_2</th>\n",
       "      <th>SC177Q01JA_3</th>\n",
       "      <th>SC177Q02JA_1</th>\n",
       "      <th>SC177Q02JA_2</th>\n",
       "      <th>SC177Q02JA_3</th>\n",
       "      <th>SC177Q03JA_1</th>\n",
       "      <th>SC177Q03JA_2</th>\n",
       "      <th>SC177Q03JA_3</th>\n",
       "      <th>MATHEXC_0</th>\n",
       "      <th>MATHEXC_1</th>\n",
       "      <th>MATHEXC_2</th>\n",
       "      <th>MATHEXC_3</th>\n",
       "      <th>SCHLTYPE_1</th>\n",
       "      <th>SCHLTYPE_2</th>\n",
       "      <th>SCHLTYPE_3</th>\n",
       "      <th>LANGN_121</th>\n",
       "      <th>LANGN_130</th>\n",
       "      <th>LANGN_137</th>\n",
       "      <th>LANGN_170</th>\n",
       "      <th>LANGN_244</th>\n",
       "      <th>LANGN_258</th>\n",
       "      <th>LANGN_263</th>\n",
       "      <th>LANGN_264</th>\n",
       "      <th>LANGN_266</th>\n",
       "      <th>LANGN_317</th>\n",
       "      <th>LANGN_340</th>\n",
       "      <th>LANGN_369</th>\n",
       "      <th>LANGN_381</th>\n",
       "      <th>LANGN_404</th>\n",
       "      <th>LANGN_420</th>\n",
       "      <th>LANGN_449</th>\n",
       "      <th>LANGN_467</th>\n",
       "      <th>LANGN_494</th>\n",
       "      <th>LANGN_495</th>\n",
       "      <th>LANGN_514</th>\n",
       "      <th>LANGN_523</th>\n",
       "      <th>LANGN_529</th>\n",
       "      <th>LANGN_540</th>\n",
       "      <th>LANGN_547</th>\n",
       "      <th>LANGN_600</th>\n",
       "      <th>LANGN_607</th>\n",
       "      <th>LANGN_618</th>\n",
       "      <th>LANGN_619</th>\n",
       "      <th>LANGN_630</th>\n",
       "      <th>LANGN_635</th>\n",
       "      <th>LANGN_650</th>\n",
       "      <th>LANGN_661</th>\n",
       "      <th>LANGN_673</th>\n",
       "      <th>LANGN_674</th>\n",
       "      <th>LANGN_809</th>\n",
       "      <th>LANGN_810</th>\n",
       "      <th>LANGN_811</th>\n",
       "      <th>LANGN_812</th>\n",
       "      <th>LANGN_813</th>\n",
       "      <th>LANGN_814</th>\n",
       "      <th>LANGN_815</th>\n",
       "      <th>LANGN_816</th>\n",
       "      <th>LANGN_818</th>\n",
       "      <th>LANGN_832</th>\n",
       "      <th>LANGN_868</th>\n",
       "      <th>LANGN_870</th>\n",
       "      <th>LANGN_920</th>\n",
       "      <th>LANGN_921</th>\n",
       "      <th>LANGN_113</th>\n",
       "      <th>LANGN_147</th>\n",
       "      <th>LANGN_275</th>\n",
       "      <th>LANGN_286</th>\n",
       "      <th>LANGN_363</th>\n",
       "      <th>LANGN_422</th>\n",
       "      <th>LANGN_434</th>\n",
       "      <th>LANGN_442</th>\n",
       "      <th>LANGN_471</th>\n",
       "      <th>LANGN_611</th>\n",
       "      <th>LANGN_614</th>\n",
       "      <th>LANGN_624</th>\n",
       "      <th>LANGN_642</th>\n",
       "      <th>LANGN_675</th>\n",
       "      <th>LANGN_676</th>\n",
       "      <th>LANGN_677</th>\n",
       "      <th>LANGN_678</th>\n",
       "      <th>LANGN_817</th>\n",
       "      <th>LANGN_819</th>\n",
       "      <th>LANGN_821</th>\n",
       "      <th>LANGN_823</th>\n",
       "      <th>LANGN_824</th>\n",
       "      <th>LANGN_825</th>\n",
       "      <th>LANGN_826</th>\n",
       "      <th>LANGN_827</th>\n",
       "      <th>LANGN_828</th>\n",
       "      <th>LANGN_885</th>\n",
       "      <th>LANGN_896</th>\n",
       "      <th>LANGN_916</th>\n",
       "      <th>LANGN_112</th>\n",
       "      <th>LANGN_154</th>\n",
       "      <th>LANGN_202</th>\n",
       "      <th>LANGN_246</th>\n",
       "      <th>LANGN_254</th>\n",
       "      <th>LANGN_272</th>\n",
       "      <th>LANGN_301</th>\n",
       "      <th>LANGN_325</th>\n",
       "      <th>LANGN_338</th>\n",
       "      <th>LANGN_358</th>\n",
       "      <th>LANGN_371</th>\n",
       "      <th>LANGN_375</th>\n",
       "      <th>LANGN_383</th>\n",
       "      <th>LANGN_409</th>\n",
       "      <th>LANGN_428</th>\n",
       "      <th>LANGN_465</th>\n",
       "      <th>LANGN_517</th>\n",
       "      <th>LANGN_527</th>\n",
       "      <th>LANGN_561</th>\n",
       "      <th>LANGN_562</th>\n",
       "      <th>LANGN_563</th>\n",
       "      <th>LANGN_565</th>\n",
       "      <th>LANGN_566</th>\n",
       "      <th>LANGN_567</th>\n",
       "      <th>LANGN_601</th>\n",
       "      <th>LANGN_622</th>\n",
       "      <th>LANGN_623</th>\n",
       "      <th>LANGN_628</th>\n",
       "      <th>LANGN_631</th>\n",
       "      <th>LANGN_831</th>\n",
       "      <th>LANGN_833</th>\n",
       "      <th>LANGN_836</th>\n",
       "      <th>LANGN_837</th>\n",
       "      <th>LANGN_838</th>\n",
       "      <th>LANGN_839</th>\n",
       "      <th>LANGN_840</th>\n",
       "      <th>LANGN_841</th>\n",
       "      <th>LANGN_845</th>\n",
       "      <th>LANGN_872</th>\n",
       "      <th>LANGN_873</th>\n",
       "      <th>LANGN_881</th>\n",
       "      <th>LANGN_890</th>\n",
       "      <th>LANGN_897</th>\n",
       "      <th>LANGN_898</th>\n",
       "      <th>LANGN_899</th>\n",
       "      <th>LANGN_900</th>\n",
       "      <th>LANGN_901</th>\n",
       "      <th>LANGN_902</th>\n",
       "      <th>LANGN_903</th>\n",
       "      <th>LANGN_904</th>\n",
       "      <th>LANGN_905</th>\n",
       "      <th>LANGN_906</th>\n",
       "      <th>LANGN_907</th>\n",
       "      <th>LANGN_908</th>\n",
       "      <th>LANGN_909</th>\n",
       "      <th>LANGN_910</th>\n",
       "      <th>LANGN_911</th>\n",
       "      <th>LANGN_912</th>\n",
       "      <th>LANGN_913</th>\n",
       "      <th>LANGN_914</th>\n",
       "      <th>LANGN_918</th>\n",
       "      <th>LANGN_919</th>\n",
       "      <th>LANGN_160</th>\n",
       "      <th>LANGN_327</th>\n",
       "      <th>LANGN_451</th>\n",
       "      <th>LANGN_474</th>\n",
       "      <th>LANGN_503</th>\n",
       "      <th>LANGN_608</th>\n",
       "      <th>LANGN_627</th>\n",
       "      <th>LANGN_639</th>\n",
       "      <th>LANGN_668</th>\n",
       "      <th>LANGN_842</th>\n",
       "      <th>LANGN_843</th>\n",
       "      <th>LANGN_844</th>\n",
       "      <th>LANGN_846</th>\n",
       "      <th>LANGN_849</th>\n",
       "      <th>LANGN_850</th>\n",
       "      <th>LANGN_851</th>\n",
       "      <th>LANGN_852</th>\n",
       "      <th>LANGN_861</th>\n",
       "      <th>LANGN_879</th>\n",
       "      <th>LANGN_133</th>\n",
       "      <th>LANGN_195</th>\n",
       "      <th>LANGN_237</th>\n",
       "      <th>LANGN_379</th>\n",
       "      <th>LANGN_382</th>\n",
       "      <th>LANGN_472</th>\n",
       "      <th>LANGN_492</th>\n",
       "      <th>LANGN_555</th>\n",
       "      <th>LANGN_605</th>\n",
       "      <th>LANGN_616</th>\n",
       "      <th>LANGN_626</th>\n",
       "      <th>LANGN_634</th>\n",
       "      <th>LANGN_648</th>\n",
       "      <th>LANGN_662</th>\n",
       "      <th>LANGN_665</th>\n",
       "      <th>LANGN_666</th>\n",
       "      <th>LANGN_667</th>\n",
       "      <th>LANGN_829</th>\n",
       "      <th>LANGN_854</th>\n",
       "      <th>LANGN_855</th>\n",
       "      <th>LANGN_857</th>\n",
       "      <th>LANGN_859</th>\n",
       "      <th>LANGN_860</th>\n",
       "      <th>LANGN_866</th>\n",
       "      <th>LANGN_877</th>\n",
       "      <th>LANGN_922</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>573394</th>\n",
       "      <td>United_States</td>\n",
       "      <td>84000060.0</td>\n",
       "      <td>84000002.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573395</th>\n",
       "      <td>United_States</td>\n",
       "      <td>84000055.0</td>\n",
       "      <td>84000003.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573396</th>\n",
       "      <td>United_States</td>\n",
       "      <td>84000121.0</td>\n",
       "      <td>84000004.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573397</th>\n",
       "      <td>United_States</td>\n",
       "      <td>84000013.0</td>\n",
       "      <td>84000005.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573398</th>\n",
       "      <td>United_States</td>\n",
       "      <td>84000010.0</td>\n",
       "      <td>84000006.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  CNT    CNTSCHID    CNTSTUID  MATH_Proficient  SISCO  \\\n",
       "573394  United_States  84000060.0  84000002.0              1.0    1.0   \n",
       "573395  United_States  84000055.0  84000003.0              1.0    0.0   \n",
       "573396  United_States  84000121.0  84000004.0              1.0    1.0   \n",
       "573397  United_States  84000013.0  84000005.0              1.0    1.0   \n",
       "573398  United_States  84000010.0  84000006.0              1.0    1.0   \n",
       "\n",
       "        ST250Q01JA  ST250Q02JA  ST250Q03JA  ST250Q04JA  ST250Q05JA  \\\n",
       "573394         1.0         1.0         1.0         1.0         1.0   \n",
       "573395         1.0         1.0         1.0         1.0         1.0   \n",
       "573396         1.0         1.0         1.0         1.0         1.0   \n",
       "573397         1.0         1.0         2.0         1.0         1.0   \n",
       "573398         1.0         1.0         1.0         1.0         1.0   \n",
       "\n",
       "        ST251Q01JA  ST251Q02JA  ST251Q03JA  ST251Q04JA  ST251Q06JA  \\\n",
       "573394         4.0         1.0         4.0         4.0         4.0   \n",
       "573395         3.0         1.0         4.0         4.0         3.0   \n",
       "573396         4.0         1.0         4.0         4.0         2.0   \n",
       "573397         3.0         1.0         3.0         3.0         1.0   \n",
       "573398         2.0         1.0         2.0         2.0         1.0   \n",
       "\n",
       "        ST251Q07JA  ST253Q01JA  ST254Q01JA  ST254Q02JA  ST254Q03JA  \\\n",
       "573394         NaN         8.0         2.0         2.0         3.0   \n",
       "573395         NaN         8.0         4.0         2.0         2.0   \n",
       "573396         NaN         8.0         4.0         2.0         3.0   \n",
       "573397         NaN         6.0         2.0         2.0         2.0   \n",
       "573398         NaN         8.0         3.0         3.0         4.0   \n",
       "\n",
       "        ST254Q04JA  ST254Q05JA  ST254Q06JA  ST255Q01JA  ST256Q01JA  \\\n",
       "573394         2.0         2.0         3.0         5.0         3.0   \n",
       "573395         2.0         1.0         3.0         4.0         NaN   \n",
       "573396         2.0         1.0         3.0         6.0         2.0   \n",
       "573397         2.0         1.0         3.0         2.0         1.0   \n",
       "573398         2.0         1.0         4.0         2.0         2.0   \n",
       "\n",
       "        ST256Q02JA  ST256Q03JA  ST256Q06JA  ST256Q07JA  ST256Q08JA  \\\n",
       "573394         2.0         2.0         1.0         2.0         2.0   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         2.0         3.0         3.0         2.0         2.0   \n",
       "573397         1.0         1.0         2.0         2.0         1.0   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST256Q09JA  ST256Q10JA  ST267Q01JA  ST267Q02JA  ST267Q03JA  \\\n",
       "573394         2.0         2.0         NaN         NaN         3.0   \n",
       "573395         NaN         NaN         3.0         NaN         3.0   \n",
       "573396         1.0         2.0         3.0         NaN         3.0   \n",
       "573397         1.0         1.0         3.0         NaN         2.0   \n",
       "573398         NaN         2.0         NaN         3.0         3.0   \n",
       "\n",
       "        ST267Q04JA  ST267Q05JA  ST267Q06JA  ST267Q07JA  ST267Q08JA  \\\n",
       "573394         2.0         3.0         3.0         3.0         NaN   \n",
       "573395         NaN         3.0         3.0         NaN         2.0   \n",
       "573396         1.0         3.0         3.0         NaN         NaN   \n",
       "573397         1.0         NaN         NaN         3.0         2.0   \n",
       "573398         NaN         3.0         4.0         4.0         NaN   \n",
       "\n",
       "        ST034Q01TA  ST034Q02TA  ST034Q03TA  ST034Q04TA  ST034Q05TA  \\\n",
       "573394         3.0         NaN         2.0         3.0         2.0   \n",
       "573395         4.0         2.0         2.0         4.0         2.0   \n",
       "573396         3.0         2.0         2.0         3.0         NaN   \n",
       "573397         3.0         2.0         3.0         NaN         2.0   \n",
       "573398         4.0         1.0         1.0         NaN         1.0   \n",
       "\n",
       "        ST034Q06TA  ST038Q03NA  ST038Q04NA  ST038Q05NA  ST038Q06NA  \\\n",
       "573394         3.0         1.0         1.0         1.0         1.0   \n",
       "573395         NaN         1.0         1.0         1.0         1.0   \n",
       "573396         3.0         1.0         1.0         1.0         1.0   \n",
       "573397         3.0         1.0         2.0         2.0         1.0   \n",
       "573398         4.0         1.0         3.0         1.0         1.0   \n",
       "\n",
       "        ST038Q07NA  ST038Q08NA  ST038Q09JA  ST038Q10JA  ST038Q11JA  \\\n",
       "573394         1.0         1.0         1.0         1.0         1.0   \n",
       "573395         1.0         1.0         1.0         1.0         1.0   \n",
       "573396         1.0         1.0         1.0         1.0         1.0   \n",
       "573397         2.0         2.0         1.0         1.0         1.0   \n",
       "573398         1.0         1.0         1.0         1.0         1.0   \n",
       "\n",
       "        ST265Q01JA  ST265Q02JA  ST265Q03JA  ST265Q04JA  ST266Q01JA  \\\n",
       "573394         2.0         2.0         2.0         2.0         2.0   \n",
       "573395         4.0         4.0         4.0         4.0         2.0   \n",
       "573396         2.0         2.0         2.0         2.0         2.0   \n",
       "573397         2.0         2.0         2.0         2.0         1.0   \n",
       "573398         1.0         1.0         1.0         1.0         2.0   \n",
       "\n",
       "        ST266Q02JA  ST266Q03JA  ST266Q04JA  ST266Q05JA  ST307Q01JA  \\\n",
       "573394         2.0         2.0         2.0         2.0         NaN   \n",
       "573395         2.0         2.0         2.0         2.0         NaN   \n",
       "573396         2.0         2.0         1.0         2.0         NaN   \n",
       "573397         1.0         2.0         1.0         2.0         NaN   \n",
       "573398         2.0         2.0         2.0         2.0         NaN   \n",
       "\n",
       "        ST307Q02JA  ST307Q03JA  ST307Q04JA  ST307Q05JA  ST307Q06JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST307Q07JA  ST307Q08JA  ST307Q09JA  ST307Q10JA  ST301Q01JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST301Q02JA  ST301Q03JA  ST301Q04JA  ST301Q05JA  ST301Q06JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST301Q07JA  ST301Q08JA  ST301Q09JA  ST301Q10JA  ST343Q01JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST343Q02JA  ST343Q03JA  ST343Q04JA  ST343Q05JA  ST343Q06JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST343Q07JA  ST343Q08JA  ST343Q09JA  ST343Q10JA  ST311Q01JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST311Q02JA  ST311Q03JA  ST311Q04JA  ST311Q05JA  ST311Q06JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST311Q07JA  ST311Q08JA  ST311Q09JA  ST311Q10JA  ST305Q01JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST305Q02JA  ST305Q03JA  ST305Q04JA  ST305Q05JA  ST305Q06JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST305Q07JA  ST305Q08JA  ST305Q09JA  ST305Q10JA  ST345Q01JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST345Q02JA  ST345Q03JA  ST345Q04JA  ST345Q05JA  ST345Q06JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST345Q07JA  ST345Q08JA  ST345Q09JA  ST345Q10JA  ST313Q01JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST313Q02JA  ST313Q03JA  ST313Q04JA  ST313Q05JA  ST313Q06JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST313Q07JA  ST313Q08JA  ST313Q09JA  ST313Q10JA  ST263Q02JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         1.0   \n",
       "573395         NaN         NaN         NaN         NaN         2.0   \n",
       "573396         NaN         NaN         NaN         NaN         1.0   \n",
       "573397         NaN         NaN         NaN         NaN         3.0   \n",
       "573398         NaN         NaN         NaN         NaN         2.0   \n",
       "\n",
       "        ST263Q04JA  ST263Q06JA  ST263Q08JA  ST273Q01JA  ST273Q02JA  \\\n",
       "573394         3.0         3.0         NaN         3.0         3.0   \n",
       "573395         3.0         2.0         NaN         3.0         4.0   \n",
       "573396         3.0         2.0         NaN         NaN         4.0   \n",
       "573397         3.0         3.0         NaN         1.0         NaN   \n",
       "573398         2.0         2.0         NaN         NaN         NaN   \n",
       "\n",
       "        ST273Q03JA  ST273Q04JA  ST273Q05JA  ST273Q06JA  ST273Q07JA  \\\n",
       "573394         NaN         3.0         NaN         4.0         4.0   \n",
       "573395         4.0         3.0         4.0         NaN         NaN   \n",
       "573396         4.0         NaN         3.0         3.0         3.0   \n",
       "573397         1.0         1.0         NaN         1.0         1.0   \n",
       "573398         4.0         4.0         4.0         4.0         4.0   \n",
       "\n",
       "        ST270Q01JA  ST270Q02JA  ST270Q03JA  ST270Q04JA  ST285Q01JA  \\\n",
       "573394         1.0         1.0         1.0         2.0         NaN   \n",
       "573395         2.0         1.0         1.0         2.0         NaN   \n",
       "573396         2.0         2.0         1.0         2.0         3.0   \n",
       "573397         3.0         3.0         3.0         3.0         2.0   \n",
       "573398         2.0         1.0         1.0         2.0         NaN   \n",
       "\n",
       "        ST285Q02JA  ST285Q03JA  ST285Q04JA  ST285Q05JA  ST285Q06JA  \\\n",
       "573394         3.0         NaN         NaN         4.0         2.0   \n",
       "573395         NaN         1.0         1.0         1.0         NaN   \n",
       "573396         4.0         NaN         4.0         4.0         2.0   \n",
       "573397         3.0         3.0         3.0         NaN         NaN   \n",
       "573398         5.0         NaN         NaN         2.0         4.0   \n",
       "\n",
       "        ST285Q07JA  ST285Q08JA  ST285Q09JA  ST283Q01JA  ST283Q02JA  \\\n",
       "573394         2.0         NaN         4.0         1.0         NaN   \n",
       "573395         3.0         2.0         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         2.0         NaN   \n",
       "573397         2.0         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         2.0         5.0         NaN         1.0   \n",
       "\n",
       "        ST283Q03JA  ST283Q04JA  ST283Q05JA  ST283Q06JA  ST283Q07JA  \\\n",
       "573394         4.0         NaN         4.0         NaN         NaN   \n",
       "573395         NaN         2.0         2.0         1.0         1.0   \n",
       "573396         5.0         NaN         NaN         2.0         4.0   \n",
       "573397         3.0         NaN         3.0         3.0         2.0   \n",
       "573398         2.0         4.0         NaN         1.0         NaN   \n",
       "\n",
       "        ST283Q08JA  ST283Q09JA  ST275Q01WA  ST275Q02WA  ST275Q03WA  \\\n",
       "573394         1.0         1.0         NaN         NaN         3.0   \n",
       "573395         NaN         1.0         4.0         4.0         NaN   \n",
       "573396         NaN         4.0         NaN         3.0         2.0   \n",
       "573397         NaN         2.0         3.0         NaN         3.0   \n",
       "573398         1.0         NaN         NaN         4.0         4.0   \n",
       "\n",
       "        ST275Q04WA  ST275Q05WA  ST275Q06WA  ST275Q07WA  ST275Q08WA  \\\n",
       "573394         NaN         4.0         NaN         4.0         4.0   \n",
       "573395         NaN         2.0         NaN         2.0         4.0   \n",
       "573396         NaN         1.0         NaN         1.0         4.0   \n",
       "573397         3.0         NaN         NaN         NaN         3.0   \n",
       "573398         NaN         3.0         NaN         1.0         NaN   \n",
       "\n",
       "        ST275Q09WA  ST276Q01JA  ST276Q02JA  ST276Q03JA  ST276Q04JA  \\\n",
       "573394         4.0         2.0         NaN         4.0         4.0   \n",
       "573395         NaN         1.0         NaN         4.0         4.0   \n",
       "573396         NaN         NaN         NaN         NaN         2.0   \n",
       "573397         NaN         NaN         2.0         3.0         2.0   \n",
       "573398         1.0         1.0         NaN         4.0         3.0   \n",
       "\n",
       "        ST276Q05JA  ST276Q06JA  ST276Q07JA  ST276Q08JA  ST276Q09JA  \\\n",
       "573394         NaN         NaN         NaN         4.0         4.0   \n",
       "573395         NaN         NaN         NaN         4.0         NaN   \n",
       "573396         2.0         NaN         NaN         4.0         2.0   \n",
       "573397         NaN         3.0         NaN         NaN         NaN   \n",
       "573398         1.0         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST276Q10JA  ST290Q01WA  ST290Q02WA  ST290Q03WA  ST290Q04WA  \\\n",
       "573394         NaN         NaN         3.0         3.0         NaN   \n",
       "573395         1.0         3.0         3.0         3.0         NaN   \n",
       "573396         1.0         2.0         4.0         NaN         4.0   \n",
       "573397         3.0         NaN         2.0         NaN         NaN   \n",
       "573398         1.0         NaN         NaN         3.0         3.0   \n",
       "\n",
       "        ST290Q05WA  ST290Q06WA  ST290Q07WA  ST290Q08WA  ST290Q09WA  \\\n",
       "573394         3.0         NaN         3.0         NaN         3.0   \n",
       "573395         NaN         NaN         3.0         NaN         3.0   \n",
       "573396         NaN         NaN         4.0         2.0         NaN   \n",
       "573397         NaN         1.0         2.0         2.0         3.0   \n",
       "573398         1.0         4.0         1.0         NaN         NaN   \n",
       "\n",
       "        ST291Q01JA  ST291Q02JA  ST291Q03JA  ST291Q04JA  ST291Q05JA  \\\n",
       "573394         NaN         3.0         NaN         3.0         NaN   \n",
       "573395         3.0         NaN         NaN         NaN         3.0   \n",
       "573396         NaN         NaN         4.0         3.0         3.0   \n",
       "573397         NaN         3.0         NaN         3.0         NaN   \n",
       "573398         NaN         2.0         2.0         NaN         3.0   \n",
       "\n",
       "        ST291Q06JA  ST291Q07JA  ST291Q08JA  ST291Q09JA  ST291Q10JA  \\\n",
       "573394         3.0         3.0         NaN         NaN         3.0   \n",
       "573395         3.0         3.0         NaN         3.0         NaN   \n",
       "573396         NaN         4.0         NaN         4.0         NaN   \n",
       "573397         1.0         NaN         3.0         NaN         1.0   \n",
       "573398         NaN         3.0         1.0         NaN         NaN   \n",
       "\n",
       "        ST289Q01WA  ST289Q02JA  ST289Q04JA  ST289Q05WA  ST289Q06JA  \\\n",
       "573394         4.0         4.0         NaN         4.0         NaN   \n",
       "573395         NaN         2.0         4.0         NaN         NaN   \n",
       "573396         5.0         5.0         NaN         5.0         NaN   \n",
       "573397         1.0         3.0         NaN         NaN         3.0   \n",
       "573398         2.0         4.0         NaN         NaN         NaN   \n",
       "\n",
       "        ST289Q07JA  ST289Q08WA  ST289Q09WA  ST289Q10WA  ST289Q14JA  \\\n",
       "573394         4.0         NaN         NaN         NaN         5.0   \n",
       "573395         NaN         2.0         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         5.0   \n",
       "573397         3.0         NaN         NaN         NaN         1.0   \n",
       "573398         NaN         NaN         NaN         5.0         NaN   \n",
       "\n",
       "        ST293Q01JA  ST293Q02JA  ST293Q03JA  ST293Q05JA  ST293Q06JA  \\\n",
       "573394         4.0         4.0         4.0         NaN         4.0   \n",
       "573395         NaN         NaN         4.0         2.0         NaN   \n",
       "573396         NaN         5.0         4.0         4.0         NaN   \n",
       "573397         2.0         4.0         4.0         NaN         NaN   \n",
       "573398         NaN         5.0         5.0         5.0         NaN   \n",
       "\n",
       "        ST293Q07JA  ST293Q08JA  ST293Q09JA  ST292Q01JA  ST292Q02JA  \\\n",
       "573394         NaN         4.0         NaN         3.0         1.0   \n",
       "573395         NaN         3.0         4.0         3.0         3.0   \n",
       "573396         NaN         3.0         NaN         NaN         3.0   \n",
       "573397         NaN         NaN         3.0         1.0         1.0   \n",
       "573398         NaN         5.0         5.0         3.0         3.0   \n",
       "\n",
       "        ST292Q03JA  ST292Q04JA  ST292Q05JA  ST292Q06JA  ST334Q01JA  \\\n",
       "573394         3.0         3.0         3.0         NaN         NaN   \n",
       "573395         3.0         3.0         3.0         NaN         NaN   \n",
       "573396         3.0         4.0         3.0         4.0         NaN   \n",
       "573397         1.0         NaN         1.0         1.0         NaN   \n",
       "573398         NaN         3.0         3.0         3.0         NaN   \n",
       "\n",
       "        ST334Q02JA  ST334Q03JA  ST334Q04JA  ST334Q05JA  ST334Q06JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST334Q07JA  ST334Q08JA  ST334Q09JA  ST334Q10JA  ST335Q01JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST335Q02JA  ST335Q03JA  ST335Q05JA  ST335Q06JA  ST335Q07JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST336Q01JA  ST336Q03JA  ST336Q04JA  ST336Q05JA  ST336Q06JA  ...  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "573395         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "573396         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "573397         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "573398         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "\n",
       "        ST349Q01JA_2  ST349Q01JA_3  ST349Q01JA_4  ST349Q01JA_0  LANGN_105  \\\n",
       "573394             0             0             0             0          0   \n",
       "573395             0             0             0             0          0   \n",
       "573396             0             0             0             0          0   \n",
       "573397             1             0             0             0          0   \n",
       "573398             0             0             1             0          0   \n",
       "\n",
       "        LANGN_108  LANGN_118  LANGN_140  LANGN_148  LANGN_150  LANGN_156  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_200  LANGN_204  LANGN_232  LANGN_273  LANGN_313  LANGN_316  \\\n",
       "573394          0          0          0          0          1          0   \n",
       "573395          0          0          0          0          1          0   \n",
       "573396          0          0          0          0          1          0   \n",
       "573397          0          0          0          0          1          0   \n",
       "573398          0          0          0          0          1          0   \n",
       "\n",
       "        LANGN_322  LANGN_329  LANGN_344  LANGN_351  LANGN_415  LANGN_463  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_493  LANGN_496  LANGN_500  LANGN_520  LANGN_531  LANGN_602  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_606  LANGN_615  LANGN_621  LANGN_625  LANGN_640  LANGN_641  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_663  LANGN_669  LANGN_670  LANGN_800  LANGN_801  LANGN_802  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_804  LANGN_805  LANGN_806  LANGN_807  LANGN_808  LANGN_865  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_892  LANGN_895  LANGN_917  SC177Q01JA_1  SC177Q01JA_2  \\\n",
       "573394          0          0          0             0             0   \n",
       "573395          0          0          0             0             0   \n",
       "573396          0          0          0             1             0   \n",
       "573397          0          0          0             0             1   \n",
       "573398          0          0          0             0             1   \n",
       "\n",
       "        SC177Q01JA_3  SC177Q02JA_1  SC177Q02JA_2  SC177Q02JA_3  SC177Q03JA_1  \\\n",
       "573394             1             0             1             0             0   \n",
       "573395             0             0             0             0             0   \n",
       "573396             0             1             0             0             1   \n",
       "573397             0             0             0             1             0   \n",
       "573398             0             0             1             0             0   \n",
       "\n",
       "        SC177Q03JA_2  SC177Q03JA_3  MATHEXC_0  MATHEXC_1  MATHEXC_2  \\\n",
       "573394             0             0          0          0          0   \n",
       "573395             0             0          0          0          0   \n",
       "573396             0             0          0          0          0   \n",
       "573397             0             1          0          0          0   \n",
       "573398             1             0          0          0          0   \n",
       "\n",
       "        MATHEXC_3  SCHLTYPE_1  SCHLTYPE_2  SCHLTYPE_3  LANGN_121  LANGN_130  \\\n",
       "573394          1           0           0           1          0          0   \n",
       "573395          0           0           0           0          0          0   \n",
       "573396          1           0           0           1          0          0   \n",
       "573397          0           0           0           1          0          0   \n",
       "573398          0           0           0           1          0          0   \n",
       "\n",
       "        LANGN_137  LANGN_170  LANGN_244  LANGN_258  LANGN_263  LANGN_264  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_266  LANGN_317  LANGN_340  LANGN_369  LANGN_381  LANGN_404  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_420  LANGN_449  LANGN_467  LANGN_494  LANGN_495  LANGN_514  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_523  LANGN_529  LANGN_540  LANGN_547  LANGN_600  LANGN_607  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_618  LANGN_619  LANGN_630  LANGN_635  LANGN_650  LANGN_661  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_673  LANGN_674  LANGN_809  LANGN_810  LANGN_811  LANGN_812  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_813  LANGN_814  LANGN_815  LANGN_816  LANGN_818  LANGN_832  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_868  LANGN_870  LANGN_920  LANGN_921  LANGN_113  LANGN_147  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_275  LANGN_286  LANGN_363  LANGN_422  LANGN_434  LANGN_442  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_471  LANGN_611  LANGN_614  LANGN_624  LANGN_642  LANGN_675  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_676  LANGN_677  LANGN_678  LANGN_817  LANGN_819  LANGN_821  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_823  LANGN_824  LANGN_825  LANGN_826  LANGN_827  LANGN_828  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_885  LANGN_896  LANGN_916  LANGN_112  LANGN_154  LANGN_202  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_246  LANGN_254  LANGN_272  LANGN_301  LANGN_325  LANGN_338  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_358  LANGN_371  LANGN_375  LANGN_383  LANGN_409  LANGN_428  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_465  LANGN_517  LANGN_527  LANGN_561  LANGN_562  LANGN_563  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_565  LANGN_566  LANGN_567  LANGN_601  LANGN_622  LANGN_623  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_628  LANGN_631  LANGN_831  LANGN_833  LANGN_836  LANGN_837  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_838  LANGN_839  LANGN_840  LANGN_841  LANGN_845  LANGN_872  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_873  LANGN_881  LANGN_890  LANGN_897  LANGN_898  LANGN_899  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_900  LANGN_901  LANGN_902  LANGN_903  LANGN_904  LANGN_905  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_906  LANGN_907  LANGN_908  LANGN_909  LANGN_910  LANGN_911  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_912  LANGN_913  LANGN_914  LANGN_918  LANGN_919  LANGN_160  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_327  LANGN_451  LANGN_474  LANGN_503  LANGN_608  LANGN_627  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_639  LANGN_668  LANGN_842  LANGN_843  LANGN_844  LANGN_846  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_849  LANGN_850  LANGN_851  LANGN_852  LANGN_861  LANGN_879  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_133  LANGN_195  LANGN_237  LANGN_379  LANGN_382  LANGN_472  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_492  LANGN_555  LANGN_605  LANGN_616  LANGN_626  LANGN_634  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_648  LANGN_662  LANGN_665  LANGN_666  LANGN_667  LANGN_829  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_854  LANGN_855  LANGN_857  LANGN_859  LANGN_860  LANGN_866  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_877  LANGN_922  \n",
       "573394          0          0  \n",
       "573395          0          0  \n",
       "573396          0          0  \n",
       "573397          0          0  \n",
       "573398          0          0  \n",
       "\n",
       "[5 rows x 1121 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data = data[data['CNT'] == country_name]\n",
    "print(model_data.shape)\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take out additional variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of columns to drop\n",
    "columns_to_remove = [\"CNT\", \"CNTSCHID\", \"CNTSTUID\", \"OECD\",\n",
    "    \"HOMEPOS\", \"RELATST\", \"BELONG\", \"BULLIED\", \"FEELSAFE\", \"SCHRISK\", \"PERSEVAGR\", \"CURIOAGR\", \n",
    "    \"COOPAGR\", \"EMPATAGR\", \"ASSERAGR\", \"STRESAGR\", \"EMOCOAGR\", \"GROSAGR\", \"INFOSEEK\", \"FAMSUP\", \n",
    "    \"DISCLIM\", \"TEACHSUP\", \"COGACRCO\", \"COGACMCO\", \"EXPOFA\", \"EXPO21ST\", \"MATHEFF\", \"MATHEF21\", \n",
    "    \"FAMCON\", \"ANXMAT\", \"MATHPERS\", \"CREATEFF\", \"CREATSCH\", \"CREATFAM\", \"CREATAS\", \"CREATOOS\", \n",
    "    \"CREATOP\", \"OPENART\", \"IMAGINE\", \"SCHSUST\", \"LEARRES\", \"PROBSELF\", \"FAMSUPSL\", \"FEELLAH\", \n",
    "    \"SDLEFF\", \"ICTRES\", \"FLSCHOOL\", \"FLMULTSB\", \"FLFAMILY\", \"ACCESSFP\", \"FLCONFIN\", \"FLCONICT\", \n",
    "    \"ACCESSFA\", \"ATTCONFM\", \"FRINFLFM\", \"ICTSCH\", \"ICTHOME\", \"ICTQUAL\", \"ICTSUBJ\", \"ICTENQ\", \n",
    "    \"ICTFEED\", \"ICTOUT\", \"ICTWKDY\", \"ICTWKEND\", \"ICTREG\", \"ICTINFO\", \"ICTEFFIC\", \"BODYIMA\", \n",
    "    \"SOCONPA\", \"LIFESAT\", \"PSYCHSYM\", \"SOCCON\", \"EXPWB\", \"CURSUPP\", \"PQMIMP\", \"PQMCAR\", \n",
    "    \"PARINVOL\", \"PQSCHOOL\", \"PASCHPOL\", \"ATTIMMP\", \"CREATHME\", \"CREATACT\", \"CREATOPN\", \n",
    "    \"CREATOR\", \"SCHAUTO\", \"TCHPART\", \"EDULEAD\", \"INSTLEAD\", \"ENCOURPG\", \"DIGDVPOL\", \"TEAFDBK\", \n",
    "    \"MTTRAIN\", \"DMCVIEWS\", \"NEGSCLIM\", \"STAFFSHORT\", \"EDUSHORT\", \"STUBEHA\", \"TEACHBEHA\", \n",
    "    \"STDTEST\", \"TDTEST\", \"ALLACTIV\", \"BCREATSC\", \"CREENVSC\", \"ACTCRESC\", \"OPENCUL\", \n",
    "    \"PROBSCRI\", \"SCPREPBP\", \"SCPREPAP\", \"DIGPREP\", \n",
    "    \"ESCS\", \"BMMJ1\", \"BFMJ2\", \"EFFORT1\", \"EFFORT2\", \"Option_UH\", \"SC209Q04JA\", \"SC209Q05JA\", \"SC209Q06JA\"\n",
    "]\n",
    "\n",
    "# Drop the columns above\n",
    "model_data = model_data.drop(columns=columns_to_remove, errors='ignore')  # `errors='ignore'` prevents errors if a column isn't found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4552, 1083)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MATH_Proficient</th>\n",
       "      <th>SISCO</th>\n",
       "      <th>ST250Q01JA</th>\n",
       "      <th>ST250Q02JA</th>\n",
       "      <th>ST250Q03JA</th>\n",
       "      <th>ST250Q04JA</th>\n",
       "      <th>ST250Q05JA</th>\n",
       "      <th>ST251Q01JA</th>\n",
       "      <th>ST251Q02JA</th>\n",
       "      <th>ST251Q03JA</th>\n",
       "      <th>ST251Q04JA</th>\n",
       "      <th>ST251Q06JA</th>\n",
       "      <th>ST251Q07JA</th>\n",
       "      <th>ST253Q01JA</th>\n",
       "      <th>ST254Q01JA</th>\n",
       "      <th>ST254Q02JA</th>\n",
       "      <th>ST254Q03JA</th>\n",
       "      <th>ST254Q04JA</th>\n",
       "      <th>ST254Q05JA</th>\n",
       "      <th>ST254Q06JA</th>\n",
       "      <th>ST255Q01JA</th>\n",
       "      <th>ST256Q01JA</th>\n",
       "      <th>ST256Q02JA</th>\n",
       "      <th>ST256Q03JA</th>\n",
       "      <th>ST256Q06JA</th>\n",
       "      <th>ST256Q07JA</th>\n",
       "      <th>ST256Q08JA</th>\n",
       "      <th>ST256Q09JA</th>\n",
       "      <th>ST256Q10JA</th>\n",
       "      <th>ST267Q01JA</th>\n",
       "      <th>ST267Q02JA</th>\n",
       "      <th>ST267Q03JA</th>\n",
       "      <th>ST267Q04JA</th>\n",
       "      <th>ST267Q05JA</th>\n",
       "      <th>ST267Q06JA</th>\n",
       "      <th>ST267Q07JA</th>\n",
       "      <th>ST267Q08JA</th>\n",
       "      <th>ST034Q01TA</th>\n",
       "      <th>ST034Q02TA</th>\n",
       "      <th>ST034Q03TA</th>\n",
       "      <th>ST034Q04TA</th>\n",
       "      <th>ST034Q05TA</th>\n",
       "      <th>ST034Q06TA</th>\n",
       "      <th>ST038Q03NA</th>\n",
       "      <th>ST038Q04NA</th>\n",
       "      <th>ST038Q05NA</th>\n",
       "      <th>ST038Q06NA</th>\n",
       "      <th>ST038Q07NA</th>\n",
       "      <th>ST038Q08NA</th>\n",
       "      <th>ST038Q09JA</th>\n",
       "      <th>ST038Q10JA</th>\n",
       "      <th>ST038Q11JA</th>\n",
       "      <th>ST265Q01JA</th>\n",
       "      <th>ST265Q02JA</th>\n",
       "      <th>ST265Q03JA</th>\n",
       "      <th>ST265Q04JA</th>\n",
       "      <th>ST266Q01JA</th>\n",
       "      <th>ST266Q02JA</th>\n",
       "      <th>ST266Q03JA</th>\n",
       "      <th>ST266Q04JA</th>\n",
       "      <th>ST266Q05JA</th>\n",
       "      <th>ST307Q01JA</th>\n",
       "      <th>ST307Q02JA</th>\n",
       "      <th>ST307Q03JA</th>\n",
       "      <th>ST307Q04JA</th>\n",
       "      <th>ST307Q05JA</th>\n",
       "      <th>ST307Q06JA</th>\n",
       "      <th>ST307Q07JA</th>\n",
       "      <th>ST307Q08JA</th>\n",
       "      <th>ST307Q09JA</th>\n",
       "      <th>ST307Q10JA</th>\n",
       "      <th>ST301Q01JA</th>\n",
       "      <th>ST301Q02JA</th>\n",
       "      <th>ST301Q03JA</th>\n",
       "      <th>ST301Q04JA</th>\n",
       "      <th>ST301Q05JA</th>\n",
       "      <th>ST301Q06JA</th>\n",
       "      <th>ST301Q07JA</th>\n",
       "      <th>ST301Q08JA</th>\n",
       "      <th>ST301Q09JA</th>\n",
       "      <th>ST301Q10JA</th>\n",
       "      <th>ST343Q01JA</th>\n",
       "      <th>ST343Q02JA</th>\n",
       "      <th>ST343Q03JA</th>\n",
       "      <th>ST343Q04JA</th>\n",
       "      <th>ST343Q05JA</th>\n",
       "      <th>ST343Q06JA</th>\n",
       "      <th>ST343Q07JA</th>\n",
       "      <th>ST343Q08JA</th>\n",
       "      <th>ST343Q09JA</th>\n",
       "      <th>ST343Q10JA</th>\n",
       "      <th>ST311Q01JA</th>\n",
       "      <th>ST311Q02JA</th>\n",
       "      <th>ST311Q03JA</th>\n",
       "      <th>ST311Q04JA</th>\n",
       "      <th>ST311Q05JA</th>\n",
       "      <th>ST311Q06JA</th>\n",
       "      <th>ST311Q07JA</th>\n",
       "      <th>ST311Q08JA</th>\n",
       "      <th>ST311Q09JA</th>\n",
       "      <th>ST311Q10JA</th>\n",
       "      <th>ST305Q01JA</th>\n",
       "      <th>ST305Q02JA</th>\n",
       "      <th>ST305Q03JA</th>\n",
       "      <th>ST305Q04JA</th>\n",
       "      <th>ST305Q05JA</th>\n",
       "      <th>ST305Q06JA</th>\n",
       "      <th>ST305Q07JA</th>\n",
       "      <th>ST305Q08JA</th>\n",
       "      <th>ST305Q09JA</th>\n",
       "      <th>ST305Q10JA</th>\n",
       "      <th>ST345Q01JA</th>\n",
       "      <th>ST345Q02JA</th>\n",
       "      <th>ST345Q03JA</th>\n",
       "      <th>ST345Q04JA</th>\n",
       "      <th>ST345Q05JA</th>\n",
       "      <th>ST345Q06JA</th>\n",
       "      <th>ST345Q07JA</th>\n",
       "      <th>ST345Q08JA</th>\n",
       "      <th>ST345Q09JA</th>\n",
       "      <th>ST345Q10JA</th>\n",
       "      <th>ST313Q01JA</th>\n",
       "      <th>ST313Q02JA</th>\n",
       "      <th>ST313Q03JA</th>\n",
       "      <th>ST313Q04JA</th>\n",
       "      <th>ST313Q05JA</th>\n",
       "      <th>ST313Q06JA</th>\n",
       "      <th>ST313Q07JA</th>\n",
       "      <th>ST313Q08JA</th>\n",
       "      <th>ST313Q09JA</th>\n",
       "      <th>ST313Q10JA</th>\n",
       "      <th>ST263Q02JA</th>\n",
       "      <th>ST263Q04JA</th>\n",
       "      <th>ST263Q06JA</th>\n",
       "      <th>ST263Q08JA</th>\n",
       "      <th>ST273Q01JA</th>\n",
       "      <th>ST273Q02JA</th>\n",
       "      <th>ST273Q03JA</th>\n",
       "      <th>ST273Q04JA</th>\n",
       "      <th>ST273Q05JA</th>\n",
       "      <th>ST273Q06JA</th>\n",
       "      <th>ST273Q07JA</th>\n",
       "      <th>ST270Q01JA</th>\n",
       "      <th>ST270Q02JA</th>\n",
       "      <th>ST270Q03JA</th>\n",
       "      <th>ST270Q04JA</th>\n",
       "      <th>ST285Q01JA</th>\n",
       "      <th>ST285Q02JA</th>\n",
       "      <th>ST285Q03JA</th>\n",
       "      <th>ST285Q04JA</th>\n",
       "      <th>ST285Q05JA</th>\n",
       "      <th>ST285Q06JA</th>\n",
       "      <th>ST285Q07JA</th>\n",
       "      <th>ST285Q08JA</th>\n",
       "      <th>ST285Q09JA</th>\n",
       "      <th>ST283Q01JA</th>\n",
       "      <th>ST283Q02JA</th>\n",
       "      <th>ST283Q03JA</th>\n",
       "      <th>ST283Q04JA</th>\n",
       "      <th>ST283Q05JA</th>\n",
       "      <th>ST283Q06JA</th>\n",
       "      <th>ST283Q07JA</th>\n",
       "      <th>ST283Q08JA</th>\n",
       "      <th>ST283Q09JA</th>\n",
       "      <th>ST275Q01WA</th>\n",
       "      <th>ST275Q02WA</th>\n",
       "      <th>ST275Q03WA</th>\n",
       "      <th>ST275Q04WA</th>\n",
       "      <th>ST275Q05WA</th>\n",
       "      <th>ST275Q06WA</th>\n",
       "      <th>ST275Q07WA</th>\n",
       "      <th>ST275Q08WA</th>\n",
       "      <th>ST275Q09WA</th>\n",
       "      <th>ST276Q01JA</th>\n",
       "      <th>ST276Q02JA</th>\n",
       "      <th>ST276Q03JA</th>\n",
       "      <th>ST276Q04JA</th>\n",
       "      <th>ST276Q05JA</th>\n",
       "      <th>ST276Q06JA</th>\n",
       "      <th>ST276Q07JA</th>\n",
       "      <th>ST276Q08JA</th>\n",
       "      <th>ST276Q09JA</th>\n",
       "      <th>ST276Q10JA</th>\n",
       "      <th>ST290Q01WA</th>\n",
       "      <th>ST290Q02WA</th>\n",
       "      <th>ST290Q03WA</th>\n",
       "      <th>ST290Q04WA</th>\n",
       "      <th>ST290Q05WA</th>\n",
       "      <th>ST290Q06WA</th>\n",
       "      <th>ST290Q07WA</th>\n",
       "      <th>ST290Q08WA</th>\n",
       "      <th>ST290Q09WA</th>\n",
       "      <th>ST291Q01JA</th>\n",
       "      <th>ST291Q02JA</th>\n",
       "      <th>ST291Q03JA</th>\n",
       "      <th>ST291Q04JA</th>\n",
       "      <th>ST291Q05JA</th>\n",
       "      <th>ST291Q06JA</th>\n",
       "      <th>ST291Q07JA</th>\n",
       "      <th>ST291Q08JA</th>\n",
       "      <th>ST291Q09JA</th>\n",
       "      <th>ST291Q10JA</th>\n",
       "      <th>ST289Q01WA</th>\n",
       "      <th>ST289Q02JA</th>\n",
       "      <th>ST289Q04JA</th>\n",
       "      <th>ST289Q05WA</th>\n",
       "      <th>ST289Q06JA</th>\n",
       "      <th>ST289Q07JA</th>\n",
       "      <th>ST289Q08WA</th>\n",
       "      <th>ST289Q09WA</th>\n",
       "      <th>ST289Q10WA</th>\n",
       "      <th>ST289Q14JA</th>\n",
       "      <th>ST293Q01JA</th>\n",
       "      <th>ST293Q02JA</th>\n",
       "      <th>ST293Q03JA</th>\n",
       "      <th>ST293Q05JA</th>\n",
       "      <th>ST293Q06JA</th>\n",
       "      <th>ST293Q07JA</th>\n",
       "      <th>ST293Q08JA</th>\n",
       "      <th>ST293Q09JA</th>\n",
       "      <th>ST292Q01JA</th>\n",
       "      <th>ST292Q02JA</th>\n",
       "      <th>ST292Q03JA</th>\n",
       "      <th>ST292Q04JA</th>\n",
       "      <th>ST292Q05JA</th>\n",
       "      <th>ST292Q06JA</th>\n",
       "      <th>ST334Q01JA</th>\n",
       "      <th>ST334Q02JA</th>\n",
       "      <th>ST334Q03JA</th>\n",
       "      <th>ST334Q04JA</th>\n",
       "      <th>ST334Q05JA</th>\n",
       "      <th>ST334Q06JA</th>\n",
       "      <th>ST334Q07JA</th>\n",
       "      <th>ST334Q08JA</th>\n",
       "      <th>ST334Q09JA</th>\n",
       "      <th>ST334Q10JA</th>\n",
       "      <th>ST335Q01JA</th>\n",
       "      <th>ST335Q02JA</th>\n",
       "      <th>ST335Q03JA</th>\n",
       "      <th>ST335Q05JA</th>\n",
       "      <th>ST335Q06JA</th>\n",
       "      <th>ST335Q07JA</th>\n",
       "      <th>ST336Q01JA</th>\n",
       "      <th>ST336Q03JA</th>\n",
       "      <th>ST336Q04JA</th>\n",
       "      <th>ST336Q05JA</th>\n",
       "      <th>ST336Q06JA</th>\n",
       "      <th>ST336Q07JA</th>\n",
       "      <th>ST337Q01JA</th>\n",
       "      <th>ST337Q02JA</th>\n",
       "      <th>...</th>\n",
       "      <th>ST349Q01JA_2</th>\n",
       "      <th>ST349Q01JA_3</th>\n",
       "      <th>ST349Q01JA_4</th>\n",
       "      <th>ST349Q01JA_0</th>\n",
       "      <th>LANGN_105</th>\n",
       "      <th>LANGN_108</th>\n",
       "      <th>LANGN_118</th>\n",
       "      <th>LANGN_140</th>\n",
       "      <th>LANGN_148</th>\n",
       "      <th>LANGN_150</th>\n",
       "      <th>LANGN_156</th>\n",
       "      <th>LANGN_200</th>\n",
       "      <th>LANGN_204</th>\n",
       "      <th>LANGN_232</th>\n",
       "      <th>LANGN_273</th>\n",
       "      <th>LANGN_313</th>\n",
       "      <th>LANGN_316</th>\n",
       "      <th>LANGN_322</th>\n",
       "      <th>LANGN_329</th>\n",
       "      <th>LANGN_344</th>\n",
       "      <th>LANGN_351</th>\n",
       "      <th>LANGN_415</th>\n",
       "      <th>LANGN_463</th>\n",
       "      <th>LANGN_493</th>\n",
       "      <th>LANGN_496</th>\n",
       "      <th>LANGN_500</th>\n",
       "      <th>LANGN_520</th>\n",
       "      <th>LANGN_531</th>\n",
       "      <th>LANGN_602</th>\n",
       "      <th>LANGN_606</th>\n",
       "      <th>LANGN_615</th>\n",
       "      <th>LANGN_621</th>\n",
       "      <th>LANGN_625</th>\n",
       "      <th>LANGN_640</th>\n",
       "      <th>LANGN_641</th>\n",
       "      <th>LANGN_663</th>\n",
       "      <th>LANGN_669</th>\n",
       "      <th>LANGN_670</th>\n",
       "      <th>LANGN_800</th>\n",
       "      <th>LANGN_801</th>\n",
       "      <th>LANGN_802</th>\n",
       "      <th>LANGN_804</th>\n",
       "      <th>LANGN_805</th>\n",
       "      <th>LANGN_806</th>\n",
       "      <th>LANGN_807</th>\n",
       "      <th>LANGN_808</th>\n",
       "      <th>LANGN_865</th>\n",
       "      <th>LANGN_892</th>\n",
       "      <th>LANGN_895</th>\n",
       "      <th>LANGN_917</th>\n",
       "      <th>SC177Q01JA_1</th>\n",
       "      <th>SC177Q01JA_2</th>\n",
       "      <th>SC177Q01JA_3</th>\n",
       "      <th>SC177Q02JA_1</th>\n",
       "      <th>SC177Q02JA_2</th>\n",
       "      <th>SC177Q02JA_3</th>\n",
       "      <th>SC177Q03JA_1</th>\n",
       "      <th>SC177Q03JA_2</th>\n",
       "      <th>SC177Q03JA_3</th>\n",
       "      <th>MATHEXC_0</th>\n",
       "      <th>MATHEXC_1</th>\n",
       "      <th>MATHEXC_2</th>\n",
       "      <th>MATHEXC_3</th>\n",
       "      <th>SCHLTYPE_1</th>\n",
       "      <th>SCHLTYPE_2</th>\n",
       "      <th>SCHLTYPE_3</th>\n",
       "      <th>LANGN_121</th>\n",
       "      <th>LANGN_130</th>\n",
       "      <th>LANGN_137</th>\n",
       "      <th>LANGN_170</th>\n",
       "      <th>LANGN_244</th>\n",
       "      <th>LANGN_258</th>\n",
       "      <th>LANGN_263</th>\n",
       "      <th>LANGN_264</th>\n",
       "      <th>LANGN_266</th>\n",
       "      <th>LANGN_317</th>\n",
       "      <th>LANGN_340</th>\n",
       "      <th>LANGN_369</th>\n",
       "      <th>LANGN_381</th>\n",
       "      <th>LANGN_404</th>\n",
       "      <th>LANGN_420</th>\n",
       "      <th>LANGN_449</th>\n",
       "      <th>LANGN_467</th>\n",
       "      <th>LANGN_494</th>\n",
       "      <th>LANGN_495</th>\n",
       "      <th>LANGN_514</th>\n",
       "      <th>LANGN_523</th>\n",
       "      <th>LANGN_529</th>\n",
       "      <th>LANGN_540</th>\n",
       "      <th>LANGN_547</th>\n",
       "      <th>LANGN_600</th>\n",
       "      <th>LANGN_607</th>\n",
       "      <th>LANGN_618</th>\n",
       "      <th>LANGN_619</th>\n",
       "      <th>LANGN_630</th>\n",
       "      <th>LANGN_635</th>\n",
       "      <th>LANGN_650</th>\n",
       "      <th>LANGN_661</th>\n",
       "      <th>LANGN_673</th>\n",
       "      <th>LANGN_674</th>\n",
       "      <th>LANGN_809</th>\n",
       "      <th>LANGN_810</th>\n",
       "      <th>LANGN_811</th>\n",
       "      <th>LANGN_812</th>\n",
       "      <th>LANGN_813</th>\n",
       "      <th>LANGN_814</th>\n",
       "      <th>LANGN_815</th>\n",
       "      <th>LANGN_816</th>\n",
       "      <th>LANGN_818</th>\n",
       "      <th>LANGN_832</th>\n",
       "      <th>LANGN_868</th>\n",
       "      <th>LANGN_870</th>\n",
       "      <th>LANGN_920</th>\n",
       "      <th>LANGN_921</th>\n",
       "      <th>LANGN_113</th>\n",
       "      <th>LANGN_147</th>\n",
       "      <th>LANGN_275</th>\n",
       "      <th>LANGN_286</th>\n",
       "      <th>LANGN_363</th>\n",
       "      <th>LANGN_422</th>\n",
       "      <th>LANGN_434</th>\n",
       "      <th>LANGN_442</th>\n",
       "      <th>LANGN_471</th>\n",
       "      <th>LANGN_611</th>\n",
       "      <th>LANGN_614</th>\n",
       "      <th>LANGN_624</th>\n",
       "      <th>LANGN_642</th>\n",
       "      <th>LANGN_675</th>\n",
       "      <th>LANGN_676</th>\n",
       "      <th>LANGN_677</th>\n",
       "      <th>LANGN_678</th>\n",
       "      <th>LANGN_817</th>\n",
       "      <th>LANGN_819</th>\n",
       "      <th>LANGN_821</th>\n",
       "      <th>LANGN_823</th>\n",
       "      <th>LANGN_824</th>\n",
       "      <th>LANGN_825</th>\n",
       "      <th>LANGN_826</th>\n",
       "      <th>LANGN_827</th>\n",
       "      <th>LANGN_828</th>\n",
       "      <th>LANGN_885</th>\n",
       "      <th>LANGN_896</th>\n",
       "      <th>LANGN_916</th>\n",
       "      <th>LANGN_112</th>\n",
       "      <th>LANGN_154</th>\n",
       "      <th>LANGN_202</th>\n",
       "      <th>LANGN_246</th>\n",
       "      <th>LANGN_254</th>\n",
       "      <th>LANGN_272</th>\n",
       "      <th>LANGN_301</th>\n",
       "      <th>LANGN_325</th>\n",
       "      <th>LANGN_338</th>\n",
       "      <th>LANGN_358</th>\n",
       "      <th>LANGN_371</th>\n",
       "      <th>LANGN_375</th>\n",
       "      <th>LANGN_383</th>\n",
       "      <th>LANGN_409</th>\n",
       "      <th>LANGN_428</th>\n",
       "      <th>LANGN_465</th>\n",
       "      <th>LANGN_517</th>\n",
       "      <th>LANGN_527</th>\n",
       "      <th>LANGN_561</th>\n",
       "      <th>LANGN_562</th>\n",
       "      <th>LANGN_563</th>\n",
       "      <th>LANGN_565</th>\n",
       "      <th>LANGN_566</th>\n",
       "      <th>LANGN_567</th>\n",
       "      <th>LANGN_601</th>\n",
       "      <th>LANGN_622</th>\n",
       "      <th>LANGN_623</th>\n",
       "      <th>LANGN_628</th>\n",
       "      <th>LANGN_631</th>\n",
       "      <th>LANGN_831</th>\n",
       "      <th>LANGN_833</th>\n",
       "      <th>LANGN_836</th>\n",
       "      <th>LANGN_837</th>\n",
       "      <th>LANGN_838</th>\n",
       "      <th>LANGN_839</th>\n",
       "      <th>LANGN_840</th>\n",
       "      <th>LANGN_841</th>\n",
       "      <th>LANGN_845</th>\n",
       "      <th>LANGN_872</th>\n",
       "      <th>LANGN_873</th>\n",
       "      <th>LANGN_881</th>\n",
       "      <th>LANGN_890</th>\n",
       "      <th>LANGN_897</th>\n",
       "      <th>LANGN_898</th>\n",
       "      <th>LANGN_899</th>\n",
       "      <th>LANGN_900</th>\n",
       "      <th>LANGN_901</th>\n",
       "      <th>LANGN_902</th>\n",
       "      <th>LANGN_903</th>\n",
       "      <th>LANGN_904</th>\n",
       "      <th>LANGN_905</th>\n",
       "      <th>LANGN_906</th>\n",
       "      <th>LANGN_907</th>\n",
       "      <th>LANGN_908</th>\n",
       "      <th>LANGN_909</th>\n",
       "      <th>LANGN_910</th>\n",
       "      <th>LANGN_911</th>\n",
       "      <th>LANGN_912</th>\n",
       "      <th>LANGN_913</th>\n",
       "      <th>LANGN_914</th>\n",
       "      <th>LANGN_918</th>\n",
       "      <th>LANGN_919</th>\n",
       "      <th>LANGN_160</th>\n",
       "      <th>LANGN_327</th>\n",
       "      <th>LANGN_451</th>\n",
       "      <th>LANGN_474</th>\n",
       "      <th>LANGN_503</th>\n",
       "      <th>LANGN_608</th>\n",
       "      <th>LANGN_627</th>\n",
       "      <th>LANGN_639</th>\n",
       "      <th>LANGN_668</th>\n",
       "      <th>LANGN_842</th>\n",
       "      <th>LANGN_843</th>\n",
       "      <th>LANGN_844</th>\n",
       "      <th>LANGN_846</th>\n",
       "      <th>LANGN_849</th>\n",
       "      <th>LANGN_850</th>\n",
       "      <th>LANGN_851</th>\n",
       "      <th>LANGN_852</th>\n",
       "      <th>LANGN_861</th>\n",
       "      <th>LANGN_879</th>\n",
       "      <th>LANGN_133</th>\n",
       "      <th>LANGN_195</th>\n",
       "      <th>LANGN_237</th>\n",
       "      <th>LANGN_379</th>\n",
       "      <th>LANGN_382</th>\n",
       "      <th>LANGN_472</th>\n",
       "      <th>LANGN_492</th>\n",
       "      <th>LANGN_555</th>\n",
       "      <th>LANGN_605</th>\n",
       "      <th>LANGN_616</th>\n",
       "      <th>LANGN_626</th>\n",
       "      <th>LANGN_634</th>\n",
       "      <th>LANGN_648</th>\n",
       "      <th>LANGN_662</th>\n",
       "      <th>LANGN_665</th>\n",
       "      <th>LANGN_666</th>\n",
       "      <th>LANGN_667</th>\n",
       "      <th>LANGN_829</th>\n",
       "      <th>LANGN_854</th>\n",
       "      <th>LANGN_855</th>\n",
       "      <th>LANGN_857</th>\n",
       "      <th>LANGN_859</th>\n",
       "      <th>LANGN_860</th>\n",
       "      <th>LANGN_866</th>\n",
       "      <th>LANGN_877</th>\n",
       "      <th>LANGN_922</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>573394</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573395</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573396</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573397</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573398</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1083 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MATH_Proficient  SISCO  ST250Q01JA  ST250Q02JA  ST250Q03JA  \\\n",
       "573394              1.0    1.0         1.0         1.0         1.0   \n",
       "573395              1.0    0.0         1.0         1.0         1.0   \n",
       "573396              1.0    1.0         1.0         1.0         1.0   \n",
       "573397              1.0    1.0         1.0         1.0         2.0   \n",
       "573398              1.0    1.0         1.0         1.0         1.0   \n",
       "\n",
       "        ST250Q04JA  ST250Q05JA  ST251Q01JA  ST251Q02JA  ST251Q03JA  \\\n",
       "573394         1.0         1.0         4.0         1.0         4.0   \n",
       "573395         1.0         1.0         3.0         1.0         4.0   \n",
       "573396         1.0         1.0         4.0         1.0         4.0   \n",
       "573397         1.0         1.0         3.0         1.0         3.0   \n",
       "573398         1.0         1.0         2.0         1.0         2.0   \n",
       "\n",
       "        ST251Q04JA  ST251Q06JA  ST251Q07JA  ST253Q01JA  ST254Q01JA  \\\n",
       "573394         4.0         4.0         NaN         8.0         2.0   \n",
       "573395         4.0         3.0         NaN         8.0         4.0   \n",
       "573396         4.0         2.0         NaN         8.0         4.0   \n",
       "573397         3.0         1.0         NaN         6.0         2.0   \n",
       "573398         2.0         1.0         NaN         8.0         3.0   \n",
       "\n",
       "        ST254Q02JA  ST254Q03JA  ST254Q04JA  ST254Q05JA  ST254Q06JA  \\\n",
       "573394         2.0         3.0         2.0         2.0         3.0   \n",
       "573395         2.0         2.0         2.0         1.0         3.0   \n",
       "573396         2.0         3.0         2.0         1.0         3.0   \n",
       "573397         2.0         2.0         2.0         1.0         3.0   \n",
       "573398         3.0         4.0         2.0         1.0         4.0   \n",
       "\n",
       "        ST255Q01JA  ST256Q01JA  ST256Q02JA  ST256Q03JA  ST256Q06JA  \\\n",
       "573394         5.0         3.0         2.0         2.0         1.0   \n",
       "573395         4.0         NaN         NaN         NaN         NaN   \n",
       "573396         6.0         2.0         2.0         3.0         3.0   \n",
       "573397         2.0         1.0         1.0         1.0         2.0   \n",
       "573398         2.0         2.0         NaN         NaN         NaN   \n",
       "\n",
       "        ST256Q07JA  ST256Q08JA  ST256Q09JA  ST256Q10JA  ST267Q01JA  \\\n",
       "573394         2.0         2.0         2.0         2.0         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         3.0   \n",
       "573396         2.0         2.0         1.0         2.0         3.0   \n",
       "573397         2.0         1.0         1.0         1.0         3.0   \n",
       "573398         NaN         NaN         NaN         2.0         NaN   \n",
       "\n",
       "        ST267Q02JA  ST267Q03JA  ST267Q04JA  ST267Q05JA  ST267Q06JA  \\\n",
       "573394         NaN         3.0         2.0         3.0         3.0   \n",
       "573395         NaN         3.0         NaN         3.0         3.0   \n",
       "573396         NaN         3.0         1.0         3.0         3.0   \n",
       "573397         NaN         2.0         1.0         NaN         NaN   \n",
       "573398         3.0         3.0         NaN         3.0         4.0   \n",
       "\n",
       "        ST267Q07JA  ST267Q08JA  ST034Q01TA  ST034Q02TA  ST034Q03TA  \\\n",
       "573394         3.0         NaN         3.0         NaN         2.0   \n",
       "573395         NaN         2.0         4.0         2.0         2.0   \n",
       "573396         NaN         NaN         3.0         2.0         2.0   \n",
       "573397         3.0         2.0         3.0         2.0         3.0   \n",
       "573398         4.0         NaN         4.0         1.0         1.0   \n",
       "\n",
       "        ST034Q04TA  ST034Q05TA  ST034Q06TA  ST038Q03NA  ST038Q04NA  \\\n",
       "573394         3.0         2.0         3.0         1.0         1.0   \n",
       "573395         4.0         2.0         NaN         1.0         1.0   \n",
       "573396         3.0         NaN         3.0         1.0         1.0   \n",
       "573397         NaN         2.0         3.0         1.0         2.0   \n",
       "573398         NaN         1.0         4.0         1.0         3.0   \n",
       "\n",
       "        ST038Q05NA  ST038Q06NA  ST038Q07NA  ST038Q08NA  ST038Q09JA  \\\n",
       "573394         1.0         1.0         1.0         1.0         1.0   \n",
       "573395         1.0         1.0         1.0         1.0         1.0   \n",
       "573396         1.0         1.0         1.0         1.0         1.0   \n",
       "573397         2.0         1.0         2.0         2.0         1.0   \n",
       "573398         1.0         1.0         1.0         1.0         1.0   \n",
       "\n",
       "        ST038Q10JA  ST038Q11JA  ST265Q01JA  ST265Q02JA  ST265Q03JA  \\\n",
       "573394         1.0         1.0         2.0         2.0         2.0   \n",
       "573395         1.0         1.0         4.0         4.0         4.0   \n",
       "573396         1.0         1.0         2.0         2.0         2.0   \n",
       "573397         1.0         1.0         2.0         2.0         2.0   \n",
       "573398         1.0         1.0         1.0         1.0         1.0   \n",
       "\n",
       "        ST265Q04JA  ST266Q01JA  ST266Q02JA  ST266Q03JA  ST266Q04JA  \\\n",
       "573394         2.0         2.0         2.0         2.0         2.0   \n",
       "573395         4.0         2.0         2.0         2.0         2.0   \n",
       "573396         2.0         2.0         2.0         2.0         1.0   \n",
       "573397         2.0         1.0         1.0         2.0         1.0   \n",
       "573398         1.0         2.0         2.0         2.0         2.0   \n",
       "\n",
       "        ST266Q05JA  ST307Q01JA  ST307Q02JA  ST307Q03JA  ST307Q04JA  \\\n",
       "573394         2.0         NaN         NaN         NaN         NaN   \n",
       "573395         2.0         NaN         NaN         NaN         NaN   \n",
       "573396         2.0         NaN         NaN         NaN         NaN   \n",
       "573397         2.0         NaN         NaN         NaN         NaN   \n",
       "573398         2.0         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST307Q05JA  ST307Q06JA  ST307Q07JA  ST307Q08JA  ST307Q09JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST307Q10JA  ST301Q01JA  ST301Q02JA  ST301Q03JA  ST301Q04JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST301Q05JA  ST301Q06JA  ST301Q07JA  ST301Q08JA  ST301Q09JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST301Q10JA  ST343Q01JA  ST343Q02JA  ST343Q03JA  ST343Q04JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST343Q05JA  ST343Q06JA  ST343Q07JA  ST343Q08JA  ST343Q09JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST343Q10JA  ST311Q01JA  ST311Q02JA  ST311Q03JA  ST311Q04JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST311Q05JA  ST311Q06JA  ST311Q07JA  ST311Q08JA  ST311Q09JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST311Q10JA  ST305Q01JA  ST305Q02JA  ST305Q03JA  ST305Q04JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST305Q05JA  ST305Q06JA  ST305Q07JA  ST305Q08JA  ST305Q09JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST305Q10JA  ST345Q01JA  ST345Q02JA  ST345Q03JA  ST345Q04JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST345Q05JA  ST345Q06JA  ST345Q07JA  ST345Q08JA  ST345Q09JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST345Q10JA  ST313Q01JA  ST313Q02JA  ST313Q03JA  ST313Q04JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST313Q05JA  ST313Q06JA  ST313Q07JA  ST313Q08JA  ST313Q09JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST313Q10JA  ST263Q02JA  ST263Q04JA  ST263Q06JA  ST263Q08JA  \\\n",
       "573394         NaN         1.0         3.0         3.0         NaN   \n",
       "573395         NaN         2.0         3.0         2.0         NaN   \n",
       "573396         NaN         1.0         3.0         2.0         NaN   \n",
       "573397         NaN         3.0         3.0         3.0         NaN   \n",
       "573398         NaN         2.0         2.0         2.0         NaN   \n",
       "\n",
       "        ST273Q01JA  ST273Q02JA  ST273Q03JA  ST273Q04JA  ST273Q05JA  \\\n",
       "573394         3.0         3.0         NaN         3.0         NaN   \n",
       "573395         3.0         4.0         4.0         3.0         4.0   \n",
       "573396         NaN         4.0         4.0         NaN         3.0   \n",
       "573397         1.0         NaN         1.0         1.0         NaN   \n",
       "573398         NaN         NaN         4.0         4.0         4.0   \n",
       "\n",
       "        ST273Q06JA  ST273Q07JA  ST270Q01JA  ST270Q02JA  ST270Q03JA  \\\n",
       "573394         4.0         4.0         1.0         1.0         1.0   \n",
       "573395         NaN         NaN         2.0         1.0         1.0   \n",
       "573396         3.0         3.0         2.0         2.0         1.0   \n",
       "573397         1.0         1.0         3.0         3.0         3.0   \n",
       "573398         4.0         4.0         2.0         1.0         1.0   \n",
       "\n",
       "        ST270Q04JA  ST285Q01JA  ST285Q02JA  ST285Q03JA  ST285Q04JA  \\\n",
       "573394         2.0         NaN         3.0         NaN         NaN   \n",
       "573395         2.0         NaN         NaN         1.0         1.0   \n",
       "573396         2.0         3.0         4.0         NaN         4.0   \n",
       "573397         3.0         2.0         3.0         3.0         3.0   \n",
       "573398         2.0         NaN         5.0         NaN         NaN   \n",
       "\n",
       "        ST285Q05JA  ST285Q06JA  ST285Q07JA  ST285Q08JA  ST285Q09JA  \\\n",
       "573394         4.0         2.0         2.0         NaN         4.0   \n",
       "573395         1.0         NaN         3.0         2.0         NaN   \n",
       "573396         4.0         2.0         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         2.0         NaN         NaN   \n",
       "573398         2.0         4.0         NaN         2.0         5.0   \n",
       "\n",
       "        ST283Q01JA  ST283Q02JA  ST283Q03JA  ST283Q04JA  ST283Q05JA  \\\n",
       "573394         1.0         NaN         4.0         NaN         4.0   \n",
       "573395         NaN         NaN         NaN         2.0         2.0   \n",
       "573396         2.0         NaN         5.0         NaN         NaN   \n",
       "573397         NaN         NaN         3.0         NaN         3.0   \n",
       "573398         NaN         1.0         2.0         4.0         NaN   \n",
       "\n",
       "        ST283Q06JA  ST283Q07JA  ST283Q08JA  ST283Q09JA  ST275Q01WA  \\\n",
       "573394         NaN         NaN         1.0         1.0         NaN   \n",
       "573395         1.0         1.0         NaN         1.0         4.0   \n",
       "573396         2.0         4.0         NaN         4.0         NaN   \n",
       "573397         3.0         2.0         NaN         2.0         3.0   \n",
       "573398         1.0         NaN         1.0         NaN         NaN   \n",
       "\n",
       "        ST275Q02WA  ST275Q03WA  ST275Q04WA  ST275Q05WA  ST275Q06WA  \\\n",
       "573394         NaN         3.0         NaN         4.0         NaN   \n",
       "573395         4.0         NaN         NaN         2.0         NaN   \n",
       "573396         3.0         2.0         NaN         1.0         NaN   \n",
       "573397         NaN         3.0         3.0         NaN         NaN   \n",
       "573398         4.0         4.0         NaN         3.0         NaN   \n",
       "\n",
       "        ST275Q07WA  ST275Q08WA  ST275Q09WA  ST276Q01JA  ST276Q02JA  \\\n",
       "573394         4.0         4.0         4.0         2.0         NaN   \n",
       "573395         2.0         4.0         NaN         1.0         NaN   \n",
       "573396         1.0         4.0         NaN         NaN         NaN   \n",
       "573397         NaN         3.0         NaN         NaN         2.0   \n",
       "573398         1.0         NaN         1.0         1.0         NaN   \n",
       "\n",
       "        ST276Q03JA  ST276Q04JA  ST276Q05JA  ST276Q06JA  ST276Q07JA  \\\n",
       "573394         4.0         4.0         NaN         NaN         NaN   \n",
       "573395         4.0         4.0         NaN         NaN         NaN   \n",
       "573396         NaN         2.0         2.0         NaN         NaN   \n",
       "573397         3.0         2.0         NaN         3.0         NaN   \n",
       "573398         4.0         3.0         1.0         NaN         NaN   \n",
       "\n",
       "        ST276Q08JA  ST276Q09JA  ST276Q10JA  ST290Q01WA  ST290Q02WA  \\\n",
       "573394         4.0         4.0         NaN         NaN         3.0   \n",
       "573395         4.0         NaN         1.0         3.0         3.0   \n",
       "573396         4.0         2.0         1.0         2.0         4.0   \n",
       "573397         NaN         NaN         3.0         NaN         2.0   \n",
       "573398         NaN         NaN         1.0         NaN         NaN   \n",
       "\n",
       "        ST290Q03WA  ST290Q04WA  ST290Q05WA  ST290Q06WA  ST290Q07WA  \\\n",
       "573394         3.0         NaN         3.0         NaN         3.0   \n",
       "573395         3.0         NaN         NaN         NaN         3.0   \n",
       "573396         NaN         4.0         NaN         NaN         4.0   \n",
       "573397         NaN         NaN         NaN         1.0         2.0   \n",
       "573398         3.0         3.0         1.0         4.0         1.0   \n",
       "\n",
       "        ST290Q08WA  ST290Q09WA  ST291Q01JA  ST291Q02JA  ST291Q03JA  \\\n",
       "573394         NaN         3.0         NaN         3.0         NaN   \n",
       "573395         NaN         3.0         3.0         NaN         NaN   \n",
       "573396         2.0         NaN         NaN         NaN         4.0   \n",
       "573397         2.0         3.0         NaN         3.0         NaN   \n",
       "573398         NaN         NaN         NaN         2.0         2.0   \n",
       "\n",
       "        ST291Q04JA  ST291Q05JA  ST291Q06JA  ST291Q07JA  ST291Q08JA  \\\n",
       "573394         3.0         NaN         3.0         3.0         NaN   \n",
       "573395         NaN         3.0         3.0         3.0         NaN   \n",
       "573396         3.0         3.0         NaN         4.0         NaN   \n",
       "573397         3.0         NaN         1.0         NaN         3.0   \n",
       "573398         NaN         3.0         NaN         3.0         1.0   \n",
       "\n",
       "        ST291Q09JA  ST291Q10JA  ST289Q01WA  ST289Q02JA  ST289Q04JA  \\\n",
       "573394         NaN         3.0         4.0         4.0         NaN   \n",
       "573395         3.0         NaN         NaN         2.0         4.0   \n",
       "573396         4.0         NaN         5.0         5.0         NaN   \n",
       "573397         NaN         1.0         1.0         3.0         NaN   \n",
       "573398         NaN         NaN         2.0         4.0         NaN   \n",
       "\n",
       "        ST289Q05WA  ST289Q06JA  ST289Q07JA  ST289Q08WA  ST289Q09WA  \\\n",
       "573394         4.0         NaN         4.0         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         2.0         NaN   \n",
       "573396         5.0         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         3.0         3.0         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST289Q10WA  ST289Q14JA  ST293Q01JA  ST293Q02JA  ST293Q03JA  \\\n",
       "573394         NaN         5.0         4.0         4.0         4.0   \n",
       "573395         NaN         NaN         NaN         NaN         4.0   \n",
       "573396         NaN         5.0         NaN         5.0         4.0   \n",
       "573397         NaN         1.0         2.0         4.0         4.0   \n",
       "573398         5.0         NaN         NaN         5.0         5.0   \n",
       "\n",
       "        ST293Q05JA  ST293Q06JA  ST293Q07JA  ST293Q08JA  ST293Q09JA  \\\n",
       "573394         NaN         4.0         NaN         4.0         NaN   \n",
       "573395         2.0         NaN         NaN         3.0         4.0   \n",
       "573396         4.0         NaN         NaN         3.0         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         3.0   \n",
       "573398         5.0         NaN         NaN         5.0         5.0   \n",
       "\n",
       "        ST292Q01JA  ST292Q02JA  ST292Q03JA  ST292Q04JA  ST292Q05JA  \\\n",
       "573394         3.0         1.0         3.0         3.0         3.0   \n",
       "573395         3.0         3.0         3.0         3.0         3.0   \n",
       "573396         NaN         3.0         3.0         4.0         3.0   \n",
       "573397         1.0         1.0         1.0         NaN         1.0   \n",
       "573398         3.0         3.0         NaN         3.0         3.0   \n",
       "\n",
       "        ST292Q06JA  ST334Q01JA  ST334Q02JA  ST334Q03JA  ST334Q04JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         4.0         NaN         NaN         NaN         NaN   \n",
       "573397         1.0         NaN         NaN         NaN         NaN   \n",
       "573398         3.0         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST334Q05JA  ST334Q06JA  ST334Q07JA  ST334Q08JA  ST334Q09JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST334Q10JA  ST335Q01JA  ST335Q02JA  ST335Q03JA  ST335Q05JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST335Q06JA  ST335Q07JA  ST336Q01JA  ST336Q03JA  ST336Q04JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST336Q05JA  ST336Q06JA  ST336Q07JA  ST337Q01JA  ST337Q02JA  ...  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "573395         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "573396         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "573397         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "573398         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "\n",
       "        ST349Q01JA_2  ST349Q01JA_3  ST349Q01JA_4  ST349Q01JA_0  LANGN_105  \\\n",
       "573394             0             0             0             0          0   \n",
       "573395             0             0             0             0          0   \n",
       "573396             0             0             0             0          0   \n",
       "573397             1             0             0             0          0   \n",
       "573398             0             0             1             0          0   \n",
       "\n",
       "        LANGN_108  LANGN_118  LANGN_140  LANGN_148  LANGN_150  LANGN_156  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_200  LANGN_204  LANGN_232  LANGN_273  LANGN_313  LANGN_316  \\\n",
       "573394          0          0          0          0          1          0   \n",
       "573395          0          0          0          0          1          0   \n",
       "573396          0          0          0          0          1          0   \n",
       "573397          0          0          0          0          1          0   \n",
       "573398          0          0          0          0          1          0   \n",
       "\n",
       "        LANGN_322  LANGN_329  LANGN_344  LANGN_351  LANGN_415  LANGN_463  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_493  LANGN_496  LANGN_500  LANGN_520  LANGN_531  LANGN_602  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_606  LANGN_615  LANGN_621  LANGN_625  LANGN_640  LANGN_641  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_663  LANGN_669  LANGN_670  LANGN_800  LANGN_801  LANGN_802  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_804  LANGN_805  LANGN_806  LANGN_807  LANGN_808  LANGN_865  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_892  LANGN_895  LANGN_917  SC177Q01JA_1  SC177Q01JA_2  \\\n",
       "573394          0          0          0             0             0   \n",
       "573395          0          0          0             0             0   \n",
       "573396          0          0          0             1             0   \n",
       "573397          0          0          0             0             1   \n",
       "573398          0          0          0             0             1   \n",
       "\n",
       "        SC177Q01JA_3  SC177Q02JA_1  SC177Q02JA_2  SC177Q02JA_3  SC177Q03JA_1  \\\n",
       "573394             1             0             1             0             0   \n",
       "573395             0             0             0             0             0   \n",
       "573396             0             1             0             0             1   \n",
       "573397             0             0             0             1             0   \n",
       "573398             0             0             1             0             0   \n",
       "\n",
       "        SC177Q03JA_2  SC177Q03JA_3  MATHEXC_0  MATHEXC_1  MATHEXC_2  \\\n",
       "573394             0             0          0          0          0   \n",
       "573395             0             0          0          0          0   \n",
       "573396             0             0          0          0          0   \n",
       "573397             0             1          0          0          0   \n",
       "573398             1             0          0          0          0   \n",
       "\n",
       "        MATHEXC_3  SCHLTYPE_1  SCHLTYPE_2  SCHLTYPE_3  LANGN_121  LANGN_130  \\\n",
       "573394          1           0           0           1          0          0   \n",
       "573395          0           0           0           0          0          0   \n",
       "573396          1           0           0           1          0          0   \n",
       "573397          0           0           0           1          0          0   \n",
       "573398          0           0           0           1          0          0   \n",
       "\n",
       "        LANGN_137  LANGN_170  LANGN_244  LANGN_258  LANGN_263  LANGN_264  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_266  LANGN_317  LANGN_340  LANGN_369  LANGN_381  LANGN_404  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_420  LANGN_449  LANGN_467  LANGN_494  LANGN_495  LANGN_514  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_523  LANGN_529  LANGN_540  LANGN_547  LANGN_600  LANGN_607  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_618  LANGN_619  LANGN_630  LANGN_635  LANGN_650  LANGN_661  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_673  LANGN_674  LANGN_809  LANGN_810  LANGN_811  LANGN_812  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_813  LANGN_814  LANGN_815  LANGN_816  LANGN_818  LANGN_832  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_868  LANGN_870  LANGN_920  LANGN_921  LANGN_113  LANGN_147  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_275  LANGN_286  LANGN_363  LANGN_422  LANGN_434  LANGN_442  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_471  LANGN_611  LANGN_614  LANGN_624  LANGN_642  LANGN_675  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_676  LANGN_677  LANGN_678  LANGN_817  LANGN_819  LANGN_821  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_823  LANGN_824  LANGN_825  LANGN_826  LANGN_827  LANGN_828  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_885  LANGN_896  LANGN_916  LANGN_112  LANGN_154  LANGN_202  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_246  LANGN_254  LANGN_272  LANGN_301  LANGN_325  LANGN_338  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_358  LANGN_371  LANGN_375  LANGN_383  LANGN_409  LANGN_428  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_465  LANGN_517  LANGN_527  LANGN_561  LANGN_562  LANGN_563  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_565  LANGN_566  LANGN_567  LANGN_601  LANGN_622  LANGN_623  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_628  LANGN_631  LANGN_831  LANGN_833  LANGN_836  LANGN_837  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_838  LANGN_839  LANGN_840  LANGN_841  LANGN_845  LANGN_872  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_873  LANGN_881  LANGN_890  LANGN_897  LANGN_898  LANGN_899  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_900  LANGN_901  LANGN_902  LANGN_903  LANGN_904  LANGN_905  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_906  LANGN_907  LANGN_908  LANGN_909  LANGN_910  LANGN_911  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_912  LANGN_913  LANGN_914  LANGN_918  LANGN_919  LANGN_160  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_327  LANGN_451  LANGN_474  LANGN_503  LANGN_608  LANGN_627  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_639  LANGN_668  LANGN_842  LANGN_843  LANGN_844  LANGN_846  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_849  LANGN_850  LANGN_851  LANGN_852  LANGN_861  LANGN_879  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_133  LANGN_195  LANGN_237  LANGN_379  LANGN_382  LANGN_472  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_492  LANGN_555  LANGN_605  LANGN_616  LANGN_626  LANGN_634  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_648  LANGN_662  LANGN_665  LANGN_666  LANGN_667  LANGN_829  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_854  LANGN_855  LANGN_857  LANGN_859  LANGN_860  LANGN_866  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_877  LANGN_922  \n",
       "573394          0          0  \n",
       "573395          0          0  \n",
       "573396          0          0  \n",
       "573397          0          0  \n",
       "573398          0          0  \n",
       "\n",
       "[5 rows x 1083 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model_data.shape)\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker's XGBoost container expects data in the libSVM or CSV data format.  **Note that the first column must be the target variable and the CSV should not include headers.**  Although repetitive, it's easiest to do this after the train|validation|test split rather than before.  This avoids any misalignment issues due to random reordering.\n",
    "* `MATH_Proficient`: Is the student falling behind in Math? (Average of 10 Math plausible values < 420.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students who are NOT proficient in Math:  1607 ( 35.3 %)\n"
     ]
    }
   ],
   "source": [
    "# Get percent of students not proficient in Math\n",
    "proficient_n = (model_data['MATH_Proficient'] == 1).sum()\n",
    "not_proficient_n = (model_data['MATH_Proficient'] == 0).sum()\n",
    "not_proficient_p = round( not_proficient_n / (not_proficient_n + proficient_n) * 100, 1)\n",
    "print(\"Students who are NOT proficient in Math: \", not_proficient_n, \"(\", not_proficient_p, \"%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalance ratio: 1.8\n"
     ]
    }
   ],
   "source": [
    "# Get imbalance ratio \n",
    "not_proficient_pp = not_proficient_n / (not_proficient_n + proficient_n)\n",
    "\n",
    "if not_proficient_pp < 0.5:\n",
    "    imbalance_ratio = (1 - not_proficient_pp) / not_proficient_pp\n",
    "else:\n",
    "    imbalance_ratio = not_proficient_pp / (1 - not_proficient_pp)\n",
    "    \n",
    "print(\"Imbalance ratio:\", round(imbalance_ratio,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4552, 1083)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MATH_Proficient</th>\n",
       "      <th>SISCO</th>\n",
       "      <th>ST250Q01JA</th>\n",
       "      <th>ST250Q02JA</th>\n",
       "      <th>ST250Q03JA</th>\n",
       "      <th>ST250Q04JA</th>\n",
       "      <th>ST250Q05JA</th>\n",
       "      <th>ST251Q01JA</th>\n",
       "      <th>ST251Q02JA</th>\n",
       "      <th>ST251Q03JA</th>\n",
       "      <th>ST251Q04JA</th>\n",
       "      <th>ST251Q06JA</th>\n",
       "      <th>ST251Q07JA</th>\n",
       "      <th>ST253Q01JA</th>\n",
       "      <th>ST254Q01JA</th>\n",
       "      <th>ST254Q02JA</th>\n",
       "      <th>ST254Q03JA</th>\n",
       "      <th>ST254Q04JA</th>\n",
       "      <th>ST254Q05JA</th>\n",
       "      <th>ST254Q06JA</th>\n",
       "      <th>ST255Q01JA</th>\n",
       "      <th>ST256Q01JA</th>\n",
       "      <th>ST256Q02JA</th>\n",
       "      <th>ST256Q03JA</th>\n",
       "      <th>ST256Q06JA</th>\n",
       "      <th>ST256Q07JA</th>\n",
       "      <th>ST256Q08JA</th>\n",
       "      <th>ST256Q09JA</th>\n",
       "      <th>ST256Q10JA</th>\n",
       "      <th>ST267Q01JA</th>\n",
       "      <th>ST267Q02JA</th>\n",
       "      <th>ST267Q03JA</th>\n",
       "      <th>ST267Q04JA</th>\n",
       "      <th>ST267Q05JA</th>\n",
       "      <th>ST267Q06JA</th>\n",
       "      <th>ST267Q07JA</th>\n",
       "      <th>ST267Q08JA</th>\n",
       "      <th>ST034Q01TA</th>\n",
       "      <th>ST034Q02TA</th>\n",
       "      <th>ST034Q03TA</th>\n",
       "      <th>ST034Q04TA</th>\n",
       "      <th>ST034Q05TA</th>\n",
       "      <th>ST034Q06TA</th>\n",
       "      <th>ST038Q03NA</th>\n",
       "      <th>ST038Q04NA</th>\n",
       "      <th>ST038Q05NA</th>\n",
       "      <th>ST038Q06NA</th>\n",
       "      <th>ST038Q07NA</th>\n",
       "      <th>ST038Q08NA</th>\n",
       "      <th>ST038Q09JA</th>\n",
       "      <th>ST038Q10JA</th>\n",
       "      <th>ST038Q11JA</th>\n",
       "      <th>ST265Q01JA</th>\n",
       "      <th>ST265Q02JA</th>\n",
       "      <th>ST265Q03JA</th>\n",
       "      <th>ST265Q04JA</th>\n",
       "      <th>ST266Q01JA</th>\n",
       "      <th>ST266Q02JA</th>\n",
       "      <th>ST266Q03JA</th>\n",
       "      <th>ST266Q04JA</th>\n",
       "      <th>ST266Q05JA</th>\n",
       "      <th>ST307Q01JA</th>\n",
       "      <th>ST307Q02JA</th>\n",
       "      <th>ST307Q03JA</th>\n",
       "      <th>ST307Q04JA</th>\n",
       "      <th>ST307Q05JA</th>\n",
       "      <th>ST307Q06JA</th>\n",
       "      <th>ST307Q07JA</th>\n",
       "      <th>ST307Q08JA</th>\n",
       "      <th>ST307Q09JA</th>\n",
       "      <th>ST307Q10JA</th>\n",
       "      <th>ST301Q01JA</th>\n",
       "      <th>ST301Q02JA</th>\n",
       "      <th>ST301Q03JA</th>\n",
       "      <th>ST301Q04JA</th>\n",
       "      <th>ST301Q05JA</th>\n",
       "      <th>ST301Q06JA</th>\n",
       "      <th>ST301Q07JA</th>\n",
       "      <th>ST301Q08JA</th>\n",
       "      <th>ST301Q09JA</th>\n",
       "      <th>ST301Q10JA</th>\n",
       "      <th>ST343Q01JA</th>\n",
       "      <th>ST343Q02JA</th>\n",
       "      <th>ST343Q03JA</th>\n",
       "      <th>ST343Q04JA</th>\n",
       "      <th>ST343Q05JA</th>\n",
       "      <th>ST343Q06JA</th>\n",
       "      <th>ST343Q07JA</th>\n",
       "      <th>ST343Q08JA</th>\n",
       "      <th>ST343Q09JA</th>\n",
       "      <th>ST343Q10JA</th>\n",
       "      <th>ST311Q01JA</th>\n",
       "      <th>ST311Q02JA</th>\n",
       "      <th>ST311Q03JA</th>\n",
       "      <th>ST311Q04JA</th>\n",
       "      <th>ST311Q05JA</th>\n",
       "      <th>ST311Q06JA</th>\n",
       "      <th>ST311Q07JA</th>\n",
       "      <th>ST311Q08JA</th>\n",
       "      <th>ST311Q09JA</th>\n",
       "      <th>ST311Q10JA</th>\n",
       "      <th>ST305Q01JA</th>\n",
       "      <th>ST305Q02JA</th>\n",
       "      <th>ST305Q03JA</th>\n",
       "      <th>ST305Q04JA</th>\n",
       "      <th>ST305Q05JA</th>\n",
       "      <th>ST305Q06JA</th>\n",
       "      <th>ST305Q07JA</th>\n",
       "      <th>ST305Q08JA</th>\n",
       "      <th>ST305Q09JA</th>\n",
       "      <th>ST305Q10JA</th>\n",
       "      <th>ST345Q01JA</th>\n",
       "      <th>ST345Q02JA</th>\n",
       "      <th>ST345Q03JA</th>\n",
       "      <th>ST345Q04JA</th>\n",
       "      <th>ST345Q05JA</th>\n",
       "      <th>ST345Q06JA</th>\n",
       "      <th>ST345Q07JA</th>\n",
       "      <th>ST345Q08JA</th>\n",
       "      <th>ST345Q09JA</th>\n",
       "      <th>ST345Q10JA</th>\n",
       "      <th>ST313Q01JA</th>\n",
       "      <th>ST313Q02JA</th>\n",
       "      <th>ST313Q03JA</th>\n",
       "      <th>ST313Q04JA</th>\n",
       "      <th>ST313Q05JA</th>\n",
       "      <th>ST313Q06JA</th>\n",
       "      <th>ST313Q07JA</th>\n",
       "      <th>ST313Q08JA</th>\n",
       "      <th>ST313Q09JA</th>\n",
       "      <th>ST313Q10JA</th>\n",
       "      <th>ST263Q02JA</th>\n",
       "      <th>ST263Q04JA</th>\n",
       "      <th>ST263Q06JA</th>\n",
       "      <th>ST263Q08JA</th>\n",
       "      <th>ST273Q01JA</th>\n",
       "      <th>ST273Q02JA</th>\n",
       "      <th>ST273Q03JA</th>\n",
       "      <th>ST273Q04JA</th>\n",
       "      <th>ST273Q05JA</th>\n",
       "      <th>ST273Q06JA</th>\n",
       "      <th>ST273Q07JA</th>\n",
       "      <th>ST270Q01JA</th>\n",
       "      <th>ST270Q02JA</th>\n",
       "      <th>ST270Q03JA</th>\n",
       "      <th>ST270Q04JA</th>\n",
       "      <th>ST285Q01JA</th>\n",
       "      <th>ST285Q02JA</th>\n",
       "      <th>ST285Q03JA</th>\n",
       "      <th>ST285Q04JA</th>\n",
       "      <th>ST285Q05JA</th>\n",
       "      <th>ST285Q06JA</th>\n",
       "      <th>ST285Q07JA</th>\n",
       "      <th>ST285Q08JA</th>\n",
       "      <th>ST285Q09JA</th>\n",
       "      <th>ST283Q01JA</th>\n",
       "      <th>ST283Q02JA</th>\n",
       "      <th>ST283Q03JA</th>\n",
       "      <th>ST283Q04JA</th>\n",
       "      <th>ST283Q05JA</th>\n",
       "      <th>ST283Q06JA</th>\n",
       "      <th>ST283Q07JA</th>\n",
       "      <th>ST283Q08JA</th>\n",
       "      <th>ST283Q09JA</th>\n",
       "      <th>ST275Q01WA</th>\n",
       "      <th>ST275Q02WA</th>\n",
       "      <th>ST275Q03WA</th>\n",
       "      <th>ST275Q04WA</th>\n",
       "      <th>ST275Q05WA</th>\n",
       "      <th>ST275Q06WA</th>\n",
       "      <th>ST275Q07WA</th>\n",
       "      <th>ST275Q08WA</th>\n",
       "      <th>ST275Q09WA</th>\n",
       "      <th>ST276Q01JA</th>\n",
       "      <th>ST276Q02JA</th>\n",
       "      <th>ST276Q03JA</th>\n",
       "      <th>ST276Q04JA</th>\n",
       "      <th>ST276Q05JA</th>\n",
       "      <th>ST276Q06JA</th>\n",
       "      <th>ST276Q07JA</th>\n",
       "      <th>ST276Q08JA</th>\n",
       "      <th>ST276Q09JA</th>\n",
       "      <th>ST276Q10JA</th>\n",
       "      <th>ST290Q01WA</th>\n",
       "      <th>ST290Q02WA</th>\n",
       "      <th>ST290Q03WA</th>\n",
       "      <th>ST290Q04WA</th>\n",
       "      <th>ST290Q05WA</th>\n",
       "      <th>ST290Q06WA</th>\n",
       "      <th>ST290Q07WA</th>\n",
       "      <th>ST290Q08WA</th>\n",
       "      <th>ST290Q09WA</th>\n",
       "      <th>ST291Q01JA</th>\n",
       "      <th>ST291Q02JA</th>\n",
       "      <th>ST291Q03JA</th>\n",
       "      <th>ST291Q04JA</th>\n",
       "      <th>ST291Q05JA</th>\n",
       "      <th>ST291Q06JA</th>\n",
       "      <th>ST291Q07JA</th>\n",
       "      <th>ST291Q08JA</th>\n",
       "      <th>ST291Q09JA</th>\n",
       "      <th>ST291Q10JA</th>\n",
       "      <th>ST289Q01WA</th>\n",
       "      <th>ST289Q02JA</th>\n",
       "      <th>ST289Q04JA</th>\n",
       "      <th>ST289Q05WA</th>\n",
       "      <th>ST289Q06JA</th>\n",
       "      <th>ST289Q07JA</th>\n",
       "      <th>ST289Q08WA</th>\n",
       "      <th>ST289Q09WA</th>\n",
       "      <th>ST289Q10WA</th>\n",
       "      <th>ST289Q14JA</th>\n",
       "      <th>ST293Q01JA</th>\n",
       "      <th>ST293Q02JA</th>\n",
       "      <th>ST293Q03JA</th>\n",
       "      <th>ST293Q05JA</th>\n",
       "      <th>ST293Q06JA</th>\n",
       "      <th>ST293Q07JA</th>\n",
       "      <th>ST293Q08JA</th>\n",
       "      <th>ST293Q09JA</th>\n",
       "      <th>ST292Q01JA</th>\n",
       "      <th>ST292Q02JA</th>\n",
       "      <th>ST292Q03JA</th>\n",
       "      <th>ST292Q04JA</th>\n",
       "      <th>ST292Q05JA</th>\n",
       "      <th>ST292Q06JA</th>\n",
       "      <th>ST334Q01JA</th>\n",
       "      <th>ST334Q02JA</th>\n",
       "      <th>ST334Q03JA</th>\n",
       "      <th>ST334Q04JA</th>\n",
       "      <th>ST334Q05JA</th>\n",
       "      <th>ST334Q06JA</th>\n",
       "      <th>ST334Q07JA</th>\n",
       "      <th>ST334Q08JA</th>\n",
       "      <th>ST334Q09JA</th>\n",
       "      <th>ST334Q10JA</th>\n",
       "      <th>ST335Q01JA</th>\n",
       "      <th>ST335Q02JA</th>\n",
       "      <th>ST335Q03JA</th>\n",
       "      <th>ST335Q05JA</th>\n",
       "      <th>ST335Q06JA</th>\n",
       "      <th>ST335Q07JA</th>\n",
       "      <th>ST336Q01JA</th>\n",
       "      <th>ST336Q03JA</th>\n",
       "      <th>ST336Q04JA</th>\n",
       "      <th>ST336Q05JA</th>\n",
       "      <th>ST336Q06JA</th>\n",
       "      <th>ST336Q07JA</th>\n",
       "      <th>ST337Q01JA</th>\n",
       "      <th>ST337Q02JA</th>\n",
       "      <th>...</th>\n",
       "      <th>ST349Q01JA_2</th>\n",
       "      <th>ST349Q01JA_3</th>\n",
       "      <th>ST349Q01JA_4</th>\n",
       "      <th>ST349Q01JA_0</th>\n",
       "      <th>LANGN_105</th>\n",
       "      <th>LANGN_108</th>\n",
       "      <th>LANGN_118</th>\n",
       "      <th>LANGN_140</th>\n",
       "      <th>LANGN_148</th>\n",
       "      <th>LANGN_150</th>\n",
       "      <th>LANGN_156</th>\n",
       "      <th>LANGN_200</th>\n",
       "      <th>LANGN_204</th>\n",
       "      <th>LANGN_232</th>\n",
       "      <th>LANGN_273</th>\n",
       "      <th>LANGN_313</th>\n",
       "      <th>LANGN_316</th>\n",
       "      <th>LANGN_322</th>\n",
       "      <th>LANGN_329</th>\n",
       "      <th>LANGN_344</th>\n",
       "      <th>LANGN_351</th>\n",
       "      <th>LANGN_415</th>\n",
       "      <th>LANGN_463</th>\n",
       "      <th>LANGN_493</th>\n",
       "      <th>LANGN_496</th>\n",
       "      <th>LANGN_500</th>\n",
       "      <th>LANGN_520</th>\n",
       "      <th>LANGN_531</th>\n",
       "      <th>LANGN_602</th>\n",
       "      <th>LANGN_606</th>\n",
       "      <th>LANGN_615</th>\n",
       "      <th>LANGN_621</th>\n",
       "      <th>LANGN_625</th>\n",
       "      <th>LANGN_640</th>\n",
       "      <th>LANGN_641</th>\n",
       "      <th>LANGN_663</th>\n",
       "      <th>LANGN_669</th>\n",
       "      <th>LANGN_670</th>\n",
       "      <th>LANGN_800</th>\n",
       "      <th>LANGN_801</th>\n",
       "      <th>LANGN_802</th>\n",
       "      <th>LANGN_804</th>\n",
       "      <th>LANGN_805</th>\n",
       "      <th>LANGN_806</th>\n",
       "      <th>LANGN_807</th>\n",
       "      <th>LANGN_808</th>\n",
       "      <th>LANGN_865</th>\n",
       "      <th>LANGN_892</th>\n",
       "      <th>LANGN_895</th>\n",
       "      <th>LANGN_917</th>\n",
       "      <th>SC177Q01JA_1</th>\n",
       "      <th>SC177Q01JA_2</th>\n",
       "      <th>SC177Q01JA_3</th>\n",
       "      <th>SC177Q02JA_1</th>\n",
       "      <th>SC177Q02JA_2</th>\n",
       "      <th>SC177Q02JA_3</th>\n",
       "      <th>SC177Q03JA_1</th>\n",
       "      <th>SC177Q03JA_2</th>\n",
       "      <th>SC177Q03JA_3</th>\n",
       "      <th>MATHEXC_0</th>\n",
       "      <th>MATHEXC_1</th>\n",
       "      <th>MATHEXC_2</th>\n",
       "      <th>MATHEXC_3</th>\n",
       "      <th>SCHLTYPE_1</th>\n",
       "      <th>SCHLTYPE_2</th>\n",
       "      <th>SCHLTYPE_3</th>\n",
       "      <th>LANGN_121</th>\n",
       "      <th>LANGN_130</th>\n",
       "      <th>LANGN_137</th>\n",
       "      <th>LANGN_170</th>\n",
       "      <th>LANGN_244</th>\n",
       "      <th>LANGN_258</th>\n",
       "      <th>LANGN_263</th>\n",
       "      <th>LANGN_264</th>\n",
       "      <th>LANGN_266</th>\n",
       "      <th>LANGN_317</th>\n",
       "      <th>LANGN_340</th>\n",
       "      <th>LANGN_369</th>\n",
       "      <th>LANGN_381</th>\n",
       "      <th>LANGN_404</th>\n",
       "      <th>LANGN_420</th>\n",
       "      <th>LANGN_449</th>\n",
       "      <th>LANGN_467</th>\n",
       "      <th>LANGN_494</th>\n",
       "      <th>LANGN_495</th>\n",
       "      <th>LANGN_514</th>\n",
       "      <th>LANGN_523</th>\n",
       "      <th>LANGN_529</th>\n",
       "      <th>LANGN_540</th>\n",
       "      <th>LANGN_547</th>\n",
       "      <th>LANGN_600</th>\n",
       "      <th>LANGN_607</th>\n",
       "      <th>LANGN_618</th>\n",
       "      <th>LANGN_619</th>\n",
       "      <th>LANGN_630</th>\n",
       "      <th>LANGN_635</th>\n",
       "      <th>LANGN_650</th>\n",
       "      <th>LANGN_661</th>\n",
       "      <th>LANGN_673</th>\n",
       "      <th>LANGN_674</th>\n",
       "      <th>LANGN_809</th>\n",
       "      <th>LANGN_810</th>\n",
       "      <th>LANGN_811</th>\n",
       "      <th>LANGN_812</th>\n",
       "      <th>LANGN_813</th>\n",
       "      <th>LANGN_814</th>\n",
       "      <th>LANGN_815</th>\n",
       "      <th>LANGN_816</th>\n",
       "      <th>LANGN_818</th>\n",
       "      <th>LANGN_832</th>\n",
       "      <th>LANGN_868</th>\n",
       "      <th>LANGN_870</th>\n",
       "      <th>LANGN_920</th>\n",
       "      <th>LANGN_921</th>\n",
       "      <th>LANGN_113</th>\n",
       "      <th>LANGN_147</th>\n",
       "      <th>LANGN_275</th>\n",
       "      <th>LANGN_286</th>\n",
       "      <th>LANGN_363</th>\n",
       "      <th>LANGN_422</th>\n",
       "      <th>LANGN_434</th>\n",
       "      <th>LANGN_442</th>\n",
       "      <th>LANGN_471</th>\n",
       "      <th>LANGN_611</th>\n",
       "      <th>LANGN_614</th>\n",
       "      <th>LANGN_624</th>\n",
       "      <th>LANGN_642</th>\n",
       "      <th>LANGN_675</th>\n",
       "      <th>LANGN_676</th>\n",
       "      <th>LANGN_677</th>\n",
       "      <th>LANGN_678</th>\n",
       "      <th>LANGN_817</th>\n",
       "      <th>LANGN_819</th>\n",
       "      <th>LANGN_821</th>\n",
       "      <th>LANGN_823</th>\n",
       "      <th>LANGN_824</th>\n",
       "      <th>LANGN_825</th>\n",
       "      <th>LANGN_826</th>\n",
       "      <th>LANGN_827</th>\n",
       "      <th>LANGN_828</th>\n",
       "      <th>LANGN_885</th>\n",
       "      <th>LANGN_896</th>\n",
       "      <th>LANGN_916</th>\n",
       "      <th>LANGN_112</th>\n",
       "      <th>LANGN_154</th>\n",
       "      <th>LANGN_202</th>\n",
       "      <th>LANGN_246</th>\n",
       "      <th>LANGN_254</th>\n",
       "      <th>LANGN_272</th>\n",
       "      <th>LANGN_301</th>\n",
       "      <th>LANGN_325</th>\n",
       "      <th>LANGN_338</th>\n",
       "      <th>LANGN_358</th>\n",
       "      <th>LANGN_371</th>\n",
       "      <th>LANGN_375</th>\n",
       "      <th>LANGN_383</th>\n",
       "      <th>LANGN_409</th>\n",
       "      <th>LANGN_428</th>\n",
       "      <th>LANGN_465</th>\n",
       "      <th>LANGN_517</th>\n",
       "      <th>LANGN_527</th>\n",
       "      <th>LANGN_561</th>\n",
       "      <th>LANGN_562</th>\n",
       "      <th>LANGN_563</th>\n",
       "      <th>LANGN_565</th>\n",
       "      <th>LANGN_566</th>\n",
       "      <th>LANGN_567</th>\n",
       "      <th>LANGN_601</th>\n",
       "      <th>LANGN_622</th>\n",
       "      <th>LANGN_623</th>\n",
       "      <th>LANGN_628</th>\n",
       "      <th>LANGN_631</th>\n",
       "      <th>LANGN_831</th>\n",
       "      <th>LANGN_833</th>\n",
       "      <th>LANGN_836</th>\n",
       "      <th>LANGN_837</th>\n",
       "      <th>LANGN_838</th>\n",
       "      <th>LANGN_839</th>\n",
       "      <th>LANGN_840</th>\n",
       "      <th>LANGN_841</th>\n",
       "      <th>LANGN_845</th>\n",
       "      <th>LANGN_872</th>\n",
       "      <th>LANGN_873</th>\n",
       "      <th>LANGN_881</th>\n",
       "      <th>LANGN_890</th>\n",
       "      <th>LANGN_897</th>\n",
       "      <th>LANGN_898</th>\n",
       "      <th>LANGN_899</th>\n",
       "      <th>LANGN_900</th>\n",
       "      <th>LANGN_901</th>\n",
       "      <th>LANGN_902</th>\n",
       "      <th>LANGN_903</th>\n",
       "      <th>LANGN_904</th>\n",
       "      <th>LANGN_905</th>\n",
       "      <th>LANGN_906</th>\n",
       "      <th>LANGN_907</th>\n",
       "      <th>LANGN_908</th>\n",
       "      <th>LANGN_909</th>\n",
       "      <th>LANGN_910</th>\n",
       "      <th>LANGN_911</th>\n",
       "      <th>LANGN_912</th>\n",
       "      <th>LANGN_913</th>\n",
       "      <th>LANGN_914</th>\n",
       "      <th>LANGN_918</th>\n",
       "      <th>LANGN_919</th>\n",
       "      <th>LANGN_160</th>\n",
       "      <th>LANGN_327</th>\n",
       "      <th>LANGN_451</th>\n",
       "      <th>LANGN_474</th>\n",
       "      <th>LANGN_503</th>\n",
       "      <th>LANGN_608</th>\n",
       "      <th>LANGN_627</th>\n",
       "      <th>LANGN_639</th>\n",
       "      <th>LANGN_668</th>\n",
       "      <th>LANGN_842</th>\n",
       "      <th>LANGN_843</th>\n",
       "      <th>LANGN_844</th>\n",
       "      <th>LANGN_846</th>\n",
       "      <th>LANGN_849</th>\n",
       "      <th>LANGN_850</th>\n",
       "      <th>LANGN_851</th>\n",
       "      <th>LANGN_852</th>\n",
       "      <th>LANGN_861</th>\n",
       "      <th>LANGN_879</th>\n",
       "      <th>LANGN_133</th>\n",
       "      <th>LANGN_195</th>\n",
       "      <th>LANGN_237</th>\n",
       "      <th>LANGN_379</th>\n",
       "      <th>LANGN_382</th>\n",
       "      <th>LANGN_472</th>\n",
       "      <th>LANGN_492</th>\n",
       "      <th>LANGN_555</th>\n",
       "      <th>LANGN_605</th>\n",
       "      <th>LANGN_616</th>\n",
       "      <th>LANGN_626</th>\n",
       "      <th>LANGN_634</th>\n",
       "      <th>LANGN_648</th>\n",
       "      <th>LANGN_662</th>\n",
       "      <th>LANGN_665</th>\n",
       "      <th>LANGN_666</th>\n",
       "      <th>LANGN_667</th>\n",
       "      <th>LANGN_829</th>\n",
       "      <th>LANGN_854</th>\n",
       "      <th>LANGN_855</th>\n",
       "      <th>LANGN_857</th>\n",
       "      <th>LANGN_859</th>\n",
       "      <th>LANGN_860</th>\n",
       "      <th>LANGN_866</th>\n",
       "      <th>LANGN_877</th>\n",
       "      <th>LANGN_922</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>573394</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573395</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573396</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573397</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573398</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1083 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MATH_Proficient  SISCO  ST250Q01JA  ST250Q02JA  ST250Q03JA  \\\n",
       "573394              1.0    1.0         1.0         1.0         1.0   \n",
       "573395              1.0    0.0         1.0         1.0         1.0   \n",
       "573396              1.0    1.0         1.0         1.0         1.0   \n",
       "573397              1.0    1.0         1.0         1.0         2.0   \n",
       "573398              1.0    1.0         1.0         1.0         1.0   \n",
       "\n",
       "        ST250Q04JA  ST250Q05JA  ST251Q01JA  ST251Q02JA  ST251Q03JA  \\\n",
       "573394         1.0         1.0         4.0         1.0         4.0   \n",
       "573395         1.0         1.0         3.0         1.0         4.0   \n",
       "573396         1.0         1.0         4.0         1.0         4.0   \n",
       "573397         1.0         1.0         3.0         1.0         3.0   \n",
       "573398         1.0         1.0         2.0         1.0         2.0   \n",
       "\n",
       "        ST251Q04JA  ST251Q06JA  ST251Q07JA  ST253Q01JA  ST254Q01JA  \\\n",
       "573394         4.0         4.0         NaN         8.0         2.0   \n",
       "573395         4.0         3.0         NaN         8.0         4.0   \n",
       "573396         4.0         2.0         NaN         8.0         4.0   \n",
       "573397         3.0         1.0         NaN         6.0         2.0   \n",
       "573398         2.0         1.0         NaN         8.0         3.0   \n",
       "\n",
       "        ST254Q02JA  ST254Q03JA  ST254Q04JA  ST254Q05JA  ST254Q06JA  \\\n",
       "573394         2.0         3.0         2.0         2.0         3.0   \n",
       "573395         2.0         2.0         2.0         1.0         3.0   \n",
       "573396         2.0         3.0         2.0         1.0         3.0   \n",
       "573397         2.0         2.0         2.0         1.0         3.0   \n",
       "573398         3.0         4.0         2.0         1.0         4.0   \n",
       "\n",
       "        ST255Q01JA  ST256Q01JA  ST256Q02JA  ST256Q03JA  ST256Q06JA  \\\n",
       "573394         5.0         3.0         2.0         2.0         1.0   \n",
       "573395         4.0         NaN         NaN         NaN         NaN   \n",
       "573396         6.0         2.0         2.0         3.0         3.0   \n",
       "573397         2.0         1.0         1.0         1.0         2.0   \n",
       "573398         2.0         2.0         NaN         NaN         NaN   \n",
       "\n",
       "        ST256Q07JA  ST256Q08JA  ST256Q09JA  ST256Q10JA  ST267Q01JA  \\\n",
       "573394         2.0         2.0         2.0         2.0         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         3.0   \n",
       "573396         2.0         2.0         1.0         2.0         3.0   \n",
       "573397         2.0         1.0         1.0         1.0         3.0   \n",
       "573398         NaN         NaN         NaN         2.0         NaN   \n",
       "\n",
       "        ST267Q02JA  ST267Q03JA  ST267Q04JA  ST267Q05JA  ST267Q06JA  \\\n",
       "573394         NaN         3.0         2.0         3.0         3.0   \n",
       "573395         NaN         3.0         NaN         3.0         3.0   \n",
       "573396         NaN         3.0         1.0         3.0         3.0   \n",
       "573397         NaN         2.0         1.0         NaN         NaN   \n",
       "573398         3.0         3.0         NaN         3.0         4.0   \n",
       "\n",
       "        ST267Q07JA  ST267Q08JA  ST034Q01TA  ST034Q02TA  ST034Q03TA  \\\n",
       "573394         3.0         NaN         3.0         NaN         2.0   \n",
       "573395         NaN         2.0         4.0         2.0         2.0   \n",
       "573396         NaN         NaN         3.0         2.0         2.0   \n",
       "573397         3.0         2.0         3.0         2.0         3.0   \n",
       "573398         4.0         NaN         4.0         1.0         1.0   \n",
       "\n",
       "        ST034Q04TA  ST034Q05TA  ST034Q06TA  ST038Q03NA  ST038Q04NA  \\\n",
       "573394         3.0         2.0         3.0         1.0         1.0   \n",
       "573395         4.0         2.0         NaN         1.0         1.0   \n",
       "573396         3.0         NaN         3.0         1.0         1.0   \n",
       "573397         NaN         2.0         3.0         1.0         2.0   \n",
       "573398         NaN         1.0         4.0         1.0         3.0   \n",
       "\n",
       "        ST038Q05NA  ST038Q06NA  ST038Q07NA  ST038Q08NA  ST038Q09JA  \\\n",
       "573394         1.0         1.0         1.0         1.0         1.0   \n",
       "573395         1.0         1.0         1.0         1.0         1.0   \n",
       "573396         1.0         1.0         1.0         1.0         1.0   \n",
       "573397         2.0         1.0         2.0         2.0         1.0   \n",
       "573398         1.0         1.0         1.0         1.0         1.0   \n",
       "\n",
       "        ST038Q10JA  ST038Q11JA  ST265Q01JA  ST265Q02JA  ST265Q03JA  \\\n",
       "573394         1.0         1.0         2.0         2.0         2.0   \n",
       "573395         1.0         1.0         4.0         4.0         4.0   \n",
       "573396         1.0         1.0         2.0         2.0         2.0   \n",
       "573397         1.0         1.0         2.0         2.0         2.0   \n",
       "573398         1.0         1.0         1.0         1.0         1.0   \n",
       "\n",
       "        ST265Q04JA  ST266Q01JA  ST266Q02JA  ST266Q03JA  ST266Q04JA  \\\n",
       "573394         2.0         2.0         2.0         2.0         2.0   \n",
       "573395         4.0         2.0         2.0         2.0         2.0   \n",
       "573396         2.0         2.0         2.0         2.0         1.0   \n",
       "573397         2.0         1.0         1.0         2.0         1.0   \n",
       "573398         1.0         2.0         2.0         2.0         2.0   \n",
       "\n",
       "        ST266Q05JA  ST307Q01JA  ST307Q02JA  ST307Q03JA  ST307Q04JA  \\\n",
       "573394         2.0         NaN         NaN         NaN         NaN   \n",
       "573395         2.0         NaN         NaN         NaN         NaN   \n",
       "573396         2.0         NaN         NaN         NaN         NaN   \n",
       "573397         2.0         NaN         NaN         NaN         NaN   \n",
       "573398         2.0         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST307Q05JA  ST307Q06JA  ST307Q07JA  ST307Q08JA  ST307Q09JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST307Q10JA  ST301Q01JA  ST301Q02JA  ST301Q03JA  ST301Q04JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST301Q05JA  ST301Q06JA  ST301Q07JA  ST301Q08JA  ST301Q09JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST301Q10JA  ST343Q01JA  ST343Q02JA  ST343Q03JA  ST343Q04JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST343Q05JA  ST343Q06JA  ST343Q07JA  ST343Q08JA  ST343Q09JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST343Q10JA  ST311Q01JA  ST311Q02JA  ST311Q03JA  ST311Q04JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST311Q05JA  ST311Q06JA  ST311Q07JA  ST311Q08JA  ST311Q09JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST311Q10JA  ST305Q01JA  ST305Q02JA  ST305Q03JA  ST305Q04JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST305Q05JA  ST305Q06JA  ST305Q07JA  ST305Q08JA  ST305Q09JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST305Q10JA  ST345Q01JA  ST345Q02JA  ST345Q03JA  ST345Q04JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST345Q05JA  ST345Q06JA  ST345Q07JA  ST345Q08JA  ST345Q09JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST345Q10JA  ST313Q01JA  ST313Q02JA  ST313Q03JA  ST313Q04JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST313Q05JA  ST313Q06JA  ST313Q07JA  ST313Q08JA  ST313Q09JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST313Q10JA  ST263Q02JA  ST263Q04JA  ST263Q06JA  ST263Q08JA  \\\n",
       "573394         NaN         1.0         3.0         3.0         NaN   \n",
       "573395         NaN         2.0         3.0         2.0         NaN   \n",
       "573396         NaN         1.0         3.0         2.0         NaN   \n",
       "573397         NaN         3.0         3.0         3.0         NaN   \n",
       "573398         NaN         2.0         2.0         2.0         NaN   \n",
       "\n",
       "        ST273Q01JA  ST273Q02JA  ST273Q03JA  ST273Q04JA  ST273Q05JA  \\\n",
       "573394         3.0         3.0         NaN         3.0         NaN   \n",
       "573395         3.0         4.0         4.0         3.0         4.0   \n",
       "573396         NaN         4.0         4.0         NaN         3.0   \n",
       "573397         1.0         NaN         1.0         1.0         NaN   \n",
       "573398         NaN         NaN         4.0         4.0         4.0   \n",
       "\n",
       "        ST273Q06JA  ST273Q07JA  ST270Q01JA  ST270Q02JA  ST270Q03JA  \\\n",
       "573394         4.0         4.0         1.0         1.0         1.0   \n",
       "573395         NaN         NaN         2.0         1.0         1.0   \n",
       "573396         3.0         3.0         2.0         2.0         1.0   \n",
       "573397         1.0         1.0         3.0         3.0         3.0   \n",
       "573398         4.0         4.0         2.0         1.0         1.0   \n",
       "\n",
       "        ST270Q04JA  ST285Q01JA  ST285Q02JA  ST285Q03JA  ST285Q04JA  \\\n",
       "573394         2.0         NaN         3.0         NaN         NaN   \n",
       "573395         2.0         NaN         NaN         1.0         1.0   \n",
       "573396         2.0         3.0         4.0         NaN         4.0   \n",
       "573397         3.0         2.0         3.0         3.0         3.0   \n",
       "573398         2.0         NaN         5.0         NaN         NaN   \n",
       "\n",
       "        ST285Q05JA  ST285Q06JA  ST285Q07JA  ST285Q08JA  ST285Q09JA  \\\n",
       "573394         4.0         2.0         2.0         NaN         4.0   \n",
       "573395         1.0         NaN         3.0         2.0         NaN   \n",
       "573396         4.0         2.0         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         2.0         NaN         NaN   \n",
       "573398         2.0         4.0         NaN         2.0         5.0   \n",
       "\n",
       "        ST283Q01JA  ST283Q02JA  ST283Q03JA  ST283Q04JA  ST283Q05JA  \\\n",
       "573394         1.0         NaN         4.0         NaN         4.0   \n",
       "573395         NaN         NaN         NaN         2.0         2.0   \n",
       "573396         2.0         NaN         5.0         NaN         NaN   \n",
       "573397         NaN         NaN         3.0         NaN         3.0   \n",
       "573398         NaN         1.0         2.0         4.0         NaN   \n",
       "\n",
       "        ST283Q06JA  ST283Q07JA  ST283Q08JA  ST283Q09JA  ST275Q01WA  \\\n",
       "573394         NaN         NaN         1.0         1.0         NaN   \n",
       "573395         1.0         1.0         NaN         1.0         4.0   \n",
       "573396         2.0         4.0         NaN         4.0         NaN   \n",
       "573397         3.0         2.0         NaN         2.0         3.0   \n",
       "573398         1.0         NaN         1.0         NaN         NaN   \n",
       "\n",
       "        ST275Q02WA  ST275Q03WA  ST275Q04WA  ST275Q05WA  ST275Q06WA  \\\n",
       "573394         NaN         3.0         NaN         4.0         NaN   \n",
       "573395         4.0         NaN         NaN         2.0         NaN   \n",
       "573396         3.0         2.0         NaN         1.0         NaN   \n",
       "573397         NaN         3.0         3.0         NaN         NaN   \n",
       "573398         4.0         4.0         NaN         3.0         NaN   \n",
       "\n",
       "        ST275Q07WA  ST275Q08WA  ST275Q09WA  ST276Q01JA  ST276Q02JA  \\\n",
       "573394         4.0         4.0         4.0         2.0         NaN   \n",
       "573395         2.0         4.0         NaN         1.0         NaN   \n",
       "573396         1.0         4.0         NaN         NaN         NaN   \n",
       "573397         NaN         3.0         NaN         NaN         2.0   \n",
       "573398         1.0         NaN         1.0         1.0         NaN   \n",
       "\n",
       "        ST276Q03JA  ST276Q04JA  ST276Q05JA  ST276Q06JA  ST276Q07JA  \\\n",
       "573394         4.0         4.0         NaN         NaN         NaN   \n",
       "573395         4.0         4.0         NaN         NaN         NaN   \n",
       "573396         NaN         2.0         2.0         NaN         NaN   \n",
       "573397         3.0         2.0         NaN         3.0         NaN   \n",
       "573398         4.0         3.0         1.0         NaN         NaN   \n",
       "\n",
       "        ST276Q08JA  ST276Q09JA  ST276Q10JA  ST290Q01WA  ST290Q02WA  \\\n",
       "573394         4.0         4.0         NaN         NaN         3.0   \n",
       "573395         4.0         NaN         1.0         3.0         3.0   \n",
       "573396         4.0         2.0         1.0         2.0         4.0   \n",
       "573397         NaN         NaN         3.0         NaN         2.0   \n",
       "573398         NaN         NaN         1.0         NaN         NaN   \n",
       "\n",
       "        ST290Q03WA  ST290Q04WA  ST290Q05WA  ST290Q06WA  ST290Q07WA  \\\n",
       "573394         3.0         NaN         3.0         NaN         3.0   \n",
       "573395         3.0         NaN         NaN         NaN         3.0   \n",
       "573396         NaN         4.0         NaN         NaN         4.0   \n",
       "573397         NaN         NaN         NaN         1.0         2.0   \n",
       "573398         3.0         3.0         1.0         4.0         1.0   \n",
       "\n",
       "        ST290Q08WA  ST290Q09WA  ST291Q01JA  ST291Q02JA  ST291Q03JA  \\\n",
       "573394         NaN         3.0         NaN         3.0         NaN   \n",
       "573395         NaN         3.0         3.0         NaN         NaN   \n",
       "573396         2.0         NaN         NaN         NaN         4.0   \n",
       "573397         2.0         3.0         NaN         3.0         NaN   \n",
       "573398         NaN         NaN         NaN         2.0         2.0   \n",
       "\n",
       "        ST291Q04JA  ST291Q05JA  ST291Q06JA  ST291Q07JA  ST291Q08JA  \\\n",
       "573394         3.0         NaN         3.0         3.0         NaN   \n",
       "573395         NaN         3.0         3.0         3.0         NaN   \n",
       "573396         3.0         3.0         NaN         4.0         NaN   \n",
       "573397         3.0         NaN         1.0         NaN         3.0   \n",
       "573398         NaN         3.0         NaN         3.0         1.0   \n",
       "\n",
       "        ST291Q09JA  ST291Q10JA  ST289Q01WA  ST289Q02JA  ST289Q04JA  \\\n",
       "573394         NaN         3.0         4.0         4.0         NaN   \n",
       "573395         3.0         NaN         NaN         2.0         4.0   \n",
       "573396         4.0         NaN         5.0         5.0         NaN   \n",
       "573397         NaN         1.0         1.0         3.0         NaN   \n",
       "573398         NaN         NaN         2.0         4.0         NaN   \n",
       "\n",
       "        ST289Q05WA  ST289Q06JA  ST289Q07JA  ST289Q08WA  ST289Q09WA  \\\n",
       "573394         4.0         NaN         4.0         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         2.0         NaN   \n",
       "573396         5.0         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         3.0         3.0         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST289Q10WA  ST289Q14JA  ST293Q01JA  ST293Q02JA  ST293Q03JA  \\\n",
       "573394         NaN         5.0         4.0         4.0         4.0   \n",
       "573395         NaN         NaN         NaN         NaN         4.0   \n",
       "573396         NaN         5.0         NaN         5.0         4.0   \n",
       "573397         NaN         1.0         2.0         4.0         4.0   \n",
       "573398         5.0         NaN         NaN         5.0         5.0   \n",
       "\n",
       "        ST293Q05JA  ST293Q06JA  ST293Q07JA  ST293Q08JA  ST293Q09JA  \\\n",
       "573394         NaN         4.0         NaN         4.0         NaN   \n",
       "573395         2.0         NaN         NaN         3.0         4.0   \n",
       "573396         4.0         NaN         NaN         3.0         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         3.0   \n",
       "573398         5.0         NaN         NaN         5.0         5.0   \n",
       "\n",
       "        ST292Q01JA  ST292Q02JA  ST292Q03JA  ST292Q04JA  ST292Q05JA  \\\n",
       "573394         3.0         1.0         3.0         3.0         3.0   \n",
       "573395         3.0         3.0         3.0         3.0         3.0   \n",
       "573396         NaN         3.0         3.0         4.0         3.0   \n",
       "573397         1.0         1.0         1.0         NaN         1.0   \n",
       "573398         3.0         3.0         NaN         3.0         3.0   \n",
       "\n",
       "        ST292Q06JA  ST334Q01JA  ST334Q02JA  ST334Q03JA  ST334Q04JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         4.0         NaN         NaN         NaN         NaN   \n",
       "573397         1.0         NaN         NaN         NaN         NaN   \n",
       "573398         3.0         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST334Q05JA  ST334Q06JA  ST334Q07JA  ST334Q08JA  ST334Q09JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST334Q10JA  ST335Q01JA  ST335Q02JA  ST335Q03JA  ST335Q05JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST335Q06JA  ST335Q07JA  ST336Q01JA  ST336Q03JA  ST336Q04JA  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN   \n",
       "573395         NaN         NaN         NaN         NaN         NaN   \n",
       "573396         NaN         NaN         NaN         NaN         NaN   \n",
       "573397         NaN         NaN         NaN         NaN         NaN   \n",
       "573398         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "        ST336Q05JA  ST336Q06JA  ST336Q07JA  ST337Q01JA  ST337Q02JA  ...  \\\n",
       "573394         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "573395         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "573396         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "573397         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "573398         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "\n",
       "        ST349Q01JA_2  ST349Q01JA_3  ST349Q01JA_4  ST349Q01JA_0  LANGN_105  \\\n",
       "573394             0             0             0             0          0   \n",
       "573395             0             0             0             0          0   \n",
       "573396             0             0             0             0          0   \n",
       "573397             1             0             0             0          0   \n",
       "573398             0             0             1             0          0   \n",
       "\n",
       "        LANGN_108  LANGN_118  LANGN_140  LANGN_148  LANGN_150  LANGN_156  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_200  LANGN_204  LANGN_232  LANGN_273  LANGN_313  LANGN_316  \\\n",
       "573394          0          0          0          0          1          0   \n",
       "573395          0          0          0          0          1          0   \n",
       "573396          0          0          0          0          1          0   \n",
       "573397          0          0          0          0          1          0   \n",
       "573398          0          0          0          0          1          0   \n",
       "\n",
       "        LANGN_322  LANGN_329  LANGN_344  LANGN_351  LANGN_415  LANGN_463  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_493  LANGN_496  LANGN_500  LANGN_520  LANGN_531  LANGN_602  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_606  LANGN_615  LANGN_621  LANGN_625  LANGN_640  LANGN_641  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_663  LANGN_669  LANGN_670  LANGN_800  LANGN_801  LANGN_802  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_804  LANGN_805  LANGN_806  LANGN_807  LANGN_808  LANGN_865  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_892  LANGN_895  LANGN_917  SC177Q01JA_1  SC177Q01JA_2  \\\n",
       "573394          0          0          0             0             0   \n",
       "573395          0          0          0             0             0   \n",
       "573396          0          0          0             1             0   \n",
       "573397          0          0          0             0             1   \n",
       "573398          0          0          0             0             1   \n",
       "\n",
       "        SC177Q01JA_3  SC177Q02JA_1  SC177Q02JA_2  SC177Q02JA_3  SC177Q03JA_1  \\\n",
       "573394             1             0             1             0             0   \n",
       "573395             0             0             0             0             0   \n",
       "573396             0             1             0             0             1   \n",
       "573397             0             0             0             1             0   \n",
       "573398             0             0             1             0             0   \n",
       "\n",
       "        SC177Q03JA_2  SC177Q03JA_3  MATHEXC_0  MATHEXC_1  MATHEXC_2  \\\n",
       "573394             0             0          0          0          0   \n",
       "573395             0             0          0          0          0   \n",
       "573396             0             0          0          0          0   \n",
       "573397             0             1          0          0          0   \n",
       "573398             1             0          0          0          0   \n",
       "\n",
       "        MATHEXC_3  SCHLTYPE_1  SCHLTYPE_2  SCHLTYPE_3  LANGN_121  LANGN_130  \\\n",
       "573394          1           0           0           1          0          0   \n",
       "573395          0           0           0           0          0          0   \n",
       "573396          1           0           0           1          0          0   \n",
       "573397          0           0           0           1          0          0   \n",
       "573398          0           0           0           1          0          0   \n",
       "\n",
       "        LANGN_137  LANGN_170  LANGN_244  LANGN_258  LANGN_263  LANGN_264  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_266  LANGN_317  LANGN_340  LANGN_369  LANGN_381  LANGN_404  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_420  LANGN_449  LANGN_467  LANGN_494  LANGN_495  LANGN_514  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_523  LANGN_529  LANGN_540  LANGN_547  LANGN_600  LANGN_607  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_618  LANGN_619  LANGN_630  LANGN_635  LANGN_650  LANGN_661  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_673  LANGN_674  LANGN_809  LANGN_810  LANGN_811  LANGN_812  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_813  LANGN_814  LANGN_815  LANGN_816  LANGN_818  LANGN_832  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_868  LANGN_870  LANGN_920  LANGN_921  LANGN_113  LANGN_147  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_275  LANGN_286  LANGN_363  LANGN_422  LANGN_434  LANGN_442  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_471  LANGN_611  LANGN_614  LANGN_624  LANGN_642  LANGN_675  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_676  LANGN_677  LANGN_678  LANGN_817  LANGN_819  LANGN_821  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_823  LANGN_824  LANGN_825  LANGN_826  LANGN_827  LANGN_828  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_885  LANGN_896  LANGN_916  LANGN_112  LANGN_154  LANGN_202  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_246  LANGN_254  LANGN_272  LANGN_301  LANGN_325  LANGN_338  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_358  LANGN_371  LANGN_375  LANGN_383  LANGN_409  LANGN_428  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_465  LANGN_517  LANGN_527  LANGN_561  LANGN_562  LANGN_563  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_565  LANGN_566  LANGN_567  LANGN_601  LANGN_622  LANGN_623  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_628  LANGN_631  LANGN_831  LANGN_833  LANGN_836  LANGN_837  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_838  LANGN_839  LANGN_840  LANGN_841  LANGN_845  LANGN_872  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_873  LANGN_881  LANGN_890  LANGN_897  LANGN_898  LANGN_899  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_900  LANGN_901  LANGN_902  LANGN_903  LANGN_904  LANGN_905  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_906  LANGN_907  LANGN_908  LANGN_909  LANGN_910  LANGN_911  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_912  LANGN_913  LANGN_914  LANGN_918  LANGN_919  LANGN_160  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_327  LANGN_451  LANGN_474  LANGN_503  LANGN_608  LANGN_627  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_639  LANGN_668  LANGN_842  LANGN_843  LANGN_844  LANGN_846  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_849  LANGN_850  LANGN_851  LANGN_852  LANGN_861  LANGN_879  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_133  LANGN_195  LANGN_237  LANGN_379  LANGN_382  LANGN_472  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_492  LANGN_555  LANGN_605  LANGN_616  LANGN_626  LANGN_634  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_648  LANGN_662  LANGN_665  LANGN_666  LANGN_667  LANGN_829  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_854  LANGN_855  LANGN_857  LANGN_859  LANGN_860  LANGN_866  \\\n",
       "573394          0          0          0          0          0          0   \n",
       "573395          0          0          0          0          0          0   \n",
       "573396          0          0          0          0          0          0   \n",
       "573397          0          0          0          0          0          0   \n",
       "573398          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_877  LANGN_922  \n",
       "573394          0          0  \n",
       "573395          0          0  \n",
       "573396          0          0  \n",
       "573397          0          0  \n",
       "573398          0          0  \n",
       "\n",
       "[5 rows x 1083 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorder columns to bring 'MATH_Proficient' first\n",
    "new_order = ['MATH_Proficient'] + [col for col in model_data.columns if col != 'MATH_Proficient']\n",
    "model_data = model_data[new_order]\n",
    "\n",
    "# Get number of features\n",
    "n_features_original = model_data.shape[1]-1\n",
    "\n",
    "# Check the shape after dropping\n",
    "print(model_data.shape)\n",
    "\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop columns with more than 20% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4552, 558)\n"
     ]
    }
   ],
   "source": [
    "model_data.dropna(thresh=int(0.8 * len(model_data)), axis=1, inplace=True)\n",
    "print(model_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features (before dropping features with more than 20% missing): 1082\n",
      "Number of features (after dropping features with more than 20% missing): 557\n",
      "Number of features with more than 20% missing: 525\n"
     ]
    }
   ],
   "source": [
    "n_features_final = model_data.shape[1]-1\n",
    "print(\"Number of features (before dropping features with more than 20% missing):\", n_features_original)\n",
    "print(\"Number of features (after dropping features with more than 20% missing):\", n_features_final)\n",
    "print(\"Number of features with more than 20% missing:\", n_features_original - n_features_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For columns with less than 20% missing values, fill missing values with the median value of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data.fillna(model_data.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll randomly split the data into 3 uneven groups.  **The model will be trained on 70% of data, it will then be evaluated on 15% of data to give us an estimate of the accuracy we hope to have on \"new\" data, and 15% will be held back as a final testing dataset which will be used later on.**\n",
    "\n",
    "A seed is included in the code so the splits can be replicated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# cell 12\n",
    "# Randomly sort the data then split out first 70%, second 15%, and last 15%\n",
    "train_data, validation_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data)), int(0.85 * len(model_data))])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in FULL dataset: 4552\n",
      "Number of rows in TRAINING dataset: 3186 ( 70.0 % )\n",
      "Number of rows in VALIDATION dataset: 683 ( 15.0 % )\n",
      "Number of rows in TEST dataset: 683 ( 15.0 % )\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows in FULL dataset:\", model_data.shape[0])\n",
    "\n",
    "train_data_percent = round(train_data.shape[0]/model_data.shape[0] * 100, 0)\n",
    "print(\"Number of rows in TRAINING dataset:\", train_data.shape[0], \"(\", train_data_percent, \"% )\")\n",
    "\n",
    "validation_data_percent = round(validation_data.shape[0]/model_data.shape[0] * 100, 0)\n",
    "print(\"Number of rows in VALIDATION dataset:\", validation_data.shape[0], \"(\", validation_data_percent, \"% )\")\n",
    "\n",
    "test_data_percent = round(test_data.shape[0]/model_data.shape[0] * 100, 0)\n",
    "print(\"Number of rows in TEST dataset:\", test_data.shape[0], \"(\", test_data_percent, \"% )\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save train dataset \n",
    "train_data.to_csv('train.csv', index=False, header=False)\n",
    "\n",
    "# Save validation dataset \n",
    "validation_data.to_csv('validation.csv', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3186, 558)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MATH_Proficient</th>\n",
       "      <th>SISCO</th>\n",
       "      <th>ST250Q01JA</th>\n",
       "      <th>ST250Q02JA</th>\n",
       "      <th>ST250Q03JA</th>\n",
       "      <th>ST250Q04JA</th>\n",
       "      <th>ST250Q05JA</th>\n",
       "      <th>ST251Q01JA</th>\n",
       "      <th>ST251Q02JA</th>\n",
       "      <th>ST251Q03JA</th>\n",
       "      <th>ST251Q04JA</th>\n",
       "      <th>ST251Q06JA</th>\n",
       "      <th>ST253Q01JA</th>\n",
       "      <th>ST254Q01JA</th>\n",
       "      <th>ST254Q02JA</th>\n",
       "      <th>ST254Q03JA</th>\n",
       "      <th>ST254Q04JA</th>\n",
       "      <th>ST254Q05JA</th>\n",
       "      <th>ST254Q06JA</th>\n",
       "      <th>ST255Q01JA</th>\n",
       "      <th>ST038Q03NA</th>\n",
       "      <th>ST038Q04NA</th>\n",
       "      <th>ST038Q05NA</th>\n",
       "      <th>ST038Q06NA</th>\n",
       "      <th>ST038Q07NA</th>\n",
       "      <th>ST038Q08NA</th>\n",
       "      <th>ST038Q09JA</th>\n",
       "      <th>ST038Q10JA</th>\n",
       "      <th>ST038Q11JA</th>\n",
       "      <th>ST265Q01JA</th>\n",
       "      <th>ST265Q02JA</th>\n",
       "      <th>ST265Q03JA</th>\n",
       "      <th>ST265Q04JA</th>\n",
       "      <th>ST266Q01JA</th>\n",
       "      <th>ST266Q02JA</th>\n",
       "      <th>ST266Q03JA</th>\n",
       "      <th>ST266Q04JA</th>\n",
       "      <th>ST266Q05JA</th>\n",
       "      <th>ST263Q02JA</th>\n",
       "      <th>ST263Q04JA</th>\n",
       "      <th>ST263Q06JA</th>\n",
       "      <th>ST270Q01JA</th>\n",
       "      <th>ST270Q02JA</th>\n",
       "      <th>ST270Q03JA</th>\n",
       "      <th>ST270Q04JA</th>\n",
       "      <th>FL166Q01HA</th>\n",
       "      <th>FL166Q02HA</th>\n",
       "      <th>FL166Q03HA</th>\n",
       "      <th>FL166Q05HA</th>\n",
       "      <th>FL166Q06HA</th>\n",
       "      <th>FL166Q07HA</th>\n",
       "      <th>FL174Q01JA</th>\n",
       "      <th>FL174Q02JA</th>\n",
       "      <th>FL174Q03JA</th>\n",
       "      <th>FL174Q04JA</th>\n",
       "      <th>FL174Q05JA</th>\n",
       "      <th>FL174Q06JA</th>\n",
       "      <th>FL174Q07JA</th>\n",
       "      <th>FL167Q01HA</th>\n",
       "      <th>FL167Q02HA</th>\n",
       "      <th>FL167Q06JA</th>\n",
       "      <th>FL167Q03HA</th>\n",
       "      <th>FL167Q04HA</th>\n",
       "      <th>FL167Q05HA</th>\n",
       "      <th>FL167Q07JA</th>\n",
       "      <th>FL170Q01JA</th>\n",
       "      <th>FL170Q02JA</th>\n",
       "      <th>FL170Q03JA</th>\n",
       "      <th>FL170Q04JA</th>\n",
       "      <th>FL170Q05JA</th>\n",
       "      <th>FL170Q06JA</th>\n",
       "      <th>FL170Q07JA</th>\n",
       "      <th>FL162Q01HA</th>\n",
       "      <th>FL162Q02HA</th>\n",
       "      <th>FL162Q03HA</th>\n",
       "      <th>FL162Q04HA</th>\n",
       "      <th>FL162Q05HA</th>\n",
       "      <th>FL162Q06HA</th>\n",
       "      <th>FL163Q01HA</th>\n",
       "      <th>FL163Q02HA</th>\n",
       "      <th>FL163Q03HA</th>\n",
       "      <th>FL163Q04HA</th>\n",
       "      <th>FL163Q05HA</th>\n",
       "      <th>FL171Q01JA</th>\n",
       "      <th>FL171Q02JA</th>\n",
       "      <th>FL171Q03JA</th>\n",
       "      <th>FL171Q04JA</th>\n",
       "      <th>FL171Q05JA</th>\n",
       "      <th>FL171Q07JA</th>\n",
       "      <th>FL171Q08JA</th>\n",
       "      <th>FL171Q09JA</th>\n",
       "      <th>FL171Q10JA</th>\n",
       "      <th>FL171Q11JA</th>\n",
       "      <th>FL171Q12JA</th>\n",
       "      <th>FL169Q01HA</th>\n",
       "      <th>FL169Q05JA</th>\n",
       "      <th>FL169Q02HA</th>\n",
       "      <th>FL169Q04HA</th>\n",
       "      <th>FL169Q08JA</th>\n",
       "      <th>FL169Q10JA</th>\n",
       "      <th>FL169Q11JA</th>\n",
       "      <th>FL172Q01JA</th>\n",
       "      <th>FL172Q03JA</th>\n",
       "      <th>FL172Q05JA</th>\n",
       "      <th>FL172Q06JA</th>\n",
       "      <th>IC170Q01JA</th>\n",
       "      <th>IC170Q02JA</th>\n",
       "      <th>IC170Q03JA</th>\n",
       "      <th>IC170Q04JA</th>\n",
       "      <th>IC170Q05JA</th>\n",
       "      <th>IC170Q06JA</th>\n",
       "      <th>IC170Q07JA</th>\n",
       "      <th>IC171Q01JA</th>\n",
       "      <th>IC171Q02JA</th>\n",
       "      <th>IC171Q03JA</th>\n",
       "      <th>IC171Q04JA</th>\n",
       "      <th>IC171Q05JA</th>\n",
       "      <th>IC171Q06JA</th>\n",
       "      <th>IC172Q01JA</th>\n",
       "      <th>IC172Q02JA</th>\n",
       "      <th>IC172Q03JA</th>\n",
       "      <th>IC172Q04JA</th>\n",
       "      <th>IC172Q05JA</th>\n",
       "      <th>IC172Q06JA</th>\n",
       "      <th>IC172Q07JA</th>\n",
       "      <th>IC172Q08JA</th>\n",
       "      <th>IC172Q09JA</th>\n",
       "      <th>IC173Q01JA</th>\n",
       "      <th>IC173Q02JA</th>\n",
       "      <th>IC173Q03JA</th>\n",
       "      <th>IC173Q04JA</th>\n",
       "      <th>IC174Q01JA</th>\n",
       "      <th>IC174Q02JA</th>\n",
       "      <th>IC174Q03JA</th>\n",
       "      <th>IC174Q04JA</th>\n",
       "      <th>IC174Q05JA</th>\n",
       "      <th>IC174Q06JA</th>\n",
       "      <th>IC174Q07JA</th>\n",
       "      <th>IC174Q08JA</th>\n",
       "      <th>IC174Q09JA</th>\n",
       "      <th>IC174Q10JA</th>\n",
       "      <th>IC175Q01JA</th>\n",
       "      <th>IC175Q02JA</th>\n",
       "      <th>IC175Q03JA</th>\n",
       "      <th>IC175Q05JA</th>\n",
       "      <th>IC176Q01JA</th>\n",
       "      <th>IC176Q02JA</th>\n",
       "      <th>IC176Q03JA</th>\n",
       "      <th>IC176Q04JA</th>\n",
       "      <th>IC176Q05JA</th>\n",
       "      <th>IC176Q06JA</th>\n",
       "      <th>IC176Q07JA</th>\n",
       "      <th>IC176Q08JA</th>\n",
       "      <th>IC177Q01JA</th>\n",
       "      <th>IC177Q02JA</th>\n",
       "      <th>IC177Q03JA</th>\n",
       "      <th>IC177Q04JA</th>\n",
       "      <th>IC177Q05JA</th>\n",
       "      <th>IC177Q06JA</th>\n",
       "      <th>IC177Q07JA</th>\n",
       "      <th>IC178Q01JA</th>\n",
       "      <th>IC178Q02JA</th>\n",
       "      <th>IC178Q03JA</th>\n",
       "      <th>IC178Q04JA</th>\n",
       "      <th>IC178Q05JA</th>\n",
       "      <th>IC178Q06JA</th>\n",
       "      <th>IC178Q07JA</th>\n",
       "      <th>IC179Q01JA</th>\n",
       "      <th>IC179Q02JA</th>\n",
       "      <th>IC179Q03JA</th>\n",
       "      <th>IC179Q04JA</th>\n",
       "      <th>IC179Q05JA</th>\n",
       "      <th>IC179Q06JA</th>\n",
       "      <th>IC180Q02JA</th>\n",
       "      <th>IC180Q03JA</th>\n",
       "      <th>IC180Q04JA</th>\n",
       "      <th>IC180Q05JA</th>\n",
       "      <th>IC180Q06JA</th>\n",
       "      <th>IC180Q07JA</th>\n",
       "      <th>IC183Q01JA</th>\n",
       "      <th>IC183Q02JA</th>\n",
       "      <th>IC183Q03JA</th>\n",
       "      <th>IC183Q04JA</th>\n",
       "      <th>IC183Q05JA</th>\n",
       "      <th>IC183Q07JA</th>\n",
       "      <th>IC183Q08JA</th>\n",
       "      <th>IC183Q09JA</th>\n",
       "      <th>IC183Q10JA</th>\n",
       "      <th>IC183Q12JA</th>\n",
       "      <th>IC183Q13JA</th>\n",
       "      <th>IC183Q14JA</th>\n",
       "      <th>IC183Q15JA</th>\n",
       "      <th>IC183Q16JA</th>\n",
       "      <th>ST347Q01JA</th>\n",
       "      <th>ST347Q02JA</th>\n",
       "      <th>ST259Q01JA</th>\n",
       "      <th>ST004D01T</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>REPEAT</th>\n",
       "      <th>EXPECEDU</th>\n",
       "      <th>ICTAVSCH</th>\n",
       "      <th>ICTAVHOM</th>\n",
       "      <th>IMMIG</th>\n",
       "      <th>TARDYSD</th>\n",
       "      <th>ST226Q01JA</th>\n",
       "      <th>MISSSC</th>\n",
       "      <th>PAREDINT</th>\n",
       "      <th>ST230Q01JA</th>\n",
       "      <th>SKIPPING</th>\n",
       "      <th>IC180Q01JA</th>\n",
       "      <th>IC180Q08JA</th>\n",
       "      <th>ST059Q02JA</th>\n",
       "      <th>ST296Q04JA</th>\n",
       "      <th>STUDYHMW</th>\n",
       "      <th>IC184Q01JA</th>\n",
       "      <th>IC184Q02JA</th>\n",
       "      <th>ST059Q01TA</th>\n",
       "      <th>ST296Q01JA</th>\n",
       "      <th>ST268Q01JA</th>\n",
       "      <th>ST268Q04JA</th>\n",
       "      <th>ST268Q07JA</th>\n",
       "      <th>ST297Q01JA</th>\n",
       "      <th>ST297Q03JA</th>\n",
       "      <th>ST297Q05JA</th>\n",
       "      <th>ST297Q06JA</th>\n",
       "      <th>ST297Q07JA</th>\n",
       "      <th>ST297Q09JA</th>\n",
       "      <th>ST258Q01JA</th>\n",
       "      <th>ST294Q01JA</th>\n",
       "      <th>ST295Q01JA</th>\n",
       "      <th>EXERPRAC</th>\n",
       "      <th>WORKPAY</th>\n",
       "      <th>WORKHOME</th>\n",
       "      <th>SC001Q01TA</th>\n",
       "      <th>SC211Q01JA</th>\n",
       "      <th>SC211Q02JA</th>\n",
       "      <th>SC211Q03JA</th>\n",
       "      <th>SC211Q04JA</th>\n",
       "      <th>SC211Q05JA</th>\n",
       "      <th>SC211Q06JA</th>\n",
       "      <th>SC037Q11JA</th>\n",
       "      <th>SC183Q02JA</th>\n",
       "      <th>SC183Q03JA</th>\n",
       "      <th>SC183Q04JA</th>\n",
       "      <th>SC175Q01JA</th>\n",
       "      <th>SC188Q01JA</th>\n",
       "      <th>SC188Q02JA</th>\n",
       "      <th>SC188Q03JA</th>\n",
       "      <th>SC188Q04JA</th>\n",
       "      <th>SC188Q05JA</th>\n",
       "      <th>...</th>\n",
       "      <th>ST349Q01JA_2</th>\n",
       "      <th>ST349Q01JA_3</th>\n",
       "      <th>ST349Q01JA_4</th>\n",
       "      <th>ST349Q01JA_0</th>\n",
       "      <th>LANGN_105</th>\n",
       "      <th>LANGN_108</th>\n",
       "      <th>LANGN_118</th>\n",
       "      <th>LANGN_140</th>\n",
       "      <th>LANGN_148</th>\n",
       "      <th>LANGN_150</th>\n",
       "      <th>LANGN_156</th>\n",
       "      <th>LANGN_200</th>\n",
       "      <th>LANGN_204</th>\n",
       "      <th>LANGN_232</th>\n",
       "      <th>LANGN_273</th>\n",
       "      <th>LANGN_313</th>\n",
       "      <th>LANGN_316</th>\n",
       "      <th>LANGN_322</th>\n",
       "      <th>LANGN_329</th>\n",
       "      <th>LANGN_344</th>\n",
       "      <th>LANGN_351</th>\n",
       "      <th>LANGN_415</th>\n",
       "      <th>LANGN_463</th>\n",
       "      <th>LANGN_493</th>\n",
       "      <th>LANGN_496</th>\n",
       "      <th>LANGN_500</th>\n",
       "      <th>LANGN_520</th>\n",
       "      <th>LANGN_531</th>\n",
       "      <th>LANGN_602</th>\n",
       "      <th>LANGN_606</th>\n",
       "      <th>LANGN_615</th>\n",
       "      <th>LANGN_621</th>\n",
       "      <th>LANGN_625</th>\n",
       "      <th>LANGN_640</th>\n",
       "      <th>LANGN_641</th>\n",
       "      <th>LANGN_663</th>\n",
       "      <th>LANGN_669</th>\n",
       "      <th>LANGN_670</th>\n",
       "      <th>LANGN_800</th>\n",
       "      <th>LANGN_801</th>\n",
       "      <th>LANGN_802</th>\n",
       "      <th>LANGN_804</th>\n",
       "      <th>LANGN_805</th>\n",
       "      <th>LANGN_806</th>\n",
       "      <th>LANGN_807</th>\n",
       "      <th>LANGN_808</th>\n",
       "      <th>LANGN_865</th>\n",
       "      <th>LANGN_892</th>\n",
       "      <th>LANGN_895</th>\n",
       "      <th>LANGN_917</th>\n",
       "      <th>SC177Q01JA_1</th>\n",
       "      <th>SC177Q01JA_2</th>\n",
       "      <th>SC177Q01JA_3</th>\n",
       "      <th>SC177Q02JA_1</th>\n",
       "      <th>SC177Q02JA_2</th>\n",
       "      <th>SC177Q02JA_3</th>\n",
       "      <th>SC177Q03JA_1</th>\n",
       "      <th>SC177Q03JA_2</th>\n",
       "      <th>SC177Q03JA_3</th>\n",
       "      <th>MATHEXC_0</th>\n",
       "      <th>MATHEXC_1</th>\n",
       "      <th>MATHEXC_2</th>\n",
       "      <th>MATHEXC_3</th>\n",
       "      <th>SCHLTYPE_1</th>\n",
       "      <th>SCHLTYPE_2</th>\n",
       "      <th>SCHLTYPE_3</th>\n",
       "      <th>LANGN_121</th>\n",
       "      <th>LANGN_130</th>\n",
       "      <th>LANGN_137</th>\n",
       "      <th>LANGN_170</th>\n",
       "      <th>LANGN_244</th>\n",
       "      <th>LANGN_258</th>\n",
       "      <th>LANGN_263</th>\n",
       "      <th>LANGN_264</th>\n",
       "      <th>LANGN_266</th>\n",
       "      <th>LANGN_317</th>\n",
       "      <th>LANGN_340</th>\n",
       "      <th>LANGN_369</th>\n",
       "      <th>LANGN_381</th>\n",
       "      <th>LANGN_404</th>\n",
       "      <th>LANGN_420</th>\n",
       "      <th>LANGN_449</th>\n",
       "      <th>LANGN_467</th>\n",
       "      <th>LANGN_494</th>\n",
       "      <th>LANGN_495</th>\n",
       "      <th>LANGN_514</th>\n",
       "      <th>LANGN_523</th>\n",
       "      <th>LANGN_529</th>\n",
       "      <th>LANGN_540</th>\n",
       "      <th>LANGN_547</th>\n",
       "      <th>LANGN_600</th>\n",
       "      <th>LANGN_607</th>\n",
       "      <th>LANGN_618</th>\n",
       "      <th>LANGN_619</th>\n",
       "      <th>LANGN_630</th>\n",
       "      <th>LANGN_635</th>\n",
       "      <th>LANGN_650</th>\n",
       "      <th>LANGN_661</th>\n",
       "      <th>LANGN_673</th>\n",
       "      <th>LANGN_674</th>\n",
       "      <th>LANGN_809</th>\n",
       "      <th>LANGN_810</th>\n",
       "      <th>LANGN_811</th>\n",
       "      <th>LANGN_812</th>\n",
       "      <th>LANGN_813</th>\n",
       "      <th>LANGN_814</th>\n",
       "      <th>LANGN_815</th>\n",
       "      <th>LANGN_816</th>\n",
       "      <th>LANGN_818</th>\n",
       "      <th>LANGN_832</th>\n",
       "      <th>LANGN_868</th>\n",
       "      <th>LANGN_870</th>\n",
       "      <th>LANGN_920</th>\n",
       "      <th>LANGN_921</th>\n",
       "      <th>LANGN_113</th>\n",
       "      <th>LANGN_147</th>\n",
       "      <th>LANGN_275</th>\n",
       "      <th>LANGN_286</th>\n",
       "      <th>LANGN_363</th>\n",
       "      <th>LANGN_422</th>\n",
       "      <th>LANGN_434</th>\n",
       "      <th>LANGN_442</th>\n",
       "      <th>LANGN_471</th>\n",
       "      <th>LANGN_611</th>\n",
       "      <th>LANGN_614</th>\n",
       "      <th>LANGN_624</th>\n",
       "      <th>LANGN_642</th>\n",
       "      <th>LANGN_675</th>\n",
       "      <th>LANGN_676</th>\n",
       "      <th>LANGN_677</th>\n",
       "      <th>LANGN_678</th>\n",
       "      <th>LANGN_817</th>\n",
       "      <th>LANGN_819</th>\n",
       "      <th>LANGN_821</th>\n",
       "      <th>LANGN_823</th>\n",
       "      <th>LANGN_824</th>\n",
       "      <th>LANGN_825</th>\n",
       "      <th>LANGN_826</th>\n",
       "      <th>LANGN_827</th>\n",
       "      <th>LANGN_828</th>\n",
       "      <th>LANGN_885</th>\n",
       "      <th>LANGN_896</th>\n",
       "      <th>LANGN_916</th>\n",
       "      <th>LANGN_112</th>\n",
       "      <th>LANGN_154</th>\n",
       "      <th>LANGN_202</th>\n",
       "      <th>LANGN_246</th>\n",
       "      <th>LANGN_254</th>\n",
       "      <th>LANGN_272</th>\n",
       "      <th>LANGN_301</th>\n",
       "      <th>LANGN_325</th>\n",
       "      <th>LANGN_338</th>\n",
       "      <th>LANGN_358</th>\n",
       "      <th>LANGN_371</th>\n",
       "      <th>LANGN_375</th>\n",
       "      <th>LANGN_383</th>\n",
       "      <th>LANGN_409</th>\n",
       "      <th>LANGN_428</th>\n",
       "      <th>LANGN_465</th>\n",
       "      <th>LANGN_517</th>\n",
       "      <th>LANGN_527</th>\n",
       "      <th>LANGN_561</th>\n",
       "      <th>LANGN_562</th>\n",
       "      <th>LANGN_563</th>\n",
       "      <th>LANGN_565</th>\n",
       "      <th>LANGN_566</th>\n",
       "      <th>LANGN_567</th>\n",
       "      <th>LANGN_601</th>\n",
       "      <th>LANGN_622</th>\n",
       "      <th>LANGN_623</th>\n",
       "      <th>LANGN_628</th>\n",
       "      <th>LANGN_631</th>\n",
       "      <th>LANGN_831</th>\n",
       "      <th>LANGN_833</th>\n",
       "      <th>LANGN_836</th>\n",
       "      <th>LANGN_837</th>\n",
       "      <th>LANGN_838</th>\n",
       "      <th>LANGN_839</th>\n",
       "      <th>LANGN_840</th>\n",
       "      <th>LANGN_841</th>\n",
       "      <th>LANGN_845</th>\n",
       "      <th>LANGN_872</th>\n",
       "      <th>LANGN_873</th>\n",
       "      <th>LANGN_881</th>\n",
       "      <th>LANGN_890</th>\n",
       "      <th>LANGN_897</th>\n",
       "      <th>LANGN_898</th>\n",
       "      <th>LANGN_899</th>\n",
       "      <th>LANGN_900</th>\n",
       "      <th>LANGN_901</th>\n",
       "      <th>LANGN_902</th>\n",
       "      <th>LANGN_903</th>\n",
       "      <th>LANGN_904</th>\n",
       "      <th>LANGN_905</th>\n",
       "      <th>LANGN_906</th>\n",
       "      <th>LANGN_907</th>\n",
       "      <th>LANGN_908</th>\n",
       "      <th>LANGN_909</th>\n",
       "      <th>LANGN_910</th>\n",
       "      <th>LANGN_911</th>\n",
       "      <th>LANGN_912</th>\n",
       "      <th>LANGN_913</th>\n",
       "      <th>LANGN_914</th>\n",
       "      <th>LANGN_918</th>\n",
       "      <th>LANGN_919</th>\n",
       "      <th>LANGN_160</th>\n",
       "      <th>LANGN_327</th>\n",
       "      <th>LANGN_451</th>\n",
       "      <th>LANGN_474</th>\n",
       "      <th>LANGN_503</th>\n",
       "      <th>LANGN_608</th>\n",
       "      <th>LANGN_627</th>\n",
       "      <th>LANGN_639</th>\n",
       "      <th>LANGN_668</th>\n",
       "      <th>LANGN_842</th>\n",
       "      <th>LANGN_843</th>\n",
       "      <th>LANGN_844</th>\n",
       "      <th>LANGN_846</th>\n",
       "      <th>LANGN_849</th>\n",
       "      <th>LANGN_850</th>\n",
       "      <th>LANGN_851</th>\n",
       "      <th>LANGN_852</th>\n",
       "      <th>LANGN_861</th>\n",
       "      <th>LANGN_879</th>\n",
       "      <th>LANGN_133</th>\n",
       "      <th>LANGN_195</th>\n",
       "      <th>LANGN_237</th>\n",
       "      <th>LANGN_379</th>\n",
       "      <th>LANGN_382</th>\n",
       "      <th>LANGN_472</th>\n",
       "      <th>LANGN_492</th>\n",
       "      <th>LANGN_555</th>\n",
       "      <th>LANGN_605</th>\n",
       "      <th>LANGN_616</th>\n",
       "      <th>LANGN_626</th>\n",
       "      <th>LANGN_634</th>\n",
       "      <th>LANGN_648</th>\n",
       "      <th>LANGN_662</th>\n",
       "      <th>LANGN_665</th>\n",
       "      <th>LANGN_666</th>\n",
       "      <th>LANGN_667</th>\n",
       "      <th>LANGN_829</th>\n",
       "      <th>LANGN_854</th>\n",
       "      <th>LANGN_855</th>\n",
       "      <th>LANGN_857</th>\n",
       "      <th>LANGN_859</th>\n",
       "      <th>LANGN_860</th>\n",
       "      <th>LANGN_866</th>\n",
       "      <th>LANGN_877</th>\n",
       "      <th>LANGN_922</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>575474</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574994</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574164</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576638</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577351</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 558 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MATH_Proficient  SISCO  ST250Q01JA  ST250Q02JA  ST250Q03JA  \\\n",
       "575474              0.0    0.0         1.0         1.0         1.0   \n",
       "574994              1.0    1.0         2.0         1.0         1.0   \n",
       "574164              0.0    1.0         1.0         2.0         2.0   \n",
       "576638              0.0    0.0         1.0         1.0         1.0   \n",
       "577351              1.0    1.0         1.0         1.0         1.0   \n",
       "\n",
       "        ST250Q04JA  ST250Q05JA  ST251Q01JA  ST251Q02JA  ST251Q03JA  \\\n",
       "575474         1.0         1.0         2.0         1.0         2.0   \n",
       "574994         1.0         1.0         3.0         2.0         2.0   \n",
       "574164         1.0         1.0         3.0         1.0         2.0   \n",
       "576638         1.0         1.0         2.0         1.0         3.0   \n",
       "577351         1.0         1.0         4.0         1.0         3.0   \n",
       "\n",
       "        ST251Q04JA  ST251Q06JA  ST253Q01JA  ST254Q01JA  ST254Q02JA  \\\n",
       "575474         2.0         1.0         7.0         3.0         2.0   \n",
       "574994         2.0         4.0         7.0         3.0         1.0   \n",
       "574164         1.0         2.0         8.0         3.0         1.0   \n",
       "576638         4.0         1.0         7.0         2.0         1.0   \n",
       "577351         3.0         1.0         8.0         3.0         1.0   \n",
       "\n",
       "        ST254Q03JA  ST254Q04JA  ST254Q05JA  ST254Q06JA  ST255Q01JA  \\\n",
       "575474         2.0         1.0         2.0         3.0         2.0   \n",
       "574994         2.0         2.0         1.0         3.0         3.0   \n",
       "574164         2.0         2.0         1.0         4.0         3.0   \n",
       "576638         2.0         2.0         1.0         3.0         2.0   \n",
       "577351         3.0         2.0         1.0         3.0         3.0   \n",
       "\n",
       "        ST038Q03NA  ST038Q04NA  ST038Q05NA  ST038Q06NA  ST038Q07NA  \\\n",
       "575474         2.0         1.0         1.0         1.0         2.0   \n",
       "574994         1.0         1.0         1.0         1.0         1.0   \n",
       "574164         1.0         1.0         1.0         1.0         1.0   \n",
       "576638         1.0         1.0         1.0         1.0         1.0   \n",
       "577351         1.0         1.0         1.0         1.0         1.0   \n",
       "\n",
       "        ST038Q08NA  ST038Q09JA  ST038Q10JA  ST038Q11JA  ST265Q01JA  \\\n",
       "575474         2.0         1.0         1.0         1.0         2.0   \n",
       "574994         2.0         1.0         2.0         1.0         2.0   \n",
       "574164         1.0         1.0         1.0         1.0         2.0   \n",
       "576638         1.0         1.0         1.0         1.0         2.0   \n",
       "577351         1.0         1.0         1.0         1.0         1.0   \n",
       "\n",
       "        ST265Q02JA  ST265Q03JA  ST265Q04JA  ST266Q01JA  ST266Q02JA  \\\n",
       "575474         2.0         2.0         2.0         2.0         2.0   \n",
       "574994         2.0         3.0         3.0         1.0         2.0   \n",
       "574164         2.0         2.0         2.0         2.0         2.0   \n",
       "576638         2.0         2.0         2.0         2.0         2.0   \n",
       "577351         2.0         2.0         2.0         2.0         2.0   \n",
       "\n",
       "        ST266Q03JA  ST266Q04JA  ST266Q05JA  ST263Q02JA  ST263Q04JA  \\\n",
       "575474         2.0         2.0         2.0         4.0         4.0   \n",
       "574994         2.0         1.0         2.0         2.0         2.0   \n",
       "574164         2.0         2.0         2.0         4.0         2.0   \n",
       "576638         2.0         2.0         2.0         2.0         3.0   \n",
       "577351         2.0         2.0         2.0         2.0         2.0   \n",
       "\n",
       "        ST263Q06JA  ST270Q01JA  ST270Q02JA  ST270Q03JA  ST270Q04JA  \\\n",
       "575474         4.0         1.0         1.0         3.0         4.0   \n",
       "574994         2.0         2.0         1.0         1.0         2.0   \n",
       "574164         2.0         1.0         2.0         1.0         2.0   \n",
       "576638         2.0         2.0         2.0         2.0         2.0   \n",
       "577351         2.0         1.0         1.0         1.0         1.0   \n",
       "\n",
       "        FL166Q01HA  FL166Q02HA  FL166Q03HA  FL166Q05HA  FL166Q06HA  \\\n",
       "575474         1.0         1.0         1.0         1.0         1.0   \n",
       "574994         2.0         1.0         1.0         1.0         1.0   \n",
       "574164         3.0         3.0         2.0         2.0         2.0   \n",
       "576638         1.0         2.0         2.0         2.0         2.0   \n",
       "577351         1.0         2.0         2.0         1.0         1.0   \n",
       "\n",
       "        FL166Q07HA  FL174Q01JA  FL174Q02JA  FL174Q03JA  FL174Q04JA  \\\n",
       "575474         1.0         2.0         2.0         2.0         2.0   \n",
       "574994         3.0         1.0         1.0         4.0         4.0   \n",
       "574164         2.0         2.0         2.0         2.0         2.0   \n",
       "576638         2.0         2.0         2.0         2.0         2.0   \n",
       "577351         1.0         2.0         4.0         4.0         4.0   \n",
       "\n",
       "        FL174Q05JA  FL174Q06JA  FL174Q07JA  FL167Q01HA  FL167Q02HA  \\\n",
       "575474         2.0         2.0         2.0         2.0         1.0   \n",
       "574994         1.0         4.0         1.0         1.0         1.0   \n",
       "574164         1.0         1.0         1.0         2.0         2.0   \n",
       "576638         2.0         2.0         2.0         2.0         2.0   \n",
       "577351         2.0         2.0         2.0         3.0         2.0   \n",
       "\n",
       "        FL167Q06JA  FL167Q03HA  FL167Q04HA  FL167Q05HA  FL167Q07JA  \\\n",
       "575474         1.0         2.0         3.0         1.0         4.0   \n",
       "574994         1.0         1.0         2.0         1.0         2.0   \n",
       "574164         2.0         2.0         2.0         2.0         2.0   \n",
       "576638         2.0         2.0         2.0         2.0         2.0   \n",
       "577351         3.0         4.0         3.0         1.0         4.0   \n",
       "\n",
       "        FL170Q01JA  FL170Q02JA  FL170Q03JA  FL170Q04JA  FL170Q05JA  \\\n",
       "575474         1.0         3.0         1.0         1.0         1.0   \n",
       "574994         1.0         1.0         1.0         1.0         1.0   \n",
       "574164         3.0         3.0         1.0         1.0         1.0   \n",
       "576638         2.0         1.0         1.0         1.0         1.0   \n",
       "577351         1.0         4.0         1.0         3.0         1.0   \n",
       "\n",
       "        FL170Q06JA  FL170Q07JA  FL162Q01HA  FL162Q02HA  FL162Q03HA  \\\n",
       "575474         1.0         1.0         1.0         1.0         1.0   \n",
       "574994         3.0         1.0         1.0         1.0         2.0   \n",
       "574164         4.0         5.0         3.0         3.0         2.0   \n",
       "576638         2.0         1.0         3.0         2.0         2.0   \n",
       "577351         2.0         1.0         2.0         2.0         2.0   \n",
       "\n",
       "        FL162Q04HA  FL162Q05HA  FL162Q06HA  FL163Q01HA  FL163Q02HA  \\\n",
       "575474         1.0         1.0         1.0         1.0         1.0   \n",
       "574994         1.0         2.0         3.0         2.0         2.0   \n",
       "574164         2.0         4.0         4.0         3.0         3.0   \n",
       "576638         2.0         3.0         3.0         3.0         3.0   \n",
       "577351         2.0         4.0         3.0         3.0         3.0   \n",
       "\n",
       "        FL163Q03HA  FL163Q04HA  FL163Q05HA  FL171Q01JA  FL171Q02JA  \\\n",
       "575474         1.0         1.0         1.0         1.0         4.0   \n",
       "574994         4.0         3.0         3.0         4.0         3.0   \n",
       "574164         3.0         3.0         3.0         3.0         3.0   \n",
       "576638         3.0         3.0         3.0         3.0         3.0   \n",
       "577351         3.0         2.0         3.0         3.0         2.0   \n",
       "\n",
       "        FL171Q03JA  FL171Q04JA  FL171Q05JA  FL171Q07JA  FL171Q08JA  \\\n",
       "575474         4.0         1.0         4.0         1.0         5.0   \n",
       "574994         4.0         4.0         4.0         3.0         4.0   \n",
       "574164         3.0         3.0         2.0         3.0         2.0   \n",
       "576638         3.0         3.0         3.0         3.0         4.0   \n",
       "577351         3.0         1.0         3.0         2.0         5.0   \n",
       "\n",
       "        FL171Q09JA  FL171Q10JA  FL171Q11JA  FL171Q12JA  FL169Q01HA  \\\n",
       "575474         1.0         1.0         1.0         1.0         4.0   \n",
       "574994         1.0         1.0         1.0         5.0         2.0   \n",
       "574164         3.0         2.0         3.0         3.0         3.0   \n",
       "576638         5.0         1.0         3.0         4.0         3.0   \n",
       "577351         2.0         3.0         2.0         5.0         3.0   \n",
       "\n",
       "        FL169Q05JA  FL169Q02HA  FL169Q04HA  FL169Q08JA  FL169Q10JA  \\\n",
       "575474         1.0         3.0         1.0         1.0         1.0   \n",
       "574994         3.0         3.0         2.0         3.0         3.0   \n",
       "574164         3.0         3.0         3.0         3.0         3.0   \n",
       "576638         3.0         3.0         3.0         3.0         3.0   \n",
       "577351         3.0         3.0         4.0         3.0         3.0   \n",
       "\n",
       "        FL169Q11JA  FL172Q01JA  FL172Q03JA  FL172Q05JA  FL172Q06JA  \\\n",
       "575474         1.0         3.0         1.0         1.0         1.0   \n",
       "574994         3.0         3.0         2.0         1.0         3.0   \n",
       "574164         3.0         3.0         2.0         3.0         3.0   \n",
       "576638         3.0         2.0         2.0         2.0         2.0   \n",
       "577351         4.0         1.0         1.0         1.0         3.0   \n",
       "\n",
       "        IC170Q01JA  IC170Q02JA  IC170Q03JA  IC170Q04JA  IC170Q05JA  \\\n",
       "575474         5.0         5.0         1.0         5.0         5.0   \n",
       "574994         5.0         5.0         1.0         5.0         4.0   \n",
       "574164         5.0         5.0         5.0         5.0         2.0   \n",
       "576638         3.0         3.0         1.0         3.0         3.0   \n",
       "577351         5.0         1.0         1.0         5.0         5.0   \n",
       "\n",
       "        IC170Q06JA  IC170Q07JA  IC171Q01JA  IC171Q02JA  IC171Q03JA  \\\n",
       "575474         5.0         5.0         5.0         5.0         1.0   \n",
       "574994         2.0         5.0         4.0         5.0         1.0   \n",
       "574164         5.0         5.0         5.0         5.0         4.0   \n",
       "576638         4.0         3.0         4.0         5.0         4.0   \n",
       "577351         1.0         5.0         5.0         5.0         3.0   \n",
       "\n",
       "        IC171Q04JA  IC171Q05JA  IC171Q06JA  IC172Q01JA  IC172Q02JA  \\\n",
       "575474         5.0         1.0         1.0         4.0         4.0   \n",
       "574994         4.0         1.0         3.0         3.0         3.0   \n",
       "574164         5.0         4.0         5.0         3.0         3.0   \n",
       "576638         4.0         4.0         3.0         1.0         2.0   \n",
       "577351         5.0         2.0         1.0         4.0         4.0   \n",
       "\n",
       "        IC172Q03JA  IC172Q04JA  IC172Q05JA  IC172Q06JA  IC172Q07JA  \\\n",
       "575474         1.0         3.0         3.0         3.0         3.0   \n",
       "574994         3.0         3.0         3.0         2.0         3.0   \n",
       "574164         3.0         3.0         3.0         3.0         3.0   \n",
       "576638         3.0         3.0         3.0         2.0         1.0   \n",
       "577351         4.0         4.0         4.0         3.0         3.0   \n",
       "\n",
       "        IC172Q08JA  IC172Q09JA  IC173Q01JA  IC173Q02JA  IC173Q03JA  \\\n",
       "575474         3.0         3.0         4.0         4.0         4.0   \n",
       "574994         3.0         3.0         5.0         6.0         6.0   \n",
       "574164         3.0         3.0         4.0         4.0         5.0   \n",
       "576638         2.0         3.0         3.0         3.0         4.0   \n",
       "577351         3.0         4.0         4.0         3.0         4.0   \n",
       "\n",
       "        IC173Q04JA  IC174Q01JA  IC174Q02JA  IC174Q03JA  IC174Q04JA  \\\n",
       "575474         1.0         3.0         4.0         1.0         1.0   \n",
       "574994         6.0         3.0         4.0         4.0         1.0   \n",
       "574164         4.0         3.0         2.0         3.0         2.0   \n",
       "576638         2.0         5.0         4.0         3.0         2.0   \n",
       "577351         6.0         4.0         5.0         2.0         2.0   \n",
       "\n",
       "        IC174Q05JA  IC174Q06JA  IC174Q07JA  IC174Q08JA  IC174Q09JA  \\\n",
       "575474         1.0         1.0         1.0         1.0         1.0   \n",
       "574994         1.0         1.0         3.0         4.0         2.0   \n",
       "574164         3.0         3.0         2.0         3.0         2.0   \n",
       "576638         1.0         2.0         3.0         4.0         3.0   \n",
       "577351         1.0         1.0         3.0         5.0         3.0   \n",
       "\n",
       "        IC174Q10JA  IC175Q01JA  IC175Q02JA  IC175Q03JA  IC175Q05JA  \\\n",
       "575474         1.0         1.0         2.0         1.0         1.0   \n",
       "574994         4.0         4.0         1.0         4.0         3.0   \n",
       "574164         3.0         2.0         3.0         2.0         3.0   \n",
       "576638         5.0         5.0         4.0         3.0         2.0   \n",
       "577351         4.0         4.0         3.0         1.0         1.0   \n",
       "\n",
       "        IC176Q01JA  IC176Q02JA  IC176Q03JA  IC176Q04JA  IC176Q05JA  \\\n",
       "575474         5.0         5.0         5.0         1.0         5.0   \n",
       "574994         5.0         4.0         2.0         3.0         4.0   \n",
       "574164         2.0         3.0         4.0         3.0         2.0   \n",
       "576638         5.0         5.0         5.0         5.0         5.0   \n",
       "577351         5.0         5.0         5.0         5.0         5.0   \n",
       "\n",
       "        IC176Q06JA  IC176Q07JA  IC176Q08JA  IC177Q01JA  IC177Q02JA  \\\n",
       "575474         4.0         5.0         5.0         6.0         6.0   \n",
       "574994         4.0         2.0         3.0         2.0         6.0   \n",
       "574164         4.0         4.0         4.0         2.0         3.0   \n",
       "576638         5.0         5.0         5.0         6.0         5.0   \n",
       "577351         4.0         4.0         4.0         1.0         4.0   \n",
       "\n",
       "        IC177Q03JA  IC177Q04JA  IC177Q05JA  IC177Q06JA  IC177Q07JA  \\\n",
       "575474         6.0         6.0         6.0         6.0         6.0   \n",
       "574994         5.0         2.0         5.0         2.0         1.0   \n",
       "574164         3.0         4.0         4.0         4.0         4.0   \n",
       "576638         4.0         3.0         2.0         1.0         2.0   \n",
       "577351         3.0         2.0         2.0         2.0         1.0   \n",
       "\n",
       "        IC178Q01JA  IC178Q02JA  IC178Q03JA  IC178Q04JA  IC178Q05JA  \\\n",
       "575474         6.0         6.0         6.0         6.0         6.0   \n",
       "574994         3.0         6.0         6.0         2.0         6.0   \n",
       "574164         2.0         3.0         2.0         3.0         4.0   \n",
       "576638         2.0         3.0         2.0         2.0         3.0   \n",
       "577351         1.0         5.0         3.0         3.0         4.0   \n",
       "\n",
       "        IC178Q06JA  IC178Q07JA  IC179Q01JA  IC179Q02JA  IC179Q03JA  \\\n",
       "575474         2.0         1.0         1.0         1.0         4.0   \n",
       "574994         2.0         1.0         1.0         1.0         3.0   \n",
       "574164         4.0         4.0         1.0         3.0         2.0   \n",
       "576638         3.0         3.0         1.0         2.0         3.0   \n",
       "577351         2.0         1.0         1.0         1.0         4.0   \n",
       "\n",
       "        IC179Q04JA  IC179Q05JA  IC179Q06JA  IC180Q02JA  IC180Q03JA  \\\n",
       "575474         1.0         1.0         1.0         3.0         4.0   \n",
       "574994         1.0         1.0         2.0         3.0         3.0   \n",
       "574164         3.0         2.0         3.0         3.0         3.0   \n",
       "576638         2.0         3.0         3.0         3.0         2.0   \n",
       "577351         3.0         3.0         2.0         2.0         2.0   \n",
       "\n",
       "        IC180Q04JA  IC180Q05JA  IC180Q06JA  IC180Q07JA  IC183Q01JA  \\\n",
       "575474         2.0         4.0         1.0         1.0         4.0   \n",
       "574994         3.0         2.0         2.0         1.0         3.0   \n",
       "574164         2.0         2.0         3.0         3.0         3.0   \n",
       "576638         3.0         4.0         2.0         2.0         5.0   \n",
       "577351         2.0         3.0         3.0         2.0         4.0   \n",
       "\n",
       "        IC183Q02JA  IC183Q03JA  IC183Q04JA  IC183Q05JA  IC183Q07JA  \\\n",
       "575474         4.0         4.0         4.0         3.0         4.0   \n",
       "574994         3.0         3.0         2.0         2.0         3.0   \n",
       "574164         3.0         3.0         2.0         3.0         2.0   \n",
       "576638         5.0         4.0         4.0         4.0         4.0   \n",
       "577351         3.0         4.0         4.0         4.0         4.0   \n",
       "\n",
       "        IC183Q08JA  IC183Q09JA  IC183Q10JA  IC183Q12JA  IC183Q13JA  \\\n",
       "575474         2.0         3.0         2.0         3.0         4.0   \n",
       "574994         3.0         3.0         1.0         3.0         3.0   \n",
       "574164         3.0         2.0         3.0         3.0         2.0   \n",
       "576638         4.0         4.0         4.0         4.0         4.0   \n",
       "577351         4.0         4.0         1.0         4.0         4.0   \n",
       "\n",
       "        IC183Q14JA  IC183Q15JA  IC183Q16JA  ST347Q01JA  ST347Q02JA  \\\n",
       "575474         1.0         2.0         1.0         4.0         1.0   \n",
       "574994         1.0         1.0         1.0         4.0         2.0   \n",
       "574164         3.0         3.0         3.0         3.0         1.0   \n",
       "576638         4.0         4.0         4.0         4.0         1.0   \n",
       "577351         1.0         1.0         3.0         1.0         1.0   \n",
       "\n",
       "        ST259Q01JA  ST004D01T  GRADE  REPEAT  EXPECEDU  ICTAVSCH  ICTAVHOM  \\\n",
       "575474         5.0        1.0    0.0     0.0       7.0       7.0       6.0   \n",
       "574994         3.0        1.0    1.0     0.0       7.0       7.0       6.0   \n",
       "574164         6.0        1.0    0.0     0.0       9.0       7.0       6.0   \n",
       "576638         7.0        1.0    0.0     0.0       8.0       6.0       5.0   \n",
       "577351         6.0        1.0    0.0     0.0       7.0       7.0       6.0   \n",
       "\n",
       "        IMMIG  TARDYSD  ST226Q01JA  MISSSC  PAREDINT  ST230Q01JA  SKIPPING  \\\n",
       "575474    3.0      0.0         3.0     0.0      14.5         4.0       0.0   \n",
       "574994    1.0      2.0         2.0     0.0      12.0         3.0       1.0   \n",
       "574164    1.0      1.0         3.0     0.0      16.0         4.0       0.0   \n",
       "576638    1.0      1.0         3.0     0.0      16.0         2.0       0.0   \n",
       "577351    1.0      1.0         3.0     0.0      16.0         4.0       0.0   \n",
       "\n",
       "        IC180Q01JA  IC180Q08JA  ST059Q02JA  ST296Q04JA  STUDYHMW  IC184Q01JA  \\\n",
       "575474         3.0         1.0         8.0         1.0       0.0         5.0   \n",
       "574994         3.0         3.0         8.0         1.0       1.0         4.0   \n",
       "574164         3.0         3.0         1.0         4.0       4.0         3.0   \n",
       "576638         2.0         2.0        20.0         3.0       6.0         4.0   \n",
       "577351         3.0         1.0        20.0         4.0       4.0         5.0   \n",
       "\n",
       "        IC184Q02JA  ST059Q01TA  ST296Q01JA  ST268Q01JA  ST268Q04JA  \\\n",
       "575474         5.0         3.0         1.0         1.0         2.0   \n",
       "574994         4.0         4.0         1.0         1.0         3.0   \n",
       "574164         3.0         1.0         1.0         1.0         1.0   \n",
       "576638         4.0         3.0         1.0         2.0         2.0   \n",
       "577351         3.0         5.0         2.0         4.0         4.0   \n",
       "\n",
       "        ST268Q07JA  ST297Q01JA  ST297Q03JA  ST297Q05JA  ST297Q06JA  \\\n",
       "575474         1.0         0.0         0.0         0.0         0.0   \n",
       "574994         4.0         0.0         0.0         0.0         0.0   \n",
       "574164         3.0         1.0         0.0         0.0         1.0   \n",
       "576638         4.0         0.0         0.0         0.0         0.0   \n",
       "577351         4.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "        ST297Q07JA  ST297Q09JA  ST258Q01JA  ST294Q01JA  ST295Q01JA  EXERPRAC  \\\n",
       "575474         0.0         1.0         1.0         1.0         6.0       0.0   \n",
       "574994         0.0         1.0         1.0         4.0         2.0       1.0   \n",
       "574164         1.0         0.0         1.0         2.0         6.0       9.0   \n",
       "576638         0.0         1.0         1.0         4.0         6.0       6.0   \n",
       "577351         0.0         1.0         1.0         4.0         5.0       0.0   \n",
       "\n",
       "        WORKPAY  WORKHOME  SC001Q01TA  SC211Q01JA  SC211Q02JA  SC211Q03JA  \\\n",
       "575474      1.0       1.0         4.0        49.0        12.0        53.0   \n",
       "574994      0.0       0.0         3.0        13.0        13.0        41.0   \n",
       "574164      0.0       6.0         4.0         9.0        16.0        83.0   \n",
       "576638      0.0      10.0         3.0        65.0         6.0         1.0   \n",
       "577351      0.0       0.0         3.0        20.0         2.0        22.0   \n",
       "\n",
       "        SC211Q04JA  SC211Q05JA  SC211Q06JA  SC037Q11JA  SC183Q02JA  \\\n",
       "575474        19.0        37.0         2.0         1.0         1.0   \n",
       "574994        12.0        30.0         0.0         1.0         2.0   \n",
       "574164         4.0         9.0         0.0         1.0         1.0   \n",
       "576638        65.0        80.0         0.0         1.0         1.0   \n",
       "577351         3.0         1.0         0.0         1.0         1.0   \n",
       "\n",
       "        SC183Q03JA  SC183Q04JA  SC175Q01JA  SC188Q01JA  SC188Q02JA  \\\n",
       "575474         1.0         1.0        60.0         4.0         4.0   \n",
       "574994         2.0         2.0        90.0         4.0         4.0   \n",
       "574164         1.0         1.0        50.0         3.0         3.0   \n",
       "576638         1.0         1.0        90.0         4.0         4.0   \n",
       "577351         1.0         1.0        90.0         4.0         4.0   \n",
       "\n",
       "        SC188Q03JA  SC188Q04JA  SC188Q05JA  ...  ST349Q01JA_2  ST349Q01JA_3  \\\n",
       "575474         3.0         3.0         3.0  ...             0             0   \n",
       "574994         2.0         4.0         2.0  ...             0             0   \n",
       "574164         2.0         1.0         2.0  ...             0             0   \n",
       "576638         2.0         1.0         4.0  ...             0             0   \n",
       "577351         4.0         4.0         4.0  ...             0             0   \n",
       "\n",
       "        ST349Q01JA_4  ST349Q01JA_0  LANGN_105  LANGN_108  LANGN_118  \\\n",
       "575474             0             0          0          0          0   \n",
       "574994             1             0          0          0          0   \n",
       "574164             1             0          0          0          0   \n",
       "576638             0             0          0          0          0   \n",
       "577351             0             0          0          0          0   \n",
       "\n",
       "        LANGN_140  LANGN_148  LANGN_150  LANGN_156  LANGN_200  LANGN_204  \\\n",
       "575474          0          0          0          1          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          1          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_232  LANGN_273  LANGN_313  LANGN_316  LANGN_322  LANGN_329  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          1          0          0          0   \n",
       "574164          0          0          1          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          1          0          0          0   \n",
       "\n",
       "        LANGN_344  LANGN_351  LANGN_415  LANGN_463  LANGN_493  LANGN_496  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_500  LANGN_520  LANGN_531  LANGN_602  LANGN_606  LANGN_615  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_621  LANGN_625  LANGN_640  LANGN_641  LANGN_663  LANGN_669  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_670  LANGN_800  LANGN_801  LANGN_802  LANGN_804  LANGN_805  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_806  LANGN_807  LANGN_808  LANGN_865  LANGN_892  LANGN_895  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_917  SC177Q01JA_1  SC177Q01JA_2  SC177Q01JA_3  SC177Q02JA_1  \\\n",
       "575474          0             0             0             0             0   \n",
       "574994          0             1             0             0             1   \n",
       "574164          0             0             0             1             1   \n",
       "576638          0             0             0             1             0   \n",
       "577351          0             0             0             1             0   \n",
       "\n",
       "        SC177Q02JA_2  SC177Q02JA_3  SC177Q03JA_1  SC177Q03JA_2  SC177Q03JA_3  \\\n",
       "575474             0             0             0             0             0   \n",
       "574994             0             0             1             0             0   \n",
       "574164             0             0             0             0             1   \n",
       "576638             0             1             1             0             0   \n",
       "577351             0             1             1             0             0   \n",
       "\n",
       "        MATHEXC_0  MATHEXC_1  MATHEXC_2  MATHEXC_3  SCHLTYPE_1  SCHLTYPE_2  \\\n",
       "575474          0          0          0          0           0           0   \n",
       "574994          0          0          0          0           0           0   \n",
       "574164          0          0          0          1           0           0   \n",
       "576638          0          0          0          0           0           0   \n",
       "577351          0          0          0          1           0           0   \n",
       "\n",
       "        SCHLTYPE_3  LANGN_121  LANGN_130  LANGN_137  LANGN_170  LANGN_244  \\\n",
       "575474           1          0          0          0          0          0   \n",
       "574994           1          0          0          0          0          0   \n",
       "574164           1          0          0          0          0          0   \n",
       "576638           1          0          0          0          0          0   \n",
       "577351           1          0          0          0          0          0   \n",
       "\n",
       "        LANGN_258  LANGN_263  LANGN_264  LANGN_266  LANGN_317  LANGN_340  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_369  LANGN_381  LANGN_404  LANGN_420  LANGN_449  LANGN_467  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_494  LANGN_495  LANGN_514  LANGN_523  LANGN_529  LANGN_540  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_547  LANGN_600  LANGN_607  LANGN_618  LANGN_619  LANGN_630  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_635  LANGN_650  LANGN_661  LANGN_673  LANGN_674  LANGN_809  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_810  LANGN_811  LANGN_812  LANGN_813  LANGN_814  LANGN_815  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_816  LANGN_818  LANGN_832  LANGN_868  LANGN_870  LANGN_920  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_921  LANGN_113  LANGN_147  LANGN_275  LANGN_286  LANGN_363  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_422  LANGN_434  LANGN_442  LANGN_471  LANGN_611  LANGN_614  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_624  LANGN_642  LANGN_675  LANGN_676  LANGN_677  LANGN_678  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_817  LANGN_819  LANGN_821  LANGN_823  LANGN_824  LANGN_825  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_826  LANGN_827  LANGN_828  LANGN_885  LANGN_896  LANGN_916  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_112  LANGN_154  LANGN_202  LANGN_246  LANGN_254  LANGN_272  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_301  LANGN_325  LANGN_338  LANGN_358  LANGN_371  LANGN_375  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_383  LANGN_409  LANGN_428  LANGN_465  LANGN_517  LANGN_527  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_561  LANGN_562  LANGN_563  LANGN_565  LANGN_566  LANGN_567  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_601  LANGN_622  LANGN_623  LANGN_628  LANGN_631  LANGN_831  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_833  LANGN_836  LANGN_837  LANGN_838  LANGN_839  LANGN_840  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_841  LANGN_845  LANGN_872  LANGN_873  LANGN_881  LANGN_890  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_897  LANGN_898  LANGN_899  LANGN_900  LANGN_901  LANGN_902  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_903  LANGN_904  LANGN_905  LANGN_906  LANGN_907  LANGN_908  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_909  LANGN_910  LANGN_911  LANGN_912  LANGN_913  LANGN_914  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_918  LANGN_919  LANGN_160  LANGN_327  LANGN_451  LANGN_474  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_503  LANGN_608  LANGN_627  LANGN_639  LANGN_668  LANGN_842  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_843  LANGN_844  LANGN_846  LANGN_849  LANGN_850  LANGN_851  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_852  LANGN_861  LANGN_879  LANGN_133  LANGN_195  LANGN_237  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_379  LANGN_382  LANGN_472  LANGN_492  LANGN_555  LANGN_605  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_616  LANGN_626  LANGN_634  LANGN_648  LANGN_662  LANGN_665  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_666  LANGN_667  LANGN_829  LANGN_854  LANGN_855  LANGN_857  \\\n",
       "575474          0          0          0          0          0          0   \n",
       "574994          0          0          0          0          0          0   \n",
       "574164          0          0          0          0          0          0   \n",
       "576638          0          0          0          0          0          0   \n",
       "577351          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_859  LANGN_860  LANGN_866  LANGN_877  LANGN_922  \n",
       "575474          0          0          0          0          0  \n",
       "574994          0          0          0          0          0  \n",
       "574164          0          0          0          0          0  \n",
       "576638          0          0          0          0          0  \n",
       "577351          0          0          0          0          0  \n",
       "\n",
       "[5 rows x 558 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data - Saved later to S3 as CSV\n",
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(683, 558)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MATH_Proficient</th>\n",
       "      <th>SISCO</th>\n",
       "      <th>ST250Q01JA</th>\n",
       "      <th>ST250Q02JA</th>\n",
       "      <th>ST250Q03JA</th>\n",
       "      <th>ST250Q04JA</th>\n",
       "      <th>ST250Q05JA</th>\n",
       "      <th>ST251Q01JA</th>\n",
       "      <th>ST251Q02JA</th>\n",
       "      <th>ST251Q03JA</th>\n",
       "      <th>ST251Q04JA</th>\n",
       "      <th>ST251Q06JA</th>\n",
       "      <th>ST253Q01JA</th>\n",
       "      <th>ST254Q01JA</th>\n",
       "      <th>ST254Q02JA</th>\n",
       "      <th>ST254Q03JA</th>\n",
       "      <th>ST254Q04JA</th>\n",
       "      <th>ST254Q05JA</th>\n",
       "      <th>ST254Q06JA</th>\n",
       "      <th>ST255Q01JA</th>\n",
       "      <th>ST038Q03NA</th>\n",
       "      <th>ST038Q04NA</th>\n",
       "      <th>ST038Q05NA</th>\n",
       "      <th>ST038Q06NA</th>\n",
       "      <th>ST038Q07NA</th>\n",
       "      <th>ST038Q08NA</th>\n",
       "      <th>ST038Q09JA</th>\n",
       "      <th>ST038Q10JA</th>\n",
       "      <th>ST038Q11JA</th>\n",
       "      <th>ST265Q01JA</th>\n",
       "      <th>ST265Q02JA</th>\n",
       "      <th>ST265Q03JA</th>\n",
       "      <th>ST265Q04JA</th>\n",
       "      <th>ST266Q01JA</th>\n",
       "      <th>ST266Q02JA</th>\n",
       "      <th>ST266Q03JA</th>\n",
       "      <th>ST266Q04JA</th>\n",
       "      <th>ST266Q05JA</th>\n",
       "      <th>ST263Q02JA</th>\n",
       "      <th>ST263Q04JA</th>\n",
       "      <th>ST263Q06JA</th>\n",
       "      <th>ST270Q01JA</th>\n",
       "      <th>ST270Q02JA</th>\n",
       "      <th>ST270Q03JA</th>\n",
       "      <th>ST270Q04JA</th>\n",
       "      <th>FL166Q01HA</th>\n",
       "      <th>FL166Q02HA</th>\n",
       "      <th>FL166Q03HA</th>\n",
       "      <th>FL166Q05HA</th>\n",
       "      <th>FL166Q06HA</th>\n",
       "      <th>FL166Q07HA</th>\n",
       "      <th>FL174Q01JA</th>\n",
       "      <th>FL174Q02JA</th>\n",
       "      <th>FL174Q03JA</th>\n",
       "      <th>FL174Q04JA</th>\n",
       "      <th>FL174Q05JA</th>\n",
       "      <th>FL174Q06JA</th>\n",
       "      <th>FL174Q07JA</th>\n",
       "      <th>FL167Q01HA</th>\n",
       "      <th>FL167Q02HA</th>\n",
       "      <th>FL167Q06JA</th>\n",
       "      <th>FL167Q03HA</th>\n",
       "      <th>FL167Q04HA</th>\n",
       "      <th>FL167Q05HA</th>\n",
       "      <th>FL167Q07JA</th>\n",
       "      <th>FL170Q01JA</th>\n",
       "      <th>FL170Q02JA</th>\n",
       "      <th>FL170Q03JA</th>\n",
       "      <th>FL170Q04JA</th>\n",
       "      <th>FL170Q05JA</th>\n",
       "      <th>FL170Q06JA</th>\n",
       "      <th>FL170Q07JA</th>\n",
       "      <th>FL162Q01HA</th>\n",
       "      <th>FL162Q02HA</th>\n",
       "      <th>FL162Q03HA</th>\n",
       "      <th>FL162Q04HA</th>\n",
       "      <th>FL162Q05HA</th>\n",
       "      <th>FL162Q06HA</th>\n",
       "      <th>FL163Q01HA</th>\n",
       "      <th>FL163Q02HA</th>\n",
       "      <th>FL163Q03HA</th>\n",
       "      <th>FL163Q04HA</th>\n",
       "      <th>FL163Q05HA</th>\n",
       "      <th>FL171Q01JA</th>\n",
       "      <th>FL171Q02JA</th>\n",
       "      <th>FL171Q03JA</th>\n",
       "      <th>FL171Q04JA</th>\n",
       "      <th>FL171Q05JA</th>\n",
       "      <th>FL171Q07JA</th>\n",
       "      <th>FL171Q08JA</th>\n",
       "      <th>FL171Q09JA</th>\n",
       "      <th>FL171Q10JA</th>\n",
       "      <th>FL171Q11JA</th>\n",
       "      <th>FL171Q12JA</th>\n",
       "      <th>FL169Q01HA</th>\n",
       "      <th>FL169Q05JA</th>\n",
       "      <th>FL169Q02HA</th>\n",
       "      <th>FL169Q04HA</th>\n",
       "      <th>FL169Q08JA</th>\n",
       "      <th>FL169Q10JA</th>\n",
       "      <th>FL169Q11JA</th>\n",
       "      <th>FL172Q01JA</th>\n",
       "      <th>FL172Q03JA</th>\n",
       "      <th>FL172Q05JA</th>\n",
       "      <th>FL172Q06JA</th>\n",
       "      <th>IC170Q01JA</th>\n",
       "      <th>IC170Q02JA</th>\n",
       "      <th>IC170Q03JA</th>\n",
       "      <th>IC170Q04JA</th>\n",
       "      <th>IC170Q05JA</th>\n",
       "      <th>IC170Q06JA</th>\n",
       "      <th>IC170Q07JA</th>\n",
       "      <th>IC171Q01JA</th>\n",
       "      <th>IC171Q02JA</th>\n",
       "      <th>IC171Q03JA</th>\n",
       "      <th>IC171Q04JA</th>\n",
       "      <th>IC171Q05JA</th>\n",
       "      <th>IC171Q06JA</th>\n",
       "      <th>IC172Q01JA</th>\n",
       "      <th>IC172Q02JA</th>\n",
       "      <th>IC172Q03JA</th>\n",
       "      <th>IC172Q04JA</th>\n",
       "      <th>IC172Q05JA</th>\n",
       "      <th>IC172Q06JA</th>\n",
       "      <th>IC172Q07JA</th>\n",
       "      <th>IC172Q08JA</th>\n",
       "      <th>IC172Q09JA</th>\n",
       "      <th>IC173Q01JA</th>\n",
       "      <th>IC173Q02JA</th>\n",
       "      <th>IC173Q03JA</th>\n",
       "      <th>IC173Q04JA</th>\n",
       "      <th>IC174Q01JA</th>\n",
       "      <th>IC174Q02JA</th>\n",
       "      <th>IC174Q03JA</th>\n",
       "      <th>IC174Q04JA</th>\n",
       "      <th>IC174Q05JA</th>\n",
       "      <th>IC174Q06JA</th>\n",
       "      <th>IC174Q07JA</th>\n",
       "      <th>IC174Q08JA</th>\n",
       "      <th>IC174Q09JA</th>\n",
       "      <th>IC174Q10JA</th>\n",
       "      <th>IC175Q01JA</th>\n",
       "      <th>IC175Q02JA</th>\n",
       "      <th>IC175Q03JA</th>\n",
       "      <th>IC175Q05JA</th>\n",
       "      <th>IC176Q01JA</th>\n",
       "      <th>IC176Q02JA</th>\n",
       "      <th>IC176Q03JA</th>\n",
       "      <th>IC176Q04JA</th>\n",
       "      <th>IC176Q05JA</th>\n",
       "      <th>IC176Q06JA</th>\n",
       "      <th>IC176Q07JA</th>\n",
       "      <th>IC176Q08JA</th>\n",
       "      <th>IC177Q01JA</th>\n",
       "      <th>IC177Q02JA</th>\n",
       "      <th>IC177Q03JA</th>\n",
       "      <th>IC177Q04JA</th>\n",
       "      <th>IC177Q05JA</th>\n",
       "      <th>IC177Q06JA</th>\n",
       "      <th>IC177Q07JA</th>\n",
       "      <th>IC178Q01JA</th>\n",
       "      <th>IC178Q02JA</th>\n",
       "      <th>IC178Q03JA</th>\n",
       "      <th>IC178Q04JA</th>\n",
       "      <th>IC178Q05JA</th>\n",
       "      <th>IC178Q06JA</th>\n",
       "      <th>IC178Q07JA</th>\n",
       "      <th>IC179Q01JA</th>\n",
       "      <th>IC179Q02JA</th>\n",
       "      <th>IC179Q03JA</th>\n",
       "      <th>IC179Q04JA</th>\n",
       "      <th>IC179Q05JA</th>\n",
       "      <th>IC179Q06JA</th>\n",
       "      <th>IC180Q02JA</th>\n",
       "      <th>IC180Q03JA</th>\n",
       "      <th>IC180Q04JA</th>\n",
       "      <th>IC180Q05JA</th>\n",
       "      <th>IC180Q06JA</th>\n",
       "      <th>IC180Q07JA</th>\n",
       "      <th>IC183Q01JA</th>\n",
       "      <th>IC183Q02JA</th>\n",
       "      <th>IC183Q03JA</th>\n",
       "      <th>IC183Q04JA</th>\n",
       "      <th>IC183Q05JA</th>\n",
       "      <th>IC183Q07JA</th>\n",
       "      <th>IC183Q08JA</th>\n",
       "      <th>IC183Q09JA</th>\n",
       "      <th>IC183Q10JA</th>\n",
       "      <th>IC183Q12JA</th>\n",
       "      <th>IC183Q13JA</th>\n",
       "      <th>IC183Q14JA</th>\n",
       "      <th>IC183Q15JA</th>\n",
       "      <th>IC183Q16JA</th>\n",
       "      <th>ST347Q01JA</th>\n",
       "      <th>ST347Q02JA</th>\n",
       "      <th>ST259Q01JA</th>\n",
       "      <th>ST004D01T</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>REPEAT</th>\n",
       "      <th>EXPECEDU</th>\n",
       "      <th>ICTAVSCH</th>\n",
       "      <th>ICTAVHOM</th>\n",
       "      <th>IMMIG</th>\n",
       "      <th>TARDYSD</th>\n",
       "      <th>ST226Q01JA</th>\n",
       "      <th>MISSSC</th>\n",
       "      <th>PAREDINT</th>\n",
       "      <th>ST230Q01JA</th>\n",
       "      <th>SKIPPING</th>\n",
       "      <th>IC180Q01JA</th>\n",
       "      <th>IC180Q08JA</th>\n",
       "      <th>ST059Q02JA</th>\n",
       "      <th>ST296Q04JA</th>\n",
       "      <th>STUDYHMW</th>\n",
       "      <th>IC184Q01JA</th>\n",
       "      <th>IC184Q02JA</th>\n",
       "      <th>ST059Q01TA</th>\n",
       "      <th>ST296Q01JA</th>\n",
       "      <th>ST268Q01JA</th>\n",
       "      <th>ST268Q04JA</th>\n",
       "      <th>ST268Q07JA</th>\n",
       "      <th>ST297Q01JA</th>\n",
       "      <th>ST297Q03JA</th>\n",
       "      <th>ST297Q05JA</th>\n",
       "      <th>ST297Q06JA</th>\n",
       "      <th>ST297Q07JA</th>\n",
       "      <th>ST297Q09JA</th>\n",
       "      <th>ST258Q01JA</th>\n",
       "      <th>ST294Q01JA</th>\n",
       "      <th>ST295Q01JA</th>\n",
       "      <th>EXERPRAC</th>\n",
       "      <th>WORKPAY</th>\n",
       "      <th>WORKHOME</th>\n",
       "      <th>SC001Q01TA</th>\n",
       "      <th>SC211Q01JA</th>\n",
       "      <th>SC211Q02JA</th>\n",
       "      <th>SC211Q03JA</th>\n",
       "      <th>SC211Q04JA</th>\n",
       "      <th>SC211Q05JA</th>\n",
       "      <th>SC211Q06JA</th>\n",
       "      <th>SC037Q11JA</th>\n",
       "      <th>SC183Q02JA</th>\n",
       "      <th>SC183Q03JA</th>\n",
       "      <th>SC183Q04JA</th>\n",
       "      <th>SC175Q01JA</th>\n",
       "      <th>SC188Q01JA</th>\n",
       "      <th>SC188Q02JA</th>\n",
       "      <th>SC188Q03JA</th>\n",
       "      <th>SC188Q04JA</th>\n",
       "      <th>SC188Q05JA</th>\n",
       "      <th>...</th>\n",
       "      <th>ST349Q01JA_2</th>\n",
       "      <th>ST349Q01JA_3</th>\n",
       "      <th>ST349Q01JA_4</th>\n",
       "      <th>ST349Q01JA_0</th>\n",
       "      <th>LANGN_105</th>\n",
       "      <th>LANGN_108</th>\n",
       "      <th>LANGN_118</th>\n",
       "      <th>LANGN_140</th>\n",
       "      <th>LANGN_148</th>\n",
       "      <th>LANGN_150</th>\n",
       "      <th>LANGN_156</th>\n",
       "      <th>LANGN_200</th>\n",
       "      <th>LANGN_204</th>\n",
       "      <th>LANGN_232</th>\n",
       "      <th>LANGN_273</th>\n",
       "      <th>LANGN_313</th>\n",
       "      <th>LANGN_316</th>\n",
       "      <th>LANGN_322</th>\n",
       "      <th>LANGN_329</th>\n",
       "      <th>LANGN_344</th>\n",
       "      <th>LANGN_351</th>\n",
       "      <th>LANGN_415</th>\n",
       "      <th>LANGN_463</th>\n",
       "      <th>LANGN_493</th>\n",
       "      <th>LANGN_496</th>\n",
       "      <th>LANGN_500</th>\n",
       "      <th>LANGN_520</th>\n",
       "      <th>LANGN_531</th>\n",
       "      <th>LANGN_602</th>\n",
       "      <th>LANGN_606</th>\n",
       "      <th>LANGN_615</th>\n",
       "      <th>LANGN_621</th>\n",
       "      <th>LANGN_625</th>\n",
       "      <th>LANGN_640</th>\n",
       "      <th>LANGN_641</th>\n",
       "      <th>LANGN_663</th>\n",
       "      <th>LANGN_669</th>\n",
       "      <th>LANGN_670</th>\n",
       "      <th>LANGN_800</th>\n",
       "      <th>LANGN_801</th>\n",
       "      <th>LANGN_802</th>\n",
       "      <th>LANGN_804</th>\n",
       "      <th>LANGN_805</th>\n",
       "      <th>LANGN_806</th>\n",
       "      <th>LANGN_807</th>\n",
       "      <th>LANGN_808</th>\n",
       "      <th>LANGN_865</th>\n",
       "      <th>LANGN_892</th>\n",
       "      <th>LANGN_895</th>\n",
       "      <th>LANGN_917</th>\n",
       "      <th>SC177Q01JA_1</th>\n",
       "      <th>SC177Q01JA_2</th>\n",
       "      <th>SC177Q01JA_3</th>\n",
       "      <th>SC177Q02JA_1</th>\n",
       "      <th>SC177Q02JA_2</th>\n",
       "      <th>SC177Q02JA_3</th>\n",
       "      <th>SC177Q03JA_1</th>\n",
       "      <th>SC177Q03JA_2</th>\n",
       "      <th>SC177Q03JA_3</th>\n",
       "      <th>MATHEXC_0</th>\n",
       "      <th>MATHEXC_1</th>\n",
       "      <th>MATHEXC_2</th>\n",
       "      <th>MATHEXC_3</th>\n",
       "      <th>SCHLTYPE_1</th>\n",
       "      <th>SCHLTYPE_2</th>\n",
       "      <th>SCHLTYPE_3</th>\n",
       "      <th>LANGN_121</th>\n",
       "      <th>LANGN_130</th>\n",
       "      <th>LANGN_137</th>\n",
       "      <th>LANGN_170</th>\n",
       "      <th>LANGN_244</th>\n",
       "      <th>LANGN_258</th>\n",
       "      <th>LANGN_263</th>\n",
       "      <th>LANGN_264</th>\n",
       "      <th>LANGN_266</th>\n",
       "      <th>LANGN_317</th>\n",
       "      <th>LANGN_340</th>\n",
       "      <th>LANGN_369</th>\n",
       "      <th>LANGN_381</th>\n",
       "      <th>LANGN_404</th>\n",
       "      <th>LANGN_420</th>\n",
       "      <th>LANGN_449</th>\n",
       "      <th>LANGN_467</th>\n",
       "      <th>LANGN_494</th>\n",
       "      <th>LANGN_495</th>\n",
       "      <th>LANGN_514</th>\n",
       "      <th>LANGN_523</th>\n",
       "      <th>LANGN_529</th>\n",
       "      <th>LANGN_540</th>\n",
       "      <th>LANGN_547</th>\n",
       "      <th>LANGN_600</th>\n",
       "      <th>LANGN_607</th>\n",
       "      <th>LANGN_618</th>\n",
       "      <th>LANGN_619</th>\n",
       "      <th>LANGN_630</th>\n",
       "      <th>LANGN_635</th>\n",
       "      <th>LANGN_650</th>\n",
       "      <th>LANGN_661</th>\n",
       "      <th>LANGN_673</th>\n",
       "      <th>LANGN_674</th>\n",
       "      <th>LANGN_809</th>\n",
       "      <th>LANGN_810</th>\n",
       "      <th>LANGN_811</th>\n",
       "      <th>LANGN_812</th>\n",
       "      <th>LANGN_813</th>\n",
       "      <th>LANGN_814</th>\n",
       "      <th>LANGN_815</th>\n",
       "      <th>LANGN_816</th>\n",
       "      <th>LANGN_818</th>\n",
       "      <th>LANGN_832</th>\n",
       "      <th>LANGN_868</th>\n",
       "      <th>LANGN_870</th>\n",
       "      <th>LANGN_920</th>\n",
       "      <th>LANGN_921</th>\n",
       "      <th>LANGN_113</th>\n",
       "      <th>LANGN_147</th>\n",
       "      <th>LANGN_275</th>\n",
       "      <th>LANGN_286</th>\n",
       "      <th>LANGN_363</th>\n",
       "      <th>LANGN_422</th>\n",
       "      <th>LANGN_434</th>\n",
       "      <th>LANGN_442</th>\n",
       "      <th>LANGN_471</th>\n",
       "      <th>LANGN_611</th>\n",
       "      <th>LANGN_614</th>\n",
       "      <th>LANGN_624</th>\n",
       "      <th>LANGN_642</th>\n",
       "      <th>LANGN_675</th>\n",
       "      <th>LANGN_676</th>\n",
       "      <th>LANGN_677</th>\n",
       "      <th>LANGN_678</th>\n",
       "      <th>LANGN_817</th>\n",
       "      <th>LANGN_819</th>\n",
       "      <th>LANGN_821</th>\n",
       "      <th>LANGN_823</th>\n",
       "      <th>LANGN_824</th>\n",
       "      <th>LANGN_825</th>\n",
       "      <th>LANGN_826</th>\n",
       "      <th>LANGN_827</th>\n",
       "      <th>LANGN_828</th>\n",
       "      <th>LANGN_885</th>\n",
       "      <th>LANGN_896</th>\n",
       "      <th>LANGN_916</th>\n",
       "      <th>LANGN_112</th>\n",
       "      <th>LANGN_154</th>\n",
       "      <th>LANGN_202</th>\n",
       "      <th>LANGN_246</th>\n",
       "      <th>LANGN_254</th>\n",
       "      <th>LANGN_272</th>\n",
       "      <th>LANGN_301</th>\n",
       "      <th>LANGN_325</th>\n",
       "      <th>LANGN_338</th>\n",
       "      <th>LANGN_358</th>\n",
       "      <th>LANGN_371</th>\n",
       "      <th>LANGN_375</th>\n",
       "      <th>LANGN_383</th>\n",
       "      <th>LANGN_409</th>\n",
       "      <th>LANGN_428</th>\n",
       "      <th>LANGN_465</th>\n",
       "      <th>LANGN_517</th>\n",
       "      <th>LANGN_527</th>\n",
       "      <th>LANGN_561</th>\n",
       "      <th>LANGN_562</th>\n",
       "      <th>LANGN_563</th>\n",
       "      <th>LANGN_565</th>\n",
       "      <th>LANGN_566</th>\n",
       "      <th>LANGN_567</th>\n",
       "      <th>LANGN_601</th>\n",
       "      <th>LANGN_622</th>\n",
       "      <th>LANGN_623</th>\n",
       "      <th>LANGN_628</th>\n",
       "      <th>LANGN_631</th>\n",
       "      <th>LANGN_831</th>\n",
       "      <th>LANGN_833</th>\n",
       "      <th>LANGN_836</th>\n",
       "      <th>LANGN_837</th>\n",
       "      <th>LANGN_838</th>\n",
       "      <th>LANGN_839</th>\n",
       "      <th>LANGN_840</th>\n",
       "      <th>LANGN_841</th>\n",
       "      <th>LANGN_845</th>\n",
       "      <th>LANGN_872</th>\n",
       "      <th>LANGN_873</th>\n",
       "      <th>LANGN_881</th>\n",
       "      <th>LANGN_890</th>\n",
       "      <th>LANGN_897</th>\n",
       "      <th>LANGN_898</th>\n",
       "      <th>LANGN_899</th>\n",
       "      <th>LANGN_900</th>\n",
       "      <th>LANGN_901</th>\n",
       "      <th>LANGN_902</th>\n",
       "      <th>LANGN_903</th>\n",
       "      <th>LANGN_904</th>\n",
       "      <th>LANGN_905</th>\n",
       "      <th>LANGN_906</th>\n",
       "      <th>LANGN_907</th>\n",
       "      <th>LANGN_908</th>\n",
       "      <th>LANGN_909</th>\n",
       "      <th>LANGN_910</th>\n",
       "      <th>LANGN_911</th>\n",
       "      <th>LANGN_912</th>\n",
       "      <th>LANGN_913</th>\n",
       "      <th>LANGN_914</th>\n",
       "      <th>LANGN_918</th>\n",
       "      <th>LANGN_919</th>\n",
       "      <th>LANGN_160</th>\n",
       "      <th>LANGN_327</th>\n",
       "      <th>LANGN_451</th>\n",
       "      <th>LANGN_474</th>\n",
       "      <th>LANGN_503</th>\n",
       "      <th>LANGN_608</th>\n",
       "      <th>LANGN_627</th>\n",
       "      <th>LANGN_639</th>\n",
       "      <th>LANGN_668</th>\n",
       "      <th>LANGN_842</th>\n",
       "      <th>LANGN_843</th>\n",
       "      <th>LANGN_844</th>\n",
       "      <th>LANGN_846</th>\n",
       "      <th>LANGN_849</th>\n",
       "      <th>LANGN_850</th>\n",
       "      <th>LANGN_851</th>\n",
       "      <th>LANGN_852</th>\n",
       "      <th>LANGN_861</th>\n",
       "      <th>LANGN_879</th>\n",
       "      <th>LANGN_133</th>\n",
       "      <th>LANGN_195</th>\n",
       "      <th>LANGN_237</th>\n",
       "      <th>LANGN_379</th>\n",
       "      <th>LANGN_382</th>\n",
       "      <th>LANGN_472</th>\n",
       "      <th>LANGN_492</th>\n",
       "      <th>LANGN_555</th>\n",
       "      <th>LANGN_605</th>\n",
       "      <th>LANGN_616</th>\n",
       "      <th>LANGN_626</th>\n",
       "      <th>LANGN_634</th>\n",
       "      <th>LANGN_648</th>\n",
       "      <th>LANGN_662</th>\n",
       "      <th>LANGN_665</th>\n",
       "      <th>LANGN_666</th>\n",
       "      <th>LANGN_667</th>\n",
       "      <th>LANGN_829</th>\n",
       "      <th>LANGN_854</th>\n",
       "      <th>LANGN_855</th>\n",
       "      <th>LANGN_857</th>\n",
       "      <th>LANGN_859</th>\n",
       "      <th>LANGN_860</th>\n",
       "      <th>LANGN_866</th>\n",
       "      <th>LANGN_877</th>\n",
       "      <th>LANGN_922</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>574478</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573678</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576927</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576321</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576339</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 558 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MATH_Proficient  SISCO  ST250Q01JA  ST250Q02JA  ST250Q03JA  \\\n",
       "574478              1.0    1.0         2.0         1.0         1.0   \n",
       "573678              1.0    1.0         1.0         1.0         1.0   \n",
       "576927              0.0    1.0         1.0         2.0         1.0   \n",
       "576321              1.0    0.0         1.0         1.0         1.0   \n",
       "576339              1.0    1.0         1.0         1.0         2.0   \n",
       "\n",
       "        ST250Q04JA  ST250Q05JA  ST251Q01JA  ST251Q02JA  ST251Q03JA  \\\n",
       "574478         1.0         1.0         3.0         1.0         4.0   \n",
       "573678         1.0         1.0         4.0         2.0         3.0   \n",
       "576927         1.0         1.0         3.0         1.0         3.0   \n",
       "576321         1.0         1.0         4.0         1.0         4.0   \n",
       "576339         1.0         1.0         3.0         1.0         2.0   \n",
       "\n",
       "        ST251Q04JA  ST251Q06JA  ST253Q01JA  ST254Q01JA  ST254Q02JA  \\\n",
       "574478         4.0         4.0         8.0         3.0         2.0   \n",
       "573678         3.0         4.0         5.0         3.0         2.0   \n",
       "576927         3.0         1.0         5.0         4.0         1.0   \n",
       "576321         4.0         4.0         8.0         3.0         4.0   \n",
       "576339         2.0         1.0         7.0         2.0         2.0   \n",
       "\n",
       "        ST254Q03JA  ST254Q04JA  ST254Q05JA  ST254Q06JA  ST255Q01JA  \\\n",
       "574478         3.0         2.0         1.0         4.0         4.0   \n",
       "573678         2.0         1.0         1.0         3.0         3.0   \n",
       "576927         1.0         1.0         1.0         4.0         1.0   \n",
       "576321         4.0         4.0         1.0         4.0         2.0   \n",
       "576339         2.0         2.0         1.0         2.0         2.0   \n",
       "\n",
       "        ST038Q03NA  ST038Q04NA  ST038Q05NA  ST038Q06NA  ST038Q07NA  \\\n",
       "574478         1.0         1.0         1.0         1.0         1.0   \n",
       "573678         1.0         1.0         1.0         1.0         1.0   \n",
       "576927         1.0         1.0         1.0         1.0         1.0   \n",
       "576321         1.0         1.0         1.0         1.0         1.0   \n",
       "576339         2.0         1.0         1.0         1.0         1.0   \n",
       "\n",
       "        ST038Q08NA  ST038Q09JA  ST038Q10JA  ST038Q11JA  ST265Q01JA  \\\n",
       "574478         1.0         1.0         1.0         1.0         2.0   \n",
       "573678         1.0         1.0         1.0         1.0         2.0   \n",
       "576927         1.0         1.0         1.0         1.0         2.0   \n",
       "576321         1.0         1.0         1.0         1.0         2.0   \n",
       "576339         1.0         1.0         1.0         1.0         2.0   \n",
       "\n",
       "        ST265Q02JA  ST265Q03JA  ST265Q04JA  ST266Q01JA  ST266Q02JA  \\\n",
       "574478         2.0         2.0         2.0         2.0         1.0   \n",
       "573678         2.0         2.0         2.0         2.0         2.0   \n",
       "576927         2.0         2.0         2.0         2.0         2.0   \n",
       "576321         2.0         2.0         2.0         2.0         2.0   \n",
       "576339         2.0         2.0         2.0         2.0         2.0   \n",
       "\n",
       "        ST266Q03JA  ST266Q04JA  ST266Q05JA  ST263Q02JA  ST263Q04JA  \\\n",
       "574478         1.0         2.0         2.0         2.0         3.0   \n",
       "573678         2.0         2.0         1.0         2.0         3.0   \n",
       "576927         1.0         2.0         2.0         3.0         3.0   \n",
       "576321         2.0         2.0         2.0         2.0         2.0   \n",
       "576339         2.0         2.0         2.0         3.0         2.0   \n",
       "\n",
       "        ST263Q06JA  ST270Q01JA  ST270Q02JA  ST270Q03JA  ST270Q04JA  \\\n",
       "574478         2.0         1.0         1.0         1.0         1.0   \n",
       "573678         3.0         2.0         2.0         2.0         2.0   \n",
       "576927         3.0         4.0         2.0         3.0         3.0   \n",
       "576321         2.0         1.0         1.0         2.0         2.0   \n",
       "576339         2.0         2.0         2.0         2.0         2.0   \n",
       "\n",
       "        FL166Q01HA  FL166Q02HA  FL166Q03HA  FL166Q05HA  FL166Q06HA  \\\n",
       "574478         2.0         1.0         1.0         1.0         1.0   \n",
       "573678         2.0         2.0         2.0         1.0         1.0   \n",
       "576927         2.0         2.0         2.0         1.0         1.0   \n",
       "576321         1.0         1.0         1.0         1.0         1.0   \n",
       "576339         2.0         2.0         2.0         1.0         1.0   \n",
       "\n",
       "        FL166Q07HA  FL174Q01JA  FL174Q02JA  FL174Q03JA  FL174Q04JA  \\\n",
       "574478         3.0         2.0         4.0         2.0         4.0   \n",
       "573678         2.0         2.0         2.0         2.0         2.0   \n",
       "576927         2.0         1.0         2.0         2.0         2.0   \n",
       "576321         1.0         2.0         1.0         1.0         4.0   \n",
       "576339         2.0         2.0         2.0         2.0         2.0   \n",
       "\n",
       "        FL174Q05JA  FL174Q06JA  FL174Q07JA  FL167Q01HA  FL167Q02HA  \\\n",
       "574478         2.0         1.0         1.0         4.0         4.0   \n",
       "573678         2.0         2.0         4.0         2.0         2.0   \n",
       "576927         2.0         2.0         2.0         3.0         4.0   \n",
       "576321         4.0         4.0         4.0         2.0         2.0   \n",
       "576339         2.0         2.0         2.0         2.0         2.0   \n",
       "\n",
       "        FL167Q06JA  FL167Q03HA  FL167Q04HA  FL167Q05HA  FL167Q07JA  \\\n",
       "574478         3.0         4.0         4.0         3.0         4.0   \n",
       "573678         2.0         2.0         2.0         2.0         2.0   \n",
       "576927         2.0         1.0         4.0         1.0         4.0   \n",
       "576321         1.0         1.0         2.0         2.0         2.0   \n",
       "576339         2.0         2.0         2.0         2.0         2.0   \n",
       "\n",
       "        FL170Q01JA  FL170Q02JA  FL170Q03JA  FL170Q04JA  FL170Q05JA  \\\n",
       "574478         3.0         5.0         1.0         1.0         4.0   \n",
       "573678         2.0         1.0         1.0         1.0         1.0   \n",
       "576927         2.0         1.0         1.0         1.0         1.0   \n",
       "576321         1.0         3.0         1.0         1.0         1.0   \n",
       "576339         2.0         1.0         1.0         1.0         1.0   \n",
       "\n",
       "        FL170Q06JA  FL170Q07JA  FL162Q01HA  FL162Q02HA  FL162Q03HA  \\\n",
       "574478         3.0         1.0         2.0         2.0         2.0   \n",
       "573678         2.0         1.0         2.0         2.0         2.0   \n",
       "576927         2.0         1.0         3.0         2.0         2.0   \n",
       "576321         3.0         1.0         2.0         2.0         2.0   \n",
       "576339         2.0         1.0         2.0         2.0         2.0   \n",
       "\n",
       "        FL162Q04HA  FL162Q05HA  FL162Q06HA  FL163Q01HA  FL163Q02HA  \\\n",
       "574478         3.0         4.0         4.0         2.0         4.0   \n",
       "573678         2.0         3.0         3.0         3.0         3.0   \n",
       "576927         2.0         4.0         4.0         3.0         3.0   \n",
       "576321         2.0         3.0         3.0         3.0         3.0   \n",
       "576339         2.0         3.0         3.0         3.0         3.0   \n",
       "\n",
       "        FL163Q03HA  FL163Q04HA  FL163Q05HA  FL171Q01JA  FL171Q02JA  \\\n",
       "574478         4.0         4.0         4.0         5.0         2.0   \n",
       "573678         3.0         3.0         3.0         3.0         3.0   \n",
       "576927         2.0         4.0         4.0         1.0         3.0   \n",
       "576321         4.0         4.0         3.0         1.0         4.0   \n",
       "576339         3.0         3.0         3.0         3.0         3.0   \n",
       "\n",
       "        FL171Q03JA  FL171Q04JA  FL171Q05JA  FL171Q07JA  FL171Q08JA  \\\n",
       "574478         3.0         5.0         5.0         5.0         5.0   \n",
       "573678         3.0         3.0         3.0         3.0         4.0   \n",
       "576927         5.0         3.0         3.0         3.0         4.0   \n",
       "576321         4.0         4.0         4.0         2.0         4.0   \n",
       "576339         3.0         3.0         3.0         3.0         4.0   \n",
       "\n",
       "        FL171Q09JA  FL171Q10JA  FL171Q11JA  FL171Q12JA  FL169Q01HA  \\\n",
       "574478         4.0         5.0         5.0         5.0         3.0   \n",
       "573678         2.0         1.0         3.0         4.0         3.0   \n",
       "576927         2.0         1.0         3.0         4.0         3.0   \n",
       "576321         1.0         3.0         4.0         4.0         2.0   \n",
       "576339         2.0         1.0         3.0         4.0         3.0   \n",
       "\n",
       "        FL169Q05JA  FL169Q02HA  FL169Q04HA  FL169Q08JA  FL169Q10JA  \\\n",
       "574478         3.0         2.0         4.0         3.0         4.0   \n",
       "573678         3.0         3.0         3.0         3.0         3.0   \n",
       "576927         3.0         3.0         3.0         3.0         3.0   \n",
       "576321         3.0         2.0         3.0         3.0         2.0   \n",
       "576339         3.0         3.0         3.0         3.0         3.0   \n",
       "\n",
       "        FL169Q11JA  FL172Q01JA  FL172Q03JA  FL172Q05JA  FL172Q06JA  \\\n",
       "574478         2.0         2.0         1.0         1.0         1.0   \n",
       "573678         3.0         2.0         2.0         2.0         2.0   \n",
       "576927         3.0         3.0         2.0         3.0         3.0   \n",
       "576321         3.0         1.0         2.0         1.0         1.0   \n",
       "576339         3.0         2.0         2.0         2.0         2.0   \n",
       "\n",
       "        IC170Q01JA  IC170Q02JA  IC170Q03JA  IC170Q04JA  IC170Q05JA  \\\n",
       "574478         5.0         5.0         3.0         5.0         5.0   \n",
       "573678         5.0         5.0         1.0         5.0         4.0   \n",
       "576927         4.0         5.0         3.0         5.0         4.0   \n",
       "576321         5.0         5.0         5.0         5.0         5.0   \n",
       "576339         5.0         5.0         1.0         5.0         4.0   \n",
       "\n",
       "        IC170Q06JA  IC170Q07JA  IC171Q01JA  IC171Q02JA  IC171Q03JA  \\\n",
       "574478         5.0         5.0         5.0         5.0         3.0   \n",
       "573678         3.0         5.0         4.0         5.0         2.0   \n",
       "576927         3.0         5.0         4.0         5.0         2.0   \n",
       "576321         2.0         1.0         5.0         5.0         5.0   \n",
       "576339         3.0         5.0         4.0         5.0         2.0   \n",
       "\n",
       "        IC171Q04JA  IC171Q05JA  IC171Q06JA  IC172Q01JA  IC172Q02JA  \\\n",
       "574478         5.0         5.0         5.0         3.0         3.0   \n",
       "573678         5.0         3.0         4.0         3.0         3.0   \n",
       "576927         5.0         3.0         4.0         3.0         3.0   \n",
       "576321         5.0         2.0         2.0         1.0         4.0   \n",
       "576339         5.0         3.0         4.0         3.0         3.0   \n",
       "\n",
       "        IC172Q03JA  IC172Q04JA  IC172Q05JA  IC172Q06JA  IC172Q07JA  \\\n",
       "574478         2.0         2.0         3.0         3.0         3.0   \n",
       "573678         3.0         3.0         3.0         3.0         3.0   \n",
       "576927         3.0         3.0         3.0         3.0         3.0   \n",
       "576321         3.0         3.0         3.0         3.0         3.0   \n",
       "576339         3.0         3.0         3.0         3.0         3.0   \n",
       "\n",
       "        IC172Q08JA  IC172Q09JA  IC173Q01JA  IC173Q02JA  IC173Q03JA  \\\n",
       "574478         3.0         3.0         5.0         5.0         5.0   \n",
       "573678         3.0         3.0         5.0         4.0         4.0   \n",
       "576927         3.0         4.0         5.0         4.0         4.0   \n",
       "576321         3.0         3.0         3.0         4.0         3.0   \n",
       "576339         3.0         3.0         5.0         4.0         4.0   \n",
       "\n",
       "        IC173Q04JA  IC174Q01JA  IC174Q02JA  IC174Q03JA  IC174Q04JA  \\\n",
       "574478         6.0         4.0         5.0         5.0         5.0   \n",
       "573678         5.0         3.0         4.0         3.0         3.0   \n",
       "576927         5.0         3.0         4.0         3.0         3.0   \n",
       "576321         6.0         3.0         5.0         4.0         2.0   \n",
       "576339         5.0         3.0         4.0         3.0         3.0   \n",
       "\n",
       "        IC174Q05JA  IC174Q06JA  IC174Q07JA  IC174Q08JA  IC174Q09JA  \\\n",
       "574478         5.0         5.0         5.0         5.0         5.0   \n",
       "573678         3.0         3.0         3.0         4.0         3.0   \n",
       "576927         3.0         3.0         3.0         4.0         3.0   \n",
       "576321         2.0         2.0         2.0         2.0         4.0   \n",
       "576339         3.0         3.0         3.0         4.0         3.0   \n",
       "\n",
       "        IC174Q10JA  IC175Q01JA  IC175Q02JA  IC175Q03JA  IC175Q05JA  \\\n",
       "574478         5.0         5.0         4.0         4.0         5.0   \n",
       "573678         3.0         4.0         3.0         3.0         3.0   \n",
       "576927         3.0         4.0         3.0         3.0         3.0   \n",
       "576321         4.0         3.0         1.0         1.0         1.0   \n",
       "576339         3.0         4.0         3.0         3.0         3.0   \n",
       "\n",
       "        IC176Q01JA  IC176Q02JA  IC176Q03JA  IC176Q04JA  IC176Q05JA  \\\n",
       "574478         5.0         5.0         5.0         5.0         5.0   \n",
       "573678         5.0         4.0         4.0         4.0         4.0   \n",
       "576927         5.0         4.0         4.0         4.0         4.0   \n",
       "576321         5.0         4.0         1.0         4.0         4.0   \n",
       "576339         5.0         4.0         4.0         4.0         4.0   \n",
       "\n",
       "        IC176Q06JA  IC176Q07JA  IC176Q08JA  IC177Q01JA  IC177Q02JA  \\\n",
       "574478         4.0         5.0         5.0         2.0         3.0   \n",
       "573678         4.0         4.0         4.0         3.0         3.0   \n",
       "576927         4.0         4.0         4.0         3.0         3.0   \n",
       "576321         3.0         2.0         1.0         2.0         4.0   \n",
       "576339         4.0         4.0         4.0         3.0         3.0   \n",
       "\n",
       "        IC177Q03JA  IC177Q04JA  IC177Q05JA  IC177Q06JA  IC177Q07JA  \\\n",
       "574478         3.0         3.0         3.0         3.0         2.0   \n",
       "573678         3.0         2.0         3.0         2.0         2.0   \n",
       "576927         3.0         2.0         3.0         2.0         2.0   \n",
       "576321         5.0         1.0         5.0         1.0         3.0   \n",
       "576339         3.0         2.0         3.0         2.0         2.0   \n",
       "\n",
       "        IC178Q01JA  IC178Q02JA  IC178Q03JA  IC178Q04JA  IC178Q05JA  \\\n",
       "574478         3.0         3.0         3.0         3.0         3.0   \n",
       "573678         3.0         3.0         3.0         2.0         3.0   \n",
       "576927         3.0         3.0         3.0         2.0         3.0   \n",
       "576321         2.0         6.0         6.0         2.0         4.0   \n",
       "576339         3.0         3.0         3.0         2.0         3.0   \n",
       "\n",
       "        IC178Q06JA  IC178Q07JA  IC179Q01JA  IC179Q02JA  IC179Q03JA  \\\n",
       "574478         3.0         2.0         1.0         1.0         4.0   \n",
       "573678         2.0         2.0         2.0         2.0         3.0   \n",
       "576927         2.0         2.0         2.0         2.0         3.0   \n",
       "576321         1.0         3.0         2.0         1.0         3.0   \n",
       "576339         2.0         2.0         2.0         2.0         3.0   \n",
       "\n",
       "        IC179Q04JA  IC179Q05JA  IC179Q06JA  IC180Q02JA  IC180Q03JA  \\\n",
       "574478         1.0         3.0         3.0         4.0         4.0   \n",
       "573678         2.0         2.0         2.0         3.0         3.0   \n",
       "576927         2.0         2.0         2.0         3.0         3.0   \n",
       "576321         2.0         2.0         2.0         3.0         3.0   \n",
       "576339         2.0         2.0         2.0         3.0         3.0   \n",
       "\n",
       "        IC180Q04JA  IC180Q05JA  IC180Q06JA  IC180Q07JA  IC183Q01JA  \\\n",
       "574478         4.0         4.0         4.0         3.0         3.0   \n",
       "573678         3.0         3.0         3.0         2.0         4.0   \n",
       "576927         3.0         3.0         3.0         2.0         4.0   \n",
       "576321         2.0         3.0         3.0         2.0         4.0   \n",
       "576339         3.0         3.0         3.0         2.0         4.0   \n",
       "\n",
       "        IC183Q02JA  IC183Q03JA  IC183Q04JA  IC183Q05JA  IC183Q07JA  \\\n",
       "574478         4.0         4.0         4.0         4.0         4.0   \n",
       "573678         4.0         4.0         4.0         4.0         4.0   \n",
       "576927         4.0         4.0         4.0         4.0         4.0   \n",
       "576321         4.0         4.0         3.0         4.0         5.0   \n",
       "576339         4.0         4.0         4.0         4.0         4.0   \n",
       "\n",
       "        IC183Q08JA  IC183Q09JA  IC183Q10JA  IC183Q12JA  IC183Q13JA  \\\n",
       "574478         4.0         3.0         3.0         4.0         3.0   \n",
       "573678         4.0         4.0         3.0         4.0         4.0   \n",
       "576927         4.0         4.0         3.0         4.0         4.0   \n",
       "576321         3.0         3.0         4.0         4.0         4.0   \n",
       "576339         4.0         4.0         3.0         4.0         4.0   \n",
       "\n",
       "        IC183Q14JA  IC183Q15JA  IC183Q16JA  ST347Q01JA  ST347Q02JA  \\\n",
       "574478         3.0         3.0         3.0         6.0         1.0   \n",
       "573678         2.0         3.0         3.0         4.0         1.0   \n",
       "576927         2.0         3.0         3.0         4.0         4.0   \n",
       "576321         2.0         3.0         1.0         4.0         1.0   \n",
       "576339         2.0         3.0         3.0         3.0         1.0   \n",
       "\n",
       "        ST259Q01JA  ST004D01T  GRADE  REPEAT  EXPECEDU  ICTAVSCH  ICTAVHOM  \\\n",
       "574478         7.0        1.0    0.0     0.0       6.0       7.0       6.0   \n",
       "573678         9.0        2.0    0.0     0.0       7.0       7.0       6.0   \n",
       "576927         5.0        1.0    0.0     0.0       9.0       4.0       6.0   \n",
       "576321         8.0        1.0    1.0     0.0       7.0       7.0       6.0   \n",
       "576339         4.0        2.0   -1.0     0.0       4.0       7.0       6.0   \n",
       "\n",
       "        IMMIG  TARDYSD  ST226Q01JA  MISSSC  PAREDINT  ST230Q01JA  SKIPPING  \\\n",
       "574478    1.0      0.0         3.0     0.0      12.0         4.0       0.0   \n",
       "573678    1.0      1.0         3.0     0.0      16.0         3.0       1.0   \n",
       "576927    1.0      1.0         4.0     1.0      16.0         4.0       0.0   \n",
       "576321    2.0      0.0         2.0     0.0      16.0         3.0       1.0   \n",
       "576339    1.0      0.0         1.0     0.0      12.0         4.0       0.0   \n",
       "\n",
       "        IC180Q01JA  IC180Q08JA  ST059Q02JA  ST296Q04JA  STUDYHMW  IC184Q01JA  \\\n",
       "574478         1.0         3.0         3.0         3.0       9.0         3.0   \n",
       "573678         2.0         2.0         7.0         1.0       0.0         4.0   \n",
       "576927         2.0         2.0         4.0         1.0       4.0         4.0   \n",
       "576321         2.0         2.0        20.0         6.0       5.0         3.0   \n",
       "576339         2.0         2.0         7.0         5.0       2.0         4.0   \n",
       "\n",
       "        IC184Q02JA  ST059Q01TA  ST296Q01JA  ST268Q01JA  ST268Q04JA  \\\n",
       "574478         4.0         3.0         1.0         4.0         4.0   \n",
       "573678         4.0         7.0         1.0         2.0         3.0   \n",
       "576927         4.0         1.0         1.0         1.0         1.0   \n",
       "576321         3.0         5.0         1.0         1.0         1.0   \n",
       "576339         4.0         7.0         1.0         4.0         4.0   \n",
       "\n",
       "        ST268Q07JA  ST297Q01JA  ST297Q03JA  ST297Q05JA  ST297Q06JA  \\\n",
       "574478         4.0         0.0         1.0         1.0         0.0   \n",
       "573678         4.0         0.0         0.0         0.0         0.0   \n",
       "576927         3.0         0.0         0.0         0.0         0.0   \n",
       "576321         4.0         0.0         0.0         0.0         0.0   \n",
       "576339         4.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "        ST297Q07JA  ST297Q09JA  ST258Q01JA  ST294Q01JA  ST295Q01JA  EXERPRAC  \\\n",
       "574478         0.0         0.0         5.0         1.0         6.0       3.0   \n",
       "573678         0.0         0.0         1.0         1.0         6.0       0.0   \n",
       "576927         0.0         0.0         1.0         4.0         6.0       0.0   \n",
       "576321         0.0         1.0         1.0         6.0         6.0       0.0   \n",
       "576339         0.0         1.0         1.0         1.0         6.0       0.0   \n",
       "\n",
       "        WORKPAY  WORKHOME  SC001Q01TA  SC211Q01JA  SC211Q02JA  SC211Q03JA  \\\n",
       "574478      0.0      10.0         4.0        40.0        30.0        79.0   \n",
       "573678      5.0       0.0         3.0         1.0        13.0        22.0   \n",
       "576927      0.0       0.0         4.0         5.0         2.0        83.0   \n",
       "576321      0.0       5.0         2.0        44.0        12.0         0.0   \n",
       "576339      0.0       4.0         2.0         0.0        18.0        30.0   \n",
       "\n",
       "        SC211Q04JA  SC211Q05JA  SC211Q06JA  SC037Q11JA  SC183Q02JA  \\\n",
       "574478        11.0        18.0         4.0         1.0         1.0   \n",
       "573678         0.0         4.0         0.0         2.0         2.0   \n",
       "576927        10.0         7.0         0.0         1.0         1.0   \n",
       "576321         0.0         0.0         0.0         2.0         2.0   \n",
       "576339         0.0         0.0         0.0         1.0         2.0   \n",
       "\n",
       "        SC183Q03JA  SC183Q04JA  SC175Q01JA  SC188Q01JA  SC188Q02JA  \\\n",
       "574478         1.0         1.0        60.0         4.0         4.0   \n",
       "573678         1.0         1.0        50.0         4.0         3.0   \n",
       "576927         1.0         1.0        80.0         4.0         4.0   \n",
       "576321         1.0         1.0        40.0         2.0         2.0   \n",
       "576339         2.0         2.0        55.0         2.0         4.0   \n",
       "\n",
       "        SC188Q03JA  SC188Q04JA  SC188Q05JA  ...  ST349Q01JA_2  ST349Q01JA_3  \\\n",
       "574478         3.0         3.0         3.0  ...             0             0   \n",
       "573678         2.0         4.0         2.0  ...             0             0   \n",
       "576927         3.0         3.0         3.0  ...             0             0   \n",
       "576321         2.0         4.0         1.0  ...             0             0   \n",
       "576339         2.0         3.0         4.0  ...             0             0   \n",
       "\n",
       "        ST349Q01JA_4  ST349Q01JA_0  LANGN_105  LANGN_108  LANGN_118  \\\n",
       "574478             1             0          0          0          0   \n",
       "573678             0             0          0          0          0   \n",
       "576927             1             0          0          0          0   \n",
       "576321             0             0          0          0          0   \n",
       "576339             1             0          0          0          0   \n",
       "\n",
       "        LANGN_140  LANGN_148  LANGN_150  LANGN_156  LANGN_200  LANGN_204  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_232  LANGN_273  LANGN_313  LANGN_316  LANGN_322  LANGN_329  \\\n",
       "574478          0          0          1          0          0          0   \n",
       "573678          0          0          1          0          0          0   \n",
       "576927          0          0          1          0          0          0   \n",
       "576321          0          0          1          0          0          0   \n",
       "576339          0          0          1          0          0          0   \n",
       "\n",
       "        LANGN_344  LANGN_351  LANGN_415  LANGN_463  LANGN_493  LANGN_496  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_500  LANGN_520  LANGN_531  LANGN_602  LANGN_606  LANGN_615  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_621  LANGN_625  LANGN_640  LANGN_641  LANGN_663  LANGN_669  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_670  LANGN_800  LANGN_801  LANGN_802  LANGN_804  LANGN_805  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_806  LANGN_807  LANGN_808  LANGN_865  LANGN_892  LANGN_895  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_917  SC177Q01JA_1  SC177Q01JA_2  SC177Q01JA_3  SC177Q02JA_1  \\\n",
       "574478          0             0             0             0             0   \n",
       "573678          0             0             0             1             0   \n",
       "576927          0             0             0             0             0   \n",
       "576321          0             0             0             1             0   \n",
       "576339          0             0             0             1             0   \n",
       "\n",
       "        SC177Q02JA_2  SC177Q02JA_3  SC177Q03JA_1  SC177Q03JA_2  SC177Q03JA_3  \\\n",
       "574478             0             0             0             0             0   \n",
       "573678             0             1             0             1             0   \n",
       "576927             0             0             0             0             0   \n",
       "576321             0             1             0             0             1   \n",
       "576339             0             1             0             0             1   \n",
       "\n",
       "        MATHEXC_0  MATHEXC_1  MATHEXC_2  MATHEXC_3  SCHLTYPE_1  SCHLTYPE_2  \\\n",
       "574478          0          0          0          0           0           0   \n",
       "573678          0          0          0          1           0           0   \n",
       "576927          0          0          0          0           0           0   \n",
       "576321          0          0          0          0           1           0   \n",
       "576339          0          0          0          1           0           0   \n",
       "\n",
       "        SCHLTYPE_3  LANGN_121  LANGN_130  LANGN_137  LANGN_170  LANGN_244  \\\n",
       "574478           1          0          0          0          0          0   \n",
       "573678           1          0          0          0          0          0   \n",
       "576927           1          0          0          0          0          0   \n",
       "576321           0          0          0          0          0          0   \n",
       "576339           1          0          0          0          0          0   \n",
       "\n",
       "        LANGN_258  LANGN_263  LANGN_264  LANGN_266  LANGN_317  LANGN_340  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_369  LANGN_381  LANGN_404  LANGN_420  LANGN_449  LANGN_467  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_494  LANGN_495  LANGN_514  LANGN_523  LANGN_529  LANGN_540  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_547  LANGN_600  LANGN_607  LANGN_618  LANGN_619  LANGN_630  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_635  LANGN_650  LANGN_661  LANGN_673  LANGN_674  LANGN_809  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_810  LANGN_811  LANGN_812  LANGN_813  LANGN_814  LANGN_815  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_816  LANGN_818  LANGN_832  LANGN_868  LANGN_870  LANGN_920  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_921  LANGN_113  LANGN_147  LANGN_275  LANGN_286  LANGN_363  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_422  LANGN_434  LANGN_442  LANGN_471  LANGN_611  LANGN_614  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_624  LANGN_642  LANGN_675  LANGN_676  LANGN_677  LANGN_678  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_817  LANGN_819  LANGN_821  LANGN_823  LANGN_824  LANGN_825  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_826  LANGN_827  LANGN_828  LANGN_885  LANGN_896  LANGN_916  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_112  LANGN_154  LANGN_202  LANGN_246  LANGN_254  LANGN_272  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_301  LANGN_325  LANGN_338  LANGN_358  LANGN_371  LANGN_375  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_383  LANGN_409  LANGN_428  LANGN_465  LANGN_517  LANGN_527  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_561  LANGN_562  LANGN_563  LANGN_565  LANGN_566  LANGN_567  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_601  LANGN_622  LANGN_623  LANGN_628  LANGN_631  LANGN_831  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_833  LANGN_836  LANGN_837  LANGN_838  LANGN_839  LANGN_840  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_841  LANGN_845  LANGN_872  LANGN_873  LANGN_881  LANGN_890  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_897  LANGN_898  LANGN_899  LANGN_900  LANGN_901  LANGN_902  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_903  LANGN_904  LANGN_905  LANGN_906  LANGN_907  LANGN_908  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_909  LANGN_910  LANGN_911  LANGN_912  LANGN_913  LANGN_914  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_918  LANGN_919  LANGN_160  LANGN_327  LANGN_451  LANGN_474  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_503  LANGN_608  LANGN_627  LANGN_639  LANGN_668  LANGN_842  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_843  LANGN_844  LANGN_846  LANGN_849  LANGN_850  LANGN_851  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_852  LANGN_861  LANGN_879  LANGN_133  LANGN_195  LANGN_237  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_379  LANGN_382  LANGN_472  LANGN_492  LANGN_555  LANGN_605  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_616  LANGN_626  LANGN_634  LANGN_648  LANGN_662  LANGN_665  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_666  LANGN_667  LANGN_829  LANGN_854  LANGN_855  LANGN_857  \\\n",
       "574478          0          0          0          0          0          0   \n",
       "573678          0          0          0          0          0          0   \n",
       "576927          0          0          0          0          0          0   \n",
       "576321          0          0          0          0          0          0   \n",
       "576339          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_859  LANGN_860  LANGN_866  LANGN_877  LANGN_922  \n",
       "574478          0          0          0          0          0  \n",
       "573678          0          0          0          0          0  \n",
       "576927          0          0          0          0          0  \n",
       "576321          0          0          0          0          0  \n",
       "576339          0          0          0          0          0  \n",
       "\n",
       "[5 rows x 558 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation data - Saved later to S3 as CSV\n",
    "print(validation_data.shape)\n",
    "validation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(683, 558)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MATH_Proficient</th>\n",
       "      <th>SISCO</th>\n",
       "      <th>ST250Q01JA</th>\n",
       "      <th>ST250Q02JA</th>\n",
       "      <th>ST250Q03JA</th>\n",
       "      <th>ST250Q04JA</th>\n",
       "      <th>ST250Q05JA</th>\n",
       "      <th>ST251Q01JA</th>\n",
       "      <th>ST251Q02JA</th>\n",
       "      <th>ST251Q03JA</th>\n",
       "      <th>ST251Q04JA</th>\n",
       "      <th>ST251Q06JA</th>\n",
       "      <th>ST253Q01JA</th>\n",
       "      <th>ST254Q01JA</th>\n",
       "      <th>ST254Q02JA</th>\n",
       "      <th>ST254Q03JA</th>\n",
       "      <th>ST254Q04JA</th>\n",
       "      <th>ST254Q05JA</th>\n",
       "      <th>ST254Q06JA</th>\n",
       "      <th>ST255Q01JA</th>\n",
       "      <th>ST038Q03NA</th>\n",
       "      <th>ST038Q04NA</th>\n",
       "      <th>ST038Q05NA</th>\n",
       "      <th>ST038Q06NA</th>\n",
       "      <th>ST038Q07NA</th>\n",
       "      <th>ST038Q08NA</th>\n",
       "      <th>ST038Q09JA</th>\n",
       "      <th>ST038Q10JA</th>\n",
       "      <th>ST038Q11JA</th>\n",
       "      <th>ST265Q01JA</th>\n",
       "      <th>ST265Q02JA</th>\n",
       "      <th>ST265Q03JA</th>\n",
       "      <th>ST265Q04JA</th>\n",
       "      <th>ST266Q01JA</th>\n",
       "      <th>ST266Q02JA</th>\n",
       "      <th>ST266Q03JA</th>\n",
       "      <th>ST266Q04JA</th>\n",
       "      <th>ST266Q05JA</th>\n",
       "      <th>ST263Q02JA</th>\n",
       "      <th>ST263Q04JA</th>\n",
       "      <th>ST263Q06JA</th>\n",
       "      <th>ST270Q01JA</th>\n",
       "      <th>ST270Q02JA</th>\n",
       "      <th>ST270Q03JA</th>\n",
       "      <th>ST270Q04JA</th>\n",
       "      <th>FL166Q01HA</th>\n",
       "      <th>FL166Q02HA</th>\n",
       "      <th>FL166Q03HA</th>\n",
       "      <th>FL166Q05HA</th>\n",
       "      <th>FL166Q06HA</th>\n",
       "      <th>FL166Q07HA</th>\n",
       "      <th>FL174Q01JA</th>\n",
       "      <th>FL174Q02JA</th>\n",
       "      <th>FL174Q03JA</th>\n",
       "      <th>FL174Q04JA</th>\n",
       "      <th>FL174Q05JA</th>\n",
       "      <th>FL174Q06JA</th>\n",
       "      <th>FL174Q07JA</th>\n",
       "      <th>FL167Q01HA</th>\n",
       "      <th>FL167Q02HA</th>\n",
       "      <th>FL167Q06JA</th>\n",
       "      <th>FL167Q03HA</th>\n",
       "      <th>FL167Q04HA</th>\n",
       "      <th>FL167Q05HA</th>\n",
       "      <th>FL167Q07JA</th>\n",
       "      <th>FL170Q01JA</th>\n",
       "      <th>FL170Q02JA</th>\n",
       "      <th>FL170Q03JA</th>\n",
       "      <th>FL170Q04JA</th>\n",
       "      <th>FL170Q05JA</th>\n",
       "      <th>FL170Q06JA</th>\n",
       "      <th>FL170Q07JA</th>\n",
       "      <th>FL162Q01HA</th>\n",
       "      <th>FL162Q02HA</th>\n",
       "      <th>FL162Q03HA</th>\n",
       "      <th>FL162Q04HA</th>\n",
       "      <th>FL162Q05HA</th>\n",
       "      <th>FL162Q06HA</th>\n",
       "      <th>FL163Q01HA</th>\n",
       "      <th>FL163Q02HA</th>\n",
       "      <th>FL163Q03HA</th>\n",
       "      <th>FL163Q04HA</th>\n",
       "      <th>FL163Q05HA</th>\n",
       "      <th>FL171Q01JA</th>\n",
       "      <th>FL171Q02JA</th>\n",
       "      <th>FL171Q03JA</th>\n",
       "      <th>FL171Q04JA</th>\n",
       "      <th>FL171Q05JA</th>\n",
       "      <th>FL171Q07JA</th>\n",
       "      <th>FL171Q08JA</th>\n",
       "      <th>FL171Q09JA</th>\n",
       "      <th>FL171Q10JA</th>\n",
       "      <th>FL171Q11JA</th>\n",
       "      <th>FL171Q12JA</th>\n",
       "      <th>FL169Q01HA</th>\n",
       "      <th>FL169Q05JA</th>\n",
       "      <th>FL169Q02HA</th>\n",
       "      <th>FL169Q04HA</th>\n",
       "      <th>FL169Q08JA</th>\n",
       "      <th>FL169Q10JA</th>\n",
       "      <th>FL169Q11JA</th>\n",
       "      <th>FL172Q01JA</th>\n",
       "      <th>FL172Q03JA</th>\n",
       "      <th>FL172Q05JA</th>\n",
       "      <th>FL172Q06JA</th>\n",
       "      <th>IC170Q01JA</th>\n",
       "      <th>IC170Q02JA</th>\n",
       "      <th>IC170Q03JA</th>\n",
       "      <th>IC170Q04JA</th>\n",
       "      <th>IC170Q05JA</th>\n",
       "      <th>IC170Q06JA</th>\n",
       "      <th>IC170Q07JA</th>\n",
       "      <th>IC171Q01JA</th>\n",
       "      <th>IC171Q02JA</th>\n",
       "      <th>IC171Q03JA</th>\n",
       "      <th>IC171Q04JA</th>\n",
       "      <th>IC171Q05JA</th>\n",
       "      <th>IC171Q06JA</th>\n",
       "      <th>IC172Q01JA</th>\n",
       "      <th>IC172Q02JA</th>\n",
       "      <th>IC172Q03JA</th>\n",
       "      <th>IC172Q04JA</th>\n",
       "      <th>IC172Q05JA</th>\n",
       "      <th>IC172Q06JA</th>\n",
       "      <th>IC172Q07JA</th>\n",
       "      <th>IC172Q08JA</th>\n",
       "      <th>IC172Q09JA</th>\n",
       "      <th>IC173Q01JA</th>\n",
       "      <th>IC173Q02JA</th>\n",
       "      <th>IC173Q03JA</th>\n",
       "      <th>IC173Q04JA</th>\n",
       "      <th>IC174Q01JA</th>\n",
       "      <th>IC174Q02JA</th>\n",
       "      <th>IC174Q03JA</th>\n",
       "      <th>IC174Q04JA</th>\n",
       "      <th>IC174Q05JA</th>\n",
       "      <th>IC174Q06JA</th>\n",
       "      <th>IC174Q07JA</th>\n",
       "      <th>IC174Q08JA</th>\n",
       "      <th>IC174Q09JA</th>\n",
       "      <th>IC174Q10JA</th>\n",
       "      <th>IC175Q01JA</th>\n",
       "      <th>IC175Q02JA</th>\n",
       "      <th>IC175Q03JA</th>\n",
       "      <th>IC175Q05JA</th>\n",
       "      <th>IC176Q01JA</th>\n",
       "      <th>IC176Q02JA</th>\n",
       "      <th>IC176Q03JA</th>\n",
       "      <th>IC176Q04JA</th>\n",
       "      <th>IC176Q05JA</th>\n",
       "      <th>IC176Q06JA</th>\n",
       "      <th>IC176Q07JA</th>\n",
       "      <th>IC176Q08JA</th>\n",
       "      <th>IC177Q01JA</th>\n",
       "      <th>IC177Q02JA</th>\n",
       "      <th>IC177Q03JA</th>\n",
       "      <th>IC177Q04JA</th>\n",
       "      <th>IC177Q05JA</th>\n",
       "      <th>IC177Q06JA</th>\n",
       "      <th>IC177Q07JA</th>\n",
       "      <th>IC178Q01JA</th>\n",
       "      <th>IC178Q02JA</th>\n",
       "      <th>IC178Q03JA</th>\n",
       "      <th>IC178Q04JA</th>\n",
       "      <th>IC178Q05JA</th>\n",
       "      <th>IC178Q06JA</th>\n",
       "      <th>IC178Q07JA</th>\n",
       "      <th>IC179Q01JA</th>\n",
       "      <th>IC179Q02JA</th>\n",
       "      <th>IC179Q03JA</th>\n",
       "      <th>IC179Q04JA</th>\n",
       "      <th>IC179Q05JA</th>\n",
       "      <th>IC179Q06JA</th>\n",
       "      <th>IC180Q02JA</th>\n",
       "      <th>IC180Q03JA</th>\n",
       "      <th>IC180Q04JA</th>\n",
       "      <th>IC180Q05JA</th>\n",
       "      <th>IC180Q06JA</th>\n",
       "      <th>IC180Q07JA</th>\n",
       "      <th>IC183Q01JA</th>\n",
       "      <th>IC183Q02JA</th>\n",
       "      <th>IC183Q03JA</th>\n",
       "      <th>IC183Q04JA</th>\n",
       "      <th>IC183Q05JA</th>\n",
       "      <th>IC183Q07JA</th>\n",
       "      <th>IC183Q08JA</th>\n",
       "      <th>IC183Q09JA</th>\n",
       "      <th>IC183Q10JA</th>\n",
       "      <th>IC183Q12JA</th>\n",
       "      <th>IC183Q13JA</th>\n",
       "      <th>IC183Q14JA</th>\n",
       "      <th>IC183Q15JA</th>\n",
       "      <th>IC183Q16JA</th>\n",
       "      <th>ST347Q01JA</th>\n",
       "      <th>ST347Q02JA</th>\n",
       "      <th>ST259Q01JA</th>\n",
       "      <th>ST004D01T</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>REPEAT</th>\n",
       "      <th>EXPECEDU</th>\n",
       "      <th>ICTAVSCH</th>\n",
       "      <th>ICTAVHOM</th>\n",
       "      <th>IMMIG</th>\n",
       "      <th>TARDYSD</th>\n",
       "      <th>ST226Q01JA</th>\n",
       "      <th>MISSSC</th>\n",
       "      <th>PAREDINT</th>\n",
       "      <th>ST230Q01JA</th>\n",
       "      <th>SKIPPING</th>\n",
       "      <th>IC180Q01JA</th>\n",
       "      <th>IC180Q08JA</th>\n",
       "      <th>ST059Q02JA</th>\n",
       "      <th>ST296Q04JA</th>\n",
       "      <th>STUDYHMW</th>\n",
       "      <th>IC184Q01JA</th>\n",
       "      <th>IC184Q02JA</th>\n",
       "      <th>ST059Q01TA</th>\n",
       "      <th>ST296Q01JA</th>\n",
       "      <th>ST268Q01JA</th>\n",
       "      <th>ST268Q04JA</th>\n",
       "      <th>ST268Q07JA</th>\n",
       "      <th>ST297Q01JA</th>\n",
       "      <th>ST297Q03JA</th>\n",
       "      <th>ST297Q05JA</th>\n",
       "      <th>ST297Q06JA</th>\n",
       "      <th>ST297Q07JA</th>\n",
       "      <th>ST297Q09JA</th>\n",
       "      <th>ST258Q01JA</th>\n",
       "      <th>ST294Q01JA</th>\n",
       "      <th>ST295Q01JA</th>\n",
       "      <th>EXERPRAC</th>\n",
       "      <th>WORKPAY</th>\n",
       "      <th>WORKHOME</th>\n",
       "      <th>SC001Q01TA</th>\n",
       "      <th>SC211Q01JA</th>\n",
       "      <th>SC211Q02JA</th>\n",
       "      <th>SC211Q03JA</th>\n",
       "      <th>SC211Q04JA</th>\n",
       "      <th>SC211Q05JA</th>\n",
       "      <th>SC211Q06JA</th>\n",
       "      <th>SC037Q11JA</th>\n",
       "      <th>SC183Q02JA</th>\n",
       "      <th>SC183Q03JA</th>\n",
       "      <th>SC183Q04JA</th>\n",
       "      <th>SC175Q01JA</th>\n",
       "      <th>SC188Q01JA</th>\n",
       "      <th>SC188Q02JA</th>\n",
       "      <th>SC188Q03JA</th>\n",
       "      <th>SC188Q04JA</th>\n",
       "      <th>SC188Q05JA</th>\n",
       "      <th>...</th>\n",
       "      <th>ST349Q01JA_2</th>\n",
       "      <th>ST349Q01JA_3</th>\n",
       "      <th>ST349Q01JA_4</th>\n",
       "      <th>ST349Q01JA_0</th>\n",
       "      <th>LANGN_105</th>\n",
       "      <th>LANGN_108</th>\n",
       "      <th>LANGN_118</th>\n",
       "      <th>LANGN_140</th>\n",
       "      <th>LANGN_148</th>\n",
       "      <th>LANGN_150</th>\n",
       "      <th>LANGN_156</th>\n",
       "      <th>LANGN_200</th>\n",
       "      <th>LANGN_204</th>\n",
       "      <th>LANGN_232</th>\n",
       "      <th>LANGN_273</th>\n",
       "      <th>LANGN_313</th>\n",
       "      <th>LANGN_316</th>\n",
       "      <th>LANGN_322</th>\n",
       "      <th>LANGN_329</th>\n",
       "      <th>LANGN_344</th>\n",
       "      <th>LANGN_351</th>\n",
       "      <th>LANGN_415</th>\n",
       "      <th>LANGN_463</th>\n",
       "      <th>LANGN_493</th>\n",
       "      <th>LANGN_496</th>\n",
       "      <th>LANGN_500</th>\n",
       "      <th>LANGN_520</th>\n",
       "      <th>LANGN_531</th>\n",
       "      <th>LANGN_602</th>\n",
       "      <th>LANGN_606</th>\n",
       "      <th>LANGN_615</th>\n",
       "      <th>LANGN_621</th>\n",
       "      <th>LANGN_625</th>\n",
       "      <th>LANGN_640</th>\n",
       "      <th>LANGN_641</th>\n",
       "      <th>LANGN_663</th>\n",
       "      <th>LANGN_669</th>\n",
       "      <th>LANGN_670</th>\n",
       "      <th>LANGN_800</th>\n",
       "      <th>LANGN_801</th>\n",
       "      <th>LANGN_802</th>\n",
       "      <th>LANGN_804</th>\n",
       "      <th>LANGN_805</th>\n",
       "      <th>LANGN_806</th>\n",
       "      <th>LANGN_807</th>\n",
       "      <th>LANGN_808</th>\n",
       "      <th>LANGN_865</th>\n",
       "      <th>LANGN_892</th>\n",
       "      <th>LANGN_895</th>\n",
       "      <th>LANGN_917</th>\n",
       "      <th>SC177Q01JA_1</th>\n",
       "      <th>SC177Q01JA_2</th>\n",
       "      <th>SC177Q01JA_3</th>\n",
       "      <th>SC177Q02JA_1</th>\n",
       "      <th>SC177Q02JA_2</th>\n",
       "      <th>SC177Q02JA_3</th>\n",
       "      <th>SC177Q03JA_1</th>\n",
       "      <th>SC177Q03JA_2</th>\n",
       "      <th>SC177Q03JA_3</th>\n",
       "      <th>MATHEXC_0</th>\n",
       "      <th>MATHEXC_1</th>\n",
       "      <th>MATHEXC_2</th>\n",
       "      <th>MATHEXC_3</th>\n",
       "      <th>SCHLTYPE_1</th>\n",
       "      <th>SCHLTYPE_2</th>\n",
       "      <th>SCHLTYPE_3</th>\n",
       "      <th>LANGN_121</th>\n",
       "      <th>LANGN_130</th>\n",
       "      <th>LANGN_137</th>\n",
       "      <th>LANGN_170</th>\n",
       "      <th>LANGN_244</th>\n",
       "      <th>LANGN_258</th>\n",
       "      <th>LANGN_263</th>\n",
       "      <th>LANGN_264</th>\n",
       "      <th>LANGN_266</th>\n",
       "      <th>LANGN_317</th>\n",
       "      <th>LANGN_340</th>\n",
       "      <th>LANGN_369</th>\n",
       "      <th>LANGN_381</th>\n",
       "      <th>LANGN_404</th>\n",
       "      <th>LANGN_420</th>\n",
       "      <th>LANGN_449</th>\n",
       "      <th>LANGN_467</th>\n",
       "      <th>LANGN_494</th>\n",
       "      <th>LANGN_495</th>\n",
       "      <th>LANGN_514</th>\n",
       "      <th>LANGN_523</th>\n",
       "      <th>LANGN_529</th>\n",
       "      <th>LANGN_540</th>\n",
       "      <th>LANGN_547</th>\n",
       "      <th>LANGN_600</th>\n",
       "      <th>LANGN_607</th>\n",
       "      <th>LANGN_618</th>\n",
       "      <th>LANGN_619</th>\n",
       "      <th>LANGN_630</th>\n",
       "      <th>LANGN_635</th>\n",
       "      <th>LANGN_650</th>\n",
       "      <th>LANGN_661</th>\n",
       "      <th>LANGN_673</th>\n",
       "      <th>LANGN_674</th>\n",
       "      <th>LANGN_809</th>\n",
       "      <th>LANGN_810</th>\n",
       "      <th>LANGN_811</th>\n",
       "      <th>LANGN_812</th>\n",
       "      <th>LANGN_813</th>\n",
       "      <th>LANGN_814</th>\n",
       "      <th>LANGN_815</th>\n",
       "      <th>LANGN_816</th>\n",
       "      <th>LANGN_818</th>\n",
       "      <th>LANGN_832</th>\n",
       "      <th>LANGN_868</th>\n",
       "      <th>LANGN_870</th>\n",
       "      <th>LANGN_920</th>\n",
       "      <th>LANGN_921</th>\n",
       "      <th>LANGN_113</th>\n",
       "      <th>LANGN_147</th>\n",
       "      <th>LANGN_275</th>\n",
       "      <th>LANGN_286</th>\n",
       "      <th>LANGN_363</th>\n",
       "      <th>LANGN_422</th>\n",
       "      <th>LANGN_434</th>\n",
       "      <th>LANGN_442</th>\n",
       "      <th>LANGN_471</th>\n",
       "      <th>LANGN_611</th>\n",
       "      <th>LANGN_614</th>\n",
       "      <th>LANGN_624</th>\n",
       "      <th>LANGN_642</th>\n",
       "      <th>LANGN_675</th>\n",
       "      <th>LANGN_676</th>\n",
       "      <th>LANGN_677</th>\n",
       "      <th>LANGN_678</th>\n",
       "      <th>LANGN_817</th>\n",
       "      <th>LANGN_819</th>\n",
       "      <th>LANGN_821</th>\n",
       "      <th>LANGN_823</th>\n",
       "      <th>LANGN_824</th>\n",
       "      <th>LANGN_825</th>\n",
       "      <th>LANGN_826</th>\n",
       "      <th>LANGN_827</th>\n",
       "      <th>LANGN_828</th>\n",
       "      <th>LANGN_885</th>\n",
       "      <th>LANGN_896</th>\n",
       "      <th>LANGN_916</th>\n",
       "      <th>LANGN_112</th>\n",
       "      <th>LANGN_154</th>\n",
       "      <th>LANGN_202</th>\n",
       "      <th>LANGN_246</th>\n",
       "      <th>LANGN_254</th>\n",
       "      <th>LANGN_272</th>\n",
       "      <th>LANGN_301</th>\n",
       "      <th>LANGN_325</th>\n",
       "      <th>LANGN_338</th>\n",
       "      <th>LANGN_358</th>\n",
       "      <th>LANGN_371</th>\n",
       "      <th>LANGN_375</th>\n",
       "      <th>LANGN_383</th>\n",
       "      <th>LANGN_409</th>\n",
       "      <th>LANGN_428</th>\n",
       "      <th>LANGN_465</th>\n",
       "      <th>LANGN_517</th>\n",
       "      <th>LANGN_527</th>\n",
       "      <th>LANGN_561</th>\n",
       "      <th>LANGN_562</th>\n",
       "      <th>LANGN_563</th>\n",
       "      <th>LANGN_565</th>\n",
       "      <th>LANGN_566</th>\n",
       "      <th>LANGN_567</th>\n",
       "      <th>LANGN_601</th>\n",
       "      <th>LANGN_622</th>\n",
       "      <th>LANGN_623</th>\n",
       "      <th>LANGN_628</th>\n",
       "      <th>LANGN_631</th>\n",
       "      <th>LANGN_831</th>\n",
       "      <th>LANGN_833</th>\n",
       "      <th>LANGN_836</th>\n",
       "      <th>LANGN_837</th>\n",
       "      <th>LANGN_838</th>\n",
       "      <th>LANGN_839</th>\n",
       "      <th>LANGN_840</th>\n",
       "      <th>LANGN_841</th>\n",
       "      <th>LANGN_845</th>\n",
       "      <th>LANGN_872</th>\n",
       "      <th>LANGN_873</th>\n",
       "      <th>LANGN_881</th>\n",
       "      <th>LANGN_890</th>\n",
       "      <th>LANGN_897</th>\n",
       "      <th>LANGN_898</th>\n",
       "      <th>LANGN_899</th>\n",
       "      <th>LANGN_900</th>\n",
       "      <th>LANGN_901</th>\n",
       "      <th>LANGN_902</th>\n",
       "      <th>LANGN_903</th>\n",
       "      <th>LANGN_904</th>\n",
       "      <th>LANGN_905</th>\n",
       "      <th>LANGN_906</th>\n",
       "      <th>LANGN_907</th>\n",
       "      <th>LANGN_908</th>\n",
       "      <th>LANGN_909</th>\n",
       "      <th>LANGN_910</th>\n",
       "      <th>LANGN_911</th>\n",
       "      <th>LANGN_912</th>\n",
       "      <th>LANGN_913</th>\n",
       "      <th>LANGN_914</th>\n",
       "      <th>LANGN_918</th>\n",
       "      <th>LANGN_919</th>\n",
       "      <th>LANGN_160</th>\n",
       "      <th>LANGN_327</th>\n",
       "      <th>LANGN_451</th>\n",
       "      <th>LANGN_474</th>\n",
       "      <th>LANGN_503</th>\n",
       "      <th>LANGN_608</th>\n",
       "      <th>LANGN_627</th>\n",
       "      <th>LANGN_639</th>\n",
       "      <th>LANGN_668</th>\n",
       "      <th>LANGN_842</th>\n",
       "      <th>LANGN_843</th>\n",
       "      <th>LANGN_844</th>\n",
       "      <th>LANGN_846</th>\n",
       "      <th>LANGN_849</th>\n",
       "      <th>LANGN_850</th>\n",
       "      <th>LANGN_851</th>\n",
       "      <th>LANGN_852</th>\n",
       "      <th>LANGN_861</th>\n",
       "      <th>LANGN_879</th>\n",
       "      <th>LANGN_133</th>\n",
       "      <th>LANGN_195</th>\n",
       "      <th>LANGN_237</th>\n",
       "      <th>LANGN_379</th>\n",
       "      <th>LANGN_382</th>\n",
       "      <th>LANGN_472</th>\n",
       "      <th>LANGN_492</th>\n",
       "      <th>LANGN_555</th>\n",
       "      <th>LANGN_605</th>\n",
       "      <th>LANGN_616</th>\n",
       "      <th>LANGN_626</th>\n",
       "      <th>LANGN_634</th>\n",
       "      <th>LANGN_648</th>\n",
       "      <th>LANGN_662</th>\n",
       "      <th>LANGN_665</th>\n",
       "      <th>LANGN_666</th>\n",
       "      <th>LANGN_667</th>\n",
       "      <th>LANGN_829</th>\n",
       "      <th>LANGN_854</th>\n",
       "      <th>LANGN_855</th>\n",
       "      <th>LANGN_857</th>\n",
       "      <th>LANGN_859</th>\n",
       "      <th>LANGN_860</th>\n",
       "      <th>LANGN_866</th>\n",
       "      <th>LANGN_877</th>\n",
       "      <th>LANGN_922</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>577660</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577072</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576813</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577850</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573800</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 558 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MATH_Proficient  SISCO  ST250Q01JA  ST250Q02JA  ST250Q03JA  \\\n",
       "577660              1.0    1.0         1.0         1.0         1.0   \n",
       "577072              0.0    1.0         1.0         1.0         1.0   \n",
       "576813              0.0    1.0         1.0         1.0         1.0   \n",
       "577850              0.0    1.0         1.0         1.0         2.0   \n",
       "573800              1.0    1.0         1.0         1.0         1.0   \n",
       "\n",
       "        ST250Q04JA  ST250Q05JA  ST251Q01JA  ST251Q02JA  ST251Q03JA  \\\n",
       "577660         1.0         1.0         3.0         1.0         3.0   \n",
       "577072         1.0         1.0         2.0         1.0         2.0   \n",
       "576813         1.0         1.0         3.0         1.0         4.0   \n",
       "577850         1.0         1.0         3.0         1.0         3.0   \n",
       "573800         1.0         1.0         3.0         1.0         3.0   \n",
       "\n",
       "        ST251Q04JA  ST251Q06JA  ST253Q01JA  ST254Q01JA  ST254Q02JA  \\\n",
       "577660         3.0         2.0         7.0         3.0         2.0   \n",
       "577072         2.0         1.0         8.0         3.0         2.0   \n",
       "576813         4.0         1.0         7.0         3.0         3.0   \n",
       "577850         3.0         1.0         7.0         3.0         2.0   \n",
       "573800         3.0         2.0         8.0         3.0         3.0   \n",
       "\n",
       "        ST254Q03JA  ST254Q04JA  ST254Q05JA  ST254Q06JA  ST255Q01JA  \\\n",
       "577660         2.0         2.0         1.0         3.0         4.0   \n",
       "577072         2.0         4.0         1.0         4.0         3.0   \n",
       "576813         2.0         3.0         1.0         3.0         5.0   \n",
       "577850         3.0         1.0         1.0         3.0         4.0   \n",
       "573800         2.0         2.0         1.0         3.0         4.0   \n",
       "\n",
       "        ST038Q03NA  ST038Q04NA  ST038Q05NA  ST038Q06NA  ST038Q07NA  \\\n",
       "577660         1.0         1.0         1.0         1.0         1.0   \n",
       "577072         1.0         2.0         2.0         1.0         2.0   \n",
       "576813         2.0         3.0         1.0         1.0         1.0   \n",
       "577850         1.0         1.0         1.0         1.0         1.0   \n",
       "573800         3.0         4.0         1.0         1.0         1.0   \n",
       "\n",
       "        ST038Q08NA  ST038Q09JA  ST038Q10JA  ST038Q11JA  ST265Q01JA  \\\n",
       "577660         1.0         1.0         1.0         1.0         2.0   \n",
       "577072         2.0         1.0         2.0         1.0         2.0   \n",
       "576813         3.0         1.0         1.0         1.0         2.0   \n",
       "577850         1.0         1.0         1.0         1.0         2.0   \n",
       "573800         1.0         1.0         1.0         1.0         1.0   \n",
       "\n",
       "        ST265Q02JA  ST265Q03JA  ST265Q04JA  ST266Q01JA  ST266Q02JA  \\\n",
       "577660         2.0         2.0         2.0         2.0         2.0   \n",
       "577072         2.0         2.0         2.0         2.0         1.0   \n",
       "576813         2.0         2.0         2.0         1.0         2.0   \n",
       "577850         2.0         2.0         2.0         2.0         2.0   \n",
       "573800         1.0         2.0         2.0         2.0         1.0   \n",
       "\n",
       "        ST266Q03JA  ST266Q04JA  ST266Q05JA  ST263Q02JA  ST263Q04JA  \\\n",
       "577660         2.0         2.0         2.0         2.0         3.0   \n",
       "577072         1.0         1.0         1.0         3.0         2.0   \n",
       "576813         2.0         2.0         2.0         2.0         4.0   \n",
       "577850         2.0         2.0         2.0         2.0         3.0   \n",
       "573800         2.0         1.0         2.0         2.0         3.0   \n",
       "\n",
       "        ST263Q06JA  ST270Q01JA  ST270Q02JA  ST270Q03JA  ST270Q04JA  \\\n",
       "577660         3.0         2.0         1.0         1.0         2.0   \n",
       "577072         2.0         2.0         1.0         1.0         1.0   \n",
       "576813         4.0         3.0         2.0         2.0         3.0   \n",
       "577850         3.0         2.0         1.0         1.0         2.0   \n",
       "573800         2.0         3.0         2.0         3.0         3.0   \n",
       "\n",
       "        FL166Q01HA  FL166Q02HA  FL166Q03HA  FL166Q05HA  FL166Q06HA  \\\n",
       "577660         2.0         2.0         2.0         1.0         1.0   \n",
       "577072         3.0         3.0         2.0         2.0         2.0   \n",
       "576813         2.0         2.0         2.0         2.0         2.0   \n",
       "577850         2.0         2.0         2.0         1.0         1.0   \n",
       "573800         1.0         1.0         1.0         1.0         2.0   \n",
       "\n",
       "        FL166Q07HA  FL174Q01JA  FL174Q02JA  FL174Q03JA  FL174Q04JA  \\\n",
       "577660         2.0         2.0         2.0         2.0         2.0   \n",
       "577072         2.0         1.0         2.0         2.0         1.0   \n",
       "576813         2.0         2.0         2.0         2.0         2.0   \n",
       "577850         2.0         2.0         2.0         2.0         2.0   \n",
       "573800         3.0         2.0         1.0         1.0         4.0   \n",
       "\n",
       "        FL174Q05JA  FL174Q06JA  FL174Q07JA  FL167Q01HA  FL167Q02HA  \\\n",
       "577660         2.0         2.0         2.0         2.0         2.0   \n",
       "577072         1.0         2.0         3.0         3.0         3.0   \n",
       "576813         2.0         2.0         4.0         1.0         1.0   \n",
       "577850         2.0         2.0         2.0         2.0         2.0   \n",
       "573800         3.0         1.0         2.0         4.0         3.0   \n",
       "\n",
       "        FL167Q06JA  FL167Q03HA  FL167Q04HA  FL167Q05HA  FL167Q07JA  \\\n",
       "577660         2.0         2.0         2.0         2.0         2.0   \n",
       "577072         2.0         3.0         3.0         3.0         3.0   \n",
       "576813         1.0         1.0         1.0         1.0         2.0   \n",
       "577850         2.0         2.0         2.0         2.0         2.0   \n",
       "573800         4.0         4.0         4.0         3.0         4.0   \n",
       "\n",
       "        FL170Q01JA  FL170Q02JA  FL170Q03JA  FL170Q04JA  FL170Q05JA  \\\n",
       "577660         2.0         1.0         1.0         1.0         1.0   \n",
       "577072         3.0         2.0         4.0         1.0         2.0   \n",
       "576813         1.0         1.0         4.0         1.0         1.0   \n",
       "577850         2.0         1.0         1.0         1.0         1.0   \n",
       "573800         3.0         5.0         1.0         1.0         1.0   \n",
       "\n",
       "        FL170Q06JA  FL170Q07JA  FL162Q01HA  FL162Q02HA  FL162Q03HA  \\\n",
       "577660         2.0         1.0         2.0         2.0         2.0   \n",
       "577072         3.0         2.0         3.0         4.0         2.0   \n",
       "576813         2.0         1.0         2.0         2.0         2.0   \n",
       "577850         2.0         1.0         2.0         2.0         2.0   \n",
       "573800         4.0         1.0         2.0         2.0         1.0   \n",
       "\n",
       "        FL162Q04HA  FL162Q05HA  FL162Q06HA  FL163Q01HA  FL163Q02HA  \\\n",
       "577660         2.0         3.0         3.0         3.0         3.0   \n",
       "577072         3.0         4.0         3.0         4.0         3.0   \n",
       "576813         2.0         2.0         2.0         2.0         3.0   \n",
       "577850         2.0         3.0         3.0         3.0         3.0   \n",
       "573800         1.0         3.0         4.0         2.0         3.0   \n",
       "\n",
       "        FL163Q03HA  FL163Q04HA  FL163Q05HA  FL171Q01JA  FL171Q02JA  \\\n",
       "577660         3.0         3.0         3.0         3.0         3.0   \n",
       "577072         3.0         3.0         3.0         4.0         4.0   \n",
       "576813         3.0         2.0         2.0         3.0         3.0   \n",
       "577850         3.0         3.0         3.0         3.0         3.0   \n",
       "573800         4.0         4.0         4.0         4.0         3.0   \n",
       "\n",
       "        FL171Q03JA  FL171Q04JA  FL171Q05JA  FL171Q07JA  FL171Q08JA  \\\n",
       "577660         3.0         3.0         3.0         3.0         4.0   \n",
       "577072         3.0         5.0         3.0         5.0         4.0   \n",
       "576813         3.0         3.0         3.0         3.0         3.0   \n",
       "577850         3.0         3.0         3.0         3.0         4.0   \n",
       "573800         4.0         3.0         4.0         4.0         5.0   \n",
       "\n",
       "        FL171Q09JA  FL171Q10JA  FL171Q11JA  FL171Q12JA  FL169Q01HA  \\\n",
       "577660         2.0         1.0         3.0         4.0         3.0   \n",
       "577072         4.0         3.0         4.0         4.0         3.0   \n",
       "576813         3.0         3.0         3.0         3.0         3.0   \n",
       "577850         2.0         1.0         3.0         4.0         3.0   \n",
       "573800         1.0         1.0         3.0         3.0         2.0   \n",
       "\n",
       "        FL169Q05JA  FL169Q02HA  FL169Q04HA  FL169Q08JA  FL169Q10JA  \\\n",
       "577660         3.0         3.0         3.0         3.0         3.0   \n",
       "577072         4.0         2.0         3.0         3.0         3.0   \n",
       "576813         3.0         2.0         2.0         2.0         2.0   \n",
       "577850         3.0         3.0         3.0         3.0         3.0   \n",
       "573800         4.0         2.0         2.0         3.0         3.0   \n",
       "\n",
       "        FL169Q11JA  FL172Q01JA  FL172Q03JA  FL172Q05JA  FL172Q06JA  \\\n",
       "577660         3.0         2.0         2.0         2.0         2.0   \n",
       "577072         3.0         2.0         1.0         3.0         2.0   \n",
       "576813         2.0         2.0         2.0         2.0         2.0   \n",
       "577850         3.0         2.0         2.0         2.0         2.0   \n",
       "573800         4.0         1.0         3.0         3.0         3.0   \n",
       "\n",
       "        IC170Q01JA  IC170Q02JA  IC170Q03JA  IC170Q04JA  IC170Q05JA  \\\n",
       "577660         5.0         5.0         1.0         5.0         4.0   \n",
       "577072         5.0         5.0         4.0         5.0         3.0   \n",
       "576813         5.0         5.0         4.0         5.0         5.0   \n",
       "577850         5.0         5.0         1.0         5.0         4.0   \n",
       "573800         5.0         5.0         1.0         5.0         5.0   \n",
       "\n",
       "        IC170Q06JA  IC170Q07JA  IC171Q01JA  IC171Q02JA  IC171Q03JA  \\\n",
       "577660         3.0         5.0         4.0         5.0         2.0   \n",
       "577072         5.0         5.0         5.0         5.0         3.0   \n",
       "576813         5.0         5.0         4.0         4.0         4.0   \n",
       "577850         3.0         5.0         4.0         5.0         2.0   \n",
       "573800         5.0         5.0         5.0         5.0         2.0   \n",
       "\n",
       "        IC171Q04JA  IC171Q05JA  IC171Q06JA  IC172Q01JA  IC172Q02JA  \\\n",
       "577660         5.0         3.0         4.0         3.0         3.0   \n",
       "577072         5.0         2.0         2.0         3.0         3.0   \n",
       "576813         4.0         4.0         4.0         3.0         3.0   \n",
       "577850         5.0         3.0         4.0         3.0         3.0   \n",
       "573800         5.0         4.0         4.0         2.0         3.0   \n",
       "\n",
       "        IC172Q03JA  IC172Q04JA  IC172Q05JA  IC172Q06JA  IC172Q07JA  \\\n",
       "577660         3.0         3.0         3.0         3.0         3.0   \n",
       "577072         2.0         2.0         3.0         2.0         3.0   \n",
       "576813         3.0         3.0         3.0         3.0         3.0   \n",
       "577850         3.0         3.0         3.0         3.0         3.0   \n",
       "573800         1.0         2.0         3.0         4.0         3.0   \n",
       "\n",
       "        IC172Q08JA  IC172Q09JA  IC173Q01JA  IC173Q02JA  IC173Q03JA  \\\n",
       "577660         3.0         3.0         5.0         4.0         4.0   \n",
       "577072         3.0         3.0         3.0         4.0         3.0   \n",
       "576813         3.0         3.0         2.0         2.0         2.0   \n",
       "577850         3.0         3.0         5.0         4.0         4.0   \n",
       "573800         3.0         4.0         4.0         1.0         4.0   \n",
       "\n",
       "        IC173Q04JA  IC174Q01JA  IC174Q02JA  IC174Q03JA  IC174Q04JA  \\\n",
       "577660         5.0         3.0         4.0         3.0         3.0   \n",
       "577072         4.0         5.0         4.0         3.0         2.0   \n",
       "576813         2.0         4.0         4.0         3.0         4.0   \n",
       "577850         5.0         3.0         4.0         3.0         3.0   \n",
       "573800         6.0         4.0         4.0         5.0         3.0   \n",
       "\n",
       "        IC174Q05JA  IC174Q06JA  IC174Q07JA  IC174Q08JA  IC174Q09JA  \\\n",
       "577660         3.0         3.0         3.0         4.0         3.0   \n",
       "577072         4.0         3.0         3.0         2.0         4.0   \n",
       "576813         4.0         3.0         4.0         3.0         4.0   \n",
       "577850         3.0         3.0         3.0         4.0         3.0   \n",
       "573800         1.0         1.0         5.0         4.0         4.0   \n",
       "\n",
       "        IC174Q10JA  IC175Q01JA  IC175Q02JA  IC175Q03JA  IC175Q05JA  \\\n",
       "577660         3.0         4.0         3.0         3.0         3.0   \n",
       "577072         4.0         3.0         3.0         4.0         3.0   \n",
       "576813         4.0         4.0         3.0         2.0         2.0   \n",
       "577850         3.0         4.0         3.0         3.0         3.0   \n",
       "573800         5.0         4.0         2.0         5.0         2.0   \n",
       "\n",
       "        IC176Q01JA  IC176Q02JA  IC176Q03JA  IC176Q04JA  IC176Q05JA  \\\n",
       "577660         5.0         4.0         4.0         4.0         4.0   \n",
       "577072         3.0         3.0         4.0         3.0         2.0   \n",
       "576813         3.0         4.0         2.0         4.0         3.0   \n",
       "577850         5.0         4.0         4.0         4.0         4.0   \n",
       "573800         5.0         5.0         4.0         5.0         4.0   \n",
       "\n",
       "        IC176Q06JA  IC176Q07JA  IC176Q08JA  IC177Q01JA  IC177Q02JA  \\\n",
       "577660         4.0         4.0         4.0         3.0         3.0   \n",
       "577072         3.0         2.0         3.0         6.0         6.0   \n",
       "576813         3.0         4.0         3.0         3.0         5.0   \n",
       "577850         4.0         4.0         4.0         3.0         3.0   \n",
       "573800         1.0         5.0         4.0         2.0         4.0   \n",
       "\n",
       "        IC177Q03JA  IC177Q04JA  IC177Q05JA  IC177Q06JA  IC177Q07JA  \\\n",
       "577660         3.0         2.0         3.0         2.0         2.0   \n",
       "577072         6.0         5.0         6.0         4.0         4.0   \n",
       "576813         2.0         6.0         4.0         6.0         3.0   \n",
       "577850         3.0         2.0         3.0         2.0         2.0   \n",
       "573800         3.0         1.0         5.0         2.0         3.0   \n",
       "\n",
       "        IC178Q01JA  IC178Q02JA  IC178Q03JA  IC178Q04JA  IC178Q05JA  \\\n",
       "577660         3.0         3.0         3.0         2.0         3.0   \n",
       "577072         6.0         6.0         6.0         4.0         5.0   \n",
       "576813         1.0         6.0         3.0         5.0         5.0   \n",
       "577850         3.0         3.0         3.0         2.0         3.0   \n",
       "573800         5.0         5.0         2.0         1.0         6.0   \n",
       "\n",
       "        IC178Q06JA  IC178Q07JA  IC179Q01JA  IC179Q02JA  IC179Q03JA  \\\n",
       "577660         2.0         2.0         2.0         2.0         3.0   \n",
       "577072         3.0         4.0         1.0         1.0         3.0   \n",
       "576813         2.0         4.0         2.0         2.0         3.0   \n",
       "577850         2.0         2.0         2.0         2.0         3.0   \n",
       "573800         2.0         3.0         1.0         4.0         2.0   \n",
       "\n",
       "        IC179Q04JA  IC179Q05JA  IC179Q06JA  IC180Q02JA  IC180Q03JA  \\\n",
       "577660         2.0         2.0         2.0         3.0         3.0   \n",
       "577072         2.0         2.0         3.0         3.0         2.0   \n",
       "576813         3.0         3.0         3.0         2.0         3.0   \n",
       "577850         2.0         2.0         2.0         3.0         3.0   \n",
       "573800         2.0         3.0         3.0         4.0         4.0   \n",
       "\n",
       "        IC180Q04JA  IC180Q05JA  IC180Q06JA  IC180Q07JA  IC183Q01JA  \\\n",
       "577660         3.0         3.0         3.0         2.0         4.0   \n",
       "577072         3.0         3.0         3.0         3.0         4.0   \n",
       "576813         3.0         2.0         3.0         2.0         5.0   \n",
       "577850         3.0         3.0         3.0         2.0         4.0   \n",
       "573800         1.0         4.0         4.0         3.0         4.0   \n",
       "\n",
       "        IC183Q02JA  IC183Q03JA  IC183Q04JA  IC183Q05JA  IC183Q07JA  \\\n",
       "577660         4.0         4.0         4.0         4.0         4.0   \n",
       "577072         4.0         4.0         3.0         4.0         4.0   \n",
       "576813         3.0         4.0         2.0         2.0         4.0   \n",
       "577850         4.0         4.0         4.0         4.0         4.0   \n",
       "573800         4.0         4.0         4.0         4.0         4.0   \n",
       "\n",
       "        IC183Q08JA  IC183Q09JA  IC183Q10JA  IC183Q12JA  IC183Q13JA  \\\n",
       "577660         4.0         4.0         3.0         4.0         4.0   \n",
       "577072         4.0         4.0         3.0         4.0         3.0   \n",
       "576813         3.0         4.0         2.0         4.0         2.0   \n",
       "577850         4.0         4.0         3.0         4.0         4.0   \n",
       "573800         4.0         4.0         4.0         4.0         3.0   \n",
       "\n",
       "        IC183Q14JA  IC183Q15JA  IC183Q16JA  ST347Q01JA  ST347Q02JA  \\\n",
       "577660         2.0         3.0         3.0         4.0         1.0   \n",
       "577072         4.0         3.0         3.0         3.0         1.0   \n",
       "576813         3.0         2.0         2.0         4.0         2.0   \n",
       "577850         2.0         3.0         3.0         1.0         1.0   \n",
       "573800         3.0         3.0         3.0         4.0         1.0   \n",
       "\n",
       "        ST259Q01JA  ST004D01T  GRADE  REPEAT  EXPECEDU  ICTAVSCH  ICTAVHOM  \\\n",
       "577660         7.0        2.0    0.0     0.0       7.0       7.0       6.0   \n",
       "577072         9.0        1.0    0.0     0.0       8.0       7.0       6.0   \n",
       "576813         8.0        1.0    0.0     0.0       8.0       7.0       6.0   \n",
       "577850         7.0        2.0    0.0     0.0       7.0       7.0       6.0   \n",
       "573800         8.0        1.0    0.0     0.0       8.0       7.0       6.0   \n",
       "\n",
       "        IMMIG  TARDYSD  ST226Q01JA  MISSSC  PAREDINT  ST230Q01JA  SKIPPING  \\\n",
       "577660    1.0      0.0         3.0     0.0      16.0         3.0       0.0   \n",
       "577072    1.0      2.0         4.0     0.0      16.0         4.0       1.0   \n",
       "576813    1.0      0.0         4.0     0.0      16.0         4.0       0.0   \n",
       "577850    1.0      0.0         3.0     0.0      12.0         3.0       0.0   \n",
       "573800    1.0      0.0         3.0     0.0      16.0         1.0       1.0   \n",
       "\n",
       "        IC180Q01JA  IC180Q08JA  ST059Q02JA  ST296Q04JA  STUDYHMW  IC184Q01JA  \\\n",
       "577660         2.0         2.0         8.0         3.0       4.0         4.0   \n",
       "577072         3.0         1.0         7.0         4.0       8.0         5.0   \n",
       "576813         3.0         3.0         4.0         1.0       6.0         4.0   \n",
       "577850         2.0         2.0         8.0         3.0       4.0         4.0   \n",
       "573800         2.0         1.0         7.0         5.0       7.0         4.0   \n",
       "\n",
       "        IC184Q02JA  ST059Q01TA  ST296Q01JA  ST268Q01JA  ST268Q04JA  \\\n",
       "577660         4.0         4.0         1.0         2.0         3.0   \n",
       "577072         4.0         1.0         2.0         2.0         2.0   \n",
       "576813         5.0         2.0         1.0         1.0         1.0   \n",
       "577850         4.0         4.0         1.0         2.0         3.0   \n",
       "573800         5.0         4.0         3.0         1.0         2.0   \n",
       "\n",
       "        ST268Q07JA  ST297Q01JA  ST297Q03JA  ST297Q05JA  ST297Q06JA  \\\n",
       "577660         4.0         0.0         0.0         0.0         0.0   \n",
       "577072         4.0         1.0         1.0         0.0         1.0   \n",
       "576813         4.0         0.0         0.0         0.0         0.0   \n",
       "577850         4.0         0.0         0.0         0.0         0.0   \n",
       "573800         4.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "        ST297Q07JA  ST297Q09JA  ST258Q01JA  ST294Q01JA  ST295Q01JA  EXERPRAC  \\\n",
       "577660         0.0         1.0         1.0         3.0         6.0       5.0   \n",
       "577072         1.0         0.0         1.0         5.0         6.0       7.0   \n",
       "576813         0.0         1.0         1.0         5.0         6.0       2.0   \n",
       "577850         0.0         1.0         1.0         3.0         6.0       5.0   \n",
       "573800         0.0         1.0         1.0         2.0         6.0       0.0   \n",
       "\n",
       "        WORKPAY  WORKHOME  SC001Q01TA  SC211Q01JA  SC211Q02JA  SC211Q03JA  \\\n",
       "577660      0.0       4.0         2.0         1.0        13.0        29.0   \n",
       "577072      3.0       8.0         3.0         9.0        13.0        44.0   \n",
       "576813      4.0       8.0         3.0         1.0         3.0         5.0   \n",
       "577850      0.0       4.0         3.0         5.0        46.0        80.0   \n",
       "573800      0.0       0.0         2.0        18.0        14.0        77.0   \n",
       "\n",
       "        SC211Q04JA  SC211Q05JA  SC211Q06JA  SC037Q11JA  SC183Q02JA  \\\n",
       "577660         1.0         1.0         0.0         2.0         1.0   \n",
       "577072         3.0         4.0         0.0         1.0         1.0   \n",
       "576813         0.0         2.0         0.0         1.0         2.0   \n",
       "577850         0.0        10.0         0.0         2.0         1.0   \n",
       "573800         6.0         5.0         0.0         1.0         1.0   \n",
       "\n",
       "        SC183Q03JA  SC183Q04JA  SC175Q01JA  SC188Q01JA  SC188Q02JA  \\\n",
       "577660         1.0         1.0        90.0         3.0         3.0   \n",
       "577072         1.0         1.0        60.0         4.0         4.0   \n",
       "576813         2.0         2.0        80.0         4.0         4.0   \n",
       "577850         1.0         1.0        45.0         3.0         4.0   \n",
       "573800         1.0         1.0        65.0         4.0         4.0   \n",
       "\n",
       "        SC188Q03JA  SC188Q04JA  SC188Q05JA  ...  ST349Q01JA_2  ST349Q01JA_3  \\\n",
       "577660         3.0         3.0         2.0  ...             0             0   \n",
       "577072         3.0         3.0         3.0  ...             1             0   \n",
       "576813         3.0         4.0         3.0  ...             0             0   \n",
       "577850         1.0         3.0         3.0  ...             0             0   \n",
       "573800         2.0         3.0         3.0  ...             0             0   \n",
       "\n",
       "        ST349Q01JA_4  ST349Q01JA_0  LANGN_105  LANGN_108  LANGN_118  \\\n",
       "577660             0             0          0          0          0   \n",
       "577072             0             0          0          0          0   \n",
       "576813             0             0          0          0          0   \n",
       "577850             0             0          0          0          0   \n",
       "573800             0             0          0          0          0   \n",
       "\n",
       "        LANGN_140  LANGN_148  LANGN_150  LANGN_156  LANGN_200  LANGN_204  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_232  LANGN_273  LANGN_313  LANGN_316  LANGN_322  LANGN_329  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          1          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          1          0          0          0   \n",
       "573800          0          0          1          0          0          0   \n",
       "\n",
       "        LANGN_344  LANGN_351  LANGN_415  LANGN_463  LANGN_493  LANGN_496  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_500  LANGN_520  LANGN_531  LANGN_602  LANGN_606  LANGN_615  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_621  LANGN_625  LANGN_640  LANGN_641  LANGN_663  LANGN_669  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_670  LANGN_800  LANGN_801  LANGN_802  LANGN_804  LANGN_805  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_806  LANGN_807  LANGN_808  LANGN_865  LANGN_892  LANGN_895  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_917  SC177Q01JA_1  SC177Q01JA_2  SC177Q01JA_3  SC177Q02JA_1  \\\n",
       "577660          0             0             0             1             1   \n",
       "577072          0             0             0             0             0   \n",
       "576813          0             0             0             1             0   \n",
       "577850          0             0             0             1             0   \n",
       "573800          0             1             0             0             0   \n",
       "\n",
       "        SC177Q02JA_2  SC177Q02JA_3  SC177Q03JA_1  SC177Q03JA_2  SC177Q03JA_3  \\\n",
       "577660             0             0             0             0             1   \n",
       "577072             0             0             0             0             0   \n",
       "576813             0             1             0             0             1   \n",
       "577850             0             1             0             0             1   \n",
       "573800             0             1             1             0             0   \n",
       "\n",
       "        MATHEXC_0  MATHEXC_1  MATHEXC_2  MATHEXC_3  SCHLTYPE_1  SCHLTYPE_2  \\\n",
       "577660          0          0          0          1           0           0   \n",
       "577072          0          0          0          0           0           0   \n",
       "576813          0          0          0          0           0           0   \n",
       "577850          0          0          0          1           0           0   \n",
       "573800          0          0          0          1           0           0   \n",
       "\n",
       "        SCHLTYPE_3  LANGN_121  LANGN_130  LANGN_137  LANGN_170  LANGN_244  \\\n",
       "577660           1          0          0          0          0          0   \n",
       "577072           1          0          0          0          0          0   \n",
       "576813           1          0          0          0          0          0   \n",
       "577850           1          0          0          0          0          0   \n",
       "573800           1          0          0          0          0          0   \n",
       "\n",
       "        LANGN_258  LANGN_263  LANGN_264  LANGN_266  LANGN_317  LANGN_340  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_369  LANGN_381  LANGN_404  LANGN_420  LANGN_449  LANGN_467  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_494  LANGN_495  LANGN_514  LANGN_523  LANGN_529  LANGN_540  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_547  LANGN_600  LANGN_607  LANGN_618  LANGN_619  LANGN_630  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_635  LANGN_650  LANGN_661  LANGN_673  LANGN_674  LANGN_809  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_810  LANGN_811  LANGN_812  LANGN_813  LANGN_814  LANGN_815  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_816  LANGN_818  LANGN_832  LANGN_868  LANGN_870  LANGN_920  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_921  LANGN_113  LANGN_147  LANGN_275  LANGN_286  LANGN_363  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_422  LANGN_434  LANGN_442  LANGN_471  LANGN_611  LANGN_614  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_624  LANGN_642  LANGN_675  LANGN_676  LANGN_677  LANGN_678  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_817  LANGN_819  LANGN_821  LANGN_823  LANGN_824  LANGN_825  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_826  LANGN_827  LANGN_828  LANGN_885  LANGN_896  LANGN_916  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_112  LANGN_154  LANGN_202  LANGN_246  LANGN_254  LANGN_272  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_301  LANGN_325  LANGN_338  LANGN_358  LANGN_371  LANGN_375  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_383  LANGN_409  LANGN_428  LANGN_465  LANGN_517  LANGN_527  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_561  LANGN_562  LANGN_563  LANGN_565  LANGN_566  LANGN_567  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_601  LANGN_622  LANGN_623  LANGN_628  LANGN_631  LANGN_831  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_833  LANGN_836  LANGN_837  LANGN_838  LANGN_839  LANGN_840  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_841  LANGN_845  LANGN_872  LANGN_873  LANGN_881  LANGN_890  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_897  LANGN_898  LANGN_899  LANGN_900  LANGN_901  LANGN_902  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_903  LANGN_904  LANGN_905  LANGN_906  LANGN_907  LANGN_908  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_909  LANGN_910  LANGN_911  LANGN_912  LANGN_913  LANGN_914  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_918  LANGN_919  LANGN_160  LANGN_327  LANGN_451  LANGN_474  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_503  LANGN_608  LANGN_627  LANGN_639  LANGN_668  LANGN_842  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_843  LANGN_844  LANGN_846  LANGN_849  LANGN_850  LANGN_851  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_852  LANGN_861  LANGN_879  LANGN_133  LANGN_195  LANGN_237  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_379  LANGN_382  LANGN_472  LANGN_492  LANGN_555  LANGN_605  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_616  LANGN_626  LANGN_634  LANGN_648  LANGN_662  LANGN_665  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_666  LANGN_667  LANGN_829  LANGN_854  LANGN_855  LANGN_857  \\\n",
       "577660          0          0          0          0          0          0   \n",
       "577072          0          0          0          0          0          0   \n",
       "576813          0          0          0          0          0          0   \n",
       "577850          0          0          0          0          0          0   \n",
       "573800          0          0          0          0          0          0   \n",
       "\n",
       "        LANGN_859  LANGN_860  LANGN_866  LANGN_877  LANGN_922  \n",
       "577660          0          0          0          0          0  \n",
       "577072          0          0          0          0          0  \n",
       "576813          1          0          0          0          0  \n",
       "577850          0          0          0          0          0  \n",
       "573800          0          0          0          0          0  \n",
       "\n",
       "[5 rows x 558 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data - NOT SAVED TO S3\n",
    "print(test_data.shape)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll copy the file to S3 for Amazon SageMaker's managed training to pickup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cell 14\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 15\n",
    "container = sagemaker.image_uris.retrieve(region=boto3.Session().region_name, framework='xgboost', version='latest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, because we're training with the CSV file format, we'll create `s3_input`s that our training function can use as a pointer to the files in S3, which also specify that the content type is CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 16\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='text/csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/validation/'.format(bucket, prefix), content_type='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 17\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "linear_learner = sagemaker.estimator.Estimator(\n",
    "    image_uri=sagemaker.image_uris.retrieve(\"linear-learner\", sess.boto_region_name),\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    output_path=f's3://{bucket}/{prefix}/output',\n",
    "    sagemaker_session=sess\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters for logistic regression - Set to default values\n",
    "\n",
    "linear_learner.set_hyperparameters(\n",
    "    predictor_type='binary_classifier',  # Logistic regression for binary classification\n",
    "    loss='logistic',  \n",
    "    optimizer=\"auto\",  \n",
    "    use_bias=True,  # Include an intercept (bias term) in the model\n",
    "    epochs=30,  # Number of passes over the data (Can't be tuned)\n",
    "    \n",
    "    mini_batch_size=1000,      \n",
    "    learning_rate=0.1, \n",
    "    wd=0.0,  # For L2 regularization (weight decay)\n",
    "    l1=0.0  # For L1 regularization (sparsity)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use auto-tuning to find best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "mini_batch_upper_limit = int(train_data.shape[0]*0.16)\n",
    "\n",
    "hyperparameter_ranges = {'mini_batch_size': IntegerParameter(30, mini_batch_upper_limit),\n",
    "                         'learning_rate': ContinuousParameter(0.001, 0.01),\n",
    "                         'wd': ContinuousParameter(0.0001, 0.01),\n",
    "                         'l1': ContinuousParameter(0.0001, 0.01)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(estimator=linear_learner,\n",
    "                            objective_metric_name='validation:roc_auc_score',\n",
    "                            hyperparameter_ranges=hyperparameter_ranges,\n",
    "                            max_jobs=50,  \n",
    "                            max_parallel_jobs=5)\n",
    "\n",
    "# May need to adjust number of jobs depending on budget!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Completed'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell 26\n",
    "boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training job: linear-learner-250301-2235-047-38dbd788\n"
     ]
    }
   ],
   "source": [
    "# cell 27\n",
    "# Return the best training job name\n",
    "best_training_job = tuner.best_training_job()\n",
    "print(\"Best training job:\", best_training_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST mini batch size:  34\n",
      "BEST learning rate:  0.001\n",
      "BEST weight decay:  0.008\n",
      "BEST L1:  0.004\n"
     ]
    }
   ],
   "source": [
    "# Print out hyperparameters of BEST model\n",
    "\n",
    "response = boto3.client('sagemaker').describe_training_job(TrainingJobName=best_training_job)\n",
    "best_hyperparameters = response[\"HyperParameters\"]\n",
    "\n",
    "best_mini_batch_size = int(best_hyperparameters[\"mini_batch_size\"])\n",
    "best_learning_rate = float(best_hyperparameters[\"learning_rate\"])\n",
    "best_weight_decay = float(best_hyperparameters[\"wd\"])\n",
    "best_L1 = float(best_hyperparameters[\"l1\"])\n",
    "\n",
    "print(\"BEST mini batch size: \", best_mini_batch_size)\n",
    "print(\"BEST learning rate: \", round(best_learning_rate, 3))\n",
    "print(\"BEST weight decay: \", round(best_weight_decay, 3))\n",
    "print(\"BEST L1: \", round(best_L1, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model (the best model identified by HyperparameterTuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-03-01 22:56:39 Starting - Found matching resource for reuse\n",
      "2025-03-01 22:56:39 Downloading - Downloading the training image\n",
      "2025-03-01 22:56:39 Training - Training image download completed. Training in progress.\n",
      "2025-03-01 22:56:39 Uploading - Uploading generated training model\n",
      "2025-03-01 22:56:39 Completed - Resource retained for reuse\n",
      "-------!"
     ]
    }
   ],
   "source": [
    "# cell 28\n",
    "linear_learner_predictor = tuner.deploy(initial_instance_count=1,\n",
    "                           instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 29\n",
    "# Create a serializer\n",
    "linear_learner_predictor.serializer = sagemaker.serializers.CSVSerializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use a simple function to:\n",
    "1. Loop over our test dataset\n",
    "1. Split it into mini-batches of rows \n",
    "1. Convert those mini-batches to CSV string payloads (notice, we drop the target variable from our dataset first)\n",
    "1. Retrieve mini-batch predictions by invoking the XGBoost endpoint\n",
    "1. Collect predictions and convert from the CSV output our model provides into a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the raw prediction output\n",
    "raw_predictions = linear_learner_predictor.predict(test_data.drop(['MATH_Proficient'], axis=1).to_numpy())\n",
    "\n",
    "# Decode and parse JSON\n",
    "parsed_predictions = json.loads(raw_predictions.decode(\"utf-8\"))\n",
    "\n",
    "# Extract the scores\n",
    "predictions = np.array([pred[\"score\"] for pred in parsed_predictions[\"predictions\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the real values for the test set\n",
    "real_values = test_data['MATH_Proficient']\n",
    "real_values.to_csv('real_values.csv', index=False, header=False)\n",
    "\n",
    "# Save the predicted values for the test set\n",
    "predicted_values_full = predictions\n",
    "predicted_values_full = pd.DataFrame(predicted_values_full, columns=['Predicted Values'])\n",
    "predicted_values_full.to_csv('predicted_values_full.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "linear_learner_predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain the trained model using Clarify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-03-01 22:56:39 Starting - Found matching resource for reuse\n",
      "2025-03-01 22:56:39 Downloading - Downloading the training image\n",
      "2025-03-01 22:56:39 Training - Training image download completed. Training in progress.\n",
      "2025-03-01 22:56:39 Uploading - Uploading generated training model\n",
      "2025-03-01 22:56:39 Completed - Resource released due to keep alive period expiry\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Clarify-United-States-01-03-2025-23-03-01'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "model_name = \"Clarify-{}-{}\".format(country_name_edited, datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\"))\n",
    "\n",
    "best_model = sagemaker.estimator.Estimator.attach(best_training_job)  # Attach the best training job\n",
    "\n",
    "model = best_model.create_model(name=model_name)  # Create a model from the best job\n",
    "\n",
    "container_def = model.prepare_container_def()\n",
    "\n",
    "session.create_model(model_name, role, container_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test_data.drop([\"MATH_Proficient\"], axis=1)\n",
    "test_target = test_data[\"MATH_Proficient\"]\n",
    "test_features.to_csv(\"test_features.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import clarify\n",
    "\n",
    "clarify_processor = clarify.SageMakerClarifyProcessor(\n",
    "    role=role, instance_count=1, instance_type=\"ml.m5.2xlarge\", sagemaker_session=session\n",
    ")\n",
    "\n",
    "model_config = clarify.ModelConfig(\n",
    "    model_name=model_name,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    accept_type=\"text/csv\",\n",
    "    content_type=\"text/csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "# Download data from S3 to local instance\n",
    "local_path = S3Downloader.download('s3://{}/{}/train'.format(bucket, prefix), './tmp/train_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and sample\n",
    "full_data = pd.read_csv('./tmp/train_data/train.csv', header=None)\n",
    "n = min(3000, len(full_data))  \n",
    "sampled_data = full_data.sample(n=n)  # If full_data has less than n, use the full sample\n",
    "\n",
    "# Save sampled data back to S3\n",
    "sampled_path = 'sampled_train_data.csv'\n",
    "sampled_data.to_csv(sampled_path, index=False)\n",
    "\n",
    "from sagemaker.s3 import S3Uploader\n",
    "sampled_s3_uri = S3Uploader.upload(sampled_path, 's3://{}/{}/sampled_train'.format(bucket, prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 558)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>...</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "      <th>313</th>\n",
       "      <th>314</th>\n",
       "      <th>315</th>\n",
       "      <th>316</th>\n",
       "      <th>317</th>\n",
       "      <th>318</th>\n",
       "      <th>319</th>\n",
       "      <th>320</th>\n",
       "      <th>321</th>\n",
       "      <th>322</th>\n",
       "      <th>323</th>\n",
       "      <th>324</th>\n",
       "      <th>325</th>\n",
       "      <th>326</th>\n",
       "      <th>327</th>\n",
       "      <th>328</th>\n",
       "      <th>329</th>\n",
       "      <th>330</th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "      <th>334</th>\n",
       "      <th>335</th>\n",
       "      <th>336</th>\n",
       "      <th>337</th>\n",
       "      <th>338</th>\n",
       "      <th>339</th>\n",
       "      <th>340</th>\n",
       "      <th>341</th>\n",
       "      <th>342</th>\n",
       "      <th>343</th>\n",
       "      <th>344</th>\n",
       "      <th>345</th>\n",
       "      <th>346</th>\n",
       "      <th>347</th>\n",
       "      <th>348</th>\n",
       "      <th>349</th>\n",
       "      <th>350</th>\n",
       "      <th>351</th>\n",
       "      <th>352</th>\n",
       "      <th>353</th>\n",
       "      <th>354</th>\n",
       "      <th>355</th>\n",
       "      <th>356</th>\n",
       "      <th>357</th>\n",
       "      <th>358</th>\n",
       "      <th>359</th>\n",
       "      <th>360</th>\n",
       "      <th>361</th>\n",
       "      <th>362</th>\n",
       "      <th>363</th>\n",
       "      <th>364</th>\n",
       "      <th>365</th>\n",
       "      <th>366</th>\n",
       "      <th>367</th>\n",
       "      <th>368</th>\n",
       "      <th>369</th>\n",
       "      <th>370</th>\n",
       "      <th>371</th>\n",
       "      <th>372</th>\n",
       "      <th>373</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "      <th>384</th>\n",
       "      <th>385</th>\n",
       "      <th>386</th>\n",
       "      <th>387</th>\n",
       "      <th>388</th>\n",
       "      <th>389</th>\n",
       "      <th>390</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>398</th>\n",
       "      <th>399</th>\n",
       "      <th>400</th>\n",
       "      <th>401</th>\n",
       "      <th>402</th>\n",
       "      <th>403</th>\n",
       "      <th>404</th>\n",
       "      <th>405</th>\n",
       "      <th>406</th>\n",
       "      <th>407</th>\n",
       "      <th>408</th>\n",
       "      <th>409</th>\n",
       "      <th>410</th>\n",
       "      <th>411</th>\n",
       "      <th>412</th>\n",
       "      <th>413</th>\n",
       "      <th>414</th>\n",
       "      <th>415</th>\n",
       "      <th>416</th>\n",
       "      <th>417</th>\n",
       "      <th>418</th>\n",
       "      <th>419</th>\n",
       "      <th>420</th>\n",
       "      <th>421</th>\n",
       "      <th>422</th>\n",
       "      <th>423</th>\n",
       "      <th>424</th>\n",
       "      <th>425</th>\n",
       "      <th>426</th>\n",
       "      <th>427</th>\n",
       "      <th>428</th>\n",
       "      <th>429</th>\n",
       "      <th>430</th>\n",
       "      <th>431</th>\n",
       "      <th>432</th>\n",
       "      <th>433</th>\n",
       "      <th>434</th>\n",
       "      <th>435</th>\n",
       "      <th>436</th>\n",
       "      <th>437</th>\n",
       "      <th>438</th>\n",
       "      <th>439</th>\n",
       "      <th>440</th>\n",
       "      <th>441</th>\n",
       "      <th>442</th>\n",
       "      <th>443</th>\n",
       "      <th>444</th>\n",
       "      <th>445</th>\n",
       "      <th>446</th>\n",
       "      <th>447</th>\n",
       "      <th>448</th>\n",
       "      <th>449</th>\n",
       "      <th>450</th>\n",
       "      <th>451</th>\n",
       "      <th>452</th>\n",
       "      <th>453</th>\n",
       "      <th>454</th>\n",
       "      <th>455</th>\n",
       "      <th>456</th>\n",
       "      <th>457</th>\n",
       "      <th>458</th>\n",
       "      <th>459</th>\n",
       "      <th>460</th>\n",
       "      <th>461</th>\n",
       "      <th>462</th>\n",
       "      <th>463</th>\n",
       "      <th>464</th>\n",
       "      <th>465</th>\n",
       "      <th>466</th>\n",
       "      <th>467</th>\n",
       "      <th>468</th>\n",
       "      <th>469</th>\n",
       "      <th>470</th>\n",
       "      <th>471</th>\n",
       "      <th>472</th>\n",
       "      <th>473</th>\n",
       "      <th>474</th>\n",
       "      <th>475</th>\n",
       "      <th>476</th>\n",
       "      <th>477</th>\n",
       "      <th>478</th>\n",
       "      <th>479</th>\n",
       "      <th>480</th>\n",
       "      <th>481</th>\n",
       "      <th>482</th>\n",
       "      <th>483</th>\n",
       "      <th>484</th>\n",
       "      <th>485</th>\n",
       "      <th>486</th>\n",
       "      <th>487</th>\n",
       "      <th>488</th>\n",
       "      <th>489</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "      <th>512</th>\n",
       "      <th>513</th>\n",
       "      <th>514</th>\n",
       "      <th>515</th>\n",
       "      <th>516</th>\n",
       "      <th>517</th>\n",
       "      <th>518</th>\n",
       "      <th>519</th>\n",
       "      <th>520</th>\n",
       "      <th>521</th>\n",
       "      <th>522</th>\n",
       "      <th>523</th>\n",
       "      <th>524</th>\n",
       "      <th>525</th>\n",
       "      <th>526</th>\n",
       "      <th>527</th>\n",
       "      <th>528</th>\n",
       "      <th>529</th>\n",
       "      <th>530</th>\n",
       "      <th>531</th>\n",
       "      <th>532</th>\n",
       "      <th>533</th>\n",
       "      <th>534</th>\n",
       "      <th>535</th>\n",
       "      <th>536</th>\n",
       "      <th>537</th>\n",
       "      <th>538</th>\n",
       "      <th>539</th>\n",
       "      <th>540</th>\n",
       "      <th>541</th>\n",
       "      <th>542</th>\n",
       "      <th>543</th>\n",
       "      <th>544</th>\n",
       "      <th>545</th>\n",
       "      <th>546</th>\n",
       "      <th>547</th>\n",
       "      <th>548</th>\n",
       "      <th>549</th>\n",
       "      <th>550</th>\n",
       "      <th>551</th>\n",
       "      <th>552</th>\n",
       "      <th>553</th>\n",
       "      <th>554</th>\n",
       "      <th>555</th>\n",
       "      <th>556</th>\n",
       "      <th>557</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 558 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    10   11   12   13   \\\n",
       "315   0.0  1.0  1.0  1.0  1.0  1.0  1.0  2.0  1.0  3.0  4.0  1.0  5.0  3.0   \n",
       "1673  0.0  1.0  1.0  1.0  1.0  1.0  1.0  3.0  1.0  2.0  2.0  4.0  7.0  2.0   \n",
       "2640  1.0  1.0  1.0  1.0  1.0  1.0  1.0  2.0  1.0  2.0  2.0  1.0  7.0  2.0   \n",
       "391   1.0  1.0  2.0  1.0  1.0  1.0  1.0  4.0  1.0  2.0  2.0  3.0  7.0  3.0   \n",
       "2655  1.0  1.0  1.0  1.0  1.0  1.0  1.0  3.0  1.0  3.0  3.0  4.0  8.0  2.0   \n",
       "\n",
       "      14   15   16   17   18   19   20   21   22   23   24   25   26   27   \\\n",
       "315   1.0  2.0  2.0  1.0  3.0  2.0  2.0  2.0  1.0  2.0  2.0  1.0  2.0  1.0   \n",
       "1673  2.0  2.0  2.0  1.0  3.0  4.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0   \n",
       "2640  1.0  3.0  2.0  1.0  3.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0   \n",
       "391   2.0  2.0  2.0  1.0  3.0  6.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0   \n",
       "2655  3.0  3.0  3.0  2.0  3.0  5.0  2.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0   \n",
       "\n",
       "      28   29   30   31   32   33   34   35   36   37   38   39   40   41   \\\n",
       "315   1.0  1.0  1.0  1.0  1.0  2.0  1.0  1.0  2.0  2.0  4.0  2.0  2.0  2.0   \n",
       "1673  1.0  2.0  2.0  2.0  2.0  2.0  1.0  2.0  2.0  2.0  3.0  3.0  3.0  3.0   \n",
       "2640  1.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  1.0   \n",
       "391   1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  2.0  2.0  1.0  1.0  1.0  1.0   \n",
       "2655  1.0  2.0  2.0  2.0  2.0  1.0  2.0  2.0  1.0  1.0  1.0  2.0  2.0  2.0   \n",
       "\n",
       "      42   43   44   45   46   47   48   49   50   51   52   53   54   55   \\\n",
       "315   2.0  2.0  2.0  1.0  2.0  2.0  1.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0   \n",
       "1673  4.0  3.0  4.0  3.0  3.0  3.0  3.0  3.0  3.0  2.0  1.0  1.0  1.0  3.0   \n",
       "2640  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  3.0  2.0  2.0  2.0  2.0  1.0   \n",
       "391   1.0  1.0  1.0  1.0  1.0  2.0  1.0  1.0  2.0  1.0  2.0  4.0  4.0  1.0   \n",
       "2655  1.0  1.0  3.0  2.0  3.0  3.0  1.0  2.0  1.0  1.0  1.0  3.0  3.0  3.0   \n",
       "\n",
       "      56   57   58   59   60   61   62   63   64   65   66   67   68   69   \\\n",
       "315   1.0  1.0  4.0  3.0  4.0  4.0  4.0  4.0  4.0  3.0  3.0  4.0  3.0  3.0   \n",
       "1673  3.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  2.0  3.0  3.0  1.0  1.0  3.0   \n",
       "2640  2.0  2.0  2.0  2.0  2.0  1.0  2.0  1.0  1.0  1.0  3.0  1.0  1.0  1.0   \n",
       "391   2.0  1.0  1.0  1.0  2.0  1.0  1.0  1.0  3.0  1.0  1.0  1.0  1.0  3.0   \n",
       "2655  2.0  2.0  3.0  2.0  2.0  3.0  3.0  3.0  3.0  4.0  1.0  1.0  1.0  2.0   \n",
       "\n",
       "      70   71   72   73   74   75   76   77   78   79   80   81   82   83   \\\n",
       "315   4.0  4.0  4.0  2.0  2.0  2.0  4.0  4.0  4.0  4.0  4.0  3.0  3.0  4.0   \n",
       "1673  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  3.0  5.0   \n",
       "2640  2.0  1.0  3.0  1.0  1.0  3.0  4.0  3.0  4.0  4.0  4.0  2.0  4.0  1.0   \n",
       "391   1.0  1.0  1.0  1.0  1.0  1.0  2.0  1.0  1.0  3.0  1.0  1.0  1.0  5.0   \n",
       "2655  2.0  1.0  2.0  2.0  3.0  2.0  3.0  3.0  2.0  4.0  4.0  4.0  3.0  4.0   \n",
       "\n",
       "      84   85   86   87   88   89   90   91   92   93   94   95   96   97   \\\n",
       "315   5.0  4.0  5.0  5.0  5.0  4.0  1.0  4.0  3.0  4.0  4.0  4.0  4.0  3.0   \n",
       "1673  5.0  5.0  2.0  5.0  5.0  5.0  2.0  1.0  1.0  3.0  2.0  3.0  3.0  2.0   \n",
       "2640  3.0  3.0  1.0  4.0  1.0  5.0  1.0  3.0  3.0  2.0  3.0  3.0  3.0  3.0   \n",
       "391   5.0  2.0  1.0  2.0  1.0  5.0  1.0  1.0  1.0  4.0  2.0  2.0  1.0  3.0   \n",
       "2655  3.0  2.0  4.0  4.0  3.0  3.0  2.0  1.0  2.0  4.0  2.0  3.0  4.0  3.0   \n",
       "\n",
       "      98   99   100  101  102  103  104  105  106  107  108  109  110  111  \\\n",
       "315   3.0  4.0  4.0  3.0  1.0  1.0  1.0  4.0  6.0  1.0  6.0  5.0  5.0  5.0   \n",
       "1673  3.0  3.0  3.0  1.0  1.0  2.0  3.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0   \n",
       "2640  3.0  3.0  1.0  1.0  1.0  1.0  1.0  5.0  5.0  1.0  5.0  5.0  5.0  5.0   \n",
       "391   3.0  4.0  4.0  1.0  1.0  1.0  1.0  3.0  5.0  1.0  5.0  4.0  3.0  5.0   \n",
       "2655  3.0  3.0  1.0  3.0  3.0  2.0  4.0  5.0  5.0  1.0  5.0  5.0  5.0  5.0   \n",
       "\n",
       "      112  113  114  115  116  117  118  119  120  121  122  123  124  125  \\\n",
       "315   6.0  6.0  1.0  5.0  4.0  3.0  2.0  2.0  4.0  4.0  3.0  3.0  3.0  2.0   \n",
       "1673  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0   \n",
       "2640  5.0  5.0  1.0  5.0  5.0  5.0  4.0  4.0  2.0  3.0  4.0  3.0  3.0  3.0   \n",
       "391   5.0  5.0  1.0  5.0  2.0  4.0  4.0  4.0  2.0  3.0  3.0  4.0  3.0  3.0   \n",
       "2655  5.0  5.0  3.0  5.0  3.0  5.0  4.0  4.0  3.0  4.0  4.0  4.0  3.0  4.0   \n",
       "\n",
       "      126  127  128  129  130  131  132  133  134  135  136  137  138  139  \\\n",
       "315   3.0  3.0  3.0  3.0  3.0  4.0  4.0  4.0  4.0  3.0  3.0  3.0  3.0  4.0   \n",
       "1673  4.0  5.0  4.0  3.0  5.0  4.0  4.0  3.0  3.0  2.0  2.0  5.0  5.0  5.0   \n",
       "2640  3.0  2.0  4.0  2.0  6.0  4.0  5.0  1.0  3.0  1.0  3.0  4.0  4.0  4.0   \n",
       "391   4.0  6.0  5.0  5.0  6.0  3.0  5.0  3.0  4.0  3.0  3.0  4.0  5.0  1.0   \n",
       "2655  4.0  5.0  2.0  5.0  5.0  4.0  5.0  4.0  4.0  3.0  4.0  4.0  3.0  5.0   \n",
       "\n",
       "      140  141  142  143  144  145  146  147  148  149  150  151  152  153  \\\n",
       "315   4.0  4.0  4.0  4.0  4.0  5.0  5.0  3.0  3.0  4.0  4.0  5.0  5.0  5.0   \n",
       "1673  3.0  4.0  3.0  4.0  4.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  3.0   \n",
       "2640  3.0  5.0  4.0  5.0  3.0  5.0  4.0  4.0  5.0  4.0  2.0  2.0  2.0  2.0   \n",
       "391   1.0  5.0  4.0  3.0  3.0  5.0  5.0  5.0  5.0  5.0  5.0  4.0  5.0  3.0   \n",
       "2655  5.0  4.0  3.0  1.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  5.0  2.0   \n",
       "\n",
       "      154  155  156  157  158  159  160  161  162  163  164  165  166  167  \\\n",
       "315   5.0  5.0  4.0  5.0  4.0  3.0  2.0  4.0  4.0  4.0  2.0  4.0  2.0  3.0   \n",
       "1673  3.0  3.0  2.0  3.0  3.0  6.0  4.0  4.0  4.0  3.0  4.0  4.0  4.0  1.0   \n",
       "2640  5.0  3.0  1.0  4.0  3.0  2.0  6.0  6.0  1.0  1.0  2.0  2.0  2.0  1.0   \n",
       "391   2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  3.0  2.0  2.0  3.0  2.0  2.0   \n",
       "2655  1.0  4.0  2.0  2.0  3.0  2.0  3.0  1.0  5.0  3.0  1.0  3.0  2.0  1.0   \n",
       "\n",
       "      168  169  170  171  172  173  174  175  176  177  178  179  180  181  \\\n",
       "315   3.0  3.0  2.0  2.0  3.0  3.0  3.0  3.0  4.0  3.0  2.0  2.0  2.0  2.0   \n",
       "1673  2.0  4.0  3.0  1.0  3.0  3.0  3.0  2.0  3.0  3.0  4.0  4.0  4.0  4.0   \n",
       "2640  1.0  3.0  1.0  1.0  3.0  3.0  2.0  3.0  3.0  2.0  2.0  3.0  3.0  3.0   \n",
       "391   2.0  3.0  3.0  1.0  3.0  2.0  4.0  4.0  4.0  4.0  3.0  4.0  4.0  4.0   \n",
       "2655  1.0  4.0  3.0  2.0  1.0  3.0  3.0  2.0  4.0  4.0  2.0  4.0  4.0  4.0   \n",
       "\n",
       "      182  183  184  185  186  187  188  189  190  191  192  193  194  195  \\\n",
       "315   4.0  2.0  4.0  3.0  2.0  3.0  3.0  4.0  3.0  3.0  3.0  6.0  1.0  8.0   \n",
       "1673  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  1.0  1.0  2.0  4.0  1.0  4.0   \n",
       "2640  4.0  3.0  4.0  3.0  4.0  3.0  4.0  3.0  2.0  3.0  3.0  4.0  1.0  5.0   \n",
       "391   4.0  4.0  4.0  3.0  4.0  3.0  4.0  3.0  2.0  3.0  3.0  4.0  1.0  2.0   \n",
       "2655  4.0  4.0  4.0  4.0  4.0  4.0  4.0  4.0  3.0  4.0  4.0  5.0  1.0  7.0   \n",
       "\n",
       "      196  197  198  199  200  201  202  203  204  205   206  207  208  209  \\\n",
       "315   2.0  0.0  0.0  8.0  5.0  4.0  1.0  2.0  1.0  0.0  16.0  4.0  0.0  3.0   \n",
       "1673  1.0  1.0  0.0  8.0  7.0  6.0  2.0  0.0  2.0  0.0  12.0  4.0  1.0  2.0   \n",
       "2640  1.0  0.0  0.0  6.0  7.0  6.0  1.0  0.0  3.0  0.0   3.0  3.0  0.0  3.0   \n",
       "391   2.0  0.0  0.0  7.0  7.0  6.0  2.0  1.0  3.0  0.0  12.0  4.0  0.0  2.0   \n",
       "2655  1.0  0.0  0.0  8.0  7.0  6.0  1.0  1.0  3.0  0.0  16.0  2.0  1.0  3.0   \n",
       "\n",
       "      210   211  212  213  214  215  216  217  218  219  220  221  222  223  \\\n",
       "315   3.0   4.0  3.0  4.0  5.0  5.0  1.0  1.0  3.0  2.0  4.0  1.0  0.0  1.0   \n",
       "1673  1.0  42.0  3.0  7.0  4.0  4.0  3.0  1.0  1.0  3.0  2.0  0.0  1.0  0.0   \n",
       "2640  2.0   6.0  3.0  1.0  5.0  5.0  1.0  1.0  3.0  2.0  4.0  0.0  0.0  0.0   \n",
       "391   1.0  20.0  3.0  3.0  1.0  5.0  5.0  2.0  2.0  3.0  4.0  0.0  0.0  0.0   \n",
       "2655  1.0   3.0  5.0  3.0  4.0  4.0  3.0  2.0  2.0  2.0  4.0  0.0  1.0  1.0   \n",
       "\n",
       "      224  225  226  227  228  229   230  231  232  233   234   235   236  \\\n",
       "315   0.0  1.0  0.0  4.0  1.0  4.0   6.0  1.0  5.0  5.0  15.0  17.0  61.0   \n",
       "1673  1.0  0.0  0.0  1.0  6.0  6.0   2.0  0.0  9.0  4.0  41.0  25.0  65.0   \n",
       "2640  0.0  0.0  1.0  5.0  2.0  6.0   5.0  0.0  0.0  4.0   5.0   3.0  11.0   \n",
       "391   0.0  0.0  1.0  1.0  6.0  6.0  10.0  0.0  7.0  4.0  10.0  14.0  74.0   \n",
       "2655  1.0  0.0  0.0  1.0  4.0  6.0   5.0  0.0  2.0  5.0   4.0   6.0  12.0   \n",
       "\n",
       "       237   238  239  240  241  242  243   244  245  246  247  248  249  ...  \\\n",
       "315   12.0  24.0  5.0  1.0  1.0  1.0  1.0  50.0  3.0  3.0  2.0  3.0  3.0  ...   \n",
       "1673  41.0   0.0  0.0  1.0  1.0  1.0  1.0  85.0  4.0  4.0  4.0  3.0  3.0  ...   \n",
       "2640   0.0   0.0  0.0  1.0  1.0  1.0  1.0  60.0  4.0  4.0  3.0  2.0  3.0  ...   \n",
       "391    4.0  22.0  0.0  1.0  1.0  1.0  1.0  90.0  4.0  2.0  2.0  4.0  1.0  ...   \n",
       "2655   8.0  14.0  8.0  1.0  2.0  2.0  2.0  65.0  3.0  4.0  1.0  2.0  2.0  ...   \n",
       "\n",
       "      308  309  310  311  312  313  314  315  316  317  318  319  320  321  \\\n",
       "315     1    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "1673    0    0    1    0    0    0    0    0    0    0    1    0    0    0   \n",
       "2640    0    0    1    0    0    0    0    0    0    0    1    0    0    0   \n",
       "391     0    0    0    0    0    0    0    0    0    0    1    0    0    0   \n",
       "2655    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "      322  323  324  325  326  327  328  329  330  331  332  333  334  335  \\\n",
       "315     0    1    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "1673    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2640    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "391     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2655    0    1    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "      336  337  338  339  340  341  342  343  344  345  346  347  348  349  \\\n",
       "315     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "1673    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2640    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "391     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2655    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "      350  351  352  353  354  355  356  357  358  359  360  361  362  363  \\\n",
       "315     0    0    0    0    0    0    0    0    0    0    1    0    0    1   \n",
       "1673    0    0    0    0    0    0    0    0    0    0    1    0    0    1   \n",
       "2640    0    0    0    0    0    0    0    0    0    0    1    0    0    1   \n",
       "391     0    0    0    0    0    0    0    0    0    0    1    0    0    1   \n",
       "2655    0    0    0    0    0    0    0    0    0    0    1    0    0    1   \n",
       "\n",
       "      364  365  366  367  368  369  370  371  372  373  374  375  376  377  \\\n",
       "315     0    1    0    0    0    0    0    0    0    1    0    0    0    0   \n",
       "1673    0    0    1    0    0    0    1    0    0    1    0    0    0    0   \n",
       "2640    0    0    1    0    0    0    0    0    0    1    0    0    0    0   \n",
       "391     0    0    1    0    0    1    0    0    0    1    0    0    0    0   \n",
       "2655    0    0    1    0    0    0    0    0    0    1    0    0    0    0   \n",
       "\n",
       "      378  379  380  381  382  383  384  385  386  387  388  389  390  391  \\\n",
       "315     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "1673    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2640    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "391     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2655    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "      392  393  394  395  396  397  398  399  400  401  402  403  404  405  \\\n",
       "315     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "1673    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2640    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "391     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2655    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "      406  407  408  409  410  411  412  413  414  415  416  417  418  419  \\\n",
       "315     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "1673    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2640    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "391     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2655    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "      420  421  422  423  424  425  426  427  428  429  430  431  432  433  \\\n",
       "315     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "1673    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2640    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "391     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2655    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "      434  435  436  437  438  439  440  441  442  443  444  445  446  447  \\\n",
       "315     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "1673    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2640    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "391     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2655    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "      448  449  450  451  452  453  454  455  456  457  458  459  460  461  \\\n",
       "315     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "1673    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2640    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "391     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2655    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "      462  463  464  465  466  467  468  469  470  471  472  473  474  475  \\\n",
       "315     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "1673    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2640    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "391     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2655    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "      476  477  478  479  480  481  482  483  484  485  486  487  488  489  \\\n",
       "315     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "1673    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2640    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "391     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2655    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "      490  491  492  493  494  495  496  497  498  499  500  501  502  503  \\\n",
       "315     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "1673    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2640    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "391     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2655    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "      504  505  506  507  508  509  510  511  512  513  514  515  516  517  \\\n",
       "315     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "1673    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2640    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "391     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2655    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "      518  519  520  521  522  523  524  525  526  527  528  529  530  531  \\\n",
       "315     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "1673    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2640    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "391     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2655    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "      532  533  534  535  536  537  538  539  540  541  542  543  544  545  \\\n",
       "315     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "1673    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2640    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "391     0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "2655    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "\n",
       "      546  547  548  549  550  551  552  553  554  555  556  557  \n",
       "315     0    0    0    0    0    0    0    0    0    0    0    0  \n",
       "1673    0    0    0    0    0    0    0    0    0    0    0    0  \n",
       "2640    0    0    0    0    0    0    0    0    0    0    0    0  \n",
       "391     0    0    0    0    0    0    0    0    0    0    0    0  \n",
       "2655    0    0    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 558 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sampled_data.shape)\n",
    "sampled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_config = clarify.SHAPConfig(\n",
    "    baseline=[test_features.iloc[0].values.tolist()],\n",
    "    num_samples=3000,  \n",
    "    agg_method=\"mean_abs\",\n",
    "    save_local_shap_values=True\n",
    ")\n",
    "\n",
    "explainability_output_path = \"s3://{}/{}/clarify-explainability\".format(bucket, prefix)\n",
    "\n",
    "explainability_data_config = clarify.DataConfig(\n",
    "    #s3_data_input_path='s3://{}/{}/train'.format(bucket, prefix),\n",
    "    s3_data_input_path=sampled_s3_uri,\n",
    "    s3_output_path=explainability_output_path,\n",
    "    label='MATH_Proficient',\n",
    "    headers=train_data.columns.to_list(),\n",
    "    dataset_type=\"text/csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name Clarify-Explainability-2025-03-01-23-03-08-763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34msagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\u001b[0m\n",
      "\u001b[34mWe are not in a supported iso region, /bin/sh exiting gracefully with no changes.\u001b[0m\n",
      "\u001b[34mWARNING:root:logging.conf not found when configuring logging, using default logging configuration.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:Starting SageMaker Clarify Processing job\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:Analysis config path: /opt/ml/processing/input/config/analysis_config.json\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:Analysis result path: /opt/ml/processing/output\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:This host is algo-1.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:This host is the leader.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_util:Number of hosts in the cluster is 1.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:Running Python / Pandas based analyzer.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.data_loading.data_loader_factory:Dataset type: text/csv uri: /opt/ml/processing/input/data\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:Loading dataset...\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:Loaded dataset. Dataset info:\u001b[0m\n",
      "\u001b[34m<class 'pandas.core.frame.DataFrame'>\u001b[0m\n",
      "\u001b[34mRangeIndex: 3001 entries, 0 to 3000\u001b[0m\n",
      "\u001b[34mColumns: 557 entries, SISCO to LANGN_922\u001b[0m\n",
      "\u001b[34mdtypes: float64(306), int64(251)\u001b[0m\n",
      "\u001b[34mmemory usage: 12.8 MB\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor.managed_endpoint:Spinning up shadow endpoint\u001b[0m\n",
      "\u001b[34mINFO:sagemaker:Creating endpoint-config with name sm-clarify-config-1740870354-4f2d\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor.managed_endpoint:Creating endpoint: 'sm-clarify-Clarify-United-States-01-03-2025-23--1740870354-3f7f'\u001b[0m\n",
      "\u001b[34mINFO:botocore.client:No endpoints ruleset found for service sagemaker-internal, falling back to legacy endpoint routing.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:Using endpoint name: sm-clarify-Clarify-United-States-01-03-2025-23--1740870354-3f7f\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:Waiting for endpoint ...\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor.managed_endpoint:Checking endpoint status:\u001b[0m\n",
      "\u001b[34mLegend:\u001b[0m\n",
      "\u001b[34m(OutOfService: x, Creating: -, Updating: -, InService: !, RollingBack: <, Deleting: o, Failed: *)\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor.managed_endpoint:Endpoint is in service after 241 seconds\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:Endpoint ready.\u001b[0m\n",
      "\u001b[34mINFO:explainers.shap.kernel_shap:Clarify Kernel SHAP n_coalitions: 3000, n_instances: 1, n_features_to_explain: 557, model_output_size: 1\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap.shap_analyzer:=====================================================\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap.shap_analyzer:Shap analyzer: explaining 3001 rows, 557 columns...\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap.shap_analyzer:=====================================================\u001b[0m\n",
      "\u001b[34m  0% (0 of 3001) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--\u001b[0m\n",
      "\u001b[34m  0% (15 of 3001) |                      | Elapsed Time: 0:00:30 ETA:   1:40:23\u001b[0m\n",
      "\u001b[34m  1% (31 of 3001) |                      | Elapsed Time: 0:01:01 ETA:   1:38:49\u001b[0m\n",
      "\u001b[34m  1% (47 of 3001) |                      | Elapsed Time: 0:01:33 ETA:   1:38:17\u001b[0m\n",
      "\u001b[34m  2% (63 of 3001) |                      | Elapsed Time: 0:02:04 ETA:   1:37:00\u001b[0m\n",
      "\u001b[34m  2% (79 of 3001) |                      | Elapsed Time: 0:02:35 ETA:   1:35:55\u001b[0m\n",
      "\u001b[34m  3% (95 of 3001) |                      | Elapsed Time: 0:03:06 ETA:   1:35:00\u001b[0m\n",
      "\u001b[34m  3% (111 of 3001) |                     | Elapsed Time: 0:03:37 ETA:   1:34:10\u001b[0m\n",
      "\u001b[34m  4% (127 of 3001) |                     | Elapsed Time: 0:04:07 ETA:   1:33:27\u001b[0m\n",
      "\u001b[34m  4% (143 of 3001) |#                    | Elapsed Time: 0:04:38 ETA:   1:32:41\u001b[0m\n",
      "\u001b[34m  5% (159 of 3001) |#                    | Elapsed Time: 0:05:08 ETA:   1:31:58\u001b[0m\n",
      "\u001b[34m  5% (175 of 3001) |#                    | Elapsed Time: 0:05:39 ETA:   1:31:23\u001b[0m\n",
      "\u001b[34m  6% (191 of 3001) |#                    | Elapsed Time: 0:06:10 ETA:   1:30:49\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1399 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m  6% (207 of 3001) |#                    | Elapsed Time: 0:06:41 ETA:   1:30:22\u001b[0m\n",
      "\u001b[34m  7% (223 of 3001) |#                    | Elapsed Time: 0:07:12 ETA:   1:29:47\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1399 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m  7% (239 of 3001) |#                    | Elapsed Time: 0:07:43 ETA:   1:29:16\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1399 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m  8% (255 of 3001) |#                    | Elapsed Time: 0:08:14 ETA:   1:28:46\u001b[0m\n",
      "\u001b[34m  9% (271 of 3001) |#                    | Elapsed Time: 0:08:45 ETA:   1:28:10\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1399 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1399 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m  9% (287 of 3001) |##                   | Elapsed Time: 0:09:15 ETA:   1:27:37\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1399 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1399 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1399 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1399 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 10% (303 of 3001) |##                   | Elapsed Time: 0:09:47 ETA:   1:27:09\u001b[0m\n",
      "\u001b[34m 10% (320 of 3001) |##                   | Elapsed Time: 0:10:19 ETA:   1:26:26\u001b[0m\n",
      "\u001b[34m 11% (337 of 3001) |##                   | Elapsed Time: 0:10:50 ETA:   1:25:45\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1399 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1399 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 11% (353 of 3001) |##                   | Elapsed Time: 0:11:21 ETA:   1:25:12\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1399 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1399 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 12% (369 of 3001) |##                   | Elapsed Time: 0:11:52 ETA:   1:24:40\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1399 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 12% (385 of 3001) |##                   | Elapsed Time: 0:12:22 ETA:   1:24:07\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1399 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 13% (401 of 3001) |##                   | Elapsed Time: 0:12:52 ETA:   1:23:31\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1399 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 13% (417 of 3001) |##                   | Elapsed Time: 0:13:22 ETA:   1:22:55\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1399 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 14% (433 of 3001) |###                  | Elapsed Time: 0:13:53 ETA:   1:22:20\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1399 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 14% (449 of 3001) |###                  | Elapsed Time: 0:14:23 ETA:   1:21:47\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 15% (465 of 3001) |###                  | Elapsed Time: 0:14:55 ETA:   1:21:21\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 16% (481 of 3001) |###                  | Elapsed Time: 0:15:25 ETA:   1:20:50\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 16% (497 of 3001) |###                  | Elapsed Time: 0:15:56 ETA:   1:20:17\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 17% (512 of 3001) |###                  | Elapsed Time: 0:16:26 ETA:   1:19:55\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 17% (527 of 3001) |###                  | Elapsed Time: 0:16:57 ETA:   1:19:35\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 18% (543 of 3001) |###                  | Elapsed Time: 0:17:28 ETA:   1:19:07\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 18% (559 of 3001) |###                  | Elapsed Time: 0:17:59 ETA:   1:18:36\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 19% (575 of 3001) |####                 | Elapsed Time: 0:18:31 ETA:   1:18:09\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 19% (590 of 3001) |####                 | Elapsed Time: 0:19:01 ETA:   1:17:45\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 20% (606 of 3001) |####                 | Elapsed Time: 0:19:33 ETA:   1:17:16\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 20% (622 of 3001) |####                 | Elapsed Time: 0:20:04 ETA:   1:16:46\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 21% (637 of 3001) |####                 | Elapsed Time: 0:20:34 ETA:   1:16:21\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 21% (653 of 3001) |####                 | Elapsed Time: 0:21:06 ETA:   1:15:53\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 22% (669 of 3001) |####                 | Elapsed Time: 0:21:38 ETA:   1:15:24\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 22% (685 of 3001) |####                 | Elapsed Time: 0:22:10 ETA:   1:14:57\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 23% (701 of 3001) |####                 | Elapsed Time: 0:22:40 ETA:   1:14:23\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 23% (716 of 3001) |#####                | Elapsed Time: 0:23:10 ETA:   1:13:57\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 24% (732 of 3001) |#####                | Elapsed Time: 0:23:42 ETA:   1:13:28\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 24% (748 of 3001) |#####                | Elapsed Time: 0:24:12 ETA:   1:12:55\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 25% (763 of 3001) |#####                | Elapsed Time: 0:24:43 ETA:   1:12:31\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 25% (779 of 3001) |#####                | Elapsed Time: 0:25:14 ETA:   1:12:00\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 26% (795 of 3001) |#####                | Elapsed Time: 0:25:45 ETA:   1:11:28\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 27% (811 of 3001) |#####                | Elapsed Time: 0:26:17 ETA:   1:10:58\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 27% (827 of 3001) |#####                | Elapsed Time: 0:26:47 ETA:   1:10:26\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 28% (842 of 3001) |#####                | Elapsed Time: 0:27:18 ETA:   1:10:01\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 28% (858 of 3001) |######               | Elapsed Time: 0:27:49 ETA:   1:09:29\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 29% (874 of 3001) |######               | Elapsed Time: 0:28:19 ETA:   1:08:56\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 29% (890 of 3001) |######               | Elapsed Time: 0:28:50 ETA:   1:08:25\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 30% (906 of 3001) |######               | Elapsed Time: 0:29:22 ETA:   1:07:55\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 30% (921 of 3001) |######               | Elapsed Time: 0:29:52 ETA:   1:07:28\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 31% (937 of 3001) |######               | Elapsed Time: 0:30:23 ETA:   1:06:56\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 31% (952 of 3001) |######               | Elapsed Time: 0:30:53 ETA:   1:06:30\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 32% (968 of 3001) |######               | Elapsed Time: 0:31:25 ETA:   1:05:59\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 32% (984 of 3001) |######               | Elapsed Time: 0:31:56 ETA:   1:05:29\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 33% (1000 of 3001) |######              | Elapsed Time: 0:32:27 ETA:   1:04:57\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 33% (1016 of 3001) |######              | Elapsed Time: 0:32:58 ETA:   1:04:25\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 34% (1032 of 3001) |######              | Elapsed Time: 0:33:28 ETA:   1:03:52\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 34% (1049 of 3001) |######              | Elapsed Time: 0:34:00 ETA:   1:03:16\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 35% (1065 of 3001) |#######             | Elapsed Time: 0:34:31 ETA:   1:02:45\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 36% (1081 of 3001) |#######             | Elapsed Time: 0:35:01 ETA:   1:02:12\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 36% (1097 of 3001) |#######             | Elapsed Time: 0:35:32 ETA:   1:01:41\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 37% (1113 of 3001) |#######             | Elapsed Time: 0:36:03 ETA:   1:01:10\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 37% (1129 of 3001) |#######             | Elapsed Time: 0:36:35 ETA:   1:00:39\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 38% (1145 of 3001) |#######             | Elapsed Time: 0:37:06 ETA:   1:00:08\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 38% (1161 of 3001) |#######             | Elapsed Time: 0:37:37 ETA:   0:59:37\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 39% (1176 of 3001) |#######             | Elapsed Time: 0:38:07 ETA:   0:59:10\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 39% (1192 of 3001) |#######             | Elapsed Time: 0:38:38 ETA:   0:58:37\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 40% (1208 of 3001) |########            | Elapsed Time: 0:39:09 ETA:   0:58:07\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 40% (1224 of 3001) |########            | Elapsed Time: 0:39:40 ETA:   0:57:35\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 41% (1240 of 3001) |########            | Elapsed Time: 0:40:10 ETA:   0:57:03\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 41% (1256 of 3001) |########            | Elapsed Time: 0:40:43 ETA:   0:56:34\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 42% (1271 of 3001) |########            | Elapsed Time: 0:41:13 ETA:   0:56:06\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 42% (1287 of 3001) |########            | Elapsed Time: 0:41:44 ETA:   0:55:35\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 43% (1303 of 3001) |########            | Elapsed Time: 0:42:16 ETA:   0:55:05\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 43% (1318 of 3001) |########            | Elapsed Time: 0:42:46 ETA:   0:54:37\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 44% (1334 of 3001) |########            | Elapsed Time: 0:43:18 ETA:   0:54:06\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 44% (1349 of 3001) |########            | Elapsed Time: 0:43:48 ETA:   0:53:38\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 45% (1364 of 3001) |#########           | Elapsed Time: 0:44:19 ETA:   0:53:11\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 45% (1379 of 3001) |#########           | Elapsed Time: 0:44:50 ETA:   0:52:44\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 46% (1393 of 3001) |#########           | Elapsed Time: 0:45:20 ETA:   0:52:20\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 46% (1408 of 3001) |#########           | Elapsed Time: 0:45:51 ETA:   0:51:53\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 47% (1423 of 3001) |#########           | Elapsed Time: 0:46:22 ETA:   0:51:25\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 47% (1438 of 3001) |#########           | Elapsed Time: 0:46:53 ETA:   0:50:57\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 48% (1454 of 3001) |#########           | Elapsed Time: 0:47:24 ETA:   0:50:26\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 48% (1470 of 3001) |#########           | Elapsed Time: 0:47:56 ETA:   0:49:55\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 49% (1486 of 3001) |#########           | Elapsed Time: 0:48:27 ETA:   0:49:23\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 50% (1502 of 3001) |##########          | Elapsed Time: 0:48:57 ETA:   0:48:51\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 50% (1518 of 3001) |##########          | Elapsed Time: 0:49:28 ETA:   0:48:20\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 51% (1534 of 3001) |##########          | Elapsed Time: 0:49:59 ETA:   0:47:48\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 51% (1549 of 3001) |##########          | Elapsed Time: 0:50:30 ETA:   0:47:20\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 52% (1565 of 3001) |##########          | Elapsed Time: 0:51:00 ETA:   0:46:48\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 52% (1581 of 3001) |##########          | Elapsed Time: 0:51:31 ETA:   0:46:16\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 53% (1596 of 3001) |##########          | Elapsed Time: 0:52:02 ETA:   0:45:48\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 53% (1611 of 3001) |##########          | Elapsed Time: 0:52:32 ETA:   0:45:20\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 54% (1626 of 3001) |##########          | Elapsed Time: 0:53:04 ETA:   0:44:53\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 54% (1641 of 3001) |##########          | Elapsed Time: 0:53:35 ETA:   0:44:25\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 55% (1656 of 3001) |###########         | Elapsed Time: 0:54:07 ETA:   0:43:57\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 55% (1671 of 3001) |###########         | Elapsed Time: 0:54:38 ETA:   0:43:29\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 56% (1686 of 3001) |###########         | Elapsed Time: 0:55:09 ETA:   0:43:01\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 56% (1701 of 3001) |###########         | Elapsed Time: 0:55:39 ETA:   0:42:32\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 57% (1716 of 3001) |###########         | Elapsed Time: 0:56:11 ETA:   0:42:04\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 57% (1731 of 3001) |###########         | Elapsed Time: 0:56:42 ETA:   0:41:36\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 58% (1747 of 3001) |###########         | Elapsed Time: 0:57:14 ETA:   0:41:05\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 58% (1763 of 3001) |###########         | Elapsed Time: 0:57:45 ETA:   0:40:33\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 59% (1779 of 3001) |###########         | Elapsed Time: 0:58:17 ETA:   0:40:02\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 59% (1795 of 3001) |###########         | Elapsed Time: 0:58:48 ETA:   0:39:30\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 60% (1810 of 3001) |############        | Elapsed Time: 0:59:19 ETA:   0:39:01\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 60% (1825 of 3001) |############        | Elapsed Time: 0:59:50 ETA:   0:38:33\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 61% (1839 of 3001) |############        | Elapsed Time: 1:00:20 ETA:   0:38:07\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 61% (1854 of 3001) |############        | Elapsed Time: 1:00:50 ETA:   0:37:38\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 62% (1869 of 3001) |############        | Elapsed Time: 1:01:22 ETA:   0:37:10\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 62% (1883 of 3001) |############        | Elapsed Time: 1:01:52 ETA:   0:36:44\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 63% (1899 of 3001) |############        | Elapsed Time: 1:02:24 ETA:   0:36:12\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 63% (1914 of 3001) |############        | Elapsed Time: 1:02:55 ETA:   0:35:44\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 64% (1929 of 3001) |############        | Elapsed Time: 1:03:26 ETA:   0:35:15\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 64% (1944 of 3001) |############        | Elapsed Time: 1:03:57 ETA:   0:34:46\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 65% (1959 of 3001) |#############       | Elapsed Time: 1:04:28 ETA:   0:34:17\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 65% (1974 of 3001) |#############       | Elapsed Time: 1:04:59 ETA:   0:33:48\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 66% (1989 of 3001) |#############       | Elapsed Time: 1:05:30 ETA:   0:33:20\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 66% (2005 of 3001) |#############       | Elapsed Time: 1:06:02 ETA:   0:32:48\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 67% (2021 of 3001) |#############       | Elapsed Time: 1:06:34 ETA:   0:32:16\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 67% (2036 of 3001) |#############       | Elapsed Time: 1:07:05 ETA:   0:31:48\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 68% (2051 of 3001) |#############       | Elapsed Time: 1:07:35 ETA:   0:31:18\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 68% (2066 of 3001) |#############       | Elapsed Time: 1:08:06 ETA:   0:30:49\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 69% (2082 of 3001) |#############       | Elapsed Time: 1:08:37 ETA:   0:30:17\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 69% (2098 of 3001) |#############       | Elapsed Time: 1:09:09 ETA:   0:29:45\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 70% (2113 of 3001) |##############      | Elapsed Time: 1:09:40 ETA:   0:29:16\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 70% (2128 of 3001) |##############      | Elapsed Time: 1:10:11 ETA:   0:28:47\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 71% (2143 of 3001) |##############      | Elapsed Time: 1:10:41 ETA:   0:28:18\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 71% (2158 of 3001) |##############      | Elapsed Time: 1:11:13 ETA:   0:27:49\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 72% (2173 of 3001) |##############      | Elapsed Time: 1:11:44 ETA:   0:27:20\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 72% (2187 of 3001) |##############      | Elapsed Time: 1:12:15 ETA:   0:26:53\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 73% (2200 of 3001) |##############      | Elapsed Time: 1:12:46 ETA:   0:26:29\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 73% (2215 of 3001) |##############      | Elapsed Time: 1:13:17 ETA:   0:26:00\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 74% (2229 of 3001) |##############      | Elapsed Time: 1:13:47 ETA:   0:25:33\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 74% (2244 of 3001) |##############      | Elapsed Time: 1:14:18 ETA:   0:25:04\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 75% (2259 of 3001) |###############     | Elapsed Time: 1:14:49 ETA:   0:24:34\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 75% (2274 of 3001) |###############     | Elapsed Time: 1:15:20 ETA:   0:24:05\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 76% (2289 of 3001) |###############     | Elapsed Time: 1:15:51 ETA:   0:23:35\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 76% (2303 of 3001) |###############     | Elapsed Time: 1:16:21 ETA:   0:23:08\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 77% (2318 of 3001) |###############     | Elapsed Time: 1:16:53 ETA:   0:22:39\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 77% (2333 of 3001) |###############     | Elapsed Time: 1:17:24 ETA:   0:22:09\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 78% (2348 of 3001) |###############     | Elapsed Time: 1:17:55 ETA:   0:21:40\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 78% (2364 of 3001) |###############     | Elapsed Time: 1:18:27 ETA:   0:21:08\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 79% (2380 of 3001) |###############     | Elapsed Time: 1:18:58 ETA:   0:20:36\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 79% (2395 of 3001) |###############     | Elapsed Time: 1:19:29 ETA:   0:20:06\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 80% (2410 of 3001) |################    | Elapsed Time: 1:20:00 ETA:   0:19:37\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 80% (2425 of 3001) |################    | Elapsed Time: 1:20:31 ETA:   0:19:07\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 81% (2441 of 3001) |################    | Elapsed Time: 1:21:03 ETA:   0:18:35\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 81% (2456 of 3001) |################    | Elapsed Time: 1:21:34 ETA:   0:18:06\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 82% (2471 of 3001) |################    | Elapsed Time: 1:22:05 ETA:   0:17:36\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 82% (2485 of 3001) |################    | Elapsed Time: 1:22:35 ETA:   0:17:08\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 83% (2500 of 3001) |################    | Elapsed Time: 1:23:06 ETA:   0:16:39\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 83% (2515 of 3001) |################    | Elapsed Time: 1:23:36 ETA:   0:16:09\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 84% (2530 of 3001) |################    | Elapsed Time: 1:24:08 ETA:   0:15:39\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 84% (2545 of 3001) |################    | Elapsed Time: 1:24:39 ETA:   0:15:10\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 85% (2560 of 3001) |#################   | Elapsed Time: 1:25:09 ETA:   0:14:40\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 85% (2575 of 3001) |#################   | Elapsed Time: 1:25:41 ETA:   0:14:10\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 86% (2590 of 3001) |#################   | Elapsed Time: 1:26:12 ETA:   0:13:40\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 86% (2605 of 3001) |#################   | Elapsed Time: 1:26:42 ETA:   0:13:10\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 87% (2621 of 3001) |#################   | Elapsed Time: 1:27:14 ETA:   0:12:38\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 87% (2636 of 3001) |#################   | Elapsed Time: 1:27:46 ETA:   0:12:09\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 88% (2651 of 3001) |#################   | Elapsed Time: 1:28:16 ETA:   0:11:39\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 88% (2667 of 3001) |#################   | Elapsed Time: 1:28:47 ETA:   0:11:07\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 89% (2682 of 3001) |#################   | Elapsed Time: 1:29:18 ETA:   0:10:37\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 89% (2698 of 3001) |#################   | Elapsed Time: 1:29:50 ETA:   0:10:05\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 90% (2712 of 3001) |##################  | Elapsed Time: 1:30:20 ETA:   0:09:37\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 90% (2728 of 3001) |##################  | Elapsed Time: 1:30:52 ETA:   0:09:05\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 91% (2743 of 3001) |##################  | Elapsed Time: 1:31:22 ETA:   0:08:35\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 91% (2758 of 3001) |##################  | Elapsed Time: 1:31:53 ETA:   0:08:05\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 92% (2773 of 3001) |##################  | Elapsed Time: 1:32:24 ETA:   0:07:35\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 92% (2789 of 3001) |##################  | Elapsed Time: 1:32:56 ETA:   0:07:03\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 93% (2805 of 3001) |##################  | Elapsed Time: 1:33:27 ETA:   0:06:31\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 93% (2820 of 3001) |##################  | Elapsed Time: 1:33:58 ETA:   0:06:01\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 94% (2836 of 3001) |##################  | Elapsed Time: 1:34:30 ETA:   0:05:29\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 95% (2852 of 3001) |################### | Elapsed Time: 1:35:02 ETA:   0:04:57\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 95% (2866 of 3001) |################### | Elapsed Time: 1:35:32 ETA:   0:04:30\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 96% (2882 of 3001) |################### | Elapsed Time: 1:36:04 ETA:   0:03:58\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 96% (2898 of 3001) |################### | Elapsed Time: 1:36:36 ETA:   0:03:26\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 97% (2913 of 3001) |################### | Elapsed Time: 1:37:06 ETA:   0:02:56\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 97% (2929 of 3001) |################### | Elapsed Time: 1:37:38 ETA:   0:02:24\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 98% (2944 of 3001) |################### | Elapsed Time: 1:38:09 ETA:   0:01:54\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 98% (2959 of 3001) |################### | Elapsed Time: 1:38:39 ETA:   0:01:24\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 99% (2974 of 3001) |################### | Elapsed Time: 1:39:10 ETA:   0:00:54\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m 99% (2990 of 3001) |################### | Elapsed Time: 1:39:42 ETA:   0:00:22\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.inferencing.batching:Prediction batch size is reduced to 1400 to fit max payload size limit.\u001b[0m\n",
      "\u001b[34m100% (3001 of 3001) |####################| Elapsed Time: 1:40:02 Time:  1:40:02\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap.shap_analyzer:getting explanations took 6006.03 seconds.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap.shap_analyzer:===================================================\u001b[0m\n",
      "\u001b[34mWARNING:analyzer.shap.shap_util:Falling back to generic labels: label0, label1, ...\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap.shap_analyzer:converting explanations to tabular took 2.38 seconds.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap.shap_analyzer:===================================================\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap.shap_analyzer:Wrote baseline used to compute explanations to: /opt/ml/processing/output/explanations_shap/baseline.csv\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap.shap_analyzer:Wrote 3001 local explanations to: /opt/ml/processing/output/explanations_shap/out.csv\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap.shap_analyzer:writing local explanations took 2.34 seconds.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap.shap_analyzer:===================================================\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap.shap_analyzer:aggregating local explanations took 0.01 seconds.\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap.shap_analyzer:===================================================\u001b[0m\n",
      "\u001b[34mINFO:analyzer.shap.shap_analyzer:Shap analysis finished.\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:Calculated global analysis with predictor\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor.predictor:Stop using endpoint: sm-clarify-Clarify-United-States-01-03-2025-23--1740870354-3f7f\u001b[0m\n",
      "\u001b[34mINFO:sagemaker:Deleting endpoint configuration with name: sm-clarify-config-1740870354-4f2d\u001b[0m\n",
      "\u001b[34mINFO:sagemaker:Deleting endpoint with name: sm-clarify-Clarify-United-States-01-03-2025-23--1740870354-3f7f\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor.managed_endpoint:Model endpoint delivered 0.49956 requests per second and a total of 3003 requests over 6011 seconds\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:Calculated global analysis without predictor\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-clarify-processing:Collected analyses: \u001b[0m\n",
      "\u001b[34m{'version': '1.0', 'explanations': {'kernel_shap': defaultdict(<function <lambda> at 0x7f9da2df0ee0>, {'label0': defaultdict(<function <lambda> at 0x7f9da2df0ee0>, {'global_shap_values': defaultdict(<function <lambda> at 0x7f9da2df0ee0>, {'SISCO': 0.011437137775300841, 'ST250Q01JA': 0.011201897426488418, 'ST250Q02JA': 0.013674628763402325, 'ST250Q03JA': 0.013469932039401914, 'ST250Q04JA': 0.01236365792514987, 'ST250Q05JA': 0.011364752707483763, 'ST251Q01JA': 0.0132970787576393, 'ST251Q02JA': 0.01227690859562957, 'ST251Q03JA': 0.013154040639538572, 'ST251Q04JA': 0.03047757749072003, 'ST251Q06JA': 0.027249888102754943, 'ST253Q01JA': 0.02765133801010935, 'ST254Q01JA': 0.011557198380576778, 'ST254Q02JA': 0.018055632458153476, 'ST254Q03JA': 0.015846474061364503, 'ST254Q04JA': 0.016496820308706386, 'ST254Q05JA': 0.011202513919363959, 'ST254Q06JA': 0.012871520451792857, 'ST255Q01JA': 0.03758832161448804, 'ST038Q03NA': 0.0117994772327654, 'ST038Q04NA': 0.015287205241340356, 'ST038Q05NA': 0.011431897198546728, 'ST038Q06NA': 0.012078559785149347, 'ST038Q07NA': 0.01121074030692201, 'ST038Q08NA': 0.011630878855101912, 'ST038Q09JA': 0.014222279822393753, 'ST038Q10JA': 0.012844286976749745, 'ST038Q11JA': 0.011903597076416179, 'ST265Q01JA': 0.012531885171840526, 'ST265Q02JA': 0.012360591853248542, 'ST265Q03JA': 0.013448163281008322, 'ST265Q04JA': 0.01209352344991079, 'ST266Q01JA': 0.011182293157467552, 'ST266Q02JA': 0.011549563268840582, 'ST266Q03JA': 0.011295788327031948, 'ST266Q04JA': 0.011293648222007688, 'ST266Q05JA': 0.011894792868284897, 'ST263Q02JA': 0.03448880138762252, 'ST263Q04JA': 0.0177540188951239, 'ST263Q06JA': 0.011558703061420813, 'ST270Q01JA': 0.01253964542119768, 'ST270Q02JA': 0.01589054815624121, 'ST270Q03JA': 0.012652457064421802, 'ST270Q04JA': 0.012209870975335465, 'FL166Q01HA': 0.015993623549235676, 'FL166Q02HA': 0.010940267804632217, 'FL166Q03HA': 0.017319741301702052, 'FL166Q05HA': 0.013585493600747255, 'FL166Q06HA': 0.01580725727351805, 'FL166Q07HA': 0.012090191880584557, 'FL174Q01JA': 0.019713682331499716, 'FL174Q02JA': 0.012947268327048985, 'FL174Q03JA': 0.01706816603148638, 'FL174Q04JA': 0.014696781252436208, 'FL174Q05JA': 0.01298898099095525, 'FL174Q06JA': 0.010826262794069024, 'FL174Q07JA': 0.016244453496609128, 'FL167Q01HA': 0.011423591182750305, 'FL167Q02HA': 0.013963391921919302, 'FL167Q06JA': 0.01288503327931199, 'FL167Q03HA': 0.014524803034996904, 'FL167Q04HA': 0.01157719014007891, 'FL167Q05HA': 0.011948371427643038, 'FL167Q07JA': 0.01142713019419957, 'FL170Q01JA': 0.014607194589691728, 'FL170Q02JA': 0.012199034451462318, 'FL170Q03JA': 0.017884053442526724, 'FL170Q04JA': 0.01159516657731866, 'FL170Q05JA': 0.012026802912219092, 'FL170Q06JA': 0.012415706718680659, 'FL170Q07JA': 0.01428943003112354, 'FL162Q01HA': 0.011376491449214694, 'FL162Q02HA': 0.011181768451967675, 'FL162Q03HA': 0.011228779181496815, 'FL162Q04HA': 0.01373591725688862, 'FL162Q05HA': 0.012366059229929357, 'FL162Q06HA': 0.013825541940840845, 'FL163Q01HA': 0.013414087139044387, 'FL163Q02HA': 0.013279273396473501, 'FL163Q03HA': 0.013035525682803669, 'FL163Q04HA': 0.011878657420380872, 'FL163Q05HA': 0.011655124694873134, 'FL171Q01JA': 0.021418421724495224, 'FL171Q02JA': 0.014450423053699887, 'FL171Q03JA': 0.01145549552306387, 'FL171Q04JA': 0.013094690671829423, 'FL171Q05JA': 0.011212951605295868, 'FL171Q07JA': 0.019071224928515422, 'FL171Q08JA': 0.012775033126145766, 'FL171Q09JA': 0.011511510677521335, 'FL171Q10JA': 0.011971556087432089, 'FL171Q11JA': 0.01190317109960723, 'FL171Q12JA': 0.012909324783550898, 'FL169Q01HA': 0.017037964132514436, 'FL169Q05JA': 0.012643890905917587, 'FL169Q02HA': 0.014021470212506852, 'FL169Q04HA': 0.013413263513960789, 'FL169Q08JA': 0.012987280831424789, 'FL169Q10JA': 0.0121565342599851, 'FL169Q11JA': 0.013988119033970068, 'FL172Q01JA': 0.0155322660676567, 'FL172Q03JA': 0.011723946082180539, 'FL172Q05JA': 0.01614617794319733, 'FL172Q06JA': 0.018272580217202777, 'IC170Q01JA': 0.012395116331431278, 'IC170Q02JA': 0.013703230372715028, 'IC170Q03JA': 0.011761064946393547, 'IC170Q04JA': 0.015537287432807583, 'IC170Q05JA': 0.01422334547213387, 'IC170Q06JA': 0.011297082316477244, 'IC170Q07JA': 0.014408953541397942, 'IC171Q01JA': 0.010892072128074992, 'IC171Q02JA': 0.01474036596087167, 'IC171Q03JA': 0.011566218606409216, 'IC171Q04JA': 0.011615691219510366, 'IC171Q05JA': 0.01462936276902114, 'IC171Q06JA': 0.011222447778822621, 'IC172Q01JA': 0.01301840714750395, 'IC172Q02JA': 0.011306569348141525, 'IC172Q03JA': 0.020150807307972435, 'IC172Q04JA': 0.01376747791609556, 'IC172Q05JA': 0.016530871288137388, 'IC172Q06JA': 0.015116508094461287, 'IC172Q07JA': 0.012413577878091355, 'IC172Q08JA': 0.011952502030730039, 'IC172Q09JA': 0.011203208458804683, 'IC173Q01JA': 0.019998114087379906, 'IC173Q02JA': 0.011396820045531634, 'IC173Q03JA': 0.011855853740754206, 'IC173Q04JA': 0.02583931447618854, 'IC174Q01JA': 0.011119564874138092, 'IC174Q02JA': 0.022372335894667028, 'IC174Q03JA': 0.016094210703327165, 'IC174Q04JA': 0.010797767823578514, 'IC174Q05JA': 0.015006124537459366, 'IC174Q06JA': 0.011263010817770654, 'IC174Q07JA': 0.016756739825297913, 'IC174Q08JA': 0.011552420783891617, 'IC174Q09JA': 0.011243139497442685, 'IC174Q10JA': 0.01212099490679929, 'IC175Q01JA': 0.011136599217201722, 'IC175Q02JA': 0.011716809445647977, 'IC175Q03JA': 0.013625922431183617, 'IC175Q05JA': 0.011291480989717911, 'IC176Q01JA': 0.01126598869613648, 'IC176Q02JA': 0.015006687934568077, 'IC176Q03JA': 0.013466984392729918, 'IC176Q04JA': 0.011799956550795227, 'IC176Q05JA': 0.012818143302847817, 'IC176Q06JA': 0.015697360692953022, 'IC176Q07JA': 0.011566220224856478, 'IC176Q08JA': 0.0131910630509753, 'IC177Q01JA': 0.011589840808470515, 'IC177Q02JA': 0.012958243657193459, 'IC177Q03JA': 0.012800331006952066, 'IC177Q04JA': 0.013446372874297117, 'IC177Q05JA': 0.016866071241621126, 'IC177Q06JA': 0.01155208213800154, 'IC177Q07JA': 0.01683674661172968, 'IC178Q01JA': 0.016901631407414984, 'IC178Q02JA': 0.014724234323683574, 'IC178Q03JA': 0.011472903665732299, 'IC178Q04JA': 0.01118115103773024, 'IC178Q05JA': 0.012463870452016882, 'IC178Q06JA': 0.01272199451429939, 'IC178Q07JA': 0.020279359953466566, 'IC179Q01JA': 0.011263541005588492, 'IC179Q02JA': 0.011014095328725193, 'IC179Q03JA': 0.014358528047603243, 'IC179Q04JA': 0.011139222894604317, 'IC179Q05JA': 0.010764516665963831, 'IC179Q06JA': 0.01183165996438953, 'IC180Q02JA': 0.012842704780763598, 'IC180Q03JA': 0.015043202685924155, 'IC180Q04JA': 0.012320248420528142, 'IC180Q05JA': 0.011761733428273849, 'IC180Q06JA': 0.012612159820961, 'IC180Q07JA': 0.011109676222612604, 'IC183Q01JA': 0.013764660778741111, 'IC183Q02JA': 0.012953745306414344, 'IC183Q03JA': 0.015119112432443833, 'IC183Q04JA': 0.01570859444503782, 'IC183Q05JA': 0.013538060831118776, 'IC183Q07JA': 0.014654095775137174, 'IC183Q08JA': 0.011638693150453008, 'IC183Q09JA': 0.011061367131488115, 'IC183Q10JA': 0.0115170161517283, 'IC183Q12JA': 0.011288265076421656, 'IC183Q13JA': 0.012408327218786007, 'IC183Q14JA': 0.01455885297699868, 'IC183Q15JA': 0.017080405473245318, 'IC183Q16JA': 0.012295170788260342, 'ST347Q01JA': 0.01399732346331431, 'ST347Q02JA': 0.014879123396265554, 'ST259Q01JA': 0.03158319515973238, 'ST004D01T': 0.03818348956862771, 'GRADE': 0.01886022986566671, 'REPEAT': 0.019201408859394326, 'EXPECEDU': 0.011529357694776865, 'ICTAVSCH': 0.014661044681879216, 'ICTAVHOM': 0.011013951735340949, 'IMMIG': 0.01118954662058823, 'TARDYSD': 0.02007419127485854, 'ST226Q01JA': 0.011777180192425291, 'MISSSC': 0.01537446177997253, 'PAREDINT': 0.018818604125447204, 'ST230Q01JA': 0.022512659412715557, 'SKIPPING': 0.013894357523085602, 'IC180Q01JA': 0.016946444977675498, 'IC180Q08JA': 0.020330992104167164, 'ST059Q02JA': 0.027206285371743213, 'ST296Q04JA': 0.017304705711408245, 'STUDYHMW': 0.013630283815417713, 'IC184Q01JA': 0.011732064876084879, 'IC184Q02JA': 0.011851213034279407, 'ST059Q01TA': 0.011404475917264675, 'ST296Q01JA': 0.011358892808208877, 'ST268Q01JA': 0.03172896937545478, 'ST268Q04JA': 0.03975176902142114, 'ST268Q07JA': 0.013737618646372855, 'ST297Q01JA': 0.019467891385038873, 'ST297Q03JA': 0.011134382011648375, 'ST297Q05JA': 0.014402269827970897, 'ST297Q06JA': 0.01101731231344657, 'ST297Q07JA': 0.012226507467670133, 'ST297Q09JA': 0.011167384948250854, 'ST258Q01JA': 0.015848504276516007, 'ST294Q01JA': 0.011868867919894397, 'ST295Q01JA': 0.016457978158460757, 'EXERPRAC': 0.024706933671973484, 'WORKPAY': 0.014206422714194707, 'WORKHOME': 0.01106880490062497, 'SC001Q01TA': 0.02615306429056919, 'SC211Q01JA': 0.017135002646550372, 'SC211Q02JA': 0.011236811072540527, 'SC211Q03JA': 0.020871493510578223, 'SC211Q04JA': 0.01253543603526985, 'SC211Q05JA': 0.015102992864284476, 'SC211Q06JA': 0.011149181156401683, 'SC037Q11JA': 0.015294427595261315, 'SC183Q02JA': 0.011785450497953497, 'SC183Q03JA': 0.011514237928993563, 'SC183Q04JA': 0.012174081369786633, 'SC175Q01JA': 0.012568328965754907, 'SC188Q01JA': 0.011826001894365962, 'SC188Q02JA': 0.011400439542908359, 'SC188Q03JA': 0.014382928830350738, 'SC188Q04JA': 0.014490025438919326, 'SC188Q05JA': 0.011571819050922534, 'SC188Q06JA': 0.016313051238763813, 'SC188Q07JA': 0.020096116681331763, 'SC188Q08JA': 0.013262365965965639, 'SC188Q09JA': 0.01097761268964955, 'SC188Q10JA': 0.017831006263446435, 'SC188Q11JA': 0.016011003339150967, 'SC198Q01JA': 0.01711075002311535, 'SC198Q02JA': 0.011526479937680948, 'SC198Q03JA': 0.012207150390537132, 'SC178Q01JA': 0.01211093334290584, 'SC178Q02JA': 0.013418595066436728, 'SC180Q01JA': 0.017215065610225445, 'SC189Q02WA': 0.013873393337954721, 'SC189Q03WA': 0.015843865182520612, 'SC189Q04WA': 0.011803806699765638, 'MCLSIZE': 0.011693562905010793, 'MACTIV': 0.011169448441898601, 'ABGMATH': 0.01199299570881882, 'SC064Q05WA': 0.011358765735525378, 'SC064Q06WA': 0.011213334340172403, 'SC064Q01TA': 0.014687696068034646, 'SC064Q02TA': 0.011372810611311908, 'SC064Q04NA': 0.010994241460764801, 'SC064Q03TA': 0.013054338241748618, 'SC064Q07WA': 0.011256478327910135, 'SC213Q01JA': 0.012018428510994498, 'SC213Q02JA': 0.011052229740093511, 'SC037Q01TA': 0.012682850475991617, 'SC037Q02TA': 0.011447090499551412, 'SC037Q03TA': 0.011282701097400583, 'SC037Q04TA': 0.012656481961907703, 'SC037Q05NA': 0.01145813008998935, 'SC037Q06NA': 0.011050898626823324, 'SC037Q07TA': 0.017044063542359395, 'SC037Q09TA': 0.01286199747360672, 'SC224Q01JA': 0.013610414049855055, 'RATCMP1': 0.01099588555866717, 'RATCMP2': 0.01122921367506473, 'SCHSEL': 0.014534944354318144, 'SC034Q01NA': 0.011431595034090816, 'SC034Q02NA': 0.013343728344922232, 'SC034Q03TA': 0.01687907929711475, 'SC034Q04TA': 0.014978595683075378, 'SC195Q01JA': 0.012168621856888913, 'SC195Q02JA': 0.011613291645064411, 'SC195Q03JA': 0.013906392328192728, 'SC195Q04JA': 0.011804148669022359, 'SC042Q01TA': 0.011608070567884453, 'SC042Q02TA': 0.01429408853841189, 'SC212Q01JA': 0.012266852125065597, 'SC212Q02JA': 0.013264572996676027, 'SC212Q03JA': 0.013638120979984921, 'SC037Q08TA': 0.011648171459254663, 'SC032Q01TA': 0.0115818172698906, 'SC032Q02TA': 0.012647550510312418, 'SC032Q03TA': 0.011106107890825953, 'SC032Q04TA': 0.03170365453518202, 'ST349Q01JA_1': 0.021083291483362958, 'ST349Q01JA_2': 0.012262987679621081, 'ST349Q01JA_3': 0.011221447898776445, 'ST349Q01JA_4': 0.01771292558961575, 'ST349Q01JA_0': 0.01232013294868456, 'LANGN_105': 0.011151298431550886, 'LANGN_108': 0.011318853417663196, 'LANGN_118': 0.01124254871759561, 'LANGN_140': 0.011724266350612082, 'LANGN_148': 0.010844124919578785, 'LANGN_150': 0.011321186073877887, 'LANGN_156': 0.01730684299032645, 'LANGN_200': 0.011247762442509692, 'LANGN_204': 0.011206969781659347, 'LANGN_232': 0.011555113221348525, 'LANGN_273': 0.010961442135085311, 'LANGN_313': 0.01854533876172405, 'LANGN_316': 0.011448185582859899, 'LANGN_322': 0.011060084295645147, 'LANGN_329': 0.011221540514079453, 'LANGN_344': 0.011154541581156368, 'LANGN_351': 0.01113792723436271, 'LANGN_415': 0.011334551863527572, 'LANGN_463': 0.01080928984242244, 'LANGN_493': 0.011187680647110884, 'LANGN_496': 0.01119892177577, 'LANGN_500': 0.01137053752017807, 'LANGN_520': 0.011444572023545553, 'LANGN_531': 0.010959953895174618, 'LANGN_602': 0.011156462964023731, 'LANGN_606': 0.01084656161665952, 'LANGN_615': 0.01150824434380521, 'LANGN_621': 0.011225484178178374, 'LANGN_625': 0.011292931063216967, 'LANGN_640': 0.011240833596657656, 'LANGN_641': 0.010890848519290692, 'LANGN_663': 0.011280620463060321, 'LANGN_669': 0.011148174630611983, 'LANGN_670': 0.011444575581244761, 'LANGN_800': 0.011100311746550075, 'LANGN_801': 0.011179283373136699, 'LANGN_802': 0.011062283063905994, 'LANGN_804': 0.01125248077412201, 'LANGN_805': 0.0112281645524997, 'LANGN_806': 0.010880161820488225, 'LANGN_807': 0.011302698392461114, 'LANGN_808': 0.01113418052768244, 'LANGN_865': 0.011386361755480636, 'LANGN_892': 0.011375986341732201, 'LANGN_895': 0.011268994896156036, 'LANGN_917': 0.011321394741992466, 'SC177Q01JA_1': 0.011116146147834126, 'SC177Q01JA_2': 0.014503484185130327, 'SC177Q01JA_3': 0.011893555148070717, 'SC177Q02JA_1': 0.011761856747877287, 'SC177Q02JA_2': 0.014862425319040947, 'SC177Q02JA_3': 0.015316162843252162, 'SC177Q03JA_1': 0.012051890052558894, 'SC177Q03JA_2': 0.011263832805189748, 'SC177Q03JA_3': 0.011706370315653638, 'MATHEXC_0': 0.011136610684597915, 'MATHEXC_1': 0.011019212521068609, 'MATHEXC_2': 0.013129382341012125, 'MATHEXC_3': 0.016501342174715907, 'SCHLTYPE_1': 0.011386298903295216, 'SCHLTYPE_2': 0.012178584138740053, 'SCHLTYPE_3': 0.011411510281309285, 'LANGN_121': 0.011230410618834976, 'LANGN_130': 0.011088475125685752, 'LANGN_137': 0.011219074271088173, 'LANGN_170': 0.010924440150469226, 'LANGN_244': 0.010893698457828598, 'LANGN_258': 0.011258655317001803, 'LANGN_263': 0.011235496161067704, 'LANGN_264': 0.011181245356592396, 'LANGN_266': 0.011361999713133359, 'LANGN_317': 0.01134340758252716, 'LANGN_340': 0.011164925645509761, 'LANGN_369': 0.01128390391093725, 'LANGN_381': 0.011370837213464236, 'LANGN_404': 0.01123693094908223, 'LANGN_420': 0.011313290392956567, 'LANGN_449': 0.011255057031548162, 'LANGN_467': 0.0113219726344849, 'LANGN_494': 0.011019976813240401, 'LANGN_495': 0.011091836793093347, 'LANGN_514': 0.01103252360067288, 'LANGN_523': 0.011172824588790322, 'LANGN_529': 0.010948129131069587, 'LANGN_540': 0.011257035652071876, 'LANGN_547': 0.01106631340312816, 'LANGN_600': 0.01103638731856212, 'LANGN_607': 0.011190533582299654, 'LANGN_618': 0.011118786044172182, 'LANGN_619': 0.011136276819491564, 'LANGN_630': 0.011070515135500083, 'LANGN_635': 0.01140019520718472, 'LANGN_650': 0.011335391135163344, 'LANGN_661': 0.010937832659201976, 'LANGN_673': 0.011400782314390135, 'LANGN_674': 0.011506322306360483, 'LANGN_809': 0.011220409085344175, 'LANGN_810': 0.011347775188501922, 'LANGN_811': 0.010873820368962141, 'LANGN_812': 0.01090669112998022, 'LANGN_813': 0.011043135553864823, 'LANGN_814': 0.011248231296525775, 'LANGN_815': 0.011347723813635054, 'LANGN_816': 0.011030597970578733, 'LANGN_818': 0.011085335510463298, 'LANGN_832': 0.011228411880868492, 'LANGN_868': 0.011348346457430665, 'LANGN_870': 0.011144165002472348, 'LANGN_920': 0.011001535226895868, 'LANGN_921': 0.011546707872464939, 'LANGN_113': 0.010984698283273841, 'LANGN_147': 0.0111586552032356, 'LANGN_275': 0.011275918717401476, 'LANGN_286': 0.01135326274763064, 'LANGN_363': 0.011332361015617253, 'LANGN_422': 0.01112462236619304, 'LANGN_434': 0.010968994562342535, 'LANGN_442': 0.01096664885059741, 'LANGN_471': 0.011150055063631264, 'LANGN_611': 0.01104586821160219, 'LANGN_614': 0.011266266261645603, 'LANGN_624': 0.010840238131842211, 'LANGN_642': 0.01096145381269679, 'LANGN_675': 0.010679009641893401, 'LANGN_676': 0.011381162078894336, 'LANGN_677': 0.011367372816858984, 'LANGN_678': 0.010878746625148946, 'LANGN_817': 0.011167913777108377, 'LANGN_819': 0.011302009162267665, 'LANGN_821': 0.010919137593500015, 'LANGN_823': 0.011202655953209606, 'LANGN_824': 0.011131560344024247, 'LANGN_825': 0.011047388484530024, 'LANGN_826': 0.0110533571472282, 'LANGN_827': 0.011517381825778591, 'LANGN_828': 0.011032387553744269, 'LANGN_885': 0.010616439232561602, 'LANGN_896': 0.011230396705521587, 'LANGN_916': 0.0109452703350083, 'LANGN_112': 0.011226274127482767, 'LANGN_154': 0.011194088914551254, 'LANGN_202': 0.0111641567550687, 'LANGN_246': 0.01108343342838208, 'LANGN_254': 0.011667965296222231, 'LANGN_272': 0.011592009237357358, 'LANGN_301': 0.0111427\u001b[0m\n",
      "\u001b[34m2535620826, 'LANGN_325': 0.011169946174331175, 'LANGN_338': 0.010777450701989506, 'LANGN_358': 0.011552028057777705, 'LANGN_371': 0.011319641968226265, 'LANGN_375': 0.01126219252607772, 'LANGN_383': 0.011251733335747171, 'LANGN_409': 0.011231763704089346, 'LANGN_428': 0.011303136935079552, 'LANGN_465': 0.010939360102886195, 'LANGN_517': 0.01143582976166873, 'LANGN_527': 0.01099009987633635, 'LANGN_561': 0.011287335829447352, 'LANGN_562': 0.011145401385218256, 'LANGN_563': 0.011056824775043413, 'LANGN_565': 0.011014671531154208, 'LANGN_566': 0.011102680779235895, 'LANGN_567': 0.011349057028427006, 'LANGN_601': 0.011077458636375836, 'LANGN_622': 0.01116734955883498, 'LANGN_623': 0.010984407495804975, 'LANGN_628': 0.011304108511837005, 'LANGN_631': 0.011005048618786295, 'LANGN_831': 0.011051898507366192, 'LANGN_833': 0.011163391954078967, 'LANGN_836': 0.011147277038115041, 'LANGN_837': 0.011386110562412463, 'LANGN_838': 0.011442425464199156, 'LANGN_839': 0.011293682898598447, 'LANGN_840': 0.011157179363069881, 'LANGN_841': 0.011318531017900771, 'LANGN_845': 0.011067960599398945, 'LANGN_872': 0.010955881512690745, 'LANGN_873': 0.011279162779923364, 'LANGN_881': 0.011423814625450487, 'LANGN_890': 0.011231108154171927, 'LANGN_897': 0.011150511210799881, 'LANGN_898': 0.01147038375328, 'LANGN_899': 0.010995888197641655, 'LANGN_900': 0.011331900221506035, 'LANGN_901': 0.011295327369467983, 'LANGN_902': 0.011201459619481689, 'LANGN_903': 0.011411647570145816, 'LANGN_904': 0.01086286060850214, 'LANGN_905': 0.011646353243425568, 'LANGN_906': 0.011066066881744142, 'LANGN_907': 0.011090196318585922, 'LANGN_908': 0.011054266703907899, 'LANGN_909': 0.011154469617722481, 'LANGN_910': 0.011139865800458709, 'LANGN_911': 0.010789194660307429, 'LANGN_912': 0.011097865582735145, 'LANGN_913': 0.011302691506803074, 'LANGN_914': 0.01100208571392201, 'LANGN_918': 0.011179469029795306, 'LANGN_919': 0.010856180286387471, 'LANGN_160': 0.011149133687992809, 'LANGN_327': 0.011127364029509057, 'LANGN_451': 0.011178700081069085, 'LANGN_474': 0.010999441573820665, 'LANGN_503': 0.011085496184478842, 'LANGN_608': 0.01143526249689867, 'LANGN_627': 0.011024528178319757, 'LANGN_639': 0.011116772878579217, 'LANGN_668': 0.011125621951530587, 'LANGN_842': 0.011324015609582554, 'LANGN_843': 0.011445729616092635, 'LANGN_844': 0.011026020685826322, 'LANGN_846': 0.011254626402007072, 'LANGN_849': 0.011306257325422757, 'LANGN_850': 0.011351330477462583, 'LANGN_851': 0.011088902150915646, 'LANGN_852': 0.011051805878619382, 'LANGN_861': 0.011158433809103724, 'LANGN_879': 0.011133954290068214, 'LANGN_133': 0.011239826108905083, 'LANGN_195': 0.010991358847775539, 'LANGN_237': 0.011305165836674921, 'LANGN_379': 0.011416917378068723, 'LANGN_382': 0.011228450498477495, 'LANGN_472': 0.011127722346285063, 'LANGN_492': 0.011043921167738795, 'LANGN_555': 0.011096866878902201, 'LANGN_605': 0.011423689082394141, 'LANGN_616': 0.01133215872190526, 'LANGN_626': 0.010872174840932471, 'LANGN_634': 0.010800060703214409, 'LANGN_648': 0.011128749691676322, 'LANGN_662': 0.011051182109686402, 'LANGN_665': 0.011168150066678015, 'LANGN_666': 0.011081627281878175, 'LANGN_667': 0.011315709993495631, 'LANGN_829': 0.011288718016081811, 'LANGN_854': 0.011209813376872362, 'LANGN_855': 0.011460889752034839, 'LANGN_857': 0.011297800177287102, 'LANGN_859': 0.011314664496063111, 'LANGN_860': 0.011346509835360372, 'LANGN_866': 0.010999320339907147, 'LANGN_877': 0.011257837748209433, 'LANGN_922': 0.010913463410890906}), 'expected_value': 1.0})})}}\u001b[0m\n",
      "\u001b[34mINFO:analyzer.utils.util:['jupyter', 'nbconvert', '--to', 'html', '--output', '/opt/ml/processing/output/report.html', '/opt/ml/processing/output/report.ipynb', '--template', 'sagemaker-xai']\u001b[0m\n",
      "\u001b[34m[NbConvertApp] Converting notebook /opt/ml/processing/output/report.ipynb to html\u001b[0m\n",
      "\u001b[34m[NbConvertApp] Writing 604528 bytes to /opt/ml/processing/output/report.html\u001b[0m\n",
      "\u001b[34mINFO:analyzer.utils.util:['wkhtmltopdf', '-q', '--enable-local-file-access', '/opt/ml/processing/output/report.html', '/opt/ml/processing/output/report.pdf']\u001b[0m\n",
      "\u001b[34mINFO:analyzer.utils.system_util:exit_message: Completed: SageMaker XAI Analyzer ran successfully\u001b[0m\n",
      "\u001b[34mINFO:analyzer.predictor.predictor:Stop using endpoint: None\u001b[0m\n",
      "\u001b[34m---!\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set logging level for 'sagemaker.clarify' to WARNING (hides INFO messages)\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"sagemaker.clarify\").setLevel(logging.WARNING)\n",
    "\n",
    "clarify_processor.run_explainability(\n",
    "    data_config=explainability_data_config,\n",
    "    model_config=model_config,\n",
    "    explainability_config=shap_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model again with the top 20 predictors\n",
    "#### Get the list of top 20 predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.httpchecksum:Skipping checksum validation. Response did not contain one of the following algorithms: ['crc32', 'sha1', 'sha256'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 features with the highest mean absolute SHAP values:\n",
      "ST268Q04JA\n",
      "ST004D01T\n",
      "ST255Q01JA\n",
      "ST263Q02JA\n",
      "ST268Q01JA\n",
      "SC032Q04TA\n",
      "ST259Q01JA\n",
      "ST251Q04JA\n",
      "ST253Q01JA\n",
      "ST251Q06JA\n",
      "ST059Q02JA\n",
      "SC001Q01TA\n",
      "IC173Q04JA\n",
      "EXERPRAC\n",
      "ST230Q01JA\n",
      "IC174Q02JA\n",
      "FL171Q01JA\n",
      "ST349Q01JA_1\n",
      "SC211Q03JA\n",
      "IC180Q08JA\n"
     ]
    }
   ],
   "source": [
    "# Replace with your actual bucket name and prefix used in explainability_output_path\n",
    "# bucket = \"your-bucket-name\"\n",
    "# prefix = \"your-prefix\"  # e.g., the folder structure used in your explainability_output_path\n",
    "\n",
    "# Construct the S3 key for the output file\n",
    "key = f\"{prefix}/clarify-explainability/analysis.json\"\n",
    "\n",
    "# Initialize boto3 client for S3 and download the JSON report\n",
    "s3 = boto3.client(\"s3\")\n",
    "response = s3.get_object(Bucket=bucket, Key=key)\n",
    "content = response[\"Body\"].read().decode(\"utf-8\")\n",
    "report = json.loads(content)\n",
    "\n",
    "# Navigate to the global SHAP values dictionary\n",
    "global_shap = report[\"explanations\"][\"kernel_shap\"][\"label0\"][\"global_shap_values\"]\n",
    "\n",
    "# Sort the items by the SHAP value in descending order and take the top 20\n",
    "top_20 = sorted(global_shap.items(), key=lambda item: item[1], reverse=True)[:20]\n",
    "\n",
    "# Extract just the feature names\n",
    "top_20_features = [feature for feature, value in top_20]\n",
    "\n",
    "# Print\n",
    "print(\"Top 20 features with the highest mean absolute SHAP values:\")\n",
    "for feature in top_20_features:\n",
    "    print(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3186, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MATH_Proficient</th>\n",
       "      <th>ST268Q04JA</th>\n",
       "      <th>ST004D01T</th>\n",
       "      <th>ST255Q01JA</th>\n",
       "      <th>ST263Q02JA</th>\n",
       "      <th>ST268Q01JA</th>\n",
       "      <th>SC032Q04TA</th>\n",
       "      <th>ST259Q01JA</th>\n",
       "      <th>ST251Q04JA</th>\n",
       "      <th>ST253Q01JA</th>\n",
       "      <th>ST251Q06JA</th>\n",
       "      <th>ST059Q02JA</th>\n",
       "      <th>SC001Q01TA</th>\n",
       "      <th>IC173Q04JA</th>\n",
       "      <th>EXERPRAC</th>\n",
       "      <th>ST230Q01JA</th>\n",
       "      <th>IC174Q02JA</th>\n",
       "      <th>FL171Q01JA</th>\n",
       "      <th>ST349Q01JA_1</th>\n",
       "      <th>SC211Q03JA</th>\n",
       "      <th>IC180Q08JA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>575474</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574994</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574164</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576638</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577351</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MATH_Proficient  ST268Q04JA  ST004D01T  ST255Q01JA  ST263Q02JA  \\\n",
       "575474              0.0         2.0        1.0         2.0         4.0   \n",
       "574994              1.0         3.0        1.0         3.0         2.0   \n",
       "574164              0.0         1.0        1.0         3.0         4.0   \n",
       "576638              0.0         2.0        1.0         2.0         2.0   \n",
       "577351              1.0         4.0        1.0         3.0         2.0   \n",
       "\n",
       "        ST268Q01JA  SC032Q04TA  ST259Q01JA  ST251Q04JA  ST253Q01JA  \\\n",
       "575474         1.0         1.0         5.0         2.0         7.0   \n",
       "574994         1.0         1.0         3.0         2.0         7.0   \n",
       "574164         1.0         1.0         6.0         1.0         8.0   \n",
       "576638         2.0         2.0         7.0         4.0         7.0   \n",
       "577351         4.0         1.0         6.0         3.0         8.0   \n",
       "\n",
       "        ST251Q06JA  ST059Q02JA  SC001Q01TA  IC173Q04JA  EXERPRAC  ST230Q01JA  \\\n",
       "575474         1.0         8.0         4.0         1.0       0.0         4.0   \n",
       "574994         4.0         8.0         3.0         6.0       1.0         3.0   \n",
       "574164         2.0         1.0         4.0         4.0       9.0         4.0   \n",
       "576638         1.0        20.0         3.0         2.0       6.0         2.0   \n",
       "577351         1.0        20.0         3.0         6.0       0.0         4.0   \n",
       "\n",
       "        IC174Q02JA  FL171Q01JA  ST349Q01JA_1  SC211Q03JA  IC180Q08JA  \n",
       "575474         4.0         1.0             1        53.0         1.0  \n",
       "574994         4.0         4.0             0        41.0         3.0  \n",
       "574164         2.0         3.0             0        83.0         3.0  \n",
       "576638         4.0         3.0             1         1.0         2.0  \n",
       "577351         5.0         3.0             0        22.0         1.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a subset of the training dataset (with only 20 predictors)\n",
    "variables_to_keep = [\"MATH_Proficient\"] + top_20_features\n",
    "train_data_small = train_data[variables_to_keep]\n",
    "print(train_data_small.shape)\n",
    "train_data_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train dataset \n",
    "train_data_small.to_csv('train_small.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train_small/train_small.csv')).upload_file('train_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(683, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MATH_Proficient</th>\n",
       "      <th>ST268Q04JA</th>\n",
       "      <th>ST004D01T</th>\n",
       "      <th>ST255Q01JA</th>\n",
       "      <th>ST263Q02JA</th>\n",
       "      <th>ST268Q01JA</th>\n",
       "      <th>SC032Q04TA</th>\n",
       "      <th>ST259Q01JA</th>\n",
       "      <th>ST251Q04JA</th>\n",
       "      <th>ST253Q01JA</th>\n",
       "      <th>ST251Q06JA</th>\n",
       "      <th>ST059Q02JA</th>\n",
       "      <th>SC001Q01TA</th>\n",
       "      <th>IC173Q04JA</th>\n",
       "      <th>EXERPRAC</th>\n",
       "      <th>ST230Q01JA</th>\n",
       "      <th>IC174Q02JA</th>\n",
       "      <th>FL171Q01JA</th>\n",
       "      <th>ST349Q01JA_1</th>\n",
       "      <th>SC211Q03JA</th>\n",
       "      <th>IC180Q08JA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>574478</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573678</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576927</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576321</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576339</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MATH_Proficient  ST268Q04JA  ST004D01T  ST255Q01JA  ST263Q02JA  \\\n",
       "574478              1.0         4.0        1.0         4.0         2.0   \n",
       "573678              1.0         3.0        2.0         3.0         2.0   \n",
       "576927              0.0         1.0        1.0         1.0         3.0   \n",
       "576321              1.0         1.0        1.0         2.0         2.0   \n",
       "576339              1.0         4.0        2.0         2.0         3.0   \n",
       "\n",
       "        ST268Q01JA  SC032Q04TA  ST259Q01JA  ST251Q04JA  ST253Q01JA  \\\n",
       "574478         4.0         1.0         7.0         4.0         8.0   \n",
       "573678         2.0         1.0         9.0         3.0         5.0   \n",
       "576927         1.0         1.0         5.0         3.0         5.0   \n",
       "576321         1.0         2.0         8.0         4.0         8.0   \n",
       "576339         4.0         1.0         4.0         2.0         7.0   \n",
       "\n",
       "        ST251Q06JA  ST059Q02JA  SC001Q01TA  IC173Q04JA  EXERPRAC  ST230Q01JA  \\\n",
       "574478         4.0         3.0         4.0         6.0       3.0         4.0   \n",
       "573678         4.0         7.0         3.0         5.0       0.0         3.0   \n",
       "576927         1.0         4.0         4.0         5.0       0.0         4.0   \n",
       "576321         4.0        20.0         2.0         6.0       0.0         3.0   \n",
       "576339         1.0         7.0         2.0         5.0       0.0         4.0   \n",
       "\n",
       "        IC174Q02JA  FL171Q01JA  ST349Q01JA_1  SC211Q03JA  IC180Q08JA  \n",
       "574478         5.0         5.0             0        79.0         3.0  \n",
       "573678         4.0         3.0             0        22.0         2.0  \n",
       "576927         4.0         1.0             0        83.0         2.0  \n",
       "576321         5.0         1.0             1         0.0         2.0  \n",
       "576339         4.0         3.0             0        30.0         2.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a subset of the validation dataset (with only 20 predictors)\n",
    "validation_data_small = validation_data[variables_to_keep]\n",
    "print(validation_data_small.shape)\n",
    "validation_data_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation dataset \n",
    "validation_data_small.to_csv('validation_small.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation_small/validation_small.csv')).upload_file('validation_small.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model using the hyperparameters from the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n"
     ]
    }
   ],
   "source": [
    "# cell 15\n",
    "container = sagemaker.image_uris.retrieve(region=boto3.Session().region_name, framework='xgboost', version='latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 16\n",
    "s3_input_train_small = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/train_small'.format(bucket, prefix), content_type='text/csv')\n",
    "s3_input_validation_small = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/validation_small/'.format(bucket, prefix), content_type='text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: 1.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: linear-learner-2025-03-02-00-51-22-703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-02 00:51:23 Starting - Starting the training job...\n",
      "2025-03-02 00:51:36 Starting - Preparing the instances for training...\n",
      "2025-03-02 00:52:26 Downloading - Downloading the training image.........\n",
      "2025-03-02 00:53:48 Training - Training image download completed. Training in progress...\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:04 INFO 140224006256448] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-input.json: {'mini_batch_size': '1000', 'epochs': '15', 'feature_dim': 'auto', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false'}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:04 INFO 140224006256448] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'epochs': '30', 'l1': '0.004265073434536369', 'learning_rate': '0.0010342773147247286', 'loss': 'logistic', 'mini_batch_size': '34', 'optimizer': 'auto', 'predictor_type': 'binary_classifier', 'use_bias': 'True', 'wd': '0.008154580793546683'}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:04 INFO 140224006256448] Final configuration: {'mini_batch_size': '34', 'epochs': '30', 'feature_dim': 'auto', 'use_bias': 'True', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'logistic', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': '0.008154580793546683', 'l1': '0.004265073434536369', 'momentum': 'auto', 'learning_rate': '0.0010342773147247286', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false', 'predictor_type': 'binary_classifier'}\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/scipy/optimize/_shgo.py:495: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if cons['type'] is 'ineq':\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/scipy/optimize/_shgo.py:743: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if len(self.X_min) is not 0:\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:07 WARNING 140224006256448] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:07 INFO 140224006256448] Final configuration: {'mini_batch_size': '34', 'epochs': '30', 'feature_dim': 'auto', 'use_bias': 'True', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'logistic', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': '0.008154580793546683', 'l1': '0.004265073434536369', 'momentum': 'auto', 'learning_rate': '0.0010342773147247286', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false', 'predictor_type': 'binary_classifier'}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:07 WARNING 140224006256448] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 7 is a worker.\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:07 INFO 140224006256448] Using default worker.\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:07 INFO 140224006256448] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:07 INFO 140224006256448] Create Store: local\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:08 INFO 140224006256448] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7f87e1a1cd00>\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:08 INFO 140224006256448] Scaling model computed with parameters:\n",
      " {'stdev_label': None, 'stdev_weight': \u001b[0m\n",
      "\u001b[34m[ 0.89816797  0.49980626  1.4472948   0.7897955   0.94536257  0.4909158\n",
      "  1.7022765   0.84210527  1.1056064   1.1226774  12.540319    1.1197838\n",
      "  1.2348968   3.4081633   0.92088175  1.0075177   1.3383834   0.47151628\n",
      " 27.205446    0.7920448 ]\u001b[0m\n",
      "\u001b[34m<NDArray 20 @cpu(0)>, 'mean_label': None, 'mean_weight': \u001b[0m\n",
      "\u001b[34m[ 2.5493357  1.5139157  3.5404818  2.1277676  2.2650216  1.4051234\n",
      "  7.142631   3.049336   7.1628723  2.0917141 15.032261   3.2944338\n",
      "  5.0037956  4.633143   3.065466   3.8273244  3.194814   0.3336496\n",
      " 45.40133    1.9892477]\u001b[0m\n",
      "\u001b[34m<NDArray 20 @cpu(0)>}\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:08 INFO 140224006256448] nvidia-smi: took 0.033 seconds to run.\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:08 INFO 140224006256448] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:08 INFO 140224006256448] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876848.5882676, \"EndTime\": 1740876848.5883048, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3220.0, \"count\": 1, \"min\": 3220, \"max\": 3220}, \"Total Batches Seen\": {\"sum\": 95.0, \"count\": 1, \"min\": 95, \"max\": 95}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9246593, \"EndTime\": 1740876850.9247084, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6036148783076345, \"count\": 1, \"min\": 0.6036148783076345, \"max\": 0.6036148783076345}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9247756, \"EndTime\": 1740876850.9247873, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.49574751615675094, \"count\": 1, \"min\": 0.49574751615675094, \"max\": 0.49574751615675094}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.924818, \"EndTime\": 1740876850.9248269, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4955040806837281, \"count\": 1, \"min\": 0.4955040806837281, \"max\": 0.4955040806837281}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.924866, \"EndTime\": 1740876850.9248757, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5009034728038771, \"count\": 1, \"min\": 0.5009034728038771, \"max\": 0.5009034728038771}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.924912, \"EndTime\": 1740876850.9249215, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4752693195873842, \"count\": 1, \"min\": 0.4752693195873842, \"max\": 0.4752693195873842}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9249542, \"EndTime\": 1740876850.9249635, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4753375906947291, \"count\": 1, \"min\": 0.4753375906947291, \"max\": 0.4753375906947291}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9250028, \"EndTime\": 1740876850.9250135, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4734365846596512, \"count\": 1, \"min\": 0.4734365846596512, \"max\": 0.4734365846596512}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9250479, \"EndTime\": 1740876850.9250576, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.47439631097758594, \"count\": 1, \"min\": 0.47439631097758594, \"max\": 0.47439631097758594}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9250898, \"EndTime\": 1740876850.925096, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.49776296778467166, \"count\": 1, \"min\": 0.49776296778467166, \"max\": 0.49776296778467166}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.925126, \"EndTime\": 1740876850.9251342, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5027827718904846, \"count\": 1, \"min\": 0.5027827718904846, \"max\": 0.5027827718904846}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9251668, \"EndTime\": 1740876850.9251752, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5149679959084247, \"count\": 1, \"min\": 0.5149679959084247, \"max\": 0.5149679959084247}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9251952, \"EndTime\": 1740876850.9252005, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5013170513753873, \"count\": 1, \"min\": 0.5013170513753873, \"max\": 0.5013170513753873}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9252253, \"EndTime\": 1740876850.9252331, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4689086579884403, \"count\": 1, \"min\": 0.4689086579884403, \"max\": 0.4689086579884403}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9252667, \"EndTime\": 1740876850.9252758, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4699491979501279, \"count\": 1, \"min\": 0.4699491979501279, \"max\": 0.4699491979501279}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.925311, \"EndTime\": 1740876850.92532, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.46866536803972414, \"count\": 1, \"min\": 0.46866536803972414, \"max\": 0.46866536803972414}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9253628, \"EndTime\": 1740876850.9253736, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.47021374515458647, \"count\": 1, \"min\": 0.47021374515458647, \"max\": 0.47021374515458647}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9254005, \"EndTime\": 1740876850.9254105, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5607955469352245, \"count\": 1, \"min\": 0.5607955469352245, \"max\": 0.5607955469352245}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9254363, \"EndTime\": 1740876850.9254448, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5600265177799734, \"count\": 1, \"min\": 0.5600265177799734, \"max\": 0.5600265177799734}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9254763, \"EndTime\": 1740876850.9254863, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.558134620963283, \"count\": 1, \"min\": 0.558134620963283, \"max\": 0.558134620963283}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9255207, \"EndTime\": 1740876850.925531, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.55916713537256, \"count\": 1, \"min\": 0.55916713537256, \"max\": 0.55916713537256}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9255583, \"EndTime\": 1740876850.9255674, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5661255271279457, \"count\": 1, \"min\": 0.5661255271279457, \"max\": 0.5661255271279457}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9256003, \"EndTime\": 1740876850.925609, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5641986164090604, \"count\": 1, \"min\": 0.5641986164090604, \"max\": 0.5641986164090604}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9256413, \"EndTime\": 1740876850.9256506, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5659534863321786, \"count\": 1, \"min\": 0.5659534863321786, \"max\": 0.5659534863321786}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9256828, \"EndTime\": 1740876850.9256911, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5646546452502372, \"count\": 1, \"min\": 0.5646546452502372, \"max\": 0.5646546452502372}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9257214, \"EndTime\": 1740876850.9257298, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6495555627956788, \"count\": 1, \"min\": 0.6495555627956788, \"max\": 0.6495555627956788}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.925761, \"EndTime\": 1740876850.9257705, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6495004746824936, \"count\": 1, \"min\": 0.6495004746824936, \"max\": 0.6495004746824936}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9258077, \"EndTime\": 1740876850.925817, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6478316538097133, \"count\": 1, \"min\": 0.6478316538097133, \"max\": 0.6478316538097133}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9258542, \"EndTime\": 1740876850.9258637, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6504399862416103, \"count\": 1, \"min\": 0.6504399862416103, \"max\": 0.6504399862416103}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9259007, \"EndTime\": 1740876850.9259112, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6628577541807344, \"count\": 1, \"min\": 0.6628577541807344, \"max\": 0.6628577541807344}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9259486, \"EndTime\": 1740876850.9259593, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6621442338773377, \"count\": 1, \"min\": 0.6621442338773377, \"max\": 0.6621442338773377}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9259903, \"EndTime\": 1740876850.926, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6628156772977863, \"count\": 1, \"min\": 0.6628156772977863, \"max\": 0.6628156772977863}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876850.9260378, \"EndTime\": 1740876850.926048, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6620859584048305, \"count\": 1, \"min\": 0.6620859584048305, \"max\": 0.6620859584048305}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:10 INFO 140224006256448] #quality_metric: host=algo-1, epoch=0, train binary_classification_cross_entropy_objective <loss>=0.6036148783076345\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6058578, \"EndTime\": 1740876851.6059127, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5653100170816894, \"count\": 1, \"min\": 0.5653100170816894, \"max\": 0.5653100170816894}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.605985, \"EndTime\": 1740876851.6059964, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.44680342580004984, \"count\": 1, \"min\": 0.44680342580004984, \"max\": 0.44680342580004984}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.606021, \"EndTime\": 1740876851.6060266, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4457014596654241, \"count\": 1, \"min\": 0.4457014596654241, \"max\": 0.4457014596654241}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.606047, \"EndTime\": 1740876851.6060524, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4471400401951802, \"count\": 1, \"min\": 0.4471400401951802, \"max\": 0.4471400401951802}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6060703, \"EndTime\": 1740876851.6060758, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4639504523088782, \"count\": 1, \"min\": 0.4639504523088782, \"max\": 0.4639504523088782}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6060934, \"EndTime\": 1740876851.6060984, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4705318986584117, \"count\": 1, \"min\": 0.4705318986584117, \"max\": 0.4705318986584117}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6061156, \"EndTime\": 1740876851.6061203, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46521063858035017, \"count\": 1, \"min\": 0.46521063858035017, \"max\": 0.46521063858035017}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6061378, \"EndTime\": 1740876851.6061428, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4701094579382487, \"count\": 1, \"min\": 0.4701094579382487, \"max\": 0.4701094579382487}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.60616, \"EndTime\": 1740876851.6061647, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.44631575822481123, \"count\": 1, \"min\": 0.44631575822481123, \"max\": 0.44631575822481123}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6061819, \"EndTime\": 1740876851.606187, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.449904241115073, \"count\": 1, \"min\": 0.449904241115073, \"max\": 0.449904241115073}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6062038, \"EndTime\": 1740876851.606209, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45377146691563885, \"count\": 1, \"min\": 0.45377146691563885, \"max\": 0.45377146691563885}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.606226, \"EndTime\": 1740876851.6062307, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.44837523745931956, \"count\": 1, \"min\": 0.44837523745931956, \"max\": 0.44837523745931956}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6062496, \"EndTime\": 1740876851.6062543, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4635399020608313, \"count\": 1, \"min\": 0.4635399020608313, \"max\": 0.4635399020608313}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6062715, \"EndTime\": 1740876851.6062763, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4678944576188027, \"count\": 1, \"min\": 0.4678944576188027, \"max\": 0.4678944576188027}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6062932, \"EndTime\": 1740876851.6062982, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46352626254582996, \"count\": 1, \"min\": 0.46352626254582996, \"max\": 0.46352626254582996}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.606315, \"EndTime\": 1740876851.60632, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4677484473581719, \"count\": 1, \"min\": 0.4677484473581719, \"max\": 0.4677484473581719}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6063368, \"EndTime\": 1740876851.6063416, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5535688885483525, \"count\": 1, \"min\": 0.5535688885483525, \"max\": 0.5535688885483525}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6063652, \"EndTime\": 1740876851.6063733, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5531094376199591, \"count\": 1, \"min\": 0.5531094376199591, \"max\": 0.5531094376199591}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6064012, \"EndTime\": 1740876851.6064098, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530329668678965, \"count\": 1, \"min\": 0.5530329668678965, \"max\": 0.5530329668678965}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6064386, \"EndTime\": 1740876851.6064465, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5535939605483897, \"count\": 1, \"min\": 0.5535939605483897, \"max\": 0.5535939605483897}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.606478, \"EndTime\": 1740876851.6064873, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5516603963441415, \"count\": 1, \"min\": 0.5516603963441415, \"max\": 0.5516603963441415}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6065197, \"EndTime\": 1740876851.6065283, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5490400972687483, \"count\": 1, \"min\": 0.5490400972687483, \"max\": 0.5490400972687483}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6065605, \"EndTime\": 1740876851.6065679, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5524381345047957, \"count\": 1, \"min\": 0.5524381345047957, \"max\": 0.5524381345047957}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.606602, \"EndTime\": 1740876851.6066113, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5506497337039707, \"count\": 1, \"min\": 0.5506497337039707, \"max\": 0.5506497337039707}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.60665, \"EndTime\": 1740876851.6066604, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6636866823296945, \"count\": 1, \"min\": 0.6636866823296945, \"max\": 0.6636866823296945}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6066933, \"EndTime\": 1740876851.6067028, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6639629171323985, \"count\": 1, \"min\": 0.6639629171323985, \"max\": 0.6639629171323985}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6067324, \"EndTime\": 1740876851.6067414, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6636292780824496, \"count\": 1, \"min\": 0.6636292780824496, \"max\": 0.6636292780824496}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6067724, \"EndTime\": 1740876851.6067827, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6642021153716706, \"count\": 1, \"min\": 0.6642021153716706, \"max\": 0.6642021153716706}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6068146, \"EndTime\": 1740876851.6068249, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6637030686326816, \"count\": 1, \"min\": 0.6637030686326816, \"max\": 0.6637030686326816}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6068573, \"EndTime\": 1740876851.6068668, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6650552948606835, \"count\": 1, \"min\": 0.6650552948606835, \"max\": 0.6650552948606835}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6069064, \"EndTime\": 1740876851.6069167, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6644481104603623, \"count\": 1, \"min\": 0.6644481104603623, \"max\": 0.6644481104603623}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.6069517, \"EndTime\": 1740876851.606961, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6650493103099951, \"count\": 1, \"min\": 0.6650493103099951, \"max\": 0.6650493103099951}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:11 INFO 140224006256448] #quality_metric: host=algo-1, epoch=0, validation binary_classification_cross_entropy_objective <loss>=0.5653100170816894\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:11 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=sampled_accuracy, value=0.8052708638360461\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:11 INFO 140224006256448] Epoch 0: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:11 INFO 140224006256448] Saving model for epoch: 0\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:11 INFO 140224006256448] Saved checkpoint to \"/tmp/tmp2ukxeps5/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:11 INFO 140224006256448] #progress_metric: host=algo-1, completed 3.3333333333333335 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876848.588553, \"EndTime\": 1740876851.6132615, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 6406.0, \"count\": 1, \"min\": 6406, \"max\": 6406}, \"Total Batches Seen\": {\"sum\": 189.0, \"count\": 1, \"min\": 189, \"max\": 189}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:11 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1053.2803879222013 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2245793, \"EndTime\": 1740876854.2246258, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5216081937154134, \"count\": 1, \"min\": 0.5216081937154134, \"max\": 0.5216081937154134}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2246869, \"EndTime\": 1740876854.224696, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4315993446552776, \"count\": 1, \"min\": 0.4315993446552776, \"max\": 0.4315993446552776}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2247195, \"EndTime\": 1740876854.2247257, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.43269164995028203, \"count\": 1, \"min\": 0.43269164995028203, \"max\": 0.43269164995028203}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2247465, \"EndTime\": 1740876854.224752, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.43298865571043144, \"count\": 1, \"min\": 0.43298865571043144, \"max\": 0.43298865571043144}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2247703, \"EndTime\": 1740876854.2247753, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4595093769336486, \"count\": 1, \"min\": 0.4595093769336486, \"max\": 0.4595093769336486}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2247934, \"EndTime\": 1740876854.2247984, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.46395277343619706, \"count\": 1, \"min\": 0.46395277343619706, \"max\": 0.46395277343619706}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2248158, \"EndTime\": 1740876854.224821, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4598007743529019, \"count\": 1, \"min\": 0.4598007743529019, \"max\": 0.4598007743529019}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2248383, \"EndTime\": 1740876854.224843, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4637296946270416, \"count\": 1, \"min\": 0.4637296946270416, \"max\": 0.4637296946270416}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2248635, \"EndTime\": 1740876854.2248712, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.43469386550160166, \"count\": 1, \"min\": 0.43469386550160166, \"max\": 0.43469386550160166}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2249017, \"EndTime\": 1740876854.2249095, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4339001965929933, \"count\": 1, \"min\": 0.4339001965929933, \"max\": 0.4339001965929933}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2249436, \"EndTime\": 1740876854.2249534, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4363702681153579, \"count\": 1, \"min\": 0.4363702681153579, \"max\": 0.4363702681153579}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2249837, \"EndTime\": 1740876854.2249935, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4337903949597604, \"count\": 1, \"min\": 0.4337903949597604, \"max\": 0.4337903949597604}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2250304, \"EndTime\": 1740876854.2250412, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4571708105245321, \"count\": 1, \"min\": 0.4571708105245321, \"max\": 0.4571708105245321}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.225069, \"EndTime\": 1740876854.225079, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4611053389887656, \"count\": 1, \"min\": 0.4611053389887656, \"max\": 0.4611053389887656}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2251055, \"EndTime\": 1740876854.2251134, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4571471271599342, \"count\": 1, \"min\": 0.4571471271599342, \"max\": 0.4571471271599342}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.225141, \"EndTime\": 1740876854.2251496, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4611189608178811, \"count\": 1, \"min\": 0.4611189608178811, \"max\": 0.4611189608178811}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.225176, \"EndTime\": 1740876854.2251835, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5422035584639779, \"count\": 1, \"min\": 0.5422035584639779, \"max\": 0.5422035584639779}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2252092, \"EndTime\": 1740876854.2252166, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421991876074967, \"count\": 1, \"min\": 0.5421991876074967, \"max\": 0.5421991876074967}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2252471, \"EndTime\": 1740876854.2252572, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421497102480459, \"count\": 1, \"min\": 0.5421497102480459, \"max\": 0.5421497102480459}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2252846, \"EndTime\": 1740876854.2252922, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5422212644742306, \"count\": 1, \"min\": 0.5422212644742306, \"max\": 0.5422212644742306}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2253194, \"EndTime\": 1740876854.2253287, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5587553413965369, \"count\": 1, \"min\": 0.5587553413965369, \"max\": 0.5587553413965369}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.225368, \"EndTime\": 1740876854.2253768, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5587084795537438, \"count\": 1, \"min\": 0.5587084795537438, \"max\": 0.5587084795537438}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2254062, \"EndTime\": 1740876854.2254152, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5587927660257435, \"count\": 1, \"min\": 0.5587927660257435, \"max\": 0.5587927660257435}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2254443, \"EndTime\": 1740876854.225453, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5590791762591464, \"count\": 1, \"min\": 0.5590791762591464, \"max\": 0.5590791762591464}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2254796, \"EndTime\": 1740876854.2254884, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.647082346289464, \"count\": 1, \"min\": 0.647082346289464, \"max\": 0.647082346289464}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2255175, \"EndTime\": 1740876854.2255266, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6471929308887074, \"count\": 1, \"min\": 0.6471929308887074, \"max\": 0.6471929308887074}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2255578, \"EndTime\": 1740876854.2255666, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6471091456838531, \"count\": 1, \"min\": 0.6471091456838531, \"max\": 0.6471091456838531}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.225596, \"EndTime\": 1740876854.225605, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6471503816926728, \"count\": 1, \"min\": 0.6471503816926728, \"max\": 0.6471503816926728}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2256422, \"EndTime\": 1740876854.225652, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6574434440849252, \"count\": 1, \"min\": 0.6574434440849252, \"max\": 0.6574434440849252}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.225686, \"EndTime\": 1740876854.2256966, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6574730960573296, \"count\": 1, \"min\": 0.6574730960573296, \"max\": 0.6574730960573296}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2257292, \"EndTime\": 1740876854.2257395, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6572658887473486, \"count\": 1, \"min\": 0.6572658887473486, \"max\": 0.6572658887473486}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.2257702, \"EndTime\": 1740876854.22578, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.657542460331202, \"count\": 1, \"min\": 0.657542460331202, \"max\": 0.657542460331202}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:14 INFO 140224006256448] #quality_metric: host=algo-1, epoch=1, train binary_classification_cross_entropy_objective <loss>=0.5216081937154134\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9168115, \"EndTime\": 1740876854.9168737, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5151672897366794, \"count\": 1, \"min\": 0.5151672897366794, \"max\": 0.5151672897366794}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9169483, \"EndTime\": 1740876854.9169586, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43044287306672485, \"count\": 1, \"min\": 0.43044287306672485, \"max\": 0.43044287306672485}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9169908, \"EndTime\": 1740876854.916999, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4303856777411778, \"count\": 1, \"min\": 0.4303856777411778, \"max\": 0.4303856777411778}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.917031, \"EndTime\": 1740876854.9170392, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4302084236508058, \"count\": 1, \"min\": 0.4302084236508058, \"max\": 0.4302084236508058}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9170709, \"EndTime\": 1740876854.9170804, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4601214082139826, \"count\": 1, \"min\": 0.4601214082139826, \"max\": 0.4601214082139826}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.917115, \"EndTime\": 1740876854.9171212, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.47106400311080465, \"count\": 1, \"min\": 0.47106400311080465, \"max\": 0.47106400311080465}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.917149, \"EndTime\": 1740876854.917157, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4605177742146817, \"count\": 1, \"min\": 0.4605177742146817, \"max\": 0.4605177742146817}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9171836, \"EndTime\": 1740876854.9171927, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.47085704635910547, \"count\": 1, \"min\": 0.47085704635910547, \"max\": 0.47085704635910547}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9172268, \"EndTime\": 1740876854.9172354, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43162191001422934, \"count\": 1, \"min\": 0.43162191001422934, \"max\": 0.43162191001422934}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.917267, \"EndTime\": 1740876854.9172757, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4329035777822246, \"count\": 1, \"min\": 0.4329035777822246, \"max\": 0.4329035777822246}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9173062, \"EndTime\": 1740876854.917313, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43393275119898783, \"count\": 1, \"min\": 0.43393275119898783, \"max\": 0.43393275119898783}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9173322, \"EndTime\": 1740876854.9173377, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43198975811591084, \"count\": 1, \"min\": 0.43198975811591084, \"max\": 0.43198975811591084}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9173653, \"EndTime\": 1740876854.9173732, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4599820643357965, \"count\": 1, \"min\": 0.4599820643357965, \"max\": 0.4599820643357965}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9174008, \"EndTime\": 1740876854.9174068, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46926696120732697, \"count\": 1, \"min\": 0.46926696120732697, \"max\": 0.46926696120732697}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.917428, \"EndTime\": 1740876854.9174354, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46001610539493587, \"count\": 1, \"min\": 0.46001610539493587, \"max\": 0.46001610539493587}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.917462, \"EndTime\": 1740876854.9174676, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4692718846557081, \"count\": 1, \"min\": 0.4692718846557081, \"max\": 0.4692718846557081}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9174933, \"EndTime\": 1740876854.9175012, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5528679431619267, \"count\": 1, \"min\": 0.5528679431619267, \"max\": 0.5528679431619267}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9175305, \"EndTime\": 1740876854.91754, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5526444370889734, \"count\": 1, \"min\": 0.5526444370889734, \"max\": 0.5526444370889734}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.917566, \"EndTime\": 1740876854.9175742, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5524996220629177, \"count\": 1, \"min\": 0.5524996220629177, \"max\": 0.5524996220629177}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9176064, \"EndTime\": 1740876854.917616, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5529399752442344, \"count\": 1, \"min\": 0.5529399752442344, \"max\": 0.5529399752442344}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9176412, \"EndTime\": 1740876854.9176502, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5533806097804191, \"count\": 1, \"min\": 0.5533806097804191, \"max\": 0.5533806097804191}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9176855, \"EndTime\": 1740876854.9176953, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5483532489480595, \"count\": 1, \"min\": 0.5483532489480595, \"max\": 0.5483532489480595}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9177313, \"EndTime\": 1740876854.9177415, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5536821223631785, \"count\": 1, \"min\": 0.5536821223631785, \"max\": 0.5536821223631785}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.917778, \"EndTime\": 1740876854.9177868, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5487065842350615, \"count\": 1, \"min\": 0.5487065842350615, \"max\": 0.5487065842350615}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9178169, \"EndTime\": 1740876854.9178264, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6635187623441481, \"count\": 1, \"min\": 0.6635187623441481, \"max\": 0.6635187623441481}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9178605, \"EndTime\": 1740876854.9178703, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6635978131133676, \"count\": 1, \"min\": 0.6635978131133676, \"max\": 0.6635978131133676}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9179006, \"EndTime\": 1740876854.9179103, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6637004437593206, \"count\": 1, \"min\": 0.6637004437593206, \"max\": 0.6637004437593206}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9179485, \"EndTime\": 1740876854.9179575, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6636349353748394, \"count\": 1, \"min\": 0.6636349353748394, \"max\": 0.6636349353748394}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.917988, \"EndTime\": 1740876854.917997, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6631182894699744, \"count\": 1, \"min\": 0.6631182894699744, \"max\": 0.6631182894699744}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9180274, \"EndTime\": 1740876854.9180374, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6619238102942225, \"count\": 1, \"min\": 0.6619238102942225, \"max\": 0.6619238102942225}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9180686, \"EndTime\": 1740876854.9180782, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6631354337904498, \"count\": 1, \"min\": 0.6631354337904498, \"max\": 0.6631354337904498}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9181056, \"EndTime\": 1740876854.9181132, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6633857254751605, \"count\": 1, \"min\": 0.6633857254751605, \"max\": 0.6633857254751605}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:14 INFO 140224006256448] #quality_metric: host=algo-1, epoch=1, validation binary_classification_cross_entropy_objective <loss>=0.5151672897366794\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:14 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=1, criteria=sampled_accuracy, value=0.8140556368960741\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:14 INFO 140224006256448] Epoch 1: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:14 INFO 140224006256448] Saving model for epoch: 1\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:14 INFO 140224006256448] Saved checkpoint to \"/tmp/tmpfd8qsd8u/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:14 INFO 140224006256448] #progress_metric: host=algo-1, completed 6.666666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876851.613525, \"EndTime\": 1740876854.9239695, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 9592.0, \"count\": 1, \"min\": 9592, \"max\": 9592}, \"Total Batches Seen\": {\"sum\": 283.0, \"count\": 1, \"min\": 283, \"max\": 283}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:14 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=962.3711371893803 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3186843, \"EndTime\": 1740876857.3187335, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.48628435490781335, \"count\": 1, \"min\": 0.48628435490781335, \"max\": 0.48628435490781335}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3187983, \"EndTime\": 1740876857.3188078, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42635488223607293, \"count\": 1, \"min\": 0.42635488223607293, \"max\": 0.42635488223607293}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3188396, \"EndTime\": 1740876857.3188486, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4266629374381638, \"count\": 1, \"min\": 0.4266629374381638, \"max\": 0.4266629374381638}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3188827, \"EndTime\": 1740876857.3188915, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42679732468669584, \"count\": 1, \"min\": 0.42679732468669584, \"max\": 0.42679732468669584}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3189244, \"EndTime\": 1740876857.3189337, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45653067126747626, \"count\": 1, \"min\": 0.45653067126747626, \"max\": 0.45653067126747626}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3189838, \"EndTime\": 1740876857.3189929, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.46394589820441984, \"count\": 1, \"min\": 0.46394589820441984, \"max\": 0.46394589820441984}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3190236, \"EndTime\": 1740876857.3190327, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4566526426536082, \"count\": 1, \"min\": 0.4566526426536082, \"max\": 0.4566526426536082}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3190682, \"EndTime\": 1740876857.3190765, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.46383579707763983, \"count\": 1, \"min\": 0.46383579707763983, \"max\": 0.46383579707763983}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3191087, \"EndTime\": 1740876857.319118, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.428127491496772, \"count\": 1, \"min\": 0.428127491496772, \"max\": 0.428127491496772}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.319153, \"EndTime\": 1740876857.3191626, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4277832744846911, \"count\": 1, \"min\": 0.4277832744846911, \"max\": 0.4277832744846911}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3191915, \"EndTime\": 1740876857.3192, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42845828543728776, \"count\": 1, \"min\": 0.42845828543728776, \"max\": 0.42845828543728776}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.319232, \"EndTime\": 1740876857.3192408, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4276854984372722, \"count\": 1, \"min\": 0.4276854984372722, \"max\": 0.4276854984372722}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3192713, \"EndTime\": 1740876857.3192806, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45442479671668884, \"count\": 1, \"min\": 0.45442479671668884, \"max\": 0.45442479671668884}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3193147, \"EndTime\": 1740876857.3193252, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4611593678659612, \"count\": 1, \"min\": 0.4611593678659612, \"max\": 0.4611593678659612}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3193524, \"EndTime\": 1740876857.3193607, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45441838957553116, \"count\": 1, \"min\": 0.45441838957553116, \"max\": 0.45441838957553116}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.319391, \"EndTime\": 1740876857.3194003, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4611721186604702, \"count\": 1, \"min\": 0.4611721186604702, \"max\": 0.4611721186604702}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3194304, \"EndTime\": 1740876857.3194396, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421201406137465, \"count\": 1, \"min\": 0.5421201406137465, \"max\": 0.5421201406137465}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3194764, \"EndTime\": 1740876857.3194861, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5422023448063406, \"count\": 1, \"min\": 0.5422023448063406, \"max\": 0.5422023448063406}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.319517, \"EndTime\": 1740876857.3195267, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5420983189046571, \"count\": 1, \"min\": 0.5420983189046571, \"max\": 0.5420983189046571}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.319558, \"EndTime\": 1740876857.3195672, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5422185536504621, \"count\": 1, \"min\": 0.5422185536504621, \"max\": 0.5422185536504621}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3195975, \"EndTime\": 1740876857.3196065, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5578810675546838, \"count\": 1, \"min\": 0.5578810675546838, \"max\": 0.5578810675546838}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.31964, \"EndTime\": 1740876857.31965, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5590949535068268, \"count\": 1, \"min\": 0.5590949535068268, \"max\": 0.5590949535068268}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3196833, \"EndTime\": 1740876857.319693, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5578757131650129, \"count\": 1, \"min\": 0.5578757131650129, \"max\": 0.5578757131650129}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.319726, \"EndTime\": 1740876857.3197355, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5592395165990531, \"count\": 1, \"min\": 0.5592395165990531, \"max\": 0.5592395165990531}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3197677, \"EndTime\": 1740876857.3197765, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470135043950718, \"count\": 1, \"min\": 0.6470135043950718, \"max\": 0.6470135043950718}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3198156, \"EndTime\": 1740876857.3198252, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6471966834553882, \"count\": 1, \"min\": 0.6471966834553882, \"max\": 0.6471966834553882}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3198612, \"EndTime\": 1740876857.3198698, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470363545764631, \"count\": 1, \"min\": 0.6470363545764631, \"max\": 0.6470363545764631}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3200533, \"EndTime\": 1740876857.320072, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6471554981161717, \"count\": 1, \"min\": 0.6471554981161717, \"max\": 0.6471554981161717}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.320121, \"EndTime\": 1740876857.3201318, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6570954910944263, \"count\": 1, \"min\": 0.6570954910944263, \"max\": 0.6570954910944263}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3201678, \"EndTime\": 1740876857.3201783, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575235991746394, \"count\": 1, \"min\": 0.6575235991746394, \"max\": 0.6575235991746394}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.3202055, \"EndTime\": 1740876857.3202147, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6570401701423505, \"count\": 1, \"min\": 0.6570401701423505, \"max\": 0.6570401701423505}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876857.320246, \"EndTime\": 1740876857.3202548, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575730702003899, \"count\": 1, \"min\": 0.6575730702003899, \"max\": 0.6575730702003899}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:17 INFO 140224006256448] #quality_metric: host=algo-1, epoch=2, train binary_classification_cross_entropy_objective <loss>=0.48628435490781335\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.022446, \"EndTime\": 1740876858.022509, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.487789297871848, \"count\": 1, \"min\": 0.487789297871848, \"max\": 0.487789297871848}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0225837, \"EndTime\": 1740876858.022595, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42703036315968235, \"count\": 1, \"min\": 0.42703036315968235, \"max\": 0.42703036315968235}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0226207, \"EndTime\": 1740876858.022629, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42694783769275224, \"count\": 1, \"min\": 0.42694783769275224, \"max\": 0.42694783769275224}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.022663, \"EndTime\": 1740876858.022672, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42674877598205385, \"count\": 1, \"min\": 0.42674877598205385, \"max\": 0.42674877598205385}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0227106, \"EndTime\": 1740876858.0227191, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.457001048509757, \"count\": 1, \"min\": 0.457001048509757, \"max\": 0.457001048509757}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0228164, \"EndTime\": 1740876858.0228326, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.47077958685063687, \"count\": 1, \"min\": 0.47077958685063687, \"max\": 0.47077958685063687}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0229146, \"EndTime\": 1740876858.0229268, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4572744526590819, \"count\": 1, \"min\": 0.4572744526590819, \"max\": 0.4572744526590819}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0229983, \"EndTime\": 1740876858.0230114, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.47066142688209456, \"count\": 1, \"min\": 0.47066142688209456, \"max\": 0.47066142688209456}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.023138, \"EndTime\": 1740876858.023161, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4282770994641596, \"count\": 1, \"min\": 0.4282770994641596, \"max\": 0.4282770994641596}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0232165, \"EndTime\": 1740876858.0232291, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4291203933090277, \"count\": 1, \"min\": 0.4291203933090277, \"max\": 0.4291203933090277}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0232978, \"EndTime\": 1740876858.0233083, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4292234107306552, \"count\": 1, \"min\": 0.4292234107306552, \"max\": 0.4292234107306552}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0233374, \"EndTime\": 1740876858.023347, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4286455991152963, \"count\": 1, \"min\": 0.4286455991152963, \"max\": 0.4286455991152963}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0234232, \"EndTime\": 1740876858.0234368, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45672123481029997, \"count\": 1, \"min\": 0.45672123481029997, \"max\": 0.45672123481029997}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0235121, \"EndTime\": 1740876858.0235245, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.469248447987206, \"count\": 1, \"min\": 0.469248447987206, \"max\": 0.469248447987206}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.02361, \"EndTime\": 1740876858.0236237, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45676346928273953, \"count\": 1, \"min\": 0.45676346928273953, \"max\": 0.45676346928273953}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.023666, \"EndTime\": 1740876858.0236764, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4692466677893308, \"count\": 1, \"min\": 0.4692466677893308, \"max\": 0.4692466677893308}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0237098, \"EndTime\": 1740876858.023719, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5527091609262268, \"count\": 1, \"min\": 0.5527091609262268, \"max\": 0.5527091609262268}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0237746, \"EndTime\": 1740876858.023786, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5527194003584095, \"count\": 1, \"min\": 0.5527194003584095, \"max\": 0.5527194003584095}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0238156, \"EndTime\": 1740876858.0238254, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5524867013816778, \"count\": 1, \"min\": 0.5524867013816778, \"max\": 0.5524867013816778}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0238972, \"EndTime\": 1740876858.0239096, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5529246775332517, \"count\": 1, \"min\": 0.5529246775332517, \"max\": 0.5529246775332517}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0239851, \"EndTime\": 1740876858.0239978, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5564781907362261, \"count\": 1, \"min\": 0.5564781907362261, \"max\": 0.5564781907362261}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0240412, \"EndTime\": 1740876858.024052, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5484732872919666, \"count\": 1, \"min\": 0.5484732872919666, \"max\": 0.5484732872919666}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.024087, \"EndTime\": 1740876858.0240965, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5566446093479676, \"count\": 1, \"min\": 0.5566446093479676, \"max\": 0.5566446093479676}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0241349, \"EndTime\": 1740876858.0241454, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5486226902175613, \"count\": 1, \"min\": 0.5486226902175613, \"max\": 0.5486226902175613}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0241845, \"EndTime\": 1740876858.0241914, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6633946623320461, \"count\": 1, \"min\": 0.6633946623320461, \"max\": 0.6633946623320461}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0242112, \"EndTime\": 1740876858.0242176, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6634695055195039, \"count\": 1, \"min\": 0.6634695055195039, \"max\": 0.6634695055195039}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0242481, \"EndTime\": 1740876858.0242567, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6636447826206772, \"count\": 1, \"min\": 0.6636447826206772, \"max\": 0.6636447826206772}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0242875, \"EndTime\": 1740876858.0242975, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6634109707911926, \"count\": 1, \"min\": 0.6634109707911926, \"max\": 0.6634109707911926}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0243666, \"EndTime\": 1740876858.024377, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6608002199784554, \"count\": 1, \"min\": 0.6608002199784554, \"max\": 0.6608002199784554}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0244281, \"EndTime\": 1740876858.0244384, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6606179959253895, \"count\": 1, \"min\": 0.6606179959253895, \"max\": 0.6606179959253895}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0244634, \"EndTime\": 1740876858.02447, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.660979325739915, \"count\": 1, \"min\": 0.660979325739915, \"max\": 0.660979325739915}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0244918, \"EndTime\": 1740876858.0244982, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.659680654503416, \"count\": 1, \"min\": 0.659680654503416, \"max\": 0.659680654503416}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:18 INFO 140224006256448] #quality_metric: host=algo-1, epoch=2, validation binary_classification_cross_entropy_objective <loss>=0.487789297871848\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:18 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=2, criteria=sampled_accuracy, value=0.8125915080527361\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:18 INFO 140224006256448] Epoch 2: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:18 INFO 140224006256448] Saving model for epoch: 2\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:18 INFO 140224006256448] Saved checkpoint to \"/tmp/tmp43v16i5e/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:18 INFO 140224006256448] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876854.9242232, \"EndTime\": 1740876858.0301251, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12778.0, \"count\": 1, \"min\": 12778, \"max\": 12778}, \"Total Batches Seen\": {\"sum\": 377.0, \"count\": 1, \"min\": 377, \"max\": 377}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:18 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1025.7444135605904 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3881564, \"EndTime\": 1740876860.388203, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.46692811470104123, \"count\": 1, \"min\": 0.46692811470104123, \"max\": 0.46692811470104123}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3882647, \"EndTime\": 1740876860.3882737, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4254163486304576, \"count\": 1, \"min\": 0.4254163486304576, \"max\": 0.4254163486304576}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3883095, \"EndTime\": 1740876860.388318, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4252267202043141, \"count\": 1, \"min\": 0.4252267202043141, \"max\": 0.4252267202043141}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3883467, \"EndTime\": 1740876860.3883555, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4255573217209799, \"count\": 1, \"min\": 0.4255573217209799, \"max\": 0.4255573217209799}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3883905, \"EndTime\": 1740876860.3883998, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4536420968723478, \"count\": 1, \"min\": 0.4536420968723478, \"max\": 0.4536420968723478}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3884313, \"EndTime\": 1740876860.388441, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.46374392358658056, \"count\": 1, \"min\": 0.46374392358658056, \"max\": 0.46374392358658056}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.388472, \"EndTime\": 1740876860.38848, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.453718884846291, \"count\": 1, \"min\": 0.453718884846291, \"max\": 0.453718884846291}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3885078, \"EndTime\": 1740876860.3885167, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.46367545085643985, \"count\": 1, \"min\": 0.46367545085643985, \"max\": 0.46367545085643985}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3885417, \"EndTime\": 1740876860.3885496, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4263462709671783, \"count\": 1, \"min\": 0.4263462709671783, \"max\": 0.4263462709671783}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3885767, \"EndTime\": 1740876860.3885849, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42642314504928636, \"count\": 1, \"min\": 0.42642314504928636, \"max\": 0.42642314504928636}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.388615, \"EndTime\": 1740876860.3886244, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4264284745565628, \"count\": 1, \"min\": 0.4264284745565628, \"max\": 0.4264284745565628}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.388657, \"EndTime\": 1740876860.3886666, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.426379486701671, \"count\": 1, \"min\": 0.426379486701671, \"max\": 0.426379486701671}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3886945, \"EndTime\": 1740876860.3887038, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45165049765850457, \"count\": 1, \"min\": 0.45165049765850457, \"max\": 0.45165049765850457}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3887336, \"EndTime\": 1740876860.3887436, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.460986806651145, \"count\": 1, \"min\": 0.460986806651145, \"max\": 0.460986806651145}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3887753, \"EndTime\": 1740876860.3887851, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45164830182489907, \"count\": 1, \"min\": 0.45164830182489907, \"max\": 0.45164830182489907}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3888125, \"EndTime\": 1740876860.38882, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4609942743855138, \"count\": 1, \"min\": 0.4609942743855138, \"max\": 0.4609942743855138}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3888462, \"EndTime\": 1740876860.388854, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5420692125353008, \"count\": 1, \"min\": 0.5420692125353008, \"max\": 0.5420692125353008}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.388881, \"EndTime\": 1740876860.388889, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5422196952245568, \"count\": 1, \"min\": 0.5422196952245568, \"max\": 0.5422196952245568}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3889177, \"EndTime\": 1740876860.388927, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5420586443037869, \"count\": 1, \"min\": 0.5420586443037869, \"max\": 0.5420586443037869}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3889594, \"EndTime\": 1740876860.3889682, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5422303204593742, \"count\": 1, \"min\": 0.5422303204593742, \"max\": 0.5422303204593742}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3889987, \"EndTime\": 1740876860.389008, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5567069994656818, \"count\": 1, \"min\": 0.5567069994656818, \"max\": 0.5567069994656818}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3890414, \"EndTime\": 1740876860.3890505, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5591407214290804, \"count\": 1, \"min\": 0.5591407214290804, \"max\": 0.5591407214290804}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3890812, \"EndTime\": 1740876860.389091, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.556687144521367, \"count\": 1, \"min\": 0.556687144521367, \"max\": 0.556687144521367}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3891218, \"EndTime\": 1740876860.3891306, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5592176976044068, \"count\": 1, \"min\": 0.5592176976044068, \"max\": 0.5592176976044068}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3891623, \"EndTime\": 1740876860.389172, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6469647614432618, \"count\": 1, \"min\": 0.6469647614432618, \"max\": 0.6469647614432618}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3892035, \"EndTime\": 1740876860.3892126, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6471969476611761, \"count\": 1, \"min\": 0.6471969476611761, \"max\": 0.6471969476611761}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.389244, \"EndTime\": 1740876860.3892534, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6469808719642248, \"count\": 1, \"min\": 0.6469808719642248, \"max\": 0.6469808719642248}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3892837, \"EndTime\": 1740876860.3892925, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6471526648408623, \"count\": 1, \"min\": 0.6471526648408623, \"max\": 0.6471526648408623}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3893232, \"EndTime\": 1740876860.3893325, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6563855828098826, \"count\": 1, \"min\": 0.6563855828098826, \"max\": 0.6563855828098826}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3893638, \"EndTime\": 1740876860.3893833, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6576011640824976, \"count\": 1, \"min\": 0.6576011640824976, \"max\": 0.6576011640824976}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3894215, \"EndTime\": 1740876860.3894317, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6564598131752859, \"count\": 1, \"min\": 0.6564598131752859, \"max\": 0.6564598131752859}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876860.3894656, \"EndTime\": 1740876860.3894753, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575534906212398, \"count\": 1, \"min\": 0.6575534906212398, \"max\": 0.6575534906212398}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:20 INFO 140224006256448] #quality_metric: host=algo-1, epoch=3, train binary_classification_cross_entropy_objective <loss>=0.46692811470104123\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0925612, \"EndTime\": 1740876861.0926187, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4715369302741256, \"count\": 1, \"min\": 0.4715369302741256, \"max\": 0.4715369302741256}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0926876, \"EndTime\": 1740876861.0926986, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4261704761845825, \"count\": 1, \"min\": 0.4261704761845825, \"max\": 0.4261704761845825}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0927231, \"EndTime\": 1740876861.09273, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.425846258333801, \"count\": 1, \"min\": 0.425846258333801, \"max\": 0.425846258333801}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0927658, \"EndTime\": 1740876861.0927744, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4259327866497012, \"count\": 1, \"min\": 0.4259327866497012, \"max\": 0.4259327866497012}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0928109, \"EndTime\": 1740876861.0928195, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45445254606523416, \"count\": 1, \"min\": 0.45445254606523416, \"max\": 0.45445254606523416}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.09285, \"EndTime\": 1740876861.0928578, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4702811413942284, \"count\": 1, \"min\": 0.4702811413942284, \"max\": 0.4702811413942284}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0928893, \"EndTime\": 1740876861.0928984, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4546446973024315, \"count\": 1, \"min\": 0.4546446973024315, \"max\": 0.4546446973024315}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0929298, \"EndTime\": 1740876861.0929408, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4702009373667649, \"count\": 1, \"min\": 0.4702009373667649, \"max\": 0.4702009373667649}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.092975, \"EndTime\": 1740876861.0929844, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4271858714160947, \"count\": 1, \"min\": 0.4271858714160947, \"max\": 0.4271858714160947}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.093024, \"EndTime\": 1740876861.0930343, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4279942603271842, \"count\": 1, \"min\": 0.4279942603271842, \"max\": 0.4279942603271842}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.093067, \"EndTime\": 1740876861.0930755, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42761472203546524, \"count\": 1, \"min\": 0.42761472203546524, \"max\": 0.42761472203546524}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0931087, \"EndTime\": 1740876861.0931184, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42774554105314644, \"count\": 1, \"min\": 0.42774554105314644, \"max\": 0.42774554105314644}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0931451, \"EndTime\": 1740876861.093151, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45432997378213863, \"count\": 1, \"min\": 0.45432997378213863, \"max\": 0.45432997378213863}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0931687, \"EndTime\": 1740876861.0934, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4689622998761223, \"count\": 1, \"min\": 0.4689622998761223, \"max\": 0.4689622998761223}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0934312, \"EndTime\": 1740876861.0934377, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45437031766157027, \"count\": 1, \"min\": 0.45437031766157027, \"max\": 0.45437031766157027}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.093467, \"EndTime\": 1740876861.0934758, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4689608179632776, \"count\": 1, \"min\": 0.4689608179632776, \"max\": 0.4689608179632776}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0935001, \"EndTime\": 1740876861.0935092, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5526282602312973, \"count\": 1, \"min\": 0.5526282602312973, \"max\": 0.5526282602312973}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0935378, \"EndTime\": 1740876861.0935457, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5527583856359233, \"count\": 1, \"min\": 0.5527583856359233, \"max\": 0.5527583856359233}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0935743, \"EndTime\": 1740876861.093583, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5524849195256938, \"count\": 1, \"min\": 0.5524849195256938, \"max\": 0.5524849195256938}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.093613, \"EndTime\": 1740876861.0936215, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5529101174188393, \"count\": 1, \"min\": 0.5529101174188393, \"max\": 0.5529101174188393}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0936506, \"EndTime\": 1740876861.0936565, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5582951549904238, \"count\": 1, \"min\": 0.5582951549904238, \"max\": 0.5582951549904238}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0936763, \"EndTime\": 1740876861.0936837, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5485553231804822, \"count\": 1, \"min\": 0.5485553231804822, \"max\": 0.5485553231804822}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0937195, \"EndTime\": 1740876861.0937297, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5584301582018069, \"count\": 1, \"min\": 0.5584301582018069, \"max\": 0.5584301582018069}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0937698, \"EndTime\": 1740876861.093779, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.548649909730188, \"count\": 1, \"min\": 0.548649909730188, \"max\": 0.548649909730188}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0938072, \"EndTime\": 1740876861.0938132, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6632916302492469, \"count\": 1, \"min\": 0.6632916302492469, \"max\": 0.6632916302492469}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0938356, \"EndTime\": 1740876861.093841, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6634089157836155, \"count\": 1, \"min\": 0.6634089157836155, \"max\": 0.6634089157836155}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0938735, \"EndTime\": 1740876861.0938823, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6635725660519579, \"count\": 1, \"min\": 0.6635725660519579, \"max\": 0.6635725660519579}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.093919, \"EndTime\": 1740876861.0939283, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6633568845067506, \"count\": 1, \"min\": 0.6633568845067506, \"max\": 0.6633568845067506}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0939643, \"EndTime\": 1740876861.093973, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6605443378493168, \"count\": 1, \"min\": 0.6605443378493168, \"max\": 0.6605443378493168}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.094, \"EndTime\": 1740876861.094006, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6583919560054036, \"count\": 1, \"min\": 0.6583919560054036, \"max\": 0.6583919560054036}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.094032, \"EndTime\": 1740876861.0940402, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6601864436360438, \"count\": 1, \"min\": 0.6601864436360438, \"max\": 0.6601864436360438}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.0940676, \"EndTime\": 1740876861.0940752, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6606422481215716, \"count\": 1, \"min\": 0.6606422481215716, \"max\": 0.6606422481215716}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:21 INFO 140224006256448] #quality_metric: host=algo-1, epoch=3, validation binary_classification_cross_entropy_objective <loss>=0.4715369302741256\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:21 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=3, criteria=sampled_accuracy, value=0.811127379209398\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:21 INFO 140224006256448] Epoch 3: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:21 INFO 140224006256448] Saving model for epoch: 3\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:21 INFO 140224006256448] Saved checkpoint to \"/tmp/tmp8c5owuwu/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:21 INFO 140224006256448] #progress_metric: host=algo-1, completed 13.333333333333334 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876858.0303428, \"EndTime\": 1740876861.0996125, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 15964.0, \"count\": 1, \"min\": 15964, \"max\": 15964}, \"Total Batches Seen\": {\"sum\": 471.0, \"count\": 1, \"min\": 471, \"max\": 471}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:21 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1038.0000307600385 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4319837, \"EndTime\": 1740876863.4320307, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45533135026259786, \"count\": 1, \"min\": 0.45533135026259786, \"max\": 0.45533135026259786}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4320931, \"EndTime\": 1740876863.4321024, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42523268202601316, \"count\": 1, \"min\": 0.42523268202601316, \"max\": 0.42523268202601316}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4321282, \"EndTime\": 1740876863.4321373, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4247294248922349, \"count\": 1, \"min\": 0.4247294248922349, \"max\": 0.4247294248922349}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4321733, \"EndTime\": 1740876863.4321826, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42527536498376795, \"count\": 1, \"min\": 0.42527536498376795, \"max\": 0.42527536498376795}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.432218, \"EndTime\": 1740876863.4322276, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45109730819446386, \"count\": 1, \"min\": 0.45109730819446386, \"max\": 0.45109730819446386}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4322596, \"EndTime\": 1740876863.4322684, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4635390166162615, \"count\": 1, \"min\": 0.4635390166162615, \"max\": 0.4635390166162615}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4322975, \"EndTime\": 1740876863.432307, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4511523335738547, \"count\": 1, \"min\": 0.4511523335738547, \"max\": 0.4511523335738547}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4323387, \"EndTime\": 1740876863.432349, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.46349174353535005, \"count\": 1, \"min\": 0.46349174353535005, \"max\": 0.46349174353535005}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4323783, \"EndTime\": 1740876863.4323878, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42565051020888267, \"count\": 1, \"min\": 0.42565051020888267, \"max\": 0.42565051020888267}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4324198, \"EndTime\": 1740876863.432429, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42602454386957833, \"count\": 1, \"min\": 0.42602454386957833, \"max\": 0.42602454386957833}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4324586, \"EndTime\": 1740876863.4324687, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4256697317831581, \"count\": 1, \"min\": 0.4256697317831581, \"max\": 0.4256697317831581}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4325044, \"EndTime\": 1740876863.4325147, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42600916187496296, \"count\": 1, \"min\": 0.42600916187496296, \"max\": 0.42600916187496296}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4325466, \"EndTime\": 1740876863.4325564, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4492123626139555, \"count\": 1, \"min\": 0.4492123626139555, \"max\": 0.4492123626139555}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4325883, \"EndTime\": 1740876863.4325974, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4608061455383397, \"count\": 1, \"min\": 0.4608061455383397, \"max\": 0.4608061455383397}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.43263, \"EndTime\": 1740876863.432639, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.44921275379535597, \"count\": 1, \"min\": 0.44921275379535597, \"max\": 0.44921275379535597}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4326773, \"EndTime\": 1740876863.4326866, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.46081127990732307, \"count\": 1, \"min\": 0.46081127990732307, \"max\": 0.46081127990732307}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4327228, \"EndTime\": 1740876863.4327312, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5420132156869115, \"count\": 1, \"min\": 0.5420132156869115, \"max\": 0.5420132156869115}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4327672, \"EndTime\": 1740876863.4327762, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5422266282136496, \"count\": 1, \"min\": 0.5422266282136496, \"max\": 0.5422266282136496}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.432808, \"EndTime\": 1740876863.4328177, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5420074284943804, \"count\": 1, \"min\": 0.5420074284943804, \"max\": 0.5420074284943804}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4328556, \"EndTime\": 1740876863.4328654, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5422343164211131, \"count\": 1, \"min\": 0.5422343164211131, \"max\": 0.5422343164211131}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4329047, \"EndTime\": 1740876863.4329154, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5551750091417615, \"count\": 1, \"min\": 0.5551750091417615, \"max\": 0.5551750091417615}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.432951, \"EndTime\": 1740876863.4329617, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5591730827172295, \"count\": 1, \"min\": 0.5591730827172295, \"max\": 0.5591730827172295}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.432993, \"EndTime\": 1740876863.433003, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5551436310851974, \"count\": 1, \"min\": 0.5551436310851974, \"max\": 0.5551436310851974}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4330375, \"EndTime\": 1740876863.4330473, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5592201403015252, \"count\": 1, \"min\": 0.5592201403015252, \"max\": 0.5592201403015252}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4330866, \"EndTime\": 1740876863.4330966, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6469205136091026, \"count\": 1, \"min\": 0.6469205136091026, \"max\": 0.6469205136091026}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.433132, \"EndTime\": 1740876863.433141, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6471856821194093, \"count\": 1, \"min\": 0.6471856821194093, \"max\": 0.6471856821194093}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4331715, \"EndTime\": 1740876863.4331803, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.646931534850997, \"count\": 1, \"min\": 0.646931534850997, \"max\": 0.646931534850997}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4332194, \"EndTime\": 1740876863.4332285, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6471454317550128, \"count\": 1, \"min\": 0.6471454317550128, \"max\": 0.6471454317550128}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4332616, \"EndTime\": 1740876863.4332716, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6552048399054801, \"count\": 1, \"min\": 0.6552048399054801, \"max\": 0.6552048399054801}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.433302, \"EndTime\": 1740876863.4333117, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6573999755975192, \"count\": 1, \"min\": 0.6573999755975192, \"max\": 0.6573999755975192}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4333525, \"EndTime\": 1740876863.4333618, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6552963238739651, \"count\": 1, \"min\": 0.6552963238739651, \"max\": 0.6552963238739651}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876863.4334123, \"EndTime\": 1740876863.4334235, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6574791896803178, \"count\": 1, \"min\": 0.6574791896803178, \"max\": 0.6574791896803178}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:23 INFO 140224006256448] #quality_metric: host=algo-1, epoch=4, train binary_classification_cross_entropy_objective <loss>=0.45533135026259786\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.0997384, \"EndTime\": 1740876864.099803, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4611571432032662, \"count\": 1, \"min\": 0.4611571432032662, \"max\": 0.4611571432032662}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.0998878, \"EndTime\": 1740876864.099901, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4259565789388877, \"count\": 1, \"min\": 0.4259565789388877, \"max\": 0.4259565789388877}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.0999365, \"EndTime\": 1740876864.0999618, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42540439103742295, \"count\": 1, \"min\": 0.42540439103742295, \"max\": 0.42540439103742295}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.1000452, \"EndTime\": 1740876864.1000607, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42577556565425756, \"count\": 1, \"min\": 0.42577556565425756, \"max\": 0.42577556565425756}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.1001236, \"EndTime\": 1740876864.100134, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45191826879716374, \"count\": 1, \"min\": 0.45191826879716374, \"max\": 0.45191826879716374}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.1002011, \"EndTime\": 1740876864.1002126, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46969670895078, \"count\": 1, \"min\": 0.46969670895078, \"max\": 0.46969670895078}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.100278, \"EndTime\": 1740876864.1002913, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45204687746866207, \"count\": 1, \"min\": 0.45204687746866207, \"max\": 0.45204687746866207}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.100352, \"EndTime\": 1740876864.100364, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4696370970626876, \"count\": 1, \"min\": 0.4696370970626876, \"max\": 0.4696370970626876}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.1004286, \"EndTime\": 1740876864.100441, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42673838295664307, \"count\": 1, \"min\": 0.42673838295664307, \"max\": 0.42673838295664307}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.1004844, \"EndTime\": 1740876864.1004953, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42759836627658604, \"count\": 1, \"min\": 0.42759836627658604, \"max\": 0.42759836627658604}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.1005223, \"EndTime\": 1740876864.1005304, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4269405472505494, \"count\": 1, \"min\": 0.4269405472505494, \"max\": 0.4269405472505494}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.1006055, \"EndTime\": 1740876864.1006196, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42745965326513063, \"count\": 1, \"min\": 0.42745965326513063, \"max\": 0.42745965326513063}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.1006637, \"EndTime\": 1740876864.1006737, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4522588105536834, \"count\": 1, \"min\": 0.4522588105536834, \"max\": 0.4522588105536834}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.100709, \"EndTime\": 1740876864.1007183, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46855184195855004, \"count\": 1, \"min\": 0.46855184195855004, \"max\": 0.46855184195855004}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.100752, \"EndTime\": 1740876864.10076, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4522927353706751, \"count\": 1, \"min\": 0.4522927353706751, \"max\": 0.4522927353706751}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.100788, \"EndTime\": 1740876864.100795, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46855100592268334, \"count\": 1, \"min\": 0.46855100592268334, \"max\": 0.46855100592268334}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.1008275, \"EndTime\": 1740876864.100836, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5526040642362737, \"count\": 1, \"min\": 0.5526040642362737, \"max\": 0.5526040642362737}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.100911, \"EndTime\": 1740876864.1009247, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5527763883330986, \"count\": 1, \"min\": 0.5527763883330986, \"max\": 0.5527763883330986}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.1009626, \"EndTime\": 1740876864.1009696, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5525100250369808, \"count\": 1, \"min\": 0.5525100250369808, \"max\": 0.5525100250369808}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.101032, \"EndTime\": 1740876864.1010435, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5528933218248069, \"count\": 1, \"min\": 0.5528933218248069, \"max\": 0.5528933218248069}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.1011071, \"EndTime\": 1740876864.101119, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5586873577419521, \"count\": 1, \"min\": 0.5586873577419521, \"max\": 0.5586873577419521}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.1011593, \"EndTime\": 1740876864.1011693, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5486237412839473, \"count\": 1, \"min\": 0.5486237412839473, \"max\": 0.5486237412839473}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.101192, \"EndTime\": 1740876864.1011975, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5587548768014196, \"count\": 1, \"min\": 0.5587548768014196, \"max\": 0.5587548768014196}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.101222, \"EndTime\": 1740876864.1012306, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.548698147428856, \"count\": 1, \"min\": 0.548698147428856, \"max\": 0.548698147428856}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.1012664, \"EndTime\": 1740876864.1012762, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.663227542427588, \"count\": 1, \"min\": 0.663227542427588, \"max\": 0.663227542427588}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.1013467, \"EndTime\": 1740876864.1013587, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.663330927774812, \"count\": 1, \"min\": 0.663330927774812, \"max\": 0.663330927774812}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.1014123, \"EndTime\": 1740876864.10142, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6635170038762239, \"count\": 1, \"min\": 0.6635170038762239, \"max\": 0.6635170038762239}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.1014552, \"EndTime\": 1740876864.1014645, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6633391736367087, \"count\": 1, \"min\": 0.6633391736367087, \"max\": 0.6633391736367087}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.1014948, \"EndTime\": 1740876864.101504, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6609030305728382, \"count\": 1, \"min\": 0.6609030305728382, \"max\": 0.6609030305728382}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.10154, \"EndTime\": 1740876864.1015496, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6616707141367967, \"count\": 1, \"min\": 0.6616707141367967, \"max\": 0.6616707141367967}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.1016169, \"EndTime\": 1740876864.1016283, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6604712749470031, \"count\": 1, \"min\": 0.6604712749470031, \"max\": 0.6604712749470031}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.101669, \"EndTime\": 1740876864.1016793, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6621024807585106, \"count\": 1, \"min\": 0.6621024807585106, \"max\": 0.6621024807585106}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:24 INFO 140224006256448] #quality_metric: host=algo-1, epoch=4, validation binary_classification_cross_entropy_objective <loss>=0.4611571432032662\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:24 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=4, criteria=sampled_accuracy, value=0.8096632503660601\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:24 INFO 140224006256448] Epoch 4: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:24 INFO 140224006256448] Saving model for epoch: 4\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:24 INFO 140224006256448] Saved checkpoint to \"/tmp/tmpze19ama1/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:24 INFO 140224006256448] #progress_metric: host=algo-1, completed 16.666666666666668 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876861.099772, \"EndTime\": 1740876864.1082115, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 19150.0, \"count\": 1, \"min\": 19150, \"max\": 19150}, \"Total Batches Seen\": {\"sum\": 565.0, \"count\": 1, \"min\": 565, \"max\": 565}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:24 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1058.9790733783313 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3664544, \"EndTime\": 1740876866.3665009, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.44788973366135965, \"count\": 1, \"min\": 0.44788973366135965, \"max\": 0.44788973366135965}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.366563, \"EndTime\": 1740876866.3665729, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4251996320233475, \"count\": 1, \"min\": 0.4251996320233475, \"max\": 0.4251996320233475}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.366605, \"EndTime\": 1740876866.3666146, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42448587194415, \"count\": 1, \"min\": 0.42448587194415, \"max\": 0.42448587194415}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3666437, \"EndTime\": 1740876866.366653, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4252105121142045, \"count\": 1, \"min\": 0.4252105121142045, \"max\": 0.4252105121142045}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3666883, \"EndTime\": 1740876866.366698, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4487460906712184, \"count\": 1, \"min\": 0.4487460906712184, \"max\": 0.4487460906712184}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3667352, \"EndTime\": 1740876866.366745, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.46324207494712794, \"count\": 1, \"min\": 0.46324207494712794, \"max\": 0.46324207494712794}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3667774, \"EndTime\": 1740876866.3667867, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.44878703005173626, \"count\": 1, \"min\": 0.44878703005173626, \"max\": 0.44878703005173626}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.366819, \"EndTime\": 1740876866.3668265, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.46320764721382424, \"count\": 1, \"min\": 0.46320764721382424, \"max\": 0.46320764721382424}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3668537, \"EndTime\": 1740876866.366862, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.425292803772185, \"count\": 1, \"min\": 0.425292803772185, \"max\": 0.425292803772185}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3668935, \"EndTime\": 1740876866.3669038, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4258860370013474, \"count\": 1, \"min\": 0.4258860370013474, \"max\": 0.4258860370013474}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.366938, \"EndTime\": 1740876866.3669484, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4252930411351474, \"count\": 1, \"min\": 0.4252930411351474, \"max\": 0.4252930411351474}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3669817, \"EndTime\": 1740876866.3669906, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42588221340674076, \"count\": 1, \"min\": 0.42588221340674076, \"max\": 0.42588221340674076}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3670218, \"EndTime\": 1740876866.3670309, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4470680800515741, \"count\": 1, \"min\": 0.4470680800515741, \"max\": 0.4470680800515741}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3670626, \"EndTime\": 1740876866.3670728, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.46054108515334685, \"count\": 1, \"min\": 0.46054108515334685, \"max\": 0.46054108515334685}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3671095, \"EndTime\": 1740876866.3671196, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.44706998423335675, \"count\": 1, \"min\": 0.44706998423335675, \"max\": 0.44706998423335675}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3671572, \"EndTime\": 1740876866.3671663, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4605448770794516, \"count\": 1, \"min\": 0.4605448770794516, \"max\": 0.4605448770794516}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.367198, \"EndTime\": 1740876866.3672085, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5419520957797181, \"count\": 1, \"min\": 0.5419520957797181, \"max\": 0.5419520957797181}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3672433, \"EndTime\": 1740876866.3672528, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5422284251749327, \"count\": 1, \"min\": 0.5422284251749327, \"max\": 0.5422284251749327}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3672934, \"EndTime\": 1740876866.367303, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5419487739046641, \"count\": 1, \"min\": 0.5419487739046641, \"max\": 0.5419487739046641}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3673384, \"EndTime\": 1740876866.3673491, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5422343200403704, \"count\": 1, \"min\": 0.5422343200403704, \"max\": 0.5422343200403704}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3673863, \"EndTime\": 1740876866.3673964, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5533402395881784, \"count\": 1, \"min\": 0.5533402395881784, \"max\": 0.5533402395881784}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3674319, \"EndTime\": 1740876866.3674407, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5591606436312614, \"count\": 1, \"min\": 0.5591606436312614, \"max\": 0.5591606436312614}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3674712, \"EndTime\": 1740876866.3674793, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5533136760487276, \"count\": 1, \"min\": 0.5533136760487276, \"max\": 0.5533136760487276}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3675125, \"EndTime\": 1740876866.367522, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5591912725015504, \"count\": 1, \"min\": 0.5591912725015504, \"max\": 0.5591912725015504}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3675623, \"EndTime\": 1740876866.3675728, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.646883199065641, \"count\": 1, \"min\": 0.646883199065641, \"max\": 0.646883199065641}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3676136, \"EndTime\": 1740876866.3676229, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6471745142975915, \"count\": 1, \"min\": 0.6471745142975915, \"max\": 0.6471745142975915}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3676586, \"EndTime\": 1740876866.367668, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6468880699828484, \"count\": 1, \"min\": 0.6468880699828484, \"max\": 0.6468880699828484}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3677075, \"EndTime\": 1740876866.3677185, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.647139868353229, \"count\": 1, \"min\": 0.647139868353229, \"max\": 0.647139868353229}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.367757, \"EndTime\": 1740876866.3677669, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6538787814049235, \"count\": 1, \"min\": 0.6538787814049235, \"max\": 0.6538787814049235}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.367807, \"EndTime\": 1740876866.3678164, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.657399970168633, \"count\": 1, \"min\": 0.657399970168633, \"max\": 0.657399970168633}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.367855, \"EndTime\": 1740876866.3678653, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6539478115006989, \"count\": 1, \"min\": 0.6539478115006989, \"max\": 0.6539478115006989}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876866.3678975, \"EndTime\": 1740876866.3679063, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6574289489591673, \"count\": 1, \"min\": 0.6574289489591673, \"max\": 0.6574289489591673}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:26 INFO 140224006256448] #quality_metric: host=algo-1, epoch=5, train binary_classification_cross_entropy_objective <loss>=0.44788973366135965\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0272412, \"EndTime\": 1740876867.027298, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4541370022174729, \"count\": 1, \"min\": 0.4541370022174729, \"max\": 0.4541370022174729}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.027369, \"EndTime\": 1740876867.02738, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4259083298952653, \"count\": 1, \"min\": 0.4259083298952653, \"max\": 0.4259083298952653}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0274053, \"EndTime\": 1740876867.0274148, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42519452762115056, \"count\": 1, \"min\": 0.42519452762115056, \"max\": 0.42519452762115056}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0274525, \"EndTime\": 1740876867.0274613, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42577566548985585, \"count\": 1, \"min\": 0.42577566548985585, \"max\": 0.42577566548985585}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0274975, \"EndTime\": 1740876867.0275056, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.44914224521307433, \"count\": 1, \"min\": 0.44914224521307433, \"max\": 0.44914224521307433}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.027537, \"EndTime\": 1740876867.0275602, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4690886790022843, \"count\": 1, \"min\": 0.4690886790022843, \"max\": 0.4690886790022843}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0275826, \"EndTime\": 1740876867.0275886, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4492236529401944, \"count\": 1, \"min\": 0.4492236529401944, \"max\": 0.4492236529401944}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0276062, \"EndTime\": 1740876867.0276115, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4690418068870444, \"count\": 1, \"min\": 0.4690418068870444, \"max\": 0.4690418068870444}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.027629, \"EndTime\": 1740876867.027634, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4265203657471418, \"count\": 1, \"min\": 0.4265203657471418, \"max\": 0.4265203657471418}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0276508, \"EndTime\": 1740876867.0276556, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4274295322367946, \"count\": 1, \"min\": 0.4274295322367946, \"max\": 0.4274295322367946}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0276728, \"EndTime\": 1740876867.0276797, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42661540434964407, \"count\": 1, \"min\": 0.42661540434964407, \"max\": 0.42661540434964407}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.027701, \"EndTime\": 1740876867.0277064, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4273462683006052, \"count\": 1, \"min\": 0.4273462683006052, \"max\": 0.4273462683006052}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0277233, \"EndTime\": 1740876867.0277283, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.44986524100184966, \"count\": 1, \"min\": 0.44986524100184966, \"max\": 0.44986524100184966}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0277452, \"EndTime\": 1740876867.0277503, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4680898543856329, \"count\": 1, \"min\": 0.4680898543856329, \"max\": 0.4680898543856329}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0277667, \"EndTime\": 1740876867.0277717, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4498906877344559, \"count\": 1, \"min\": 0.4498906877344559, \"max\": 0.4498906877344559}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0277927, \"EndTime\": 1740876867.027798, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4680897009669425, \"count\": 1, \"min\": 0.4680897009669425, \"max\": 0.4680897009669425}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0278177, \"EndTime\": 1740876867.0278225, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5526140521595454, \"count\": 1, \"min\": 0.5526140521595454, \"max\": 0.5526140521595454}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.02784, \"EndTime\": 1740876867.0278447, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5527830136119011, \"count\": 1, \"min\": 0.5527830136119011, \"max\": 0.5527830136119011}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0278618, \"EndTime\": 1740876867.0278666, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5525526848579395, \"count\": 1, \"min\": 0.5525526848579395, \"max\": 0.5525526848579395}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0278833, \"EndTime\": 1740876867.027888, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5528759111597109, \"count\": 1, \"min\": 0.5528759111597109, \"max\": 0.5528759111597109}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0279047, \"EndTime\": 1740876867.0279107, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5569887658687497, \"count\": 1, \"min\": 0.5569887658687497, \"max\": 0.5569887658687497}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0279315, \"EndTime\": 1740876867.0279365, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5487305706102363, \"count\": 1, \"min\": 0.5487305706102363, \"max\": 0.5487305706102363}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0279748, \"EndTime\": 1740876867.0279806, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.556997478270077, \"count\": 1, \"min\": 0.556997478270077, \"max\": 0.556997478270077}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0280027, \"EndTime\": 1740876867.0280082, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5487946203826636, \"count\": 1, \"min\": 0.5487946203826636, \"max\": 0.5487946203826636}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0280323, \"EndTime\": 1740876867.02804, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6632167678626355, \"count\": 1, \"min\": 0.6632167678626355, \"max\": 0.6632167678626355}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0280664, \"EndTime\": 1740876867.028072, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6632483274311831, \"count\": 1, \"min\": 0.6632483274311831, \"max\": 0.6632483274311831}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0280943, \"EndTime\": 1740876867.0280995, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6634680125235115, \"count\": 1, \"min\": 0.6634680125235115, \"max\": 0.6634680125235115}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0281217, \"EndTime\": 1740876867.028127, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6633737738275598, \"count\": 1, \"min\": 0.6633737738275598, \"max\": 0.6633737738275598}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0281446, \"EndTime\": 1740876867.0281498, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6607422975286034, \"count\": 1, \"min\": 0.6607422975286034, \"max\": 0.6607422975286034}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0281763, \"EndTime\": 1740876867.0281825, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6642676204399344, \"count\": 1, \"min\": 0.6642676204399344, \"max\": 0.6642676204399344}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.028207, \"EndTime\": 1740876867.0282125, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6602587221656676, \"count\": 1, \"min\": 0.6602587221656676, \"max\": 0.6602587221656676}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.028235, \"EndTime\": 1740876867.0282404, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.66181653415127, \"count\": 1, \"min\": 0.66181653415127, \"max\": 0.66181653415127}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:27 INFO 140224006256448] #quality_metric: host=algo-1, epoch=5, validation binary_classification_cross_entropy_objective <loss>=0.4541370022174729\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:27 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=5, criteria=sampled_accuracy, value=0.8096632503660601\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:27 INFO 140224006256448] Epoch 5: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:27 INFO 140224006256448] Saving model for epoch: 5\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:27 INFO 140224006256448] Saved checkpoint to \"/tmp/tmpmxoccaeq/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:27 INFO 140224006256448] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876864.1084976, \"EndTime\": 1740876867.033717, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 22336.0, \"count\": 1, \"min\": 22336, \"max\": 22336}, \"Total Batches Seen\": {\"sum\": 659.0, \"count\": 1, \"min\": 659, \"max\": 659}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:27 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1088.8854384248014 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.354535, \"EndTime\": 1740876869.3545804, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4428541429581181, \"count\": 1, \"min\": 0.4428541429581181, \"max\": 0.4428541429581181}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.3546438, \"EndTime\": 1740876869.354656, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42519476834465475, \"count\": 1, \"min\": 0.42519476834465475, \"max\": 0.42519476834465475}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.3546925, \"EndTime\": 1740876869.354702, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4243237943607067, \"count\": 1, \"min\": 0.4243237943607067, \"max\": 0.4243237943607067}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.354732, \"EndTime\": 1740876869.3547428, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4251954730442247, \"count\": 1, \"min\": 0.4251954730442247, \"max\": 0.4251954730442247}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.3547728, \"EndTime\": 1740876869.3547819, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4466264547991044, \"count\": 1, \"min\": 0.4466264547991044, \"max\": 0.4466264547991044}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.3548143, \"EndTime\": 1740876869.3548224, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4629371256710682, \"count\": 1, \"min\": 0.4629371256710682, \"max\": 0.4629371256710682}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.3548481, \"EndTime\": 1740876869.3548563, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4466573137938411, \"count\": 1, \"min\": 0.4466573137938411, \"max\": 0.4466573137938411}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.354886, \"EndTime\": 1740876869.3548937, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4629111495069278, \"count\": 1, \"min\": 0.4629111495069278, \"max\": 0.4629111495069278}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.354922, \"EndTime\": 1740876869.3549304, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42506418418160424, \"count\": 1, \"min\": 0.42506418418160424, \"max\": 0.42506418418160424}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.3549602, \"EndTime\": 1740876869.3549693, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4258318624490428, \"count\": 1, \"min\": 0.4258318624490428, \"max\": 0.4258318624490428}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.355, \"EndTime\": 1740876869.3550093, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42505831661139915, \"count\": 1, \"min\": 0.42505831661139915, \"max\": 0.42505831661139915}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.3550417, \"EndTime\": 1740876869.355051, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4258322628293891, \"count\": 1, \"min\": 0.4258322628293891, \"max\": 0.4258322628293891}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.3551135, \"EndTime\": 1740876869.3551252, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.44520075180951285, \"count\": 1, \"min\": 0.44520075180951285, \"max\": 0.44520075180951285}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.3551567, \"EndTime\": 1740876869.3551672, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.46027142680347305, \"count\": 1, \"min\": 0.46027142680347305, \"max\": 0.46027142680347305}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.3552046, \"EndTime\": 1740876869.3552144, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4452034223690431, \"count\": 1, \"min\": 0.4452034223690431, \"max\": 0.4452034223690431}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.355249, \"EndTime\": 1740876869.3552592, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.46027436488644374, \"count\": 1, \"min\": 0.46027436488644374, \"max\": 0.46027436488644374}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.355292, \"EndTime\": 1740876869.3553016, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5418848897896561, \"count\": 1, \"min\": 0.5418848897896561, \"max\": 0.5418848897896561}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.3553388, \"EndTime\": 1740876869.3553488, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5422300824932024, \"count\": 1, \"min\": 0.5422300824932024, \"max\": 0.5422300824932024}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.3553824, \"EndTime\": 1740876869.355391, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5418829664559699, \"count\": 1, \"min\": 0.5418829664559699, \"max\": 0.5418829664559699}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.3554225, \"EndTime\": 1740876869.3554323, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5422347618913741, \"count\": 1, \"min\": 0.5422347618913741, \"max\": 0.5422347618913741}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.355464, \"EndTime\": 1740876869.3554728, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5517507522336899, \"count\": 1, \"min\": 0.5517507522336899, \"max\": 0.5517507522336899}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.3555021, \"EndTime\": 1740876869.355511, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5591336931328771, \"count\": 1, \"min\": 0.5591336931328771, \"max\": 0.5591336931328771}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.3555431, \"EndTime\": 1740876869.3555522, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5517336648148423, \"count\": 1, \"min\": 0.5517336648148423, \"max\": 0.5517336648148423}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.355583, \"EndTime\": 1740876869.3555915, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5591542734366893, \"count\": 1, \"min\": 0.5591542734366893, \"max\": 0.5591542734366893}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.3556206, \"EndTime\": 1740876869.3556304, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6468516662858242, \"count\": 1, \"min\": 0.6468516662858242, \"max\": 0.6468516662858242}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.3556623, \"EndTime\": 1740876869.3556714, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6471665489153346, \"count\": 1, \"min\": 0.6471665489153346, \"max\": 0.6471665489153346}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.3564563, \"EndTime\": 1740876869.3564749, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6468513821741209, \"count\": 1, \"min\": 0.6468513821741209, \"max\": 0.6468513821741209}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.3565083, \"EndTime\": 1740876869.356519, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.647135105410533, \"count\": 1, \"min\": 0.647135105410533, \"max\": 0.647135105410533}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.3565507, \"EndTime\": 1740876869.3565607, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6528456963594016, \"count\": 1, \"min\": 0.6528456963594016, \"max\": 0.6528456963594016}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.356594, \"EndTime\": 1740876869.356604, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6574849895402497, \"count\": 1, \"min\": 0.6574849895402497, \"max\": 0.6574849895402497}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.356631, \"EndTime\": 1740876869.3566408, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6529058773709128, \"count\": 1, \"min\": 0.6529058773709128, \"max\": 0.6529058773709128}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876869.3566728, \"EndTime\": 1740876869.3566833, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6573575458369777, \"count\": 1, \"min\": 0.6573575458369777, \"max\": 0.6573575458369777}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:29 INFO 140224006256448] #quality_metric: host=algo-1, epoch=6, train binary_classification_cross_entropy_objective <loss>=0.4428541429581181\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0323343, \"EndTime\": 1740876870.0323863, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4491731432835145, \"count\": 1, \"min\": 0.4491731432835145, \"max\": 0.4491731432835145}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0324523, \"EndTime\": 1740876870.0324657, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42589100632451116, \"count\": 1, \"min\": 0.42589100632451116, \"max\": 0.42589100632451116}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0325012, \"EndTime\": 1740876870.0325115, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4250778617830961, \"count\": 1, \"min\": 0.4250778617830961, \"max\": 0.4250778617830961}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.032544, \"EndTime\": 1740876870.0325544, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42579492049545353, \"count\": 1, \"min\": 0.42579492049545353, \"max\": 0.42579492049545353}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0325842, \"EndTime\": 1740876870.0325935, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.44652874769962025, \"count\": 1, \"min\": 0.44652874769962025, \"max\": 0.44652874769962025}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0326238, \"EndTime\": 1740876870.0326316, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4684500358289716, \"count\": 1, \"min\": 0.4684500358289716, \"max\": 0.4684500358289716}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0326583, \"EndTime\": 1740876870.0326655, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.44658014479353697, \"count\": 1, \"min\": 0.44658014479353697, \"max\": 0.44658014479353697}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.032696, \"EndTime\": 1740876870.032704, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4684117868389951, \"count\": 1, \"min\": 0.4684117868389951, \"max\": 0.4684117868389951}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0327332, \"EndTime\": 1740876870.0327427, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42639678114504276, \"count\": 1, \"min\": 0.42639678114504276, \"max\": 0.42639678114504276}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.032771, \"EndTime\": 1740876870.0327795, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4273347608516017, \"count\": 1, \"min\": 0.4273347608516017, \"max\": 0.4273347608516017}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0328097, \"EndTime\": 1740876870.0328193, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4264389594163238, \"count\": 1, \"min\": 0.4264389594163238, \"max\": 0.4264389594163238}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0328503, \"EndTime\": 1740876870.0328593, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42728132646569045, \"count\": 1, \"min\": 0.42728132646569045, \"max\": 0.42728132646569045}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0328925, \"EndTime\": 1740876870.032902, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.44718865664078583, \"count\": 1, \"min\": 0.44718865664078583, \"max\": 0.44718865664078583}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0329323, \"EndTime\": 1740876870.0329413, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46756897646372003, \"count\": 1, \"min\": 0.46756897646372003, \"max\": 0.46756897646372003}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0329733, \"EndTime\": 1740876870.0329826, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.44720643121710985, \"count\": 1, \"min\": 0.44720643121710985, \"max\": 0.44720643121710985}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0330148, \"EndTime\": 1740876870.033025, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46756927946127, \"count\": 1, \"min\": 0.46756927946127, \"max\": 0.46756927946127}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0330532, \"EndTime\": 1740876870.0330625, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5526537989453026, \"count\": 1, \"min\": 0.5526537989453026, \"max\": 0.5526537989453026}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0330932, \"EndTime\": 1740876870.0331028, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5527808196722676, \"count\": 1, \"min\": 0.5527808196722676, \"max\": 0.5527808196722676}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0331337, \"EndTime\": 1740876870.0331404, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5526145677440861, \"count\": 1, \"min\": 0.5526145677440861, \"max\": 0.5526145677440861}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.033159, \"EndTime\": 1740876870.033164, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5528561557543574, \"count\": 1, \"min\": 0.5528561557543574, \"max\": 0.5528561557543574}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.033187, \"EndTime\": 1740876870.033195, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5543751838790201, \"count\": 1, \"min\": 0.5543751838790201, \"max\": 0.5543751838790201}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0332267, \"EndTime\": 1740876870.0332358, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.548882742577381, \"count\": 1, \"min\": 0.548882742577381, \"max\": 0.548882742577381}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0332596, \"EndTime\": 1740876870.0332675, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5543636539146457, \"count\": 1, \"min\": 0.5543636539146457, \"max\": 0.5543636539146457}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0332935, \"EndTime\": 1740876870.033302, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5489395848130412, \"count\": 1, \"min\": 0.5489395848130412, \"max\": 0.5489395848130412}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0333278, \"EndTime\": 1740876870.0333362, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6632241618057295, \"count\": 1, \"min\": 0.6632241618057295, \"max\": 0.6632241618057295}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0333683, \"EndTime\": 1740876870.0333858, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6631814342641202, \"count\": 1, \"min\": 0.6631814342641202, \"max\": 0.6631814342641202}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.033417, \"EndTime\": 1740876870.0334263, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6633960949379738, \"count\": 1, \"min\": 0.6633960949379738, \"max\": 0.6633960949379738}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0334568, \"EndTime\": 1740876870.0334663, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6634273970633265, \"count\": 1, \"min\": 0.6634273970633265, \"max\": 0.6634273970633265}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0335, \"EndTime\": 1740876870.033509, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6603068945872138, \"count\": 1, \"min\": 0.6603068945872138, \"max\": 0.6603068945872138}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0335464, \"EndTime\": 1740876870.0335567, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6643939760034988, \"count\": 1, \"min\": 0.6643939760034988, \"max\": 0.6643939760034988}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.033597, \"EndTime\": 1740876870.033607, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6598474483713399, \"count\": 1, \"min\": 0.6598474483713399, \"max\": 0.6598474483713399}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0336435, \"EndTime\": 1740876870.0336528, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6618984984793042, \"count\": 1, \"min\": 0.6618984984793042, \"max\": 0.6618984984793042}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:30 INFO 140224006256448] #quality_metric: host=algo-1, epoch=6, validation binary_classification_cross_entropy_objective <loss>=0.4491731432835145\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:30 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=6, criteria=sampled_accuracy, value=0.8096632503660601\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:30 INFO 140224006256448] Epoch 6: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:30 INFO 140224006256448] Saving model for epoch: 6\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:30 INFO 140224006256448] Saved checkpoint to \"/tmp/tmp8t0mc96t/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:30 INFO 140224006256448] #progress_metric: host=algo-1, completed 23.333333333333332 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876867.0345113, \"EndTime\": 1740876870.0394127, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 25522.0, \"count\": 1, \"min\": 25522, \"max\": 25522}, \"Total Batches Seen\": {\"sum\": 753.0, \"count\": 1, \"min\": 753, \"max\": 753}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:30 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1060.2270163791459 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.3322868, \"EndTime\": 1740876872.3323355, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4393018131992019, \"count\": 1, \"min\": 0.4393018131992019, \"max\": 0.4393018131992019}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.3323991, \"EndTime\": 1740876872.332408, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42519076288236535, \"count\": 1, \"min\": 0.42519076288236535, \"max\": 0.42519076288236535}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.3324404, \"EndTime\": 1740876872.3324487, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42419483222816656, \"count\": 1, \"min\": 0.42419483222816656, \"max\": 0.42419483222816656}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.3324778, \"EndTime\": 1740876872.3324864, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42518835260776083, \"count\": 1, \"min\": 0.42518835260776083, \"max\": 0.42518835260776083}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.3325212, \"EndTime\": 1740876872.3325312, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4446958577157877, \"count\": 1, \"min\": 0.4446958577157877, \"max\": 0.4446958577157877}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.3325672, \"EndTime\": 1740876872.3325775, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4626308285232438, \"count\": 1, \"min\": 0.4626308285232438, \"max\": 0.4626308285232438}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.3326087, \"EndTime\": 1740876872.3326168, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4447194320502574, \"count\": 1, \"min\": 0.4447194320502574, \"max\": 0.4447194320502574}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.3326437, \"EndTime\": 1740876872.3326516, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4626106341227484, \"count\": 1, \"min\": 0.4626106341227484, \"max\": 0.4626106341227484}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.3326793, \"EndTime\": 1740876872.332688, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42489618202465235, \"count\": 1, \"min\": 0.42489618202465235, \"max\": 0.42489618202465235}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.3327231, \"EndTime\": 1740876872.3327317, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4258056522395926, \"count\": 1, \"min\": 0.4258056522395926, \"max\": 0.4258056522395926}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.3327603, \"EndTime\": 1740876872.3327687, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4248886330077951, \"count\": 1, \"min\": 0.4248886330077951, \"max\": 0.4248886330077951}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.332795, \"EndTime\": 1740876872.3328032, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4258073902371411, \"count\": 1, \"min\": 0.4258073902371411, \"max\": 0.4258073902371411}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.332834, \"EndTime\": 1740876872.332844, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4434833528119352, \"count\": 1, \"min\": 0.4434833528119352, \"max\": 0.4434833528119352}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.3328743, \"EndTime\": 1740876872.332884, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4599941657510911, \"count\": 1, \"min\": 0.4599941657510911, \"max\": 0.4599941657510911}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.332914, \"EndTime\": 1740876872.3329241, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4434861987546454, \"count\": 1, \"min\": 0.4434861987546454, \"max\": 0.4434861987546454}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.332953, \"EndTime\": 1740876872.3329625, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45999653455503825, \"count\": 1, \"min\": 0.45999653455503825, \"max\": 0.45999653455503825}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.3329985, \"EndTime\": 1740876872.333008, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5418172639657394, \"count\": 1, \"min\": 0.5418172639657394, \"max\": 0.5418172639657394}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.3330412, \"EndTime\": 1740876872.3330512, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.542228170318893, \"count\": 1, \"min\": 0.542228170318893, \"max\": 0.542228170318893}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.3330843, \"EndTime\": 1740876872.333094, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5418162119682645, \"count\": 1, \"min\": 0.5418162119682645, \"max\": 0.5418162119682645}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.333128, \"EndTime\": 1740876872.3331378, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5422319569669141, \"count\": 1, \"min\": 0.5422319569669141, \"max\": 0.5422319569669141}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.333172, \"EndTime\": 1740876872.3331819, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5505334720213454, \"count\": 1, \"min\": 0.5505334720213454, \"max\": 0.5505334720213454}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.333217, \"EndTime\": 1740876872.3332272, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5591055325961128, \"count\": 1, \"min\": 0.5591055325961128, \"max\": 0.5591055325961128}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.333263, \"EndTime\": 1740876872.3332722, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5505232820022264, \"count\": 1, \"min\": 0.5505232820022264, \"max\": 0.5505232820022264}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.333309, \"EndTime\": 1740876872.3333197, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5591195689809993, \"count\": 1, \"min\": 0.5591195689809993, \"max\": 0.5591195689809993}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.3333564, \"EndTime\": 1740876872.3333666, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6468240055081815, \"count\": 1, \"min\": 0.6468240055081815, \"max\": 0.6468240055081815}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.3334136, \"EndTime\": 1740876872.3334239, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6471607810255096, \"count\": 1, \"min\": 0.6471607810255096, \"max\": 0.6471607810255096}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.333461, \"EndTime\": 1740876872.3334706, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6468213459572258, \"count\": 1, \"min\": 0.6468213459572258, \"max\": 0.6468213459572258}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.333506, \"EndTime\": 1740876872.3335161, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6471301422022627, \"count\": 1, \"min\": 0.6471301422022627, \"max\": 0.6471301422022627}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.333553, \"EndTime\": 1740876872.3335636, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6520780977156251, \"count\": 1, \"min\": 0.6520780977156251, \"max\": 0.6520780977156251}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.3335996, \"EndTime\": 1740876872.3336096, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575529652257119, \"count\": 1, \"min\": 0.6575529652257119, \"max\": 0.6575529652257119}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.333645, \"EndTime\": 1740876872.3336546, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6521372979083897, \"count\": 1, \"min\": 0.6521372979083897, \"max\": 0.6521372979083897}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.333691, \"EndTime\": 1740876872.3337014, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.657359664308957, \"count\": 1, \"min\": 0.657359664308957, \"max\": 0.657359664308957}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:32 INFO 140224006256448] #quality_metric: host=algo-1, epoch=7, train binary_classification_cross_entropy_objective <loss>=0.4393018131992019\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.9987009, \"EndTime\": 1740876872.9987597, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.44553774446903527, \"count\": 1, \"min\": 0.44553774446903527, \"max\": 0.44553774446903527}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.9988308, \"EndTime\": 1740876872.998841, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4258805312663535, \"count\": 1, \"min\": 0.4258805312663535, \"max\": 0.4258805312663535}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.9988744, \"EndTime\": 1740876872.9988837, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4250076057970262, \"count\": 1, \"min\": 0.4250076057970262, \"max\": 0.4250076057970262}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.9989197, \"EndTime\": 1740876872.9989269, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42581076992029326, \"count\": 1, \"min\": 0.42581076992029326, \"max\": 0.42581076992029326}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.9989514, \"EndTime\": 1740876872.9989593, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4444681985486479, \"count\": 1, \"min\": 0.4444681985486479, \"max\": 0.4444681985486479}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.998992, \"EndTime\": 1740876872.9990017, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46783538932856145, \"count\": 1, \"min\": 0.46783538932856145, \"max\": 0.46783538932856145}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.9990363, \"EndTime\": 1740876872.9990447, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.44450106828488506, \"count\": 1, \"min\": 0.44450106828488506, \"max\": 0.44450106828488506}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.9990735, \"EndTime\": 1740876872.9990823, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.467803432424805, \"count\": 1, \"min\": 0.467803432424805, \"max\": 0.467803432424805}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.99911, \"EndTime\": 1740876872.9991179, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42632176027814606, \"count\": 1, \"min\": 0.42632176027814606, \"max\": 0.42632176027814606}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.9991536, \"EndTime\": 1740876872.9991632, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42727496648428204, \"count\": 1, \"min\": 0.42727496648428204, \"max\": 0.42727496648428204}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.9992006, \"EndTime\": 1740876872.9992087, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4263370798063488, \"count\": 1, \"min\": 0.4263370798063488, \"max\": 0.4263370798063488}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.999237, \"EndTime\": 1740876872.9992452, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4272388783590336, \"count\": 1, \"min\": 0.4272388783590336, \"max\": 0.4272388783590336}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.9992778, \"EndTime\": 1740876872.9992874, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4447755590190301, \"count\": 1, \"min\": 0.4447755590190301, \"max\": 0.4447755590190301}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.9993258, \"EndTime\": 1740876872.9993358, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4670457897563281, \"count\": 1, \"min\": 0.4670457897563281, \"max\": 0.4670457897563281}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.999372, \"EndTime\": 1740876872.9993815, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4447876082332382, \"count\": 1, \"min\": 0.4447876082332382, \"max\": 0.4447876082332382}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876872.999404, \"EndTime\": 1740876872.9994123, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4670464032565518, \"count\": 1, \"min\": 0.4670464032565518, \"max\": 0.4670464032565518}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876873.0003512, \"EndTime\": 1740876873.0003672, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5527049559625316, \"count\": 1, \"min\": 0.5527049559625316, \"max\": 0.5527049559625316}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876873.0003996, \"EndTime\": 1740876873.0004082, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.55277281065811, \"count\": 1, \"min\": 0.55277281065811, \"max\": 0.55277281065811}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876873.000439, \"EndTime\": 1740876873.0004487, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5526808641665502, \"count\": 1, \"min\": 0.5526808641665502, \"max\": 0.5526808641665502}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876873.0004718, \"EndTime\": 1740876873.00048, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5528349155562863, \"count\": 1, \"min\": 0.5528349155562863, \"max\": 0.5528349155562863}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876873.0005157, \"EndTime\": 1740876873.0005257, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.552530345246523, \"count\": 1, \"min\": 0.552530345246523, \"max\": 0.552530345246523}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876873.0005484, \"EndTime\": 1740876873.0005565, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5490966009011555, \"count\": 1, \"min\": 0.5490966009011555, \"max\": 0.5490966009011555}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876873.0005832, \"EndTime\": 1740876873.0005918, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5525159779963347, \"count\": 1, \"min\": 0.5525159779963347, \"max\": 0.5525159779963347}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876873.0006247, \"EndTime\": 1740876873.000634, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5491475535346684, \"count\": 1, \"min\": 0.5491475535346684, \"max\": 0.5491475535346684}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876873.0006678, \"EndTime\": 1740876873.0006764, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.663201535952388, \"count\": 1, \"min\": 0.663201535952388, \"max\": 0.663201535952388}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876873.0007033, \"EndTime\": 1740876873.0007114, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6631293432953417, \"count\": 1, \"min\": 0.6631293432953417, \"max\": 0.6631293432953417}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876873.0007434, \"EndTime\": 1740876873.0007532, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6632889940309316, \"count\": 1, \"min\": 0.6632889940309316, \"max\": 0.6632889940309316}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876873.0007837, \"EndTime\": 1740876873.0007925, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6634890488614799, \"count\": 1, \"min\": 0.6634890488614799, \"max\": 0.6634890488614799}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876873.0008264, \"EndTime\": 1740876873.0008335, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6601844486694559, \"count\": 1, \"min\": 0.6601844486694559, \"max\": 0.6601844486694559}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876873.0008528, \"EndTime\": 1740876873.0008576, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.664385232883526, \"count\": 1, \"min\": 0.664385232883526, \"max\": 0.664385232883526}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876873.0008817, \"EndTime\": 1740876873.0008903, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6598375632508083, \"count\": 1, \"min\": 0.6598375632508083, \"max\": 0.6598375632508083}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876873.0009174, \"EndTime\": 1740876873.0009263, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6624855440148149, \"count\": 1, \"min\": 0.6624855440148149, \"max\": 0.6624855440148149}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:33 INFO 140224006256448] #quality_metric: host=algo-1, epoch=7, validation binary_classification_cross_entropy_objective <loss>=0.44553774446903527\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:33 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=7, criteria=sampled_accuracy, value=0.8096632503660601\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:33 INFO 140224006256448] Epoch 7: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:33 INFO 140224006256448] Saving model for epoch: 7\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:33 INFO 140224006256448] Saved checkpoint to \"/tmp/tmp5jy_q_kr/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:33 INFO 140224006256448] #progress_metric: host=algo-1, completed 26.666666666666668 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876870.0396469, \"EndTime\": 1740876873.0062435, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 28708.0, \"count\": 1, \"min\": 28708, \"max\": 28708}, \"Total Batches Seen\": {\"sum\": 847.0, \"count\": 1, \"min\": 847, \"max\": 847}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:33 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1073.9209213808272 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.310689, \"EndTime\": 1740876875.3107374, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4367096268776321, \"count\": 1, \"min\": 0.4367096268776321, \"max\": 0.4367096268776321}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3108037, \"EndTime\": 1740876875.3108163, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4251844784943534, \"count\": 1, \"min\": 0.4251844784943534, \"max\": 0.4251844784943534}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.310853, \"EndTime\": 1740876875.3108642, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4240802593581063, \"count\": 1, \"min\": 0.4240802593581063, \"max\": 0.4240802593581063}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.310893, \"EndTime\": 1740876875.3109033, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4251812374493806, \"count\": 1, \"min\": 0.4251812374493806, \"max\": 0.4251812374493806}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3109353, \"EndTime\": 1740876875.3109453, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4429545971051867, \"count\": 1, \"min\": 0.4429545971051867, \"max\": 0.4429545971051867}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3109834, \"EndTime\": 1740876875.310994, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4622902405706861, \"count\": 1, \"min\": 0.4622902405706861, \"max\": 0.4622902405706861}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3110242, \"EndTime\": 1740876875.3110323, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.44297277376969957, \"count\": 1, \"min\": 0.44297277376969957, \"max\": 0.44297277376969957}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3110604, \"EndTime\": 1740876875.3110685, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.46227430271845993, \"count\": 1, \"min\": 0.46227430271845993, \"max\": 0.46227430271845993}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3110976, \"EndTime\": 1740876875.3111064, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4247585897729187, \"count\": 1, \"min\": 0.4247585897729187, \"max\": 0.4247585897729187}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3111367, \"EndTime\": 1740876875.3111465, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42578988298443887, \"count\": 1, \"min\": 0.42578988298443887, \"max\": 0.42578988298443887}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3111784, \"EndTime\": 1740876875.3111873, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4247510374384089, \"count\": 1, \"min\": 0.4247510374384089, \"max\": 0.4247510374384089}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.311218, \"EndTime\": 1740876875.3112268, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42579189197388273, \"count\": 1, \"min\": 0.42579189197388273, \"max\": 0.42579189197388273}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3112583, \"EndTime\": 1740876875.311268, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4418961051745478, \"count\": 1, \"min\": 0.4418961051745478, \"max\": 0.4418961051745478}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3113, \"EndTime\": 1740876875.3113096, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4596841550944049, \"count\": 1, \"min\": 0.4596841550944049, \"max\": 0.4596841550944049}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3113487, \"EndTime\": 1740876875.3113585, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4418987855362334, \"count\": 1, \"min\": 0.4418987855362334, \"max\": 0.4418987855362334}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3113961, \"EndTime\": 1740876875.3114061, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45968609471474925, \"count\": 1, \"min\": 0.45968609471474925, \"max\": 0.45968609471474925}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3114362, \"EndTime\": 1740876875.3114462, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5417466561753564, \"count\": 1, \"min\": 0.5417466561753564, \"max\": 0.5417466561753564}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3114736, \"EndTime\": 1740876875.311482, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5422269265007776, \"count\": 1, \"min\": 0.5422269265007776, \"max\": 0.5422269265007776}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3115096, \"EndTime\": 1740876875.3115182, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5417461371135289, \"count\": 1, \"min\": 0.5417461371135289, \"max\": 0.5417461371135289}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3115518, \"EndTime\": 1740876875.311561, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5422300499198861, \"count\": 1, \"min\": 0.5422300499198861, \"max\": 0.5422300499198861}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3116002, \"EndTime\": 1740876875.3116095, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5494695683961274, \"count\": 1, \"min\": 0.5494695683961274, \"max\": 0.5494695683961274}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3116457, \"EndTime\": 1740876875.3116555, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.559059496848814, \"count\": 1, \"min\": 0.559059496848814, \"max\": 0.559059496848814}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3116853, \"EndTime\": 1740876875.3116956, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5494637287243644, \"count\": 1, \"min\": 0.5494637287243644, \"max\": 0.5494637287243644}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3117242, \"EndTime\": 1740876875.311733, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5590690601331987, \"count\": 1, \"min\": 0.5590690601331987, \"max\": 0.5590690601331987}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3117623, \"EndTime\": 1740876875.3117719, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6467974540329221, \"count\": 1, \"min\": 0.6467974540329221, \"max\": 0.6467974540329221}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3118052, \"EndTime\": 1740876875.3118145, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6471542277568356, \"count\": 1, \"min\": 0.6471542277568356, \"max\": 0.6471542277568356}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3118422, \"EndTime\": 1740876875.3118515, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6467950749744124, \"count\": 1, \"min\": 0.6467950749744124, \"max\": 0.6467950749744124}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3118846, \"EndTime\": 1740876875.3118937, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.647121946997163, \"count\": 1, \"min\": 0.647121946997163, \"max\": 0.647121946997163}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3128276, \"EndTime\": 1740876875.3128488, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6513758097774691, \"count\": 1, \"min\": 0.6513758097774691, \"max\": 0.6513758097774691}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.312896, \"EndTime\": 1740876875.3129072, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6576381040328217, \"count\": 1, \"min\": 0.6576381040328217, \"max\": 0.6576381040328217}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.3129475, \"EndTime\": 1740876875.3129575, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6514385097921083, \"count\": 1, \"min\": 0.6514385097921083, \"max\": 0.6514385097921083}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.312995, \"EndTime\": 1740876875.313004, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6574068105650581, \"count\": 1, \"min\": 0.6574068105650581, \"max\": 0.6574068105650581}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:35 INFO 140224006256448] #quality_metric: host=algo-1, epoch=8, train binary_classification_cross_entropy_objective <loss>=0.4367096268776321\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.9741325, \"EndTime\": 1740876875.9741874, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.44279862863951164, \"count\": 1, \"min\": 0.44279862863951164, \"max\": 0.44279862863951164}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.974255, \"EndTime\": 1740876875.974265, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4258702075324331, \"count\": 1, \"min\": 0.4258702075324331, \"max\": 0.4258702075324331}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.9742897, \"EndTime\": 1740876875.9742985, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4249684695443507, \"count\": 1, \"min\": 0.4249684695443507, \"max\": 0.4249684695443507}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.974332, \"EndTime\": 1740876875.9743414, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42581918298936344, \"count\": 1, \"min\": 0.42581918298936344, \"max\": 0.42581918298936344}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.9743764, \"EndTime\": 1740876875.974386, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.44281354062204653, \"count\": 1, \"min\": 0.44281354062204653, \"max\": 0.44281354062204653}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.9744174, \"EndTime\": 1740876875.9748755, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46723853215291594, \"count\": 1, \"min\": 0.46723853215291594, \"max\": 0.46723853215291594}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.9749217, \"EndTime\": 1740876875.9749322, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.44283365906593913, \"count\": 1, \"min\": 0.44283365906593913, \"max\": 0.44283365906593913}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.9749703, \"EndTime\": 1740876875.9749799, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46721121385191755, \"count\": 1, \"min\": 0.46721121385191755, \"max\": 0.46721121385191755}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.9750156, \"EndTime\": 1740876875.9750254, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42628021365901564, \"count\": 1, \"min\": 0.42628021365901564, \"max\": 0.42628021365901564}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.975061, \"EndTime\": 1740876875.9750702, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4272342555519428, \"count\": 1, \"min\": 0.4272342555519428, \"max\": 0.4272342555519428}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.975109, \"EndTime\": 1740876875.975119, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42628162427318567, \"count\": 1, \"min\": 0.42628162427318567, \"max\": 0.42628162427318567}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.9751568, \"EndTime\": 1740876875.9751663, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4272088301129432, \"count\": 1, \"min\": 0.4272088301129432, \"max\": 0.4272088301129432}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.9752016, \"EndTime\": 1740876875.975212, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4428816213440232, \"count\": 1, \"min\": 0.4428816213440232, \"max\": 0.4428816213440232}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.9752438, \"EndTime\": 1740876875.9752536, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46653031307991216, \"count\": 1, \"min\": 0.46653031307991216, \"max\": 0.46653031307991216}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.9752884, \"EndTime\": 1740876875.9752984, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.44288965845876, \"count\": 1, \"min\": 0.44288965845876, \"max\": 0.44288965845876}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.975329, \"EndTime\": 1740876875.9753377, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4665311344546071, \"count\": 1, \"min\": 0.4665311344546071, \"max\": 0.4665311344546071}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.975359, \"EndTime\": 1740876875.9753647, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5527685254070455, \"count\": 1, \"min\": 0.5527685254070455, \"max\": 0.5527685254070455}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.9753926, \"EndTime\": 1740876875.975401, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5527610117310486, \"count\": 1, \"min\": 0.5527610117310486, \"max\": 0.5527610117310486}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.9754257, \"EndTime\": 1740876875.9754345, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5527546423246013, \"count\": 1, \"min\": 0.5527546423246013, \"max\": 0.5527546423246013}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.9754713, \"EndTime\": 1740876875.9754808, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.552812882433175, \"count\": 1, \"min\": 0.552812882433175, \"max\": 0.552812882433175}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.9755151, \"EndTime\": 1740876875.9755247, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5522588145855056, \"count\": 1, \"min\": 0.5522588145855056, \"max\": 0.5522588145855056}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.975561, \"EndTime\": 1740876875.9755712, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5493136171366075, \"count\": 1, \"min\": 0.5493136171366075, \"max\": 0.5493136171366075}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.9756079, \"EndTime\": 1740876875.9756167, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5522460867684896, \"count\": 1, \"min\": 0.5522460867684896, \"max\": 0.5522460867684896}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.975655, \"EndTime\": 1740876875.975665, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5493593865222847, \"count\": 1, \"min\": 0.5493593865222847, \"max\": 0.5493593865222847}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.9757001, \"EndTime\": 1740876875.9757097, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6631691000297513, \"count\": 1, \"min\": 0.6631691000297513, \"max\": 0.6631691000297513}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.9757457, \"EndTime\": 1740876875.9757552, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6630764850585736, \"count\": 1, \"min\": 0.6630764850585736, \"max\": 0.6630764850585736}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.975788, \"EndTime\": 1740876875.9757972, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6631810892029703, \"count\": 1, \"min\": 0.6631810892029703, \"max\": 0.6631810892029703}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.97583, \"EndTime\": 1740876875.9758399, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.66355247605772, \"count\": 1, \"min\": 0.66355247605772, \"max\": 0.66355247605772}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.975872, \"EndTime\": 1740876875.9758809, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6606795494587844, \"count\": 1, \"min\": 0.6606795494587844, \"max\": 0.6606795494587844}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.975917, \"EndTime\": 1740876875.9759257, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6645681975003043, \"count\": 1, \"min\": 0.6645681975003043, \"max\": 0.6645681975003043}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.9759722, \"EndTime\": 1740876875.9759827, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6605679601387259, \"count\": 1, \"min\": 0.6605679601387259, \"max\": 0.6605679601387259}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.976012, \"EndTime\": 1740876875.976021, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6633253928333913, \"count\": 1, \"min\": 0.6633253928333913, \"max\": 0.6633253928333913}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:35 INFO 140224006256448] #quality_metric: host=algo-1, epoch=8, validation binary_classification_cross_entropy_objective <loss>=0.44279862863951164\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:35 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=8, criteria=sampled_accuracy, value=0.8096632503660601\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:35 INFO 140224006256448] Epoch 8: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:35 INFO 140224006256448] Saving model for epoch: 8\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:35 INFO 140224006256448] Saved checkpoint to \"/tmp/tmparpn7za0/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:35 INFO 140224006256448] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876873.0064223, \"EndTime\": 1740876875.981682, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 31894.0, \"count\": 1, \"min\": 31894, \"max\": 31894}, \"Total Batches Seen\": {\"sum\": 941.0, \"count\": 1, \"min\": 941, \"max\": 941}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:35 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1070.7863300475342 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2789872, \"EndTime\": 1740876878.279034, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4347648433610505, \"count\": 1, \"min\": 0.4347648433610505, \"max\": 0.4347648433610505}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2790947, \"EndTime\": 1740876878.2791042, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42517663209518247, \"count\": 1, \"min\": 0.42517663209518247, \"max\": 0.42517663209518247}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.279138, \"EndTime\": 1740876878.2791464, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42397589324623025, \"count\": 1, \"min\": 0.42397589324623025, \"max\": 0.42397589324623025}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2791781, \"EndTime\": 1740876878.2791848, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4251733253003675, \"count\": 1, \"min\": 0.4251733253003675, \"max\": 0.4251733253003675}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.279207, \"EndTime\": 1740876878.2792144, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4414707220935279, \"count\": 1, \"min\": 0.4414707220935279, \"max\": 0.4414707220935279}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2792435, \"EndTime\": 1740876878.2792523, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4619355040362634, \"count\": 1, \"min\": 0.4619355040362634, \"max\": 0.4619355040362634}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.279283, \"EndTime\": 1740876878.2792892, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4414845423785891, \"count\": 1, \"min\": 0.4414845423785891, \"max\": 0.4414845423785891}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2793078, \"EndTime\": 1740876878.279313, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.46192269096036714, \"count\": 1, \"min\": 0.46192269096036714, \"max\": 0.46192269096036714}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.279332, \"EndTime\": 1740876878.2793396, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4246404538947823, \"count\": 1, \"min\": 0.4246404538947823, \"max\": 0.4246404538947823}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2793643, \"EndTime\": 1740876878.2793725, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4257782719543959, \"count\": 1, \"min\": 0.4257782719543959, \"max\": 0.4257782719543959}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2794003, \"EndTime\": 1740876878.2794092, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.424633523016923, \"count\": 1, \"min\": 0.424633523016923, \"max\": 0.424633523016923}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2794373, \"EndTime\": 1740876878.2794456, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4257801851843219, \"count\": 1, \"min\": 0.4257801851843219, \"max\": 0.4257801851843219}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.279476, \"EndTime\": 1740876878.2794845, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.44056406072390975, \"count\": 1, \"min\": 0.44056406072390975, \"max\": 0.44056406072390975}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2795224, \"EndTime\": 1740876878.2795322, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45935678014568254, \"count\": 1, \"min\": 0.45935678014568254, \"max\": 0.45935678014568254}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2795684, \"EndTime\": 1740876878.2795773, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4405664228925518, \"count\": 1, \"min\": 0.4405664228925518, \"max\": 0.4405664228925518}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2796116, \"EndTime\": 1740876878.2796197, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45935838649274424, \"count\": 1, \"min\": 0.45935838649274424, \"max\": 0.45935838649274424}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2796412, \"EndTime\": 1740876878.2796495, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5416748742375624, \"count\": 1, \"min\": 0.5416748742375624, \"max\": 0.5416748742375624}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2796712, \"EndTime\": 1740876878.2796767, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5422204112343061, \"count\": 1, \"min\": 0.5422204112343061, \"max\": 0.5422204112343061}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2797048, \"EndTime\": 1740876878.279714, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5416746987035801, \"count\": 1, \"min\": 0.5416746987035801, \"max\": 0.5416746987035801}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2797458, \"EndTime\": 1740876878.2797544, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5422230053370245, \"count\": 1, \"min\": 0.5422230053370245, \"max\": 0.5422230053370245}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2797847, \"EndTime\": 1740876878.2797942, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5485282490179555, \"count\": 1, \"min\": 0.5485282490179555, \"max\": 0.5485282490179555}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2798262, \"EndTime\": 1740876878.279834, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.559016515151524, \"count\": 1, \"min\": 0.559016515151524, \"max\": 0.559016515151524}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2798634, \"EndTime\": 1740876878.2798724, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5485247151147407, \"count\": 1, \"min\": 0.5485247151147407, \"max\": 0.5485247151147407}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2799044, \"EndTime\": 1740876878.2799134, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5590230865164847, \"count\": 1, \"min\": 0.5590230865164847, \"max\": 0.5590230865164847}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.279964, \"EndTime\": 1740876878.279974, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6467727200280707, \"count\": 1, \"min\": 0.6467727200280707, \"max\": 0.6467727200280707}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.28001, \"EndTime\": 1740876878.2800195, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.647149252484374, \"count\": 1, \"min\": 0.647149252484374, \"max\": 0.647149252484374}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.280061, \"EndTime\": 1740876878.2800715, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6467728014613615, \"count\": 1, \"min\": 0.6467728014613615, \"max\": 0.6467728014613615}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.280149, \"EndTime\": 1740876878.2801633, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.64711363235657, \"count\": 1, \"min\": 0.64711363235657, \"max\": 0.64711363235657}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2802093, \"EndTime\": 1740876878.2802207, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6508071550758936, \"count\": 1, \"min\": 0.6508071550758936, \"max\": 0.6508071550758936}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2802625, \"EndTime\": 1740876878.2802732, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6576132958331944, \"count\": 1, \"min\": 0.6576132958331944, \"max\": 0.6576132958331944}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2803082, \"EndTime\": 1740876878.2803175, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6508714988365873, \"count\": 1, \"min\": 0.6508714988365873, \"max\": 0.6508714988365873}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.2803547, \"EndTime\": 1740876878.2803633, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6574791450428104, \"count\": 1, \"min\": 0.6574791450428104, \"max\": 0.6574791450428104}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:38 INFO 140224006256448] #quality_metric: host=algo-1, epoch=9, train binary_classification_cross_entropy_objective <loss>=0.4347648433610505\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9467359, \"EndTime\": 1740876878.946795, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.44068542860262916, \"count\": 1, \"min\": 0.44068542860262916, \"max\": 0.44068542860262916}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9468687, \"EndTime\": 1740876878.9468791, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42585697146146223, \"count\": 1, \"min\": 0.42585697146146223, \"max\": 0.42585697146146223}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9469037, \"EndTime\": 1740876878.9469125, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42494642062557214, \"count\": 1, \"min\": 0.42494642062557214, \"max\": 0.42494642062557214}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.946947, \"EndTime\": 1740876878.9469552, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42581914877996263, \"count\": 1, \"min\": 0.42581914877996263, \"max\": 0.42581914877996263}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9469914, \"EndTime\": 1740876878.9470003, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4411760282376849, \"count\": 1, \"min\": 0.4411760282376849, \"max\": 0.4411760282376849}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9470298, \"EndTime\": 1740876878.9470372, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46668939351337374, \"count\": 1, \"min\": 0.46668939351337374, \"max\": 0.46668939351337374}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.947107, \"EndTime\": 1740876878.947121, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4411864708318194, \"count\": 1, \"min\": 0.4411864708318194, \"max\": 0.4411864708318194}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9471633, \"EndTime\": 1740876878.9471734, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46666568954029336, \"count\": 1, \"min\": 0.46666568954029336, \"max\": 0.46666568954029336}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9472094, \"EndTime\": 1740876878.9472182, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4262572935350119, \"count\": 1, \"min\": 0.4262572935350119, \"max\": 0.4262572935350119}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9472535, \"EndTime\": 1740876878.9472632, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4272019322061609, \"count\": 1, \"min\": 0.4272019322061609, \"max\": 0.4272019322061609}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.947302, \"EndTime\": 1740876878.9473128, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42625149469249946, \"count\": 1, \"min\": 0.42625149469249946, \"max\": 0.42625149469249946}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9473474, \"EndTime\": 1740876878.9473567, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4271834704746788, \"count\": 1, \"min\": 0.4271834704746788, \"max\": 0.4271834704746788}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9473944, \"EndTime\": 1740876878.9474041, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4412876927835177, \"count\": 1, \"min\": 0.4412876927835177, \"max\": 0.4412876927835177}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.947441, \"EndTime\": 1740876878.947451, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46603890175700713, \"count\": 1, \"min\": 0.46603890175700713, \"max\": 0.46603890175700713}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9474905, \"EndTime\": 1740876878.9475, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4412929214984397, \"count\": 1, \"min\": 0.4412929214984397, \"max\": 0.4412929214984397}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.947539, \"EndTime\": 1740876878.9475486, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4660399316170554, \"count\": 1, \"min\": 0.4660399316170554, \"max\": 0.4660399316170554}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9475806, \"EndTime\": 1740876878.9475906, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5528251934540219, \"count\": 1, \"min\": 0.5528251934540219, \"max\": 0.5528251934540219}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9476216, \"EndTime\": 1740876878.9476311, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5527550182789346, \"count\": 1, \"min\": 0.5527550182789346, \"max\": 0.5527550182789346}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.947666, \"EndTime\": 1740876878.9476764, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5528179112150938, \"count\": 1, \"min\": 0.5528179112150938, \"max\": 0.5528179112150938}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9477143, \"EndTime\": 1740876878.9477253, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5527988206240653, \"count\": 1, \"min\": 0.5527988206240653, \"max\": 0.5527988206240653}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9477658, \"EndTime\": 1740876878.9477773, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.553379615962418, \"count\": 1, \"min\": 0.553379615962418, \"max\": 0.553379615962418}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9478128, \"EndTime\": 1740876878.947823, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5495322014192886, \"count\": 1, \"min\": 0.5495322014192886, \"max\": 0.5495322014192886}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9478626, \"EndTime\": 1740876878.9478729, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5533697887884227, \"count\": 1, \"min\": 0.5533697887884227, \"max\": 0.5533697887884227}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9479134, \"EndTime\": 1740876878.9479232, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5495734431209536, \"count\": 1, \"min\": 0.5495734431209536, \"max\": 0.5495734431209536}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9479737, \"EndTime\": 1740876878.947984, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.663131825920429, \"count\": 1, \"min\": 0.663131825920429, \"max\": 0.663131825920429}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9480257, \"EndTime\": 1740876878.9480348, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6630146143900703, \"count\": 1, \"min\": 0.6630146143900703, \"max\": 0.6630146143900703}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9480593, \"EndTime\": 1740876878.9480653, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6631100401173224, \"count\": 1, \"min\": 0.6631100401173224, \"max\": 0.6631100401173224}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9480968, \"EndTime\": 1740876878.9481056, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6635992982551608, \"count\": 1, \"min\": 0.6635992982551608, \"max\": 0.6635992982551608}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9481406, \"EndTime\": 1740876878.9481494, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6616274022427694, \"count\": 1, \"min\": 0.6616274022427694, \"max\": 0.6616274022427694}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.948188, \"EndTime\": 1740876878.9481976, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6638059520093099, \"count\": 1, \"min\": 0.6638059520093099, \"max\": 0.6638059520093099}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.94823, \"EndTime\": 1740876878.9482398, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6619657981448083, \"count\": 1, \"min\": 0.6619657981448083, \"max\": 0.6619657981448083}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9482667, \"EndTime\": 1740876878.9482737, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6635933817741986, \"count\": 1, \"min\": 0.6635933817741986, \"max\": 0.6635933817741986}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:38 INFO 140224006256448] #quality_metric: host=algo-1, epoch=9, validation binary_classification_cross_entropy_objective <loss>=0.44068542860262916\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:38 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=9, criteria=sampled_accuracy, value=0.8081991215227221\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:38 INFO 140224006256448] Epoch 9: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:38 INFO 140224006256448] Saving model for epoch: 9\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:38 INFO 140224006256448] Saved checkpoint to \"/tmp/tmptnbrll0j/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:38 INFO 140224006256448] #progress_metric: host=algo-1, completed 33.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876875.9819264, \"EndTime\": 1740876878.9545903, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 35080.0, \"count\": 1, \"min\": 35080, \"max\": 35080}, \"Total Batches Seen\": {\"sum\": 1035.0, \"count\": 1, \"min\": 1035, \"max\": 1035}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:38 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1071.721363485988 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.291025, \"EndTime\": 1740876881.291071, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4332713381087456, \"count\": 1, \"min\": 0.4332713381087456, \"max\": 0.4332713381087456}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.291135, \"EndTime\": 1740876881.2911475, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4251667355375151, \"count\": 1, \"min\": 0.4251667355375151, \"max\": 0.4251667355375151}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.291185, \"EndTime\": 1740876881.2911952, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42387913345611977, \"count\": 1, \"min\": 0.42387913345611977, \"max\": 0.42387913345611977}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.2912285, \"EndTime\": 1740876881.2912354, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42516360050662266, \"count\": 1, \"min\": 0.42516360050662266, \"max\": 0.42516360050662266}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.2912586, \"EndTime\": 1740876881.2912664, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4400918844151844, \"count\": 1, \"min\": 0.4400918844151844, \"max\": 0.4400918844151844}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.291296, \"EndTime\": 1740876881.291304, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4616035348927198, \"count\": 1, \"min\": 0.4616035348927198, \"max\": 0.4616035348927198}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.2913334, \"EndTime\": 1740876881.2913408, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.44010204442462764, \"count\": 1, \"min\": 0.44010204442462764, \"max\": 0.44010204442462764}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.2913704, \"EndTime\": 1740876881.2913783, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4615930946924353, \"count\": 1, \"min\": 0.4615930946924353, \"max\": 0.4615930946924353}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.291405, \"EndTime\": 1740876881.2914138, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4245354937722908, \"count\": 1, \"min\": 0.4245354937722908, \"max\": 0.4245354937722908}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.2914503, \"EndTime\": 1740876881.2914598, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42576675396942776, \"count\": 1, \"min\": 0.42576675396942776, \"max\": 0.42576675396942776}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.2914937, \"EndTime\": 1740876881.291503, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4245293663695671, \"count\": 1, \"min\": 0.4245293663695671, \"max\": 0.4245293663695671}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.291537, \"EndTime\": 1740876881.2915468, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42576846859260575, \"count\": 1, \"min\": 0.42576846859260575, \"max\": 0.42576846859260575}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.2915845, \"EndTime\": 1740876881.2915936, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.43937421222037715, \"count\": 1, \"min\": 0.43937421222037715, \"max\": 0.43937421222037715}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.2916312, \"EndTime\": 1740876881.2916377, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4590456099694172, \"count\": 1, \"min\": 0.4590456099694172, \"max\": 0.4590456099694172}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.2916684, \"EndTime\": 1740876881.2916775, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.43937614626103305, \"count\": 1, \"min\": 0.43937614626103305, \"max\": 0.43937614626103305}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.29171, \"EndTime\": 1740876881.2917173, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45904698694604323, \"count\": 1, \"min\": 0.45904698694604323, \"max\": 0.45904698694604323}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.2917495, \"EndTime\": 1740876881.2917564, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5416050364441845, \"count\": 1, \"min\": 0.5416050364441845, \"max\": 0.5416050364441845}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.2917914, \"EndTime\": 1740876881.2918003, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.542209395119693, \"count\": 1, \"min\": 0.542209395119693, \"max\": 0.542209395119693}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.2918382, \"EndTime\": 1740876881.2918482, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5416050825897158, \"count\": 1, \"min\": 0.5416050825897158, \"max\": 0.5416050825897158}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.2918794, \"EndTime\": 1740876881.2918887, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5422115796431192, \"count\": 1, \"min\": 0.5422115796431192, \"max\": 0.5422115796431192}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.291925, \"EndTime\": 1740876881.2919345, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5477717798921897, \"count\": 1, \"min\": 0.5477717798921897, \"max\": 0.5477717798921897}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.2919967, \"EndTime\": 1740876881.292008, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5589687569393228, \"count\": 1, \"min\": 0.5589687569393228, \"max\": 0.5589687569393228}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.2920468, \"EndTime\": 1740876881.292057, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5477693269405087, \"count\": 1, \"min\": 0.5477693269405087, \"max\": 0.5477693269405087}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.2920973, \"EndTime\": 1740876881.2921078, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5589732010857656, \"count\": 1, \"min\": 0.5589732010857656, \"max\": 0.5589732010857656}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.2921488, \"EndTime\": 1740876881.2921593, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6467490217340361, \"count\": 1, \"min\": 0.6467490217340361, \"max\": 0.6467490217340361}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.292196, \"EndTime\": 1740876881.292206, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6471414873676915, \"count\": 1, \"min\": 0.6471414873676915, \"max\": 0.6471414873676915}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.2922373, \"EndTime\": 1740876881.2922454, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6467535138356392, \"count\": 1, \"min\": 0.6467535138356392, \"max\": 0.6467535138356392}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.2922788, \"EndTime\": 1740876881.2922885, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6471030086297765, \"count\": 1, \"min\": 0.6471030086297765, \"max\": 0.6471030086297765}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.2923281, \"EndTime\": 1740876881.2923388, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6504464098202285, \"count\": 1, \"min\": 0.6504464098202285, \"max\": 0.6504464098202285}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.2923748, \"EndTime\": 1740876881.292385, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575582813115757, \"count\": 1, \"min\": 0.6575582813115757, \"max\": 0.6575582813115757}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.29242, \"EndTime\": 1740876881.29243, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6504865353202458, \"count\": 1, \"min\": 0.6504865353202458, \"max\": 0.6504865353202458}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.2924697, \"EndTime\": 1740876881.2924795, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575249950015642, \"count\": 1, \"min\": 0.6575249950015642, \"max\": 0.6575249950015642}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:41 INFO 140224006256448] #quality_metric: host=algo-1, epoch=10, train binary_classification_cross_entropy_objective <loss>=0.4332713381087456\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9627259, \"EndTime\": 1740876881.9627779, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43902282711352997, \"count\": 1, \"min\": 0.43902282711352997, \"max\": 0.43902282711352997}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9628458, \"EndTime\": 1740876881.962859, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4258397435374002, \"count\": 1, \"min\": 0.4258397435374002, \"max\": 0.4258397435374002}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.962896, \"EndTime\": 1740876881.962907, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4249336537120981, \"count\": 1, \"min\": 0.4249336537120981, \"max\": 0.4249336537120981}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9629374, \"EndTime\": 1740876881.962948, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42581129894424147, \"count\": 1, \"min\": 0.42581129894424147, \"max\": 0.42581129894424147}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.962985, \"EndTime\": 1740876881.9629924, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43907669976375463, \"count\": 1, \"min\": 0.43907669976375463, \"max\": 0.43907669976375463}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9630198, \"EndTime\": 1740876881.9630277, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4661729238043767, \"count\": 1, \"min\": 0.4661729238043767, \"max\": 0.4661729238043767}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9630597, \"EndTime\": 1740876881.9630673, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4390806460624907, \"count\": 1, \"min\": 0.4390806460624907, \"max\": 0.4390806460624907}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.963098, \"EndTime\": 1740876881.9631045, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46615198869830865, \"count\": 1, \"min\": 0.46615198869830865, \"max\": 0.46615198869830865}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9631271, \"EndTime\": 1740876881.9631352, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4262450711793467, \"count\": 1, \"min\": 0.4262450711793467, \"max\": 0.4262450711793467}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9631662, \"EndTime\": 1740876881.9631739, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4271718748841069, \"count\": 1, \"min\": 0.4271718748841069, \"max\": 0.4271718748841069}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9632018, \"EndTime\": 1740876881.9632092, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42623559849154025, \"count\": 1, \"min\": 0.42623559849154025, \"max\": 0.42623559849154025}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9632356, \"EndTime\": 1740876881.9632437, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4271581277665771, \"count\": 1, \"min\": 0.4271581277665771, \"max\": 0.4271581277665771}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9632769, \"EndTime\": 1740876881.963286, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4393766992786793, \"count\": 1, \"min\": 0.4393766992786793, \"max\": 0.4393766992786793}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9633114, \"EndTime\": 1740876881.963317, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46555964402189015, \"count\": 1, \"min\": 0.46555964402189015, \"max\": 0.46555964402189015}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9633343, \"EndTime\": 1740876881.963341, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4393799304962158, \"count\": 1, \"min\": 0.4393799304962158, \"max\": 0.4393799304962158}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9633658, \"EndTime\": 1740876881.9633737, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46556073435927203, \"count\": 1, \"min\": 0.46556073435927203, \"max\": 0.46556073435927203}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.963401, \"EndTime\": 1740876881.9634092, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5528753048155353, \"count\": 1, \"min\": 0.5528753048155353, \"max\": 0.5528753048155353}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.963439, \"EndTime\": 1740876881.9634476, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5527410364081186, \"count\": 1, \"min\": 0.5527410364081186, \"max\": 0.5527410364081186}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9634845, \"EndTime\": 1740876881.963494, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5528722193370277, \"count\": 1, \"min\": 0.5528722193370277, \"max\": 0.5528722193370277}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9635308, \"EndTime\": 1740876881.9635406, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5527783651477596, \"count\": 1, \"min\": 0.5527783651477596, \"max\": 0.5527783651477596}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9635763, \"EndTime\": 1740876881.963586, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5554673566999757, \"count\": 1, \"min\": 0.5554673566999757, \"max\": 0.5554673566999757}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.963625, \"EndTime\": 1740876881.963635, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5498168847222279, \"count\": 1, \"min\": 0.5498168847222279, \"max\": 0.5498168847222279}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.963673, \"EndTime\": 1740876881.9636843, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5554602463807403, \"count\": 1, \"min\": 0.5554602463807403, \"max\": 0.5554602463807403}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9637206, \"EndTime\": 1740876881.9637306, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5498534498591723, \"count\": 1, \"min\": 0.5498534498591723, \"max\": 0.5498534498591723}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.963764, \"EndTime\": 1740876881.9637733, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6631006129838711, \"count\": 1, \"min\": 0.6631006129838711, \"max\": 0.6631006129838711}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9638133, \"EndTime\": 1740876881.9638226, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6629479566744445, \"count\": 1, \"min\": 0.6629479566744445, \"max\": 0.6629479566744445}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9638548, \"EndTime\": 1740876881.9638636, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6630964073220249, \"count\": 1, \"min\": 0.6630964073220249, \"max\": 0.6630964073220249}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9638999, \"EndTime\": 1740876881.9639087, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6636171155932358, \"count\": 1, \"min\": 0.6636171155932358, \"max\": 0.6636171155932358}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9639566, \"EndTime\": 1740876881.9639642, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.662822296992926, \"count\": 1, \"min\": 0.662822296992926, \"max\": 0.662822296992926}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.963992, \"EndTime\": 1740876881.963999, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6630011723645435, \"count\": 1, \"min\": 0.6630011723645435, \"max\": 0.6630011723645435}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9640348, \"EndTime\": 1740876881.9640436, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6635561598516663, \"count\": 1, \"min\": 0.6635561598516663, \"max\": 0.6635561598516663}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9640777, \"EndTime\": 1740876881.964087, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6636037238345838, \"count\": 1, \"min\": 0.6636037238345838, \"max\": 0.6636037238345838}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:41 INFO 140224006256448] #quality_metric: host=algo-1, epoch=10, validation binary_classification_cross_entropy_objective <loss>=0.43902282711352997\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:41 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=10, criteria=sampled_accuracy, value=0.8081991215227221\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:41 INFO 140224006256448] Epoch 10: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:41 INFO 140224006256448] Saving model for epoch: 10\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:41 INFO 140224006256448] Saved checkpoint to \"/tmp/tmp8ua5hjjk/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:41 INFO 140224006256448] #progress_metric: host=algo-1, completed 36.666666666666664 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876878.9548142, \"EndTime\": 1740876881.9698808, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 38266.0, \"count\": 1, \"min\": 38266, \"max\": 38266}, \"Total Batches Seen\": {\"sum\": 1129.0, \"count\": 1, \"min\": 1129, \"max\": 1129}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 13.0, \"count\": 1, \"min\": 13, \"max\": 13}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:41 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1056.6517913114988 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3006442, \"EndTime\": 1740876884.3006897, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.43210153471134194, \"count\": 1, \"min\": 0.43210153471134194, \"max\": 0.43210153471134194}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3007495, \"EndTime\": 1740876884.3007593, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.425154088645853, \"count\": 1, \"min\": 0.425154088645853, \"max\": 0.425154088645853}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.300791, \"EndTime\": 1740876884.3008003, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4237887877440769, \"count\": 1, \"min\": 0.4237887877440769, \"max\": 0.4237887877440769}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3008296, \"EndTime\": 1740876884.3008392, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4251511906763182, \"count\": 1, \"min\": 0.4251511906763182, \"max\": 0.4251511906763182}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3008752, \"EndTime\": 1740876884.3008852, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.438705218886364, \"count\": 1, \"min\": 0.438705218886364, \"max\": 0.438705218886364}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.300922, \"EndTime\": 1740876884.300932, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4612451879982704, \"count\": 1, \"min\": 0.4612451879982704, \"max\": 0.4612451879982704}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3009667, \"EndTime\": 1740876884.3009775, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.43871248937120627, \"count\": 1, \"min\": 0.43871248937120627, \"max\": 0.43871248937120627}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3010075, \"EndTime\": 1740876884.3010159, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.461236585325112, \"count\": 1, \"min\": 0.461236585325112, \"max\": 0.461236585325112}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3010435, \"EndTime\": 1740876884.3010523, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42444050017977575, \"count\": 1, \"min\": 0.42444050017977575, \"max\": 0.42444050017977575}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.301087, \"EndTime\": 1740876884.3010967, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4257533464305089, \"count\": 1, \"min\": 0.4257533464305089, \"max\": 0.4257533464305089}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3011289, \"EndTime\": 1740876884.301138, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42443519826933673, \"count\": 1, \"min\": 0.42443519826933673, \"max\": 0.42443519826933673}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3011785, \"EndTime\": 1740876884.3011887, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4257548748127348, \"count\": 1, \"min\": 0.4257548748127348, \"max\": 0.4257548748127348}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3012187, \"EndTime\": 1740876884.301228, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.43819600958223964, \"count\": 1, \"min\": 0.43819600958223964, \"max\": 0.43819600958223964}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3012638, \"EndTime\": 1740876884.3012729, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4587114480083159, \"count\": 1, \"min\": 0.4587114480083159, \"max\": 0.4587114480083159}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3013034, \"EndTime\": 1740876884.3013117, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.43819746844456364, \"count\": 1, \"min\": 0.43819746844456364, \"max\": 0.43819746844456364}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.301342, \"EndTime\": 1740876884.3013506, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45871264417287594, \"count\": 1, \"min\": 0.45871264417287594, \"max\": 0.45871264417287594}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.301396, \"EndTime\": 1740876884.3014061, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5415376862870372, \"count\": 1, \"min\": 0.5415376862870372, \"max\": 0.5415376862870372}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.301447, \"EndTime\": 1740876884.3014562, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5422005985146606, \"count\": 1, \"min\": 0.5422005985146606, \"max\": 0.5422005985146606}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3014889, \"EndTime\": 1740876884.301498, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5415378539792953, \"count\": 1, \"min\": 0.5415378539792953, \"max\": 0.5415378539792953}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3015323, \"EndTime\": 1740876884.3015409, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5422024805284918, \"count\": 1, \"min\": 0.5422024805284918, \"max\": 0.5422024805284918}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.301571, \"EndTime\": 1740876884.3015804, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5471900403688106, \"count\": 1, \"min\": 0.5471900403688106, \"max\": 0.5471900403688106}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3016133, \"EndTime\": 1740876884.3016233, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5589157242627177, \"count\": 1, \"min\": 0.5589157242627177, \"max\": 0.5589157242627177}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3016577, \"EndTime\": 1740876884.301667, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5471882542652996, \"count\": 1, \"min\": 0.5471882542652996, \"max\": 0.5471882542652996}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3017004, \"EndTime\": 1740876884.3017104, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.558918783138403, \"count\": 1, \"min\": 0.558918783138403, \"max\": 0.558918783138403}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3017364, \"EndTime\": 1740876884.3017445, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6467252938827331, \"count\": 1, \"min\": 0.6467252938827331, \"max\": 0.6467252938827331}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3017733, \"EndTime\": 1740876884.3017821, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6471322654999184, \"count\": 1, \"min\": 0.6471322654999184, \"max\": 0.6471322654999184}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3018117, \"EndTime\": 1740876884.3018212, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.646732531794259, \"count\": 1, \"min\": 0.646732531794259, \"max\": 0.646732531794259}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.301853, \"EndTime\": 1740876884.3018625, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470938983557724, \"count\": 1, \"min\": 0.6470938983557724, \"max\": 0.6470938983557724}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3018963, \"EndTime\": 1740876884.3019066, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6502316358495105, \"count\": 1, \"min\": 0.6502316358495105, \"max\": 0.6502316358495105}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3019419, \"EndTime\": 1740876884.301952, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.657550623566195, \"count\": 1, \"min\": 0.657550623566195, \"max\": 0.657550623566195}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3019853, \"EndTime\": 1740876884.3019962, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.65017797131089, \"count\": 1, \"min\": 0.65017797131089, \"max\": 0.65017797131089}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.3020296, \"EndTime\": 1740876884.3020394, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575532740690073, \"count\": 1, \"min\": 0.6575532740690073, \"max\": 0.6575532740690073}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:44 INFO 140224006256448] #quality_metric: host=algo-1, epoch=11, train binary_classification_cross_entropy_objective <loss>=0.43210153471134194\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.975226, \"EndTime\": 1740876884.975281, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4376931628580498, \"count\": 1, \"min\": 0.4376931628580498, \"max\": 0.4376931628580498}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9753492, \"EndTime\": 1740876884.97536, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4258234713821076, \"count\": 1, \"min\": 0.4258234713821076, \"max\": 0.4258234713821076}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.975386, \"EndTime\": 1740876884.9753945, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4249315550700812, \"count\": 1, \"min\": 0.4249315550700812, \"max\": 0.4249315550700812}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.975431, \"EndTime\": 1740876884.9754398, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42580184004491806, \"count\": 1, \"min\": 0.42580184004491806, \"max\": 0.42580184004491806}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9754763, \"EndTime\": 1740876884.9754848, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4368825622917443, \"count\": 1, \"min\": 0.4368825622917443, \"max\": 0.4368825622917443}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9755118, \"EndTime\": 1740876884.9755194, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46554886631525805, \"count\": 1, \"min\": 0.46554886631525805, \"max\": 0.46554886631525805}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.975554, \"EndTime\": 1740876884.9755623, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4368836565562258, \"count\": 1, \"min\": 0.4368836565562258, \"max\": 0.4368836565562258}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9755924, \"EndTime\": 1740876884.9756007, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4655302728950366, \"count\": 1, \"min\": 0.4655302728950366, \"max\": 0.4655302728950366}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.975637, \"EndTime\": 1740876884.9756472, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42624462698074944, \"count\": 1, \"min\": 0.42624462698074944, \"max\": 0.42624462698074944}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9756866, \"EndTime\": 1740876884.975696, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42714708877691937, \"count\": 1, \"min\": 0.42714708877691937, \"max\": 0.42714708877691937}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9757292, \"EndTime\": 1740876884.9757383, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4262333787203184, \"count\": 1, \"min\": 0.4262333787203184, \"max\": 0.4262333787203184}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.97577, \"EndTime\": 1740876884.9757788, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4271366428665675, \"count\": 1, \"min\": 0.4271366428665675, \"max\": 0.4271366428665675}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.975819, \"EndTime\": 1740876884.9758286, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4372579063538402, \"count\": 1, \"min\": 0.4372579063538402, \"max\": 0.4372579063538402}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9758615, \"EndTime\": 1740876884.97587, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46494555900945145, \"count\": 1, \"min\": 0.46494555900945145, \"max\": 0.46494555900945145}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9759047, \"EndTime\": 1740876884.9759138, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43725992435941236, \"count\": 1, \"min\": 0.43725992435941236, \"max\": 0.43725992435941236}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9759622, \"EndTime\": 1740876884.9759724, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4649468249318191, \"count\": 1, \"min\": 0.4649468249318191, \"max\": 0.4649468249318191}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9760048, \"EndTime\": 1740876884.9760127, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5529223226698042, \"count\": 1, \"min\": 0.5529223226698042, \"max\": 0.5529223226698042}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9760418, \"EndTime\": 1740876884.9760509, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.552718103891934, \"count\": 1, \"min\": 0.552718103891934, \"max\": 0.552718103891934}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9760816, \"EndTime\": 1740876884.9760916, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.552921817557529, \"count\": 1, \"min\": 0.552921817557529, \"max\": 0.552921817557529}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9761238, \"EndTime\": 1740876884.9761317, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5527500020637345, \"count\": 1, \"min\": 0.5527500020637345, \"max\": 0.5527500020637345}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9761577, \"EndTime\": 1740876884.9761662, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.55800500481579, \"count\": 1, \"min\": 0.55800500481579, \"max\": 0.55800500481579}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9761908, \"EndTime\": 1740876884.9761965, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5500858800477548, \"count\": 1, \"min\": 0.5500858800477548, \"max\": 0.5500858800477548}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9762142, \"EndTime\": 1740876884.9762194, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5579976197741217, \"count\": 1, \"min\": 0.5579976197741217, \"max\": 0.5579976197741217}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.976239, \"EndTime\": 1740876884.9762468, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5501183552413873, \"count\": 1, \"min\": 0.5501183552413873, \"max\": 0.5501183552413873}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.976272, \"EndTime\": 1740876884.9762802, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6630716421593684, \"count\": 1, \"min\": 0.6630716421593684, \"max\": 0.6630716421593684}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.976315, \"EndTime\": 1740876884.976324, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6628978220994092, \"count\": 1, \"min\": 0.6628978220994092, \"max\": 0.6628978220994092}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9763587, \"EndTime\": 1740876884.976369, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6631121270653095, \"count\": 1, \"min\": 0.6631121270653095, \"max\": 0.6631121270653095}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9764016, \"EndTime\": 1740876884.976408, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6636215357619882, \"count\": 1, \"min\": 0.6636215357619882, \"max\": 0.6636215357619882}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9764454, \"EndTime\": 1740876884.9764552, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6637758718228096, \"count\": 1, \"min\": 0.6637758718228096, \"max\": 0.6637758718228096}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9764893, \"EndTime\": 1740876884.9764988, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6629253486239544, \"count\": 1, \"min\": 0.6629253486239544, \"max\": 0.6629253486239544}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9765344, \"EndTime\": 1740876884.9765434, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6643129712840649, \"count\": 1, \"min\": 0.6643129712840649, \"max\": 0.6643129712840649}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9765723, \"EndTime\": 1740876884.9765782, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6635576442953085, \"count\": 1, \"min\": 0.6635576442953085, \"max\": 0.6635576442953085}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:44 INFO 140224006256448] #quality_metric: host=algo-1, epoch=11, validation binary_classification_cross_entropy_objective <loss>=0.4376931628580498\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:44 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=11, criteria=sampled_accuracy, value=0.8081991215227221\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:44 INFO 140224006256448] Epoch 11: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:44 INFO 140224006256448] Saving model for epoch: 11\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:44 INFO 140224006256448] Saved checkpoint to \"/tmp/tmp9j3fp0_n/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:44 INFO 140224006256448] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876881.9701235, \"EndTime\": 1740876884.9826531, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 11, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 41452.0, \"count\": 1, \"min\": 41452, \"max\": 41452}, \"Total Batches Seen\": {\"sum\": 1223.0, \"count\": 1, \"min\": 1223, \"max\": 1223}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 14.0, \"count\": 1, \"min\": 14, \"max\": 14}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:44 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1057.5465573485071 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.263484, \"EndTime\": 1740876887.26353, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.43116962479911675, \"count\": 1, \"min\": 0.43116962479911675, \"max\": 0.43116962479911675}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2635932, \"EndTime\": 1740876887.2636049, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42514001244913546, \"count\": 1, \"min\": 0.42514001244913546, \"max\": 0.42514001244913546}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2636395, \"EndTime\": 1740876887.26365, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4237050697970888, \"count\": 1, \"min\": 0.4237050697970888, \"max\": 0.4237050697970888}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2636857, \"EndTime\": 1740876887.2636967, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4251373557634251, \"count\": 1, \"min\": 0.4251373557634251, \"max\": 0.4251373557634251}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2637339, \"EndTime\": 1740876887.2637434, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.43737123526778876, \"count\": 1, \"min\": 0.43737123526778876, \"max\": 0.43737123526778876}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.263777, \"EndTime\": 1740876887.263786, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4608892660062574, \"count\": 1, \"min\": 0.4608892660062574, \"max\": 0.4608892660062574}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2638211, \"EndTime\": 1740876887.2638314, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.43737654034507795, \"count\": 1, \"min\": 0.43737654034507795, \"max\": 0.43737654034507795}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2638617, \"EndTime\": 1740876887.2638698, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4608820879632804, \"count\": 1, \"min\": 0.4608820879632804, \"max\": 0.4608820879632804}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2639012, \"EndTime\": 1740876887.263911, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42435410428394027, \"count\": 1, \"min\": 0.42435410428394027, \"max\": 0.42435410428394027}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2639728, \"EndTime\": 1740876887.2639844, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42573893741291585, \"count\": 1, \"min\": 0.42573893741291585, \"max\": 0.42573893741291585}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.264022, \"EndTime\": 1740876887.264031, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4243495708624824, \"count\": 1, \"min\": 0.4243495708624824, \"max\": 0.4243495708624824}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2640612, \"EndTime\": 1740876887.2640715, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.425740284681471, \"count\": 1, \"min\": 0.425740284681471, \"max\": 0.425740284681471}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2641091, \"EndTime\": 1740876887.2641184, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4370441424703387, \"count\": 1, \"min\": 0.4370441424703387, \"max\": 0.4370441424703387}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2641487, \"EndTime\": 1740876887.2641566, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4583854768790451, \"count\": 1, \"min\": 0.4583854768790451, \"max\": 0.4583854768790451}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2641842, \"EndTime\": 1740876887.2641928, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4370451986902805, \"count\": 1, \"min\": 0.4370451986902805, \"max\": 0.4370451986902805}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2642238, \"EndTime\": 1740876887.264233, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45838650746258053, \"count\": 1, \"min\": 0.45838650746258053, \"max\": 0.45838650746258053}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2642658, \"EndTime\": 1740876887.2642746, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.541472008226794, \"count\": 1, \"min\": 0.541472008226794, \"max\": 0.541472008226794}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2643085, \"EndTime\": 1740876887.264318, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421939330490083, \"count\": 1, \"min\": 0.5421939330490083, \"max\": 0.5421939330490083}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2643454, \"EndTime\": 1740876887.2643538, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5414722464945707, \"count\": 1, \"min\": 0.5414722464945707, \"max\": 0.5414722464945707}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2643843, \"EndTime\": 1740876887.2643936, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421955309511362, \"count\": 1, \"min\": 0.5421955309511362, \"max\": 0.5421955309511362}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2644322, \"EndTime\": 1740876887.2644408, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5467614385615717, \"count\": 1, \"min\": 0.5467614385615717, \"max\": 0.5467614385615717}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.264474, \"EndTime\": 1740876887.2644823, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5588577775394216, \"count\": 1, \"min\": 0.5588577775394216, \"max\": 0.5588577775394216}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2645166, \"EndTime\": 1740876887.2645261, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5467603006067342, \"count\": 1, \"min\": 0.5467603006067342, \"max\": 0.5467603006067342}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2645643, \"EndTime\": 1740876887.2645743, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5588598525803123, \"count\": 1, \"min\": 0.5588598525803123, \"max\": 0.5588598525803123}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2646122, \"EndTime\": 1740876887.2646217, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6467032513989444, \"count\": 1, \"min\": 0.6467032513989444, \"max\": 0.6467032513989444}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2646563, \"EndTime\": 1740876887.264666, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6471224446450511, \"count\": 1, \"min\": 0.6471224446450511, \"max\": 0.6471224446450511}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2647038, \"EndTime\": 1740876887.2647138, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6467095561452789, \"count\": 1, \"min\": 0.6467095561452789, \"max\": 0.6467095561452789}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2647517, \"EndTime\": 1740876887.264762, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470871846333551, \"count\": 1, \"min\": 0.6470871846333551, \"max\": 0.6470871846333551}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2648005, \"EndTime\": 1740876887.2648103, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6500410560110865, \"count\": 1, \"min\": 0.6500410560110865, \"max\": 0.6500410560110865}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2648911, \"EndTime\": 1740876887.264906, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575335026692168, \"count\": 1, \"min\": 0.6575335026692168, \"max\": 0.6575335026692168}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2649531, \"EndTime\": 1740876887.264964, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6499066138704844, \"count\": 1, \"min\": 0.6499066138704844, \"max\": 0.6499066138704844}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.2650402, \"EndTime\": 1740876887.265529, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575565609579068, \"count\": 1, \"min\": 0.6575565609579068, \"max\": 0.6575565609579068}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:47 INFO 140224006256448] #quality_metric: host=algo-1, epoch=12, train binary_classification_cross_entropy_objective <loss>=0.43116962479911675\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9763005, \"EndTime\": 1740876887.9763575, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4366143669600368, \"count\": 1, \"min\": 0.4366143669600368, \"max\": 0.4366143669600368}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.976425, \"EndTime\": 1740876887.976436, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4258065951516304, \"count\": 1, \"min\": 0.4258065951516304, \"max\": 0.4258065951516304}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9764688, \"EndTime\": 1740876887.9764786, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42493556044984876, \"count\": 1, \"min\": 0.42493556044984876, \"max\": 0.42493556044984876}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.976509, \"EndTime\": 1740876887.9765189, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42578996309947825, \"count\": 1, \"min\": 0.42578996309947825, \"max\": 0.42578996309947825}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.976555, \"EndTime\": 1740876887.9765646, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4350321092158774, \"count\": 1, \"min\": 0.4350321092158774, \"max\": 0.4350321092158774}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9766045, \"EndTime\": 1740876887.9766142, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46510827288271567, \"count\": 1, \"min\": 0.46510827288271567, \"max\": 0.46510827288271567}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.97665, \"EndTime\": 1740876887.9766593, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4350324736507187, \"count\": 1, \"min\": 0.4350324736507187, \"max\": 0.4350324736507187}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9766912, \"EndTime\": 1740876887.9766994, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4650918154555917, \"count\": 1, \"min\": 0.4650918154555917, \"max\": 0.4650918154555917}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.976726, \"EndTime\": 1740876887.9767349, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4262506717469647, \"count\": 1, \"min\": 0.4262506717469647, \"max\": 0.4262506717469647}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9767637, \"EndTime\": 1740876887.9767725, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4271245812601785, \"count\": 1, \"min\": 0.4271245812601785, \"max\": 0.4271245812601785}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9768035, \"EndTime\": 1740876887.976813, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42623865255325116, \"count\": 1, \"min\": 0.42623865255325116, \"max\": 0.42623865255325116}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.976845, \"EndTime\": 1740876887.976855, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42711641725649074, \"count\": 1, \"min\": 0.42711641725649074, \"max\": 0.42711641725649074}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9768898, \"EndTime\": 1740876887.9768987, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4353386792047481, \"count\": 1, \"min\": 0.4353386792047481, \"max\": 0.4353386792047481}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9769316, \"EndTime\": 1740876887.9769413, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46448889387823306, \"count\": 1, \"min\": 0.46448889387823306, \"max\": 0.46448889387823306}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9769735, \"EndTime\": 1740876887.9769826, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43534017167712724, \"count\": 1, \"min\": 0.43534017167712724, \"max\": 0.43534017167712724}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9770138, \"EndTime\": 1740876887.9770222, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4644901816178206, \"count\": 1, \"min\": 0.4644901816178206, \"max\": 0.4644901816178206}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9770567, \"EndTime\": 1740876887.9770668, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5529556714249215, \"count\": 1, \"min\": 0.5529556714249215, \"max\": 0.5529556714249215}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9770951, \"EndTime\": 1740876887.9771035, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5527009283291997, \"count\": 1, \"min\": 0.5527009283291997, \"max\": 0.5527009283291997}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9771292, \"EndTime\": 1740876887.9771383, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5529565994421873, \"count\": 1, \"min\": 0.5529565994421873, \"max\": 0.5529565994421873}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9771712, \"EndTime\": 1740876887.97718, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5527284047614079, \"count\": 1, \"min\": 0.5527284047614079, \"max\": 0.5527284047614079}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9772131, \"EndTime\": 1740876887.9772234, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5603628703127145, \"count\": 1, \"min\": 0.5603628703127145, \"max\": 0.5603628703127145}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9772556, \"EndTime\": 1740876887.977265, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5504795354770532, \"count\": 1, \"min\": 0.5504795354770532, \"max\": 0.5504795354770532}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9772983, \"EndTime\": 1740876887.9773076, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5603519849162849, \"count\": 1, \"min\": 0.5603519849162849, \"max\": 0.5603519849162849}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9773345, \"EndTime\": 1740876887.9773424, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5505081064355496, \"count\": 1, \"min\": 0.5505081064355496, \"max\": 0.5505081064355496}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9773703, \"EndTime\": 1740876887.9773905, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6630286714866604, \"count\": 1, \"min\": 0.6630286714866604, \"max\": 0.6630286714866604}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.977423, \"EndTime\": 1740876887.977434, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6628677539560142, \"count\": 1, \"min\": 0.6628677539560142, \"max\": 0.6628677539560142}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9774652, \"EndTime\": 1740876887.9774754, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6631188774876853, \"count\": 1, \"min\": 0.6631188774876853, \"max\": 0.6631188774876853}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9775138, \"EndTime\": 1740876887.9775229, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6636230530187291, \"count\": 1, \"min\": 0.6636230530187291, \"max\": 0.6636230530187291}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9779456, \"EndTime\": 1740876887.9779637, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6640494852429079, \"count\": 1, \"min\": 0.6640494852429079, \"max\": 0.6640494852429079}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.97802, \"EndTime\": 1740876887.978032, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6632753769440323, \"count\": 1, \"min\": 0.6632753769440323, \"max\": 0.6632753769440323}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9780672, \"EndTime\": 1740876887.9780765, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6641847382178244, \"count\": 1, \"min\": 0.6641847382178244, \"max\": 0.6641847382178244}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9781106, \"EndTime\": 1740876887.9781199, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.663412818273374, \"count\": 1, \"min\": 0.663412818273374, \"max\": 0.663412818273374}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:47 INFO 140224006256448] #quality_metric: host=algo-1, epoch=12, validation binary_classification_cross_entropy_objective <loss>=0.4366143669600368\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:47 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=12, criteria=sampled_accuracy, value=0.8081991215227221\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:47 INFO 140224006256448] Epoch 12: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:47 INFO 140224006256448] Saving model for epoch: 12\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:47 INFO 140224006256448] Saved checkpoint to \"/tmp/tmpmwfvnu6q/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:47 INFO 140224006256448] #progress_metric: host=algo-1, completed 43.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876884.9828284, \"EndTime\": 1740876887.9834907, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 12, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 44638.0, \"count\": 1, \"min\": 44638, \"max\": 44638}, \"Total Batches Seen\": {\"sum\": 1317.0, \"count\": 1, \"min\": 1317, \"max\": 1317}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 15.0, \"count\": 1, \"min\": 15, \"max\": 15}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:47 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1061.7141291721953 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.283337, \"EndTime\": 1740876890.2833817, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.43041603102252723, \"count\": 1, \"min\": 0.43041603102252723, \"max\": 0.43041603102252723}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.2834423, \"EndTime\": 1740876890.2834513, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42512501650863926, \"count\": 1, \"min\": 0.42512501650863926, \"max\": 0.42512501650863926}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.2834797, \"EndTime\": 1740876890.2834892, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4236269957803609, \"count\": 1, \"min\": 0.4236269957803609, \"max\": 0.4236269957803609}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.283516, \"EndTime\": 1740876890.283522, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4251226006543463, \"count\": 1, \"min\": 0.4251226006543463, \"max\": 0.4251226006543463}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.2835455, \"EndTime\": 1740876890.2835536, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4361135466501428, \"count\": 1, \"min\": 0.4361135466501428, \"max\": 0.4361135466501428}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.283585, \"EndTime\": 1740876890.2835941, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.460584551378717, \"count\": 1, \"min\": 0.460584551378717, \"max\": 0.460584551378717}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.2836285, \"EndTime\": 1740876890.2836378, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.43611759117025123, \"count\": 1, \"min\": 0.43611759117025123, \"max\": 0.43611759117025123}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.2836683, \"EndTime\": 1740876890.283674, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.46057852999007376, \"count\": 1, \"min\": 0.46057852999007376, \"max\": 0.46057852999007376}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.2836945, \"EndTime\": 1740876890.2837, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42427447579617295, \"count\": 1, \"min\": 0.42427447579617295, \"max\": 0.42427447579617295}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.2837186, \"EndTime\": 1740876890.2837238, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4257235961349458, \"count\": 1, \"min\": 0.4257235961349458, \"max\": 0.4257235961349458}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.2837498, \"EndTime\": 1740876890.2837582, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42427061796942367, \"count\": 1, \"min\": 0.42427061796942367, \"max\": 0.42427061796942367}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.283794, \"EndTime\": 1740876890.2838187, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.425724768774333, \"count\": 1, \"min\": 0.425724768774333, \"max\": 0.425724768774333}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.2838433, \"EndTime\": 1740876890.2838492, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4359233958445193, \"count\": 1, \"min\": 0.4359233958445193, \"max\": 0.4359233958445193}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.283872, \"EndTime\": 1740876890.2838776, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4581077331082117, \"count\": 1, \"min\": 0.4581077331082117, \"max\": 0.4581077331082117}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.2839, \"EndTime\": 1740876890.2839055, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4359241741356557, \"count\": 1, \"min\": 0.4359241741356557, \"max\": 0.4359241741356557}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.2839282, \"EndTime\": 1740876890.2839336, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45810863354928427, \"count\": 1, \"min\": 0.45810863354928427, \"max\": 0.45810863354928427}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.2839746, \"EndTime\": 1740876890.2839808, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5414091043273231, \"count\": 1, \"min\": 0.5414091043273231, \"max\": 0.5414091043273231}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.2840035, \"EndTime\": 1740876890.2840092, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421893908810118, \"count\": 1, \"min\": 0.5421893908810118, \"max\": 0.5421893908810118}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.2840312, \"EndTime\": 1740876890.2840366, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5414093706443444, \"count\": 1, \"min\": 0.5414093706443444, \"max\": 0.5414093706443444}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.284055, \"EndTime\": 1740876890.28406, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421907571506681, \"count\": 1, \"min\": 0.5421907571506681, \"max\": 0.5421907571506681}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.2840817, \"EndTime\": 1740876890.284087, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5464445915801249, \"count\": 1, \"min\": 0.5464445915801249, \"max\": 0.5464445915801249}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.284109, \"EndTime\": 1740876890.2841144, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5587959751006095, \"count\": 1, \"min\": 0.5587959751006095, \"max\": 0.5587959751006095}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.2841346, \"EndTime\": 1740876890.2841399, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5464438758719804, \"count\": 1, \"min\": 0.5464438758719804, \"max\": 0.5464438758719804}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.284159, \"EndTime\": 1740876890.2841663, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5587974363757718, \"count\": 1, \"min\": 0.5587974363757718, \"max\": 0.5587974363757718}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.284198, \"EndTime\": 1740876890.284208, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6466836482946213, \"count\": 1, \"min\": 0.6466836482946213, \"max\": 0.6466836482946213}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.284246, \"EndTime\": 1740876890.2842548, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6471113763528108, \"count\": 1, \"min\": 0.6471113763528108, \"max\": 0.6471113763528108}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.2842782, \"EndTime\": 1740876890.2842836, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6466887140485171, \"count\": 1, \"min\": 0.6466887140485171, \"max\": 0.6466887140485171}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.2843032, \"EndTime\": 1740876890.2843084, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470819614417639, \"count\": 1, \"min\": 0.6470819614417639, \"max\": 0.6470819614417639}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.2843285, \"EndTime\": 1740876890.2843356, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6498075572091669, \"count\": 1, \"min\": 0.6498075572091669, \"max\": 0.6498075572091669}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.2843714, \"EndTime\": 1740876890.2843816, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575308600081288, \"count\": 1, \"min\": 0.6575308600081288, \"max\": 0.6575308600081288}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.2844195, \"EndTime\": 1740876890.2844293, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6496792997761968, \"count\": 1, \"min\": 0.6496792997761968, \"max\": 0.6496792997761968}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.284464, \"EndTime\": 1740876890.284473, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575593212448593, \"count\": 1, \"min\": 0.6575593212448593, \"max\": 0.6575593212448593}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:50 INFO 140224006256448] #quality_metric: host=algo-1, epoch=13, train binary_classification_cross_entropy_objective <loss>=0.43041603102252723\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9683628, \"EndTime\": 1740876890.968426, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43572795635435624, \"count\": 1, \"min\": 0.43572795635435624, \"max\": 0.43572795635435624}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9685, \"EndTime\": 1740876890.9685102, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4257919997805907, \"count\": 1, \"min\": 0.4257919997805907, \"max\": 0.4257919997805907}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9685395, \"EndTime\": 1740876890.9685462, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4249416903904905, \"count\": 1, \"min\": 0.4249416903904905, \"max\": 0.4249416903904905}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9685664, \"EndTime\": 1740876890.9685721, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4257790270870985, \"count\": 1, \"min\": 0.4257790270870985, \"max\": 0.4257790270870985}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9685905, \"EndTime\": 1740876890.9685957, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43361433603054955, \"count\": 1, \"min\": 0.43361433603054955, \"max\": 0.43361433603054955}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9686136, \"EndTime\": 1740876890.9686189, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46476362495087253, \"count\": 1, \"min\": 0.46476362495087253, \"max\": 0.46476362495087253}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9686363, \"EndTime\": 1740876890.968641, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43361457846349716, \"count\": 1, \"min\": 0.43361457846349716, \"max\": 0.43361457846349716}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9686582, \"EndTime\": 1740876890.968663, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46474870214699654, \"count\": 1, \"min\": 0.46474870214699654, \"max\": 0.46474870214699654}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.96868, \"EndTime\": 1740876890.968685, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42625917854281153, \"count\": 1, \"min\": 0.42625917854281153, \"max\": 0.42625917854281153}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.968707, \"EndTime\": 1740876890.9687128, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4271067375669019, \"count\": 1, \"min\": 0.4271067375669019, \"max\": 0.4271067375669019}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9687302, \"EndTime\": 1740876890.968735, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4262469844622633, \"count\": 1, \"min\": 0.4262469844622633, \"max\": 0.4262469844622633}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9687521, \"EndTime\": 1740876890.968757, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42710025942343044, \"count\": 1, \"min\": 0.42710025942343044, \"max\": 0.42710025942343044}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9687772, \"EndTime\": 1740876890.9687824, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4338446530904812, \"count\": 1, \"min\": 0.4338446530904812, \"max\": 0.4338446530904812}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9687996, \"EndTime\": 1740876890.9688044, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4641467718568414, \"count\": 1, \"min\": 0.4641467718568414, \"max\": 0.4641467718568414}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9688213, \"EndTime\": 1740876890.968826, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4338457582635726, \"count\": 1, \"min\": 0.4338457582635726, \"max\": 0.4338457582635726}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9688425, \"EndTime\": 1740876890.9688473, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46414804336441734, \"count\": 1, \"min\": 0.46414804336441734, \"max\": 0.46414804336441734}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9688678, \"EndTime\": 1740876890.9688735, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5529833677747065, \"count\": 1, \"min\": 0.5529833677747065, \"max\": 0.5529833677747065}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9688911, \"EndTime\": 1740876890.9688962, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5527067332805338, \"count\": 1, \"min\": 0.5527067332805338, \"max\": 0.5527067332805338}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9689128, \"EndTime\": 1740876890.968918, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5529850147130025, \"count\": 1, \"min\": 0.5529850147130025, \"max\": 0.5529850147130025}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9689348, \"EndTime\": 1740876890.9689395, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5527305892760024, \"count\": 1, \"min\": 0.5527305892760024, \"max\": 0.5527305892760024}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9689562, \"EndTime\": 1740876890.968961, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5619934036302358, \"count\": 1, \"min\": 0.5619934036302358, \"max\": 0.5619934036302358}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9689782, \"EndTime\": 1740876890.9689827, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.550773687802506, \"count\": 1, \"min\": 0.550773687802506, \"max\": 0.550773687802506}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9689994, \"EndTime\": 1740876890.9690044, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5619795943772635, \"count\": 1, \"min\": 0.5619795943772635, \"max\": 0.5619795943772635}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9690216, \"EndTime\": 1740876890.9690263, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.550798504802877, \"count\": 1, \"min\": 0.550798504802877, \"max\": 0.550798504802877}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.969043, \"EndTime\": 1740876890.9690478, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6629776870872754, \"count\": 1, \"min\": 0.6629776870872754, \"max\": 0.6629776870872754}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.969065, \"EndTime\": 1740876890.9690697, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6628535907404663, \"count\": 1, \"min\": 0.6628535907404663, \"max\": 0.6628535907404663}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9690924, \"EndTime\": 1740876890.9690998, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6631034893661432, \"count\": 1, \"min\": 0.6631034893661432, \"max\": 0.6631034893661432}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.969127, \"EndTime\": 1740876890.969133, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6636226145798779, \"count\": 1, \"min\": 0.6636226145798779, \"max\": 0.6636226145798779}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9691644, \"EndTime\": 1740876890.9691722, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.663644586265698, \"count\": 1, \"min\": 0.663644586265698, \"max\": 0.663644586265698}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9692018, \"EndTime\": 1740876890.9692109, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6634681249258284, \"count\": 1, \"min\": 0.6634681249258284, \"max\": 0.6634681249258284}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.969246, \"EndTime\": 1740876890.9692547, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6635897358549462, \"count\": 1, \"min\": 0.6635897358549462, \"max\": 0.6635897358549462}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9692838, \"EndTime\": 1740876890.9692903, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6633036260549007, \"count\": 1, \"min\": 0.6633036260549007, \"max\": 0.6633036260549007}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:50 INFO 140224006256448] #quality_metric: host=algo-1, epoch=13, validation binary_classification_cross_entropy_objective <loss>=0.43572795635435624\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:50 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=13, criteria=sampled_accuracy, value=0.811127379209398\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:50 INFO 140224006256448] Epoch 13: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:50 INFO 140224006256448] Saving model for epoch: 13\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:50 INFO 140224006256448] Saved checkpoint to \"/tmp/tmpaou7gcuf/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:50 INFO 140224006256448] #progress_metric: host=algo-1, completed 46.666666666666664 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876887.9837308, \"EndTime\": 1740876890.9755228, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 13, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 47824.0, \"count\": 1, \"min\": 47824, \"max\": 47824}, \"Total Batches Seen\": {\"sum\": 1411.0, \"count\": 1, \"min\": 1411, \"max\": 1411}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 16.0, \"count\": 1, \"min\": 16, \"max\": 16}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:50 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1064.874326039123 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2374947, \"EndTime\": 1740876893.23754, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42979897614297496, \"count\": 1, \"min\": 0.42979897614297496, \"max\": 0.42979897614297496}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2376, \"EndTime\": 1740876893.237612, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42510909388745455, \"count\": 1, \"min\": 0.42510909388745455, \"max\": 0.42510909388745455}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2376487, \"EndTime\": 1740876893.23766, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4235551587996944, \"count\": 1, \"min\": 0.4235551587996944, \"max\": 0.4235551587996944}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2377255, \"EndTime\": 1740876893.2377357, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4251069102688427, \"count\": 1, \"min\": 0.4251069102688427, \"max\": 0.4251069102688427}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2377741, \"EndTime\": 1740876893.2377846, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4349691787903102, \"count\": 1, \"min\": 0.4349691787903102, \"max\": 0.4349691787903102}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2378573, \"EndTime\": 1740876893.237869, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4602411562396634, \"count\": 1, \"min\": 0.4602411562396634, \"max\": 0.4602411562396634}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2379105, \"EndTime\": 1740876893.237921, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4349723984213436, \"count\": 1, \"min\": 0.4349723984213436, \"max\": 0.4349723984213436}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2379594, \"EndTime\": 1740876893.2379692, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.46023607781836684, \"count\": 1, \"min\": 0.46023607781836684, \"max\": 0.46023607781836684}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2380106, \"EndTime\": 1740876893.2380202, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42420191858329026, \"count\": 1, \"min\": 0.42420191858329026, \"max\": 0.42420191858329026}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2380893, \"EndTime\": 1740876893.2381008, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42570750808353897, \"count\": 1, \"min\": 0.42570750808353897, \"max\": 0.42570750808353897}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2381315, \"EndTime\": 1740876893.2381403, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42419864466339635, \"count\": 1, \"min\": 0.42419864466339635, \"max\": 0.42419864466339635}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2381766, \"EndTime\": 1740876893.2381873, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4257085496756489, \"count\": 1, \"min\": 0.4257085496756489, \"max\": 0.4257085496756489}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2382145, \"EndTime\": 1740876893.2382238, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.43488330180549983, \"count\": 1, \"min\": 0.43488330180549983, \"max\": 0.43488330180549983}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.238282, \"EndTime\": 1740876893.2382896, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4577912552910165, \"count\": 1, \"min\": 0.4577912552910165, \"max\": 0.4577912552910165}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2383118, \"EndTime\": 1740876893.2383199, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.43488386867168505, \"count\": 1, \"min\": 0.43488386867168505, \"max\": 0.43488386867168505}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2383473, \"EndTime\": 1740876893.2383566, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4577920613297928, \"count\": 1, \"min\": 0.4577920613297928, \"max\": 0.4577920613297928}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2384331, \"EndTime\": 1740876893.2384443, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5413513041839503, \"count\": 1, \"min\": 0.5413513041839503, \"max\": 0.5413513041839503}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2385097, \"EndTime\": 1740876893.238521, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421845817927844, \"count\": 1, \"min\": 0.5421845817927844, \"max\": 0.5421845817927844}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2385497, \"EndTime\": 1740876893.2385597, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5413515855812107, \"count\": 1, \"min\": 0.5413515855812107, \"max\": 0.5413515855812107}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2386215, \"EndTime\": 1740876893.238633, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421857547337763, \"count\": 1, \"min\": 0.5421857547337763, \"max\": 0.5421857547337763}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2387013, \"EndTime\": 1740876893.2387152, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.54610614818836, \"count\": 1, \"min\": 0.54610614818836, \"max\": 0.54610614818836}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2387872, \"EndTime\": 1740876893.2388005, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5587150729358535, \"count\": 1, \"min\": 0.5587150729358535, \"max\": 0.5587150729358535}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.238878, \"EndTime\": 1740876893.2388897, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5461055516141039, \"count\": 1, \"min\": 0.5461055516141039, \"max\": 0.5461055516141039}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2389317, \"EndTime\": 1740876893.2389414, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5587162268757443, \"count\": 1, \"min\": 0.5587162268757443, \"max\": 0.5587162268757443}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.238976, \"EndTime\": 1740876893.2389858, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.646665049534218, \"count\": 1, \"min\": 0.646665049534218, \"max\": 0.646665049534218}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2390382, \"EndTime\": 1740876893.2390487, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470987270483105, \"count\": 1, \"min\": 0.6470987270483105, \"max\": 0.6470987270483105}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2390893, \"EndTime\": 1740876893.239099, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6466709814970437, \"count\": 1, \"min\": 0.6466709814970437, \"max\": 0.6466709814970437}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2391217, \"EndTime\": 1740876893.2391298, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470764849021569, \"count\": 1, \"min\": 0.6470764849021569, \"max\": 0.6470764849021569}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.239164, \"EndTime\": 1740876893.239173, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6495113897595053, \"count\": 1, \"min\": 0.6495113897595053, \"max\": 0.6495113897595053}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2392547, \"EndTime\": 1740876893.239265, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575136860287092, \"count\": 1, \"min\": 0.6575136860287092, \"max\": 0.6575136860287092}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.2393024, \"EndTime\": 1740876893.2393124, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6494200843410504, \"count\": 1, \"min\": 0.6494200843410504, \"max\": 0.6494200843410504}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.239379, \"EndTime\": 1740876893.2393887, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575533953141292, \"count\": 1, \"min\": 0.6575533953141292, \"max\": 0.6575533953141292}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:53 INFO 140224006256448] #quality_metric: host=algo-1, epoch=14, train binary_classification_cross_entropy_objective <loss>=0.42979897614297496\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.9638588, \"EndTime\": 1740876893.963915, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4349919412705071, \"count\": 1, \"min\": 0.4349919412705071, \"max\": 0.4349919412705071}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.9640093, \"EndTime\": 1740876893.9640238, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4257735013961792, \"count\": 1, \"min\": 0.4257735013961792, \"max\": 0.4257735013961792}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.964065, \"EndTime\": 1740876893.9640765, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4249504312414725, \"count\": 1, \"min\": 0.4249504312414725, \"max\": 0.4249504312414725}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.9641159, \"EndTime\": 1740876893.9641268, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4257632790686969, \"count\": 1, \"min\": 0.4257632790686969, \"max\": 0.4257632790686969}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.9641588, \"EndTime\": 1740876893.964169, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43257624495605423, \"count\": 1, \"min\": 0.43257624495605423, \"max\": 0.43257624495605423}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.964204, \"EndTime\": 1740876893.9642148, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46434480309660925, \"count\": 1, \"min\": 0.46434480309660925, \"max\": 0.46434480309660925}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.9642467, \"EndTime\": 1740876893.9642546, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43257650746084414, \"count\": 1, \"min\": 0.43257650746084414, \"max\": 0.43257650746084414}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.9642808, \"EndTime\": 1740876893.9642887, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46433151082447993, \"count\": 1, \"min\": 0.46433151082447993, \"max\": 0.46433151082447993}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.9643192, \"EndTime\": 1740876893.9643292, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4262705320495114, \"count\": 1, \"min\": 0.4262705320495114, \"max\": 0.4262705320495114}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.9643633, \"EndTime\": 1740876893.9643726, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42708648088910395, \"count\": 1, \"min\": 0.42708648088910395, \"max\": 0.42708648088910395}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.9644082, \"EndTime\": 1740876893.964419, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42625843588464607, \"count\": 1, \"min\": 0.42625843588464607, \"max\": 0.42625843588464607}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.96445, \"EndTime\": 1740876893.9644585, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42708126168648985, \"count\": 1, \"min\": 0.42708126168648985, \"max\": 0.42708126168648985}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.964493, \"EndTime\": 1740876893.9645028, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43280065269107176, \"count\": 1, \"min\": 0.43280065269107176, \"max\": 0.43280065269107176}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.9645412, \"EndTime\": 1740876893.9645522, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4637496864114988, \"count\": 1, \"min\": 0.4637496864114988, \"max\": 0.4637496864114988}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.9645774, \"EndTime\": 1740876893.9645855, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43280149815197744, \"count\": 1, \"min\": 0.43280149815197744, \"max\": 0.43280149815197744}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.9646122, \"EndTime\": 1740876893.9646213, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4637508950854814, \"count\": 1, \"min\": 0.4637508950854814, \"max\": 0.4637508950854814}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.964649, \"EndTime\": 1740876893.9646575, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530050544403657, \"count\": 1, \"min\": 0.5530050544403657, \"max\": 0.5530050544403657}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.9646895, \"EndTime\": 1740876893.9646988, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5526998896549945, \"count\": 1, \"min\": 0.5526998896549945, \"max\": 0.5526998896549945}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.9647334, \"EndTime\": 1740876893.964744, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530070413782168, \"count\": 1, \"min\": 0.5530070413782168, \"max\": 0.5530070413782168}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.9647741, \"EndTime\": 1740876893.9647834, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.552720630151461, \"count\": 1, \"min\": 0.552720630151461, \"max\": 0.552720630151461}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.9648187, \"EndTime\": 1740876893.964828, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5627877909477423, \"count\": 1, \"min\": 0.5627877909477423, \"max\": 0.5627877909477423}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.9648607, \"EndTime\": 1740876893.9648693, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5512867085581119, \"count\": 1, \"min\": 0.5512867085581119, \"max\": 0.5512867085581119}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.964897, \"EndTime\": 1740876893.9649038, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5627744683060429, \"count\": 1, \"min\": 0.5627744683060429, \"max\": 0.5627744683060429}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.9649322, \"EndTime\": 1740876893.964938, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5513078663743607, \"count\": 1, \"min\": 0.5513078663743607, \"max\": 0.5513078663743607}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.964956, \"EndTime\": 1740876893.9649613, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6629258306972453, \"count\": 1, \"min\": 0.6629258306972453, \"max\": 0.6629258306972453}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.964988, \"EndTime\": 1740876893.964996, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6628671757124179, \"count\": 1, \"min\": 0.6628671757124179, \"max\": 0.6628671757124179}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.9650266, \"EndTime\": 1740876893.9650352, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6630637153524954, \"count\": 1, \"min\": 0.6630637153524954, \"max\": 0.6630637153524954}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.965289, \"EndTime\": 1740876893.965297, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6636274681258865, \"count\": 1, \"min\": 0.6636274681258865, \"max\": 0.6636274681258865}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.965316, \"EndTime\": 1740876893.9653213, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6630762077180742, \"count\": 1, \"min\": 0.6630762077180742, \"max\": 0.6630762077180742}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.965339, \"EndTime\": 1740876893.965344, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6635672983278468, \"count\": 1, \"min\": 0.6635672983278468, \"max\": 0.6635672983278468}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.9653609, \"EndTime\": 1740876893.9653656, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6632709946499736, \"count\": 1, \"min\": 0.6632709946499736, \"max\": 0.6632709946499736}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.9653966, \"EndTime\": 1740876893.9654024, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6633444080241079, \"count\": 1, \"min\": 0.6633444080241079, \"max\": 0.6633444080241079}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:53 INFO 140224006256448] #quality_metric: host=algo-1, epoch=14, validation binary_classification_cross_entropy_objective <loss>=0.4349919412705071\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:53 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=14, criteria=sampled_accuracy, value=0.811127379209398\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:53 INFO 140224006256448] Epoch 14: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:53 INFO 140224006256448] Saving model for epoch: 14\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:53 INFO 140224006256448] Saved checkpoint to \"/tmp/tmptmipoyhf/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:53 INFO 140224006256448] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876890.9757614, \"EndTime\": 1740876893.9708178, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 14, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 51010.0, \"count\": 1, \"min\": 51010, \"max\": 51010}, \"Total Batches Seen\": {\"sum\": 1505.0, \"count\": 1, \"min\": 1505, \"max\": 1505}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 17.0, \"count\": 1, \"min\": 17, \"max\": 17}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:53 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1063.6956863222072 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.292349, \"EndTime\": 1740876896.292406, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4292879970219978, \"count\": 1, \"min\": 0.4292879970219978, \"max\": 0.4292879970219978}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.2924683, \"EndTime\": 1740876896.2924776, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42509287267753704, \"count\": 1, \"min\": 0.42509287267753704, \"max\": 0.42509287267753704}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.292503, \"EndTime\": 1740876896.292512, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42348889818981733, \"count\": 1, \"min\": 0.42348889818981733, \"max\": 0.42348889818981733}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.2925477, \"EndTime\": 1740876896.2925572, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4250908927929545, \"count\": 1, \"min\": 0.4250908927929545, \"max\": 0.4250908927929545}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.2925935, \"EndTime\": 1740876896.292602, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4339599152443757, \"count\": 1, \"min\": 0.4339599152443757, \"max\": 0.4339599152443757}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.2926335, \"EndTime\": 1740876896.2926435, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4598825264399298, \"count\": 1, \"min\": 0.4598825264399298, \"max\": 0.4598825264399298}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.292675, \"EndTime\": 1740876896.2926853, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4339625218636925, \"count\": 1, \"min\": 0.4339625218636925, \"max\": 0.4339625218636925}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.2927194, \"EndTime\": 1740876896.2927291, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45987822857180555, \"count\": 1, \"min\": 0.45987822857180555, \"max\": 0.45987822857180555}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.292765, \"EndTime\": 1740876896.2927747, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4241354545409886, \"count\": 1, \"min\": 0.4241354545409886, \"max\": 0.4241354545409886}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.2928073, \"EndTime\": 1740876896.2928164, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4256914328503352, \"count\": 1, \"min\": 0.4256914328503352, \"max\": 0.4256914328503352}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.2928436, \"EndTime\": 1740876896.2928522, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42413268415027594, \"count\": 1, \"min\": 0.42413268415027594, \"max\": 0.42413268415027594}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.29288, \"EndTime\": 1740876896.292886, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4256923509352875, \"count\": 1, \"min\": 0.4256923509352875, \"max\": 0.4256923509352875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.292904, \"EndTime\": 1740876896.2929094, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4339668960378262, \"count\": 1, \"min\": 0.4339668960378262, \"max\": 0.4339668960378262}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.292929, \"EndTime\": 1740876896.2929368, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45745899042398547, \"count\": 1, \"min\": 0.45745899042398547, \"max\": 0.45745899042398547}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.2929654, \"EndTime\": 1740876896.292974, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4339673250706267, \"count\": 1, \"min\": 0.4339673250706267, \"max\": 0.4339673250706267}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.2930028, \"EndTime\": 1740876896.2930112, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4574596912026933, \"count\": 1, \"min\": 0.4574596912026933, \"max\": 0.4574596912026933}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.2930462, \"EndTime\": 1740876896.2930558, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5412966609378166, \"count\": 1, \"min\": 0.5412966609378166, \"max\": 0.5412966609378166}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.2930887, \"EndTime\": 1740876896.2930977, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421807610634232, \"count\": 1, \"min\": 0.5421807610634232, \"max\": 0.5421807610634232}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.2931287, \"EndTime\": 1740876896.2931385, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5412969266516283, \"count\": 1, \"min\": 0.5412969266516283, \"max\": 0.5412969266516283}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.293173, \"EndTime\": 1740876896.293197, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421817726458574, \"count\": 1, \"min\": 0.5421817726458574, \"max\": 0.5421817726458574}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.29323, \"EndTime\": 1740876896.2932403, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5456916768666991, \"count\": 1, \"min\": 0.5456916768666991, \"max\": 0.5456916768666991}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.293272, \"EndTime\": 1740876896.2932804, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5586285404130524, \"count\": 1, \"min\": 0.5586285404130524, \"max\": 0.5586285404130524}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.2933073, \"EndTime\": 1740876896.2933154, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5456910615929466, \"count\": 1, \"min\": 0.5456910615929466, \"max\": 0.5456910615929466}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.2933443, \"EndTime\": 1740876896.2933538, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.558629525454266, \"count\": 1, \"min\": 0.558629525454266, \"max\": 0.558629525454266}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.2933977, \"EndTime\": 1740876896.2934074, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6466462408568873, \"count\": 1, \"min\": 0.6466462408568873, \"max\": 0.6466462408568873}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.2934394, \"EndTime\": 1740876896.293448, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470860795534389, \"count\": 1, \"min\": 0.6470860795534389, \"max\": 0.6470860795534389}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.2934794, \"EndTime\": 1740876896.293488, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.646654392027689, \"count\": 1, \"min\": 0.646654392027689, \"max\": 0.646654392027689}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.2935178, \"EndTime\": 1740876896.293527, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.647071259900937, \"count\": 1, \"min\": 0.647071259900937, \"max\": 0.647071259900937}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.2935586, \"EndTime\": 1740876896.2935684, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6492104280002504, \"count\": 1, \"min\": 0.6492104280002504, \"max\": 0.6492104280002504}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.2936, \"EndTime\": 1740876896.2936096, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6574881986151158, \"count\": 1, \"min\": 0.6574881986151158, \"max\": 0.6574881986151158}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.2936835, \"EndTime\": 1740876896.293694, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6491230693819552, \"count\": 1, \"min\": 0.6491230693819552, \"max\": 0.6491230693819552}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876896.293736, \"EndTime\": 1740876896.293746, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575408039177467, \"count\": 1, \"min\": 0.6575408039177467, \"max\": 0.6575408039177467}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:56 INFO 140224006256448] #quality_metric: host=algo-1, epoch=15, train binary_classification_cross_entropy_objective <loss>=0.4292879970219978\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0011551, \"EndTime\": 1740876897.0012102, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43437524875121447, \"count\": 1, \"min\": 0.43437524875121447, \"max\": 0.43437524875121447}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0012798, \"EndTime\": 1740876897.0012894, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42575110715444403, \"count\": 1, \"min\": 0.42575110715444403, \"max\": 0.42575110715444403}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0013137, \"EndTime\": 1740876897.001322, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4249616339475484, \"count\": 1, \"min\": 0.4249616339475484, \"max\": 0.4249616339475484}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0013554, \"EndTime\": 1740876897.0013638, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4257429771856194, \"count\": 1, \"min\": 0.4257429771856194, \"max\": 0.4257429771856194}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0014086, \"EndTime\": 1740876897.0014172, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.431770542355617, \"count\": 1, \"min\": 0.431770542355617, \"max\": 0.431770542355617}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0014448, \"EndTime\": 1740876897.0014522, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46382013840347225, \"count\": 1, \"min\": 0.46382013840347225, \"max\": 0.46382013840347225}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0014827, \"EndTime\": 1740876897.001492, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4317708017187272, \"count\": 1, \"min\": 0.4317708017187272, \"max\": 0.4317708017187272}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0015278, \"EndTime\": 1740876897.001537, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4638081659858782, \"count\": 1, \"min\": 0.4638081659858782, \"max\": 0.4638081659858782}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0015683, \"EndTime\": 1740876897.0015767, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42628428824300474, \"count\": 1, \"min\": 0.42628428824300474, \"max\": 0.42628428824300474}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.001608, \"EndTime\": 1740876897.0016174, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42706311988272044, \"count\": 1, \"min\": 0.42706311988272044, \"max\": 0.42706311988272044}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.001652, \"EndTime\": 1740876897.0016615, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4262724469032679, \"count\": 1, \"min\": 0.4262724469032679, \"max\": 0.4262724469032679}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0016975, \"EndTime\": 1740876897.0017076, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42705885225996965, \"count\": 1, \"min\": 0.42705885225996965, \"max\": 0.42705885225996965}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0017436, \"EndTime\": 1740876897.0017543, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4320477816231254, \"count\": 1, \"min\": 0.4320477816231254, \"max\": 0.4320477816231254}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0017934, \"EndTime\": 1740876897.0018036, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4632244841420633, \"count\": 1, \"min\": 0.4632244841420633, \"max\": 0.4632244841420633}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0018365, \"EndTime\": 1740876897.001846, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43204850962011915, \"count\": 1, \"min\": 0.43204850962011915, \"max\": 0.43204850962011915}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0018787, \"EndTime\": 1740876897.0018897, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4632256629700891, \"count\": 1, \"min\": 0.4632256629700891, \"max\": 0.4632256629700891}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.001928, \"EndTime\": 1740876897.0019395, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530181936428802, \"count\": 1, \"min\": 0.5530181936428802, \"max\": 0.5530181936428802}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.001971, \"EndTime\": 1740876897.0019796, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5526852886987466, \"count\": 1, \"min\": 0.5526852886987466, \"max\": 0.5526852886987466}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0020084, \"EndTime\": 1740876897.002018, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530202193281137, \"count\": 1, \"min\": 0.5530202193281137, \"max\": 0.5530202193281137}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0020497, \"EndTime\": 1740876897.002059, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5527033259543982, \"count\": 1, \"min\": 0.5527033259543982, \"max\": 0.5527033259543982}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0020912, \"EndTime\": 1740876897.0021007, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5628428720974119, \"count\": 1, \"min\": 0.5628428720974119, \"max\": 0.5628428720974119}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0021336, \"EndTime\": 1740876897.0021424, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.551760675093789, \"count\": 1, \"min\": 0.551760675093789, \"max\": 0.551760675093789}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0021741, \"EndTime\": 1740876897.0021842, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5628325743696176, \"count\": 1, \"min\": 0.5628325743696176, \"max\": 0.5628325743696176}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0022233, \"EndTime\": 1740876897.0022328, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5517781601119705, \"count\": 1, \"min\": 0.5517781601119705, \"max\": 0.5517781601119705}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0022697, \"EndTime\": 1740876897.0022788, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.662870157864572, \"count\": 1, \"min\": 0.662870157864572, \"max\": 0.662870157864572}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0023096, \"EndTime\": 1740876897.0023189, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6629001682359688, \"count\": 1, \"min\": 0.6629001682359688, \"max\": 0.6629001682359688}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0023506, \"EndTime\": 1740876897.00236, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6630043271345415, \"count\": 1, \"min\": 0.6630043271345415, \"max\": 0.6630043271345415}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0023918, \"EndTime\": 1740876897.0024014, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6636327234578168, \"count\": 1, \"min\": 0.6636327234578168, \"max\": 0.6636327234578168}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0024326, \"EndTime\": 1740876897.0024428, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.662896521793103, \"count\": 1, \"min\": 0.662896521793103, \"max\": 0.662896521793103}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.002473, \"EndTime\": 1740876897.0024827, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6635776686633489, \"count\": 1, \"min\": 0.6635776686633489, \"max\": 0.6635776686633489}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0025153, \"EndTime\": 1740876897.0025244, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6628619181114968, \"count\": 1, \"min\": 0.6628619181114968, \"max\": 0.6628619181114968}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0034473, \"EndTime\": 1740876897.0034683, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6633424364455797, \"count\": 1, \"min\": 0.6633424364455797, \"max\": 0.6633424364455797}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:57 INFO 140224006256448] #quality_metric: host=algo-1, epoch=15, validation binary_classification_cross_entropy_objective <loss>=0.43437524875121447\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:57 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=15, criteria=sampled_accuracy, value=0.811127379209398\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:57 INFO 140224006256448] Epoch 15: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:57 INFO 140224006256448] Saving model for epoch: 15\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:57 INFO 140224006256448] Saved checkpoint to \"/tmp/tmp2_uixvin/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:57 INFO 140224006256448] #progress_metric: host=algo-1, completed 53.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876893.971071, \"EndTime\": 1740876897.0086365, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 15, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 54196.0, \"count\": 1, \"min\": 54196, \"max\": 54196}, \"Total Batches Seen\": {\"sum\": 1599.0, \"count\": 1, \"min\": 1599, \"max\": 1599}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 18.0, \"count\": 1, \"min\": 18, \"max\": 18}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:57 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1048.829895184137 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3324425, \"EndTime\": 1740876899.3324876, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.428860507985597, \"count\": 1, \"min\": 0.428860507985597, \"max\": 0.428860507985597}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3325498, \"EndTime\": 1740876899.3325617, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4250770777859769, \"count\": 1, \"min\": 0.4250770777859769, \"max\": 0.4250770777859769}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3325963, \"EndTime\": 1740876899.3326066, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4234275997325938, \"count\": 1, \"min\": 0.4234275997325938, \"max\": 0.4234275997325938}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.332636, \"EndTime\": 1740876899.3326461, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42507529922258547, \"count\": 1, \"min\": 0.42507529922258547, \"max\": 0.42507529922258547}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3326771, \"EndTime\": 1740876899.3326867, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4330520375026773, \"count\": 1, \"min\": 0.4330520375026773, \"max\": 0.4330520375026773}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3327196, \"EndTime\": 1740876899.3327277, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4595250955191992, \"count\": 1, \"min\": 0.4595250955191992, \"max\": 0.4595250955191992}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3327532, \"EndTime\": 1740876899.3327606, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4330541707532908, \"count\": 1, \"min\": 0.4330541707532908, \"max\": 0.4330541707532908}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3327887, \"EndTime\": 1740876899.3327968, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45952140990877965, \"count\": 1, \"min\": 0.45952140990877965, \"max\": 0.45952140990877965}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3328269, \"EndTime\": 1740876899.3328362, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4240740906355277, \"count\": 1, \"min\": 0.4240740906355277, \"max\": 0.4240740906355277}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3328626, \"EndTime\": 1740876899.332871, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4256757423140292, \"count\": 1, \"min\": 0.4256757423140292, \"max\": 0.4256757423140292}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3329003, \"EndTime\": 1740876899.3329103, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42407174565835815, \"count\": 1, \"min\": 0.42407174565835815, \"max\": 0.42407174565835815}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3329399, \"EndTime\": 1740876899.3329482, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42567656041699675, \"count\": 1, \"min\": 0.42567656041699675, \"max\": 0.42567656041699675}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3329778, \"EndTime\": 1740876899.3329868, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.43314685465639563, \"count\": 1, \"min\": 0.43314685465639563, \"max\": 0.43314685465639563}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3330188, \"EndTime\": 1740876899.3330276, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45712891354883567, \"count\": 1, \"min\": 0.45712891354883567, \"max\": 0.45712891354883567}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.333058, \"EndTime\": 1740876899.3330674, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4331471915489356, \"count\": 1, \"min\": 0.4331471915489356, \"max\": 0.4331471915489356}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.333095, \"EndTime\": 1740876899.333103, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45712953847394117, \"count\": 1, \"min\": 0.45712953847394117, \"max\": 0.45712953847394117}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3331294, \"EndTime\": 1740876899.3331387, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5412441177657704, \"count\": 1, \"min\": 0.5412441177657704, \"max\": 0.5412441177657704}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3331697, \"EndTime\": 1740876899.3331785, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421738054539719, \"count\": 1, \"min\": 0.5421738054539719, \"max\": 0.5421738054539719}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3332083, \"EndTime\": 1740876899.3332174, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5412443741298341, \"count\": 1, \"min\": 0.5412443741298341, \"max\": 0.5412443741298341}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3332472, \"EndTime\": 1740876899.3332558, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421746719645066, \"count\": 1, \"min\": 0.5421746719645066, \"max\": 0.5421746719645066}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3332853, \"EndTime\": 1740876899.3332946, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5452460304684913, \"count\": 1, \"min\": 0.5452460304684913, \"max\": 0.5452460304684913}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3333242, \"EndTime\": 1740876899.333333, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5585521879564125, \"count\": 1, \"min\": 0.5585521879564125, \"max\": 0.5585521879564125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3333619, \"EndTime\": 1740876899.3333714, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5452454010193142, \"count\": 1, \"min\": 0.5452454010193142, \"max\": 0.5452454010193142}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.333417, \"EndTime\": 1740876899.3334272, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5585530650231146, \"count\": 1, \"min\": 0.5585530650231146, \"max\": 0.5585530650231146}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3334596, \"EndTime\": 1740876899.3334684, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6466277187040982, \"count\": 1, \"min\": 0.6466277187040982, \"max\": 0.6466277187040982}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3334985, \"EndTime\": 1740876899.3335075, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.647074463546917, \"count\": 1, \"min\": 0.647074463546917, \"max\": 0.647074463546917}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3335383, \"EndTime\": 1740876899.3335478, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6466368802509151, \"count\": 1, \"min\": 0.6466368802509151, \"max\": 0.6466368802509151}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3335783, \"EndTime\": 1740876899.333588, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470665735658553, \"count\": 1, \"min\": 0.6470665735658553, \"max\": 0.6470665735658553}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.333623, \"EndTime\": 1740876899.3336318, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6489802836467011, \"count\": 1, \"min\": 0.6489802836467011, \"max\": 0.6489802836467011}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3336673, \"EndTime\": 1740876899.3336773, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6574923390455445, \"count\": 1, \"min\": 0.6574923390455445, \"max\": 0.6574923390455445}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3337088, \"EndTime\": 1740876899.3337193, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6489012360497414, \"count\": 1, \"min\": 0.6489012360497414, \"max\": 0.6489012360497414}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876899.3337495, \"EndTime\": 1740876899.3337588, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575532300347093, \"count\": 1, \"min\": 0.6575532300347093, \"max\": 0.6575532300347093}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:54:59 INFO 140224006256448] #quality_metric: host=algo-1, epoch=16, train binary_classification_cross_entropy_objective <loss>=0.428860507985597\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0132878, \"EndTime\": 1740876900.0133436, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43385380742141477, \"count\": 1, \"min\": 0.43385380742141477, \"max\": 0.43385380742141477}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.01342, \"EndTime\": 1740876900.013431, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42572777320141325, \"count\": 1, \"min\": 0.42572777320141325, \"max\": 0.42572777320141325}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0134583, \"EndTime\": 1740876900.013467, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42497242596627677, \"count\": 1, \"min\": 0.42497242596627677, \"max\": 0.42497242596627677}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.013504, \"EndTime\": 1740876900.0135136, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.425721202902005, \"count\": 1, \"min\": 0.425721202902005, \"max\": 0.425721202902005}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0135489, \"EndTime\": 1740876900.0135567, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4310833957498978, \"count\": 1, \"min\": 0.4310833957498978, \"max\": 0.4310833957498978}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0135882, \"EndTime\": 1740876900.0135968, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4633133706376284, \"count\": 1, \"min\": 0.4633133706376284, \"max\": 0.4633133706376284}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0136232, \"EndTime\": 1740876900.0136318, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43108360711512417, \"count\": 1, \"min\": 0.43108360711512417, \"max\": 0.43108360711512417}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0136635, \"EndTime\": 1740876900.0136719, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46330249021552494, \"count\": 1, \"min\": 0.46330249021552494, \"max\": 0.46330249021552494}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0137098, \"EndTime\": 1740876900.0137198, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42629748853373495, \"count\": 1, \"min\": 0.42629748853373495, \"max\": 0.42629748853373495}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0137606, \"EndTime\": 1740876900.0137706, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.427039371751587, \"count\": 1, \"min\": 0.427039371751587, \"max\": 0.427039371751587}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0138104, \"EndTime\": 1740876900.0138211, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42628598283010904, \"count\": 1, \"min\": 0.42628598283010904, \"max\": 0.42628598283010904}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0138571, \"EndTime\": 1740876900.013867, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42703583928187805, \"count\": 1, \"min\": 0.42703583928187805, \"max\": 0.42703583928187805}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0139062, \"EndTime\": 1740876900.013917, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4314546546684701, \"count\": 1, \"min\": 0.4314546546684701, \"max\": 0.4314546546684701}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0139523, \"EndTime\": 1740876900.0139623, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46271492604106274, \"count\": 1, \"min\": 0.46271492604106274, \"max\": 0.46271492604106274}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0139964, \"EndTime\": 1740876900.0140057, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43145523657735935, \"count\": 1, \"min\": 0.43145523657735935, \"max\": 0.43145523657735935}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0140378, \"EndTime\": 1740876900.0140467, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46271614710722625, \"count\": 1, \"min\": 0.46271614710722625, \"max\": 0.46271614710722625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0140822, \"EndTime\": 1740876900.0140917, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530273708382603, \"count\": 1, \"min\": 0.5530273708382603, \"max\": 0.5530273708382603}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0141256, \"EndTime\": 1740876900.014135, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5526707591284421, \"count\": 1, \"min\": 0.5526707591284421, \"max\": 0.5526707591284421}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0141766, \"EndTime\": 1740876900.014187, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530293136180582, \"count\": 1, \"min\": 0.5530293136180582, \"max\": 0.5530293136180582}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0142252, \"EndTime\": 1740876900.0142357, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5526864879476902, \"count\": 1, \"min\": 0.5526864879476902, \"max\": 0.5526864879476902}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0142736, \"EndTime\": 1740876900.0142841, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5624539480376907, \"count\": 1, \"min\": 0.5624539480376907, \"max\": 0.5624539480376907}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0143237, \"EndTime\": 1740876900.014334, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5522421149872407, \"count\": 1, \"min\": 0.5522421149872407, \"max\": 0.5522421149872407}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0143688, \"EndTime\": 1740876900.0143788, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5624472354900086, \"count\": 1, \"min\": 0.5624472354900086, \"max\": 0.5624472354900086}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0144172, \"EndTime\": 1740876900.014427, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5522561628333297, \"count\": 1, \"min\": 0.5522561628333297, \"max\": 0.5522561628333297}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0144672, \"EndTime\": 1740876900.0144773, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6628161680995109, \"count\": 1, \"min\": 0.6628161680995109, \"max\": 0.6628161680995109}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0145168, \"EndTime\": 1740876900.0145278, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6629453578072096, \"count\": 1, \"min\": 0.6629453578072096, \"max\": 0.6629453578072096}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0145671, \"EndTime\": 1740876900.0145767, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6629430809621406, \"count\": 1, \"min\": 0.6629430809621406, \"max\": 0.6629430809621406}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0146132, \"EndTime\": 1740876900.014623, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6636421713612614, \"count\": 1, \"min\": 0.6636421713612614, \"max\": 0.6636421713612614}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0146608, \"EndTime\": 1740876900.014671, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6626818717660526, \"count\": 1, \"min\": 0.6626818717660526, \"max\": 0.6626818717660526}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.0147085, \"EndTime\": 1740876900.0147173, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6635644674999298, \"count\": 1, \"min\": 0.6635644674999298, \"max\": 0.6635644674999298}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.014752, \"EndTime\": 1740876900.014762, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6624410288574755, \"count\": 1, \"min\": 0.6624410288574755, \"max\": 0.6624410288574755}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.014802, \"EndTime\": 1740876900.0148125, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6633455226222383, \"count\": 1, \"min\": 0.6633455226222383, \"max\": 0.6633455226222383}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:00 INFO 140224006256448] #quality_metric: host=algo-1, epoch=16, validation binary_classification_cross_entropy_objective <loss>=0.43385380742141477\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:00 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=16, criteria=sampled_accuracy, value=0.811127379209398\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:00 INFO 140224006256448] Epoch 16: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:00 INFO 140224006256448] Saving model for epoch: 16\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:00 INFO 140224006256448] Saved checkpoint to \"/tmp/tmpaskrffvf/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:00 INFO 140224006256448] #progress_metric: host=algo-1, completed 56.666666666666664 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876897.0088792, \"EndTime\": 1740876900.0211918, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 16, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 57382.0, \"count\": 1, \"min\": 57382, \"max\": 57382}, \"Total Batches Seen\": {\"sum\": 1693.0, \"count\": 1, \"min\": 1693, \"max\": 1693}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 19.0, \"count\": 1, \"min\": 19, \"max\": 19}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:00 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1057.6218871388999 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.3991125, \"EndTime\": 1740876902.39916, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42849991428633416, \"count\": 1, \"min\": 0.42849991428633416, \"max\": 0.42849991428633416}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.3992229, \"EndTime\": 1740876902.3992321, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4250614391256932, \"count\": 1, \"min\": 0.4250614391256932, \"max\": 0.4250614391256932}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.399263, \"EndTime\": 1740876902.3992722, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4233717915379948, \"count\": 1, \"min\": 0.4233717915379948, \"max\": 0.4233717915379948}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.3993027, \"EndTime\": 1740876902.399311, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4250598265957335, \"count\": 1, \"min\": 0.4250598265957335, \"max\": 0.4250598265957335}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.3993468, \"EndTime\": 1740876902.3993576, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4322186826830194, \"count\": 1, \"min\": 0.4322186826830194, \"max\": 0.4322186826830194}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.3993897, \"EndTime\": 1740876902.3993988, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4591916283047101, \"count\": 1, \"min\": 0.4591916283047101, \"max\": 0.4591916283047101}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.4001467, \"EndTime\": 1740876902.40016, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.43222044284851924, \"count\": 1, \"min\": 0.43222044284851924, \"max\": 0.43222044284851924}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.4001946, \"EndTime\": 1740876902.400204, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4591884465250767, \"count\": 1, \"min\": 0.4591884465250767, \"max\": 0.4591884465250767}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.4002411, \"EndTime\": 1740876902.4002523, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4240184308304808, \"count\": 1, \"min\": 0.4240184308304808, \"max\": 0.4240184308304808}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.4002876, \"EndTime\": 1740876902.4002972, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.425659861615909, \"count\": 1, \"min\": 0.425659861615909, \"max\": 0.425659861615909}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.4003336, \"EndTime\": 1740876902.4003437, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42401643526244964, \"count\": 1, \"min\": 0.42401643526244964, \"max\": 0.42401643526244964}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.4003787, \"EndTime\": 1740876902.4003882, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4256605841101611, \"count\": 1, \"min\": 0.4256605841101611, \"max\": 0.4256605841101611}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.4004245, \"EndTime\": 1740876902.4004343, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4323986332149614, \"count\": 1, \"min\": 0.4323986332149614, \"max\": 0.4323986332149614}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.4004722, \"EndTime\": 1740876902.4004817, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4568098298663357, \"count\": 1, \"min\": 0.4568098298663357, \"max\": 0.4568098298663357}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.4005182, \"EndTime\": 1740876902.4005282, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4323988921426656, \"count\": 1, \"min\": 0.4323988921426656, \"max\": 0.4323988921426656}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.4005637, \"EndTime\": 1740876902.4005728, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45681039673252094, \"count\": 1, \"min\": 0.45681039673252094, \"max\": 0.45681039673252094}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.40061, \"EndTime\": 1740876902.4006205, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5411976760584368, \"count\": 1, \"min\": 0.5411976760584368, \"max\": 0.5411976760584368}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.4006581, \"EndTime\": 1740876902.4006681, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421666541030179, \"count\": 1, \"min\": 0.5421666541030179, \"max\": 0.5421666541030179}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.4007025, \"EndTime\": 1740876902.4007115, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.541197904071651, \"count\": 1, \"min\": 0.541197904071651, \"max\": 0.541197904071651}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.400747, \"EndTime\": 1740876902.4007554, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421673900186827, \"count\": 1, \"min\": 0.5421673900186827, \"max\": 0.5421673900186827}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.400782, \"EndTime\": 1740876902.4007914, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5448230457486871, \"count\": 1, \"min\": 0.5448230457486871, \"max\": 0.5448230457486871}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.4008272, \"EndTime\": 1740876902.4008338, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5584762544288129, \"count\": 1, \"min\": 0.5584762544288129, \"max\": 0.5584762544288129}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.400853, \"EndTime\": 1740876902.4008589, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5448224669691131, \"count\": 1, \"min\": 0.5448224669691131, \"max\": 0.5448224669691131}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.4008915, \"EndTime\": 1740876902.4008994, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5584771598463644, \"count\": 1, \"min\": 0.5584771598463644, \"max\": 0.5584771598463644}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.400925, \"EndTime\": 1740876902.400933, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6466105127545718, \"count\": 1, \"min\": 0.6466105127545718, \"max\": 0.6466105127545718}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.400966, \"EndTime\": 1740876902.400974, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470637945794064, \"count\": 1, \"min\": 0.6470637945794064, \"max\": 0.6470637945794064}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.4010017, \"EndTime\": 1740876902.4010108, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6466185571572812, \"count\": 1, \"min\": 0.6466185571572812, \"max\": 0.6466185571572812}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.4010427, \"EndTime\": 1740876902.4010513, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470615247018272, \"count\": 1, \"min\": 0.6470615247018272, \"max\": 0.6470615247018272}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.4010851, \"EndTime\": 1740876902.4010947, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6487782319688405, \"count\": 1, \"min\": 0.6487782319688405, \"max\": 0.6487782319688405}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.4011266, \"EndTime\": 1740876902.4011352, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575203352077033, \"count\": 1, \"min\": 0.6575203352077033, \"max\": 0.6575203352077033}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.401163, \"EndTime\": 1740876902.4011712, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6486996488432428, \"count\": 1, \"min\": 0.6486996488432428, \"max\": 0.6486996488432428}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876902.401199, \"EndTime\": 1740876902.4012074, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575833790517924, \"count\": 1, \"min\": 0.6575833790517924, \"max\": 0.6575833790517924}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:02 INFO 140224006256448] #quality_metric: host=algo-1, epoch=17, train binary_classification_cross_entropy_objective <loss>=0.42849991428633416\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0827832, \"EndTime\": 1740876903.0828366, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.433409727509863, \"count\": 1, \"min\": 0.433409727509863, \"max\": 0.433409727509863}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0829034, \"EndTime\": 1740876903.082913, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42570233240309086, \"count\": 1, \"min\": 0.42570233240309086, \"max\": 0.42570233240309086}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.082938, \"EndTime\": 1740876903.0829456, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.424982783909598, \"count\": 1, \"min\": 0.424982783909598, \"max\": 0.424982783909598}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0829802, \"EndTime\": 1740876903.0829885, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4256970341348718, \"count\": 1, \"min\": 0.4256970341348718, \"max\": 0.4256970341348718}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0830262, \"EndTime\": 1740876903.0830345, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4304588493805155, \"count\": 1, \"min\": 0.4304588493805155, \"max\": 0.4304588493805155}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0830638, \"EndTime\": 1740876903.0830715, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4628249590951911, \"count\": 1, \"min\": 0.4628249590951911, \"max\": 0.4628249590951911}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0831413, \"EndTime\": 1740876903.0831518, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4304590085589519, \"count\": 1, \"min\": 0.4304590085589519, \"max\": 0.4304590085589519}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0831895, \"EndTime\": 1740876903.0831997, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4628149955199369, \"count\": 1, \"min\": 0.4628149955199369, \"max\": 0.4628149955199369}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0832372, \"EndTime\": 1740876903.083248, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42631012279851194, \"count\": 1, \"min\": 0.42631012279851194, \"max\": 0.42631012279851194}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0832853, \"EndTime\": 1740876903.0832956, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4270138304195153, \"count\": 1, \"min\": 0.4270138304195153, \"max\": 0.4270138304195153}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0833344, \"EndTime\": 1740876903.0833445, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4262990141682883, \"count\": 1, \"min\": 0.4262990141682883, \"max\": 0.4262990141682883}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0833824, \"EndTime\": 1740876903.0833929, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42701083762055786, \"count\": 1, \"min\": 0.42701083762055786, \"max\": 0.42701083762055786}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0834281, \"EndTime\": 1740876903.0834389, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43094021509541947, \"count\": 1, \"min\": 0.43094021509541947, \"max\": 0.43094021509541947}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.083472, \"EndTime\": 1740876903.0834806, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.462225864607279, \"count\": 1, \"min\": 0.462225864607279, \"max\": 0.462225864607279}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0835145, \"EndTime\": 1740876903.0835207, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4309406273536068, \"count\": 1, \"min\": 0.4309406273536068, \"max\": 0.4309406273536068}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0835502, \"EndTime\": 1740876903.0835593, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4622269690822194, \"count\": 1, \"min\": 0.4622269690822194, \"max\": 0.4622269690822194}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0835874, \"EndTime\": 1740876903.0835955, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.55303157545288, \"count\": 1, \"min\": 0.55303157545288, \"max\": 0.55303157545288}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0836275, \"EndTime\": 1740876903.0836368, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5526566505432129, \"count\": 1, \"min\": 0.5526566505432129, \"max\": 0.5526566505432129}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0836687, \"EndTime\": 1740876903.0836787, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530333531199577, \"count\": 1, \"min\": 0.5530333531199577, \"max\": 0.5530333531199577}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.083714, \"EndTime\": 1740876903.083724, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5526703617059643, \"count\": 1, \"min\": 0.5526703617059643, \"max\": 0.5526703617059643}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0837598, \"EndTime\": 1740876903.0837698, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5617772398371996, \"count\": 1, \"min\": 0.5617772398371996, \"max\": 0.5617772398371996}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0841603, \"EndTime\": 1740876903.0841773, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5527229616268488, \"count\": 1, \"min\": 0.5527229616268488, \"max\": 0.5527229616268488}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0842144, \"EndTime\": 1740876903.0842237, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5617735022856236, \"count\": 1, \"min\": 0.5617735022856236, \"max\": 0.5617735022856236}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0842614, \"EndTime\": 1740876903.0842724, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5527338667460452, \"count\": 1, \"min\": 0.5527338667460452, \"max\": 0.5527338667460452}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.084308, \"EndTime\": 1740876903.0843182, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6627722591118094, \"count\": 1, \"min\": 0.6627722591118094, \"max\": 0.6627722591118094}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.084345, \"EndTime\": 1740876903.0843537, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6629968192182907, \"count\": 1, \"min\": 0.6629968192182907, \"max\": 0.6629968192182907}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.084384, \"EndTime\": 1740876903.0843935, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6628932179678586, \"count\": 1, \"min\": 0.6628932179678586, \"max\": 0.6628932179678586}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0844252, \"EndTime\": 1740876903.0844345, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6636556758713059, \"count\": 1, \"min\": 0.6636556758713059, \"max\": 0.6636556758713059}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0844667, \"EndTime\": 1740876903.0844758, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6621782322404675, \"count\": 1, \"min\": 0.6621782322404675, \"max\": 0.6621782322404675}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0845127, \"EndTime\": 1740876903.0845222, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6635223744030753, \"count\": 1, \"min\": 0.6635223744030753, \"max\": 0.6635223744030753}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.084557, \"EndTime\": 1740876903.084567, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6621545895301405, \"count\": 1, \"min\": 0.6621545895301405, \"max\": 0.6621545895301405}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0845957, \"EndTime\": 1740876903.0846043, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.663340588439785, \"count\": 1, \"min\": 0.663340588439785, \"max\": 0.663340588439785}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:03 INFO 140224006256448] #quality_metric: host=algo-1, epoch=17, validation binary_classification_cross_entropy_objective <loss>=0.433409727509863\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:03 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=17, criteria=sampled_accuracy, value=0.8140556368960741\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:03 INFO 140224006256448] Epoch 17: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:03 INFO 140224006256448] Saving model for epoch: 17\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:03 INFO 140224006256448] Saved checkpoint to \"/tmp/tmppdad8d8u/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:03 INFO 140224006256448] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876900.021741, \"EndTime\": 1740876903.0905268, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 17, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 60568.0, \"count\": 1, \"min\": 60568, \"max\": 60568}, \"Total Batches Seen\": {\"sum\": 1787.0, \"count\": 1, \"min\": 1787, \"max\": 1787}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:03 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1038.1668781241315 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.392239, \"EndTime\": 1740876905.3922856, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42819323998173153, \"count\": 1, \"min\": 0.42819323998173153, \"max\": 0.42819323998173153}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3923485, \"EndTime\": 1740876905.3923602, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42504664420478333, \"count\": 1, \"min\": 0.42504664420478333, \"max\": 0.42504664420478333}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3923936, \"EndTime\": 1740876905.3924036, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4233202240574141, \"count\": 1, \"min\": 0.4233202240574141, \"max\": 0.4233202240574141}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3924344, \"EndTime\": 1740876905.3924446, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42504518835850713, \"count\": 1, \"min\": 0.42504518835850713, \"max\": 0.42504518835850713}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.392476, \"EndTime\": 1740876905.3924859, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4314462675616984, \"count\": 1, \"min\": 0.4314462675616984, \"max\": 0.4314462675616984}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3925176, \"EndTime\": 1740876905.392526, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45889322505880953, \"count\": 1, \"min\": 0.45889322505880953, \"max\": 0.45889322505880953}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.392552, \"EndTime\": 1740876905.3925588, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.43144772597161524, \"count\": 1, \"min\": 0.43144772597161524, \"max\": 0.43144772597161524}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3925886, \"EndTime\": 1740876905.3925974, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4588904757804316, \"count\": 1, \"min\": 0.4588904757804316, \"max\": 0.4588904757804316}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.392635, \"EndTime\": 1740876905.392645, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42396714565197474, \"count\": 1, \"min\": 0.42396714565197474, \"max\": 0.42396714565197474}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3926735, \"EndTime\": 1740876905.392683, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42564500486601914, \"count\": 1, \"min\": 0.42564500486601914, \"max\": 0.42564500486601914}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3927152, \"EndTime\": 1740876905.3927236, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4239654326876231, \"count\": 1, \"min\": 0.4239654326876231, \"max\": 0.4239654326876231}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3927534, \"EndTime\": 1740876905.3927622, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42564564984784253, \"count\": 1, \"min\": 0.42564564984784253, \"max\": 0.42564564984784253}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3927896, \"EndTime\": 1740876905.3927975, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4317052821280608, \"count\": 1, \"min\": 0.4317052821280608, \"max\": 0.4317052821280608}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.392822, \"EndTime\": 1740876905.3928304, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45652476539346404, \"count\": 1, \"min\": 0.45652476539346404, \"max\": 0.45652476539346404}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3928614, \"EndTime\": 1740876905.3928702, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4317054832984495, \"count\": 1, \"min\": 0.4317054832984495, \"max\": 0.4317054832984495}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3929024, \"EndTime\": 1740876905.3929117, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4565252571600589, \"count\": 1, \"min\": 0.4565252571600589, \"max\": 0.4565252571600589}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3929458, \"EndTime\": 1740876905.392955, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.54115352805546, \"count\": 1, \"min\": 0.54115352805546, \"max\": 0.54115352805546}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.392986, \"EndTime\": 1740876905.3929946, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.542162460288543, \"count\": 1, \"min\": 0.542162460288543, \"max\": 0.542162460288543}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3930254, \"EndTime\": 1740876905.3930347, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5411537265114057, \"count\": 1, \"min\": 0.5411537265114057, \"max\": 0.5411537265114057}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3930645, \"EndTime\": 1740876905.393073, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421630993890733, \"count\": 1, \"min\": 0.5421630993890733, \"max\": 0.5421630993890733}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3931065, \"EndTime\": 1740876905.3931127, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5444410693260932, \"count\": 1, \"min\": 0.5444410693260932, \"max\": 0.5444410693260932}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3931394, \"EndTime\": 1740876905.393148, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5583981409018587, \"count\": 1, \"min\": 0.5583981409018587, \"max\": 0.5583981409018587}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3931766, \"EndTime\": 1740876905.3936713, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5444405596140138, \"count\": 1, \"min\": 0.5444405596140138, \"max\": 0.5444405596140138}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3937025, \"EndTime\": 1740876905.3937097, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5583990770830979, \"count\": 1, \"min\": 0.5583990770830979, \"max\": 0.5583990770830979}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3937304, \"EndTime\": 1740876905.3937354, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6465944963343003, \"count\": 1, \"min\": 0.6465944963343003, \"max\": 0.6465944963343003}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.393753, \"EndTime\": 1740876905.393758, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470545214388206, \"count\": 1, \"min\": 0.6470545214388206, \"max\": 0.6470545214388206}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3937778, \"EndTime\": 1740876905.393786, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6466001345340697, \"count\": 1, \"min\": 0.6466001345340697, \"max\": 0.6466001345340697}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3938105, \"EndTime\": 1740876905.393816, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470563141776368, \"count\": 1, \"min\": 0.6470563141776368, \"max\": 0.6470563141776368}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3938386, \"EndTime\": 1740876905.3938437, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6485594792278563, \"count\": 1, \"min\": 0.6485594792278563, \"max\": 0.6485594792278563}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3938606, \"EndTime\": 1740876905.3938658, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575478216577828, \"count\": 1, \"min\": 0.6575478216577828, \"max\": 0.6575478216577828}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3938823, \"EndTime\": 1740876905.3938873, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6485158255551149, \"count\": 1, \"min\": 0.6485158255551149, \"max\": 0.6485158255551149}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876905.3939059, \"EndTime\": 1740876905.393911, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6576091572123943, \"count\": 1, \"min\": 0.6576091572123943, \"max\": 0.6576091572123943}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:05 INFO 140224006256448] #quality_metric: host=algo-1, epoch=18, train binary_classification_cross_entropy_objective <loss>=0.42819323998173153\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.063205, \"EndTime\": 1740876906.063264, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4330292399072717, \"count\": 1, \"min\": 0.4330292399072717, \"max\": 0.4330292399072717}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0633347, \"EndTime\": 1740876906.0633473, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42567715271325623, \"count\": 1, \"min\": 0.42567715271325623, \"max\": 0.42567715271325623}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0633838, \"EndTime\": 1740876906.0633943, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42499421229299655, \"count\": 1, \"min\": 0.42499421229299655, \"max\": 0.42499421229299655}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0634232, \"EndTime\": 1740876906.0634332, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42567277792432123, \"count\": 1, \"min\": 0.42567277792432123, \"max\": 0.42567277792432123}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0634649, \"EndTime\": 1740876906.0634742, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4298919015189041, \"count\": 1, \"min\": 0.4298919015189041, \"max\": 0.4298919015189041}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.063508, \"EndTime\": 1740876906.063516, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46234971869567826, \"count\": 1, \"min\": 0.46234971869567826, \"max\": 0.46234971869567826}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0635417, \"EndTime\": 1740876906.063549, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4298920280587795, \"count\": 1, \"min\": 0.4298920280587795, \"max\": 0.4298920280587795}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.063576, \"EndTime\": 1740876906.0635846, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4623407894311852, \"count\": 1, \"min\": 0.4623407894311852, \"max\": 0.4623407894311852}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0636103, \"EndTime\": 1740876906.063619, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42632372435155064, \"count\": 1, \"min\": 0.42632372435155064, \"max\": 0.42632372435155064}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.063652, \"EndTime\": 1740876906.0636625, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4269893228745914, \"count\": 1, \"min\": 0.4269893228745914, \"max\": 0.4269893228745914}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0636916, \"EndTime\": 1740876906.0637002, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4263130059877566, \"count\": 1, \"min\": 0.4263130059877566, \"max\": 0.4263130059877566}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0637305, \"EndTime\": 1740876906.0637395, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42698677252885364, \"count\": 1, \"min\": 0.42698677252885364, \"max\": 0.42698677252885364}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0637715, \"EndTime\": 1740876906.0637805, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43047873062759334, \"count\": 1, \"min\": 0.43047873062759334, \"max\": 0.43047873062759334}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.063812, \"EndTime\": 1740876906.0638223, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46174597373644044, \"count\": 1, \"min\": 0.46174597373644044, \"max\": 0.46174597373644044}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0638523, \"EndTime\": 1740876906.0638611, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4304790282144728, \"count\": 1, \"min\": 0.4304790282144728, \"max\": 0.4304790282144728}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0638883, \"EndTime\": 1740876906.063897, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4617470235810622, \"count\": 1, \"min\": 0.4617470235810622, \"max\": 0.4617470235810622}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0639257, \"EndTime\": 1740876906.0639343, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530349840007799, \"count\": 1, \"min\": 0.5530349840007799, \"max\": 0.5530349840007799}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.063986, \"EndTime\": 1740876906.0639963, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5526429988978373, \"count\": 1, \"min\": 0.5526429988978373, \"max\": 0.5526429988978373}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0640283, \"EndTime\": 1740876906.0640373, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.55303656129851, \"count\": 1, \"min\": 0.55303656129851, \"max\": 0.55303656129851}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0640666, \"EndTime\": 1740876906.0640752, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5526549992414729, \"count\": 1, \"min\": 0.5526549992414729, \"max\": 0.5526549992414729}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0641053, \"EndTime\": 1740876906.064114, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5609738634760174, \"count\": 1, \"min\": 0.5609738634760174, \"max\": 0.5609738634760174}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0641422, \"EndTime\": 1740876906.0641513, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5531986866304501, \"count\": 1, \"min\": 0.5531986866304501, \"max\": 0.5531986866304501}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0641832, \"EndTime\": 1740876906.0641913, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5609722474309047, \"count\": 1, \"min\": 0.5609722474309047, \"max\": 0.5609722474309047}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0642238, \"EndTime\": 1740876906.064234, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5532067300285463, \"count\": 1, \"min\": 0.5532067300285463, \"max\": 0.5532067300285463}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0642676, \"EndTime\": 1740876906.0642767, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6627431069425748, \"count\": 1, \"min\": 0.6627431069425748, \"max\": 0.6627431069425748}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0643065, \"EndTime\": 1740876906.0643163, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6630486698485747, \"count\": 1, \"min\": 0.6630486698485747, \"max\": 0.6630486698485747}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0643559, \"EndTime\": 1740876906.0643663, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6628606912855871, \"count\": 1, \"min\": 0.6628606912855871, \"max\": 0.6628606912855871}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0644045, \"EndTime\": 1740876906.064414, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6636719848540656, \"count\": 1, \"min\": 0.6636719848540656, \"max\": 0.6636719848540656}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0644484, \"EndTime\": 1740876906.064458, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6619556260842007, \"count\": 1, \"min\": 0.6619556260842007, \"max\": 0.6619556260842007}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0644913, \"EndTime\": 1740876906.0645018, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6634322563690811, \"count\": 1, \"min\": 0.6634322563690811, \"max\": 0.6634322563690811}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0645409, \"EndTime\": 1740876906.0645518, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6618685205719307, \"count\": 1, \"min\": 0.6618685205719307, \"max\": 0.6618685205719307}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.0645907, \"EndTime\": 1740876906.0646012, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6633074465119123, \"count\": 1, \"min\": 0.6633074465119123, \"max\": 0.6633074465119123}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:06 INFO 140224006256448] #quality_metric: host=algo-1, epoch=18, validation binary_classification_cross_entropy_objective <loss>=0.4330292399072717\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:06 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=18, criteria=sampled_accuracy, value=0.8140556368960741\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:06 INFO 140224006256448] Epoch 18: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:06 INFO 140224006256448] Saving model for epoch: 18\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:06 INFO 140224006256448] Saved checkpoint to \"/tmp/tmpa2c_zt8m/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:06 INFO 140224006256448] #progress_metric: host=algo-1, completed 63.333333333333336 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876903.0906787, \"EndTime\": 1740876906.0710337, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 18, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 63754.0, \"count\": 1, \"min\": 63754, \"max\": 63754}, \"Total Batches Seen\": {\"sum\": 1881.0, \"count\": 1, \"min\": 1881, \"max\": 1881}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 21.0, \"count\": 1, \"min\": 21, \"max\": 21}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:06 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1068.9462025321518 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4040012, \"EndTime\": 1740876908.4040499, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42793068789289695, \"count\": 1, \"min\": 0.42793068789289695, \"max\": 0.42793068789289695}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.404115, \"EndTime\": 1740876908.404127, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4250298586923212, \"count\": 1, \"min\": 0.4250298586923212, \"max\": 0.4250298586923212}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4041615, \"EndTime\": 1740876908.4041715, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42327317989453117, \"count\": 1, \"min\": 0.42327317989453117, \"max\": 0.42327317989453117}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4042027, \"EndTime\": 1740876908.404213, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42502854731473494, \"count\": 1, \"min\": 0.42502854731473494, \"max\": 0.42502854731473494}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4042485, \"EndTime\": 1740876908.4042583, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4307394471068989, \"count\": 1, \"min\": 0.4307394471068989, \"max\": 0.4307394471068989}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4042912, \"EndTime\": 1740876908.4043005, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4585831610180772, \"count\": 1, \"min\": 0.4585831610180772, \"max\": 0.4585831610180772}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.404333, \"EndTime\": 1740876908.404343, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.43074064266824935, \"count\": 1, \"min\": 0.43074064266824935, \"max\": 0.43074064266824935}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4043767, \"EndTime\": 1740876908.4043872, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45858078135635794, \"count\": 1, \"min\": 0.45858078135635794, \"max\": 0.45858078135635794}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4044144, \"EndTime\": 1740876908.4044235, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42392036418685575, \"count\": 1, \"min\": 0.42392036418685575, \"max\": 0.42392036418685575}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.404453, \"EndTime\": 1740876908.404462, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4256283083269673, \"count\": 1, \"min\": 0.4256283083269673, \"max\": 0.4256283083269673}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4044955, \"EndTime\": 1740876908.4045062, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42391889899083135, \"count\": 1, \"min\": 0.42391889899083135, \"max\": 0.42391889899083135}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4045312, \"EndTime\": 1740876908.40454, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42562888077284095, \"count\": 1, \"min\": 0.42562888077284095, \"max\": 0.42562888077284095}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4045732, \"EndTime\": 1740876908.4045832, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4310665842402517, \"count\": 1, \"min\": 0.4310665842402517, \"max\": 0.4310665842402517}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4046106, \"EndTime\": 1740876908.4046202, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45622945570779855, \"count\": 1, \"min\": 0.45622945570779855, \"max\": 0.45622945570779855}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.404647, \"EndTime\": 1740876908.4046562, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4310667516309049, \"count\": 1, \"min\": 0.4310667516309049, \"max\": 0.4310667516309049}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4046938, \"EndTime\": 1740876908.4047043, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45622989876522135, \"count\": 1, \"min\": 0.45622989876522135, \"max\": 0.45622989876522135}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4047823, \"EndTime\": 1740876908.404796, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5411122290112412, \"count\": 1, \"min\": 0.5411122290112412, \"max\": 0.5411122290112412}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4048305, \"EndTime\": 1740876908.4048407, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421558678112477, \"count\": 1, \"min\": 0.5421558678112477, \"max\": 0.5421558678112477}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.404888, \"EndTime\": 1740876908.4048984, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.541112412386948, \"count\": 1, \"min\": 0.541112412386948, \"max\": 0.541112412386948}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4049635, \"EndTime\": 1740876908.4049764, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421564333202114, \"count\": 1, \"min\": 0.5421564333202114, \"max\": 0.5421564333202114}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4050052, \"EndTime\": 1740876908.4050148, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5441248050450826, \"count\": 1, \"min\": 0.5441248050450826, \"max\": 0.5441248050450826}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4050777, \"EndTime\": 1740876908.4050884, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5583110654904524, \"count\": 1, \"min\": 0.5583110654904524, \"max\": 0.5583110654904524}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.405124, \"EndTime\": 1740876908.4051332, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5441243653053125, \"count\": 1, \"min\": 0.5441243653053125, \"max\": 0.5441243653053125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4051974, \"EndTime\": 1740876908.4052093, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5583120387690795, \"count\": 1, \"min\": 0.5583120387690795, \"max\": 0.5583120387690795}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4052746, \"EndTime\": 1740876908.4052877, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6465798902179831, \"count\": 1, \"min\": 0.6465798902179831, \"max\": 0.6465798902179831}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.405348, \"EndTime\": 1740876908.40536, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470464915131406, \"count\": 1, \"min\": 0.6470464915131406, \"max\": 0.6470464915131406}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4054034, \"EndTime\": 1740876908.405414, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6465826686012225, \"count\": 1, \"min\": 0.6465826686012225, \"max\": 0.6465826686012225}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.405471, \"EndTime\": 1740876908.405482, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470506681361431, \"count\": 1, \"min\": 0.6470506681361431, \"max\": 0.6470506681361431}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4055321, \"EndTime\": 1740876908.405543, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6483587612463356, \"count\": 1, \"min\": 0.6483587612463356, \"max\": 0.6483587612463356}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4056072, \"EndTime\": 1740876908.4056191, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575498574900521, \"count\": 1, \"min\": 0.6575498574900521, \"max\": 0.6575498574900521}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4057088, \"EndTime\": 1740876908.40572, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6483461764852583, \"count\": 1, \"min\": 0.6483461764852583, \"max\": 0.6483461764852583}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876908.4057517, \"EndTime\": 1740876908.405758, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6576086873121461, \"count\": 1, \"min\": 0.6576086873121461, \"max\": 0.6576086873121461}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:08 INFO 140224006256448] #quality_metric: host=algo-1, epoch=19, train binary_classification_cross_entropy_objective <loss>=0.42793068789289695\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1274936, \"EndTime\": 1740876909.127557, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4327011448747068, \"count\": 1, \"min\": 0.4327011448747068, \"max\": 0.4327011448747068}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1276436, \"EndTime\": 1740876909.127656, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4256516651388143, \"count\": 1, \"min\": 0.4256516651388143, \"max\": 0.4256516651388143}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.127681, \"EndTime\": 1740876909.1276875, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4250049395582163, \"count\": 1, \"min\": 0.4250049395582163, \"max\": 0.4250049395582163}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1277072, \"EndTime\": 1740876909.1277125, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4256480288191386, \"count\": 1, \"min\": 0.4256480288191386, \"max\": 0.4256480288191386}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1277306, \"EndTime\": 1740876909.1277359, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42938916627344936, \"count\": 1, \"min\": 0.42938916627344936, \"max\": 0.42938916627344936}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1277544, \"EndTime\": 1740876909.1277623, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4618875151322841, \"count\": 1, \"min\": 0.4618875151322841, \"max\": 0.4618875151322841}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.127782, \"EndTime\": 1740876909.1277874, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4293893175976866, \"count\": 1, \"min\": 0.4293893175976866, \"max\": 0.4293893175976866}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1278048, \"EndTime\": 1740876909.1278095, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46187936832056564, \"count\": 1, \"min\": 0.46187936832056564, \"max\": 0.46187936832056564}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1278267, \"EndTime\": 1740876909.1278315, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42633635704548783, \"count\": 1, \"min\": 0.42633635704548783, \"max\": 0.42633635704548783}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1278484, \"EndTime\": 1740876909.1278534, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4269645837180611, \"count\": 1, \"min\": 0.4269645837180611, \"max\": 0.4269645837180611}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1278703, \"EndTime\": 1740876909.127875, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4263260027674595, \"count\": 1, \"min\": 0.4263260027674595, \"max\": 0.4263260027674595}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1278918, \"EndTime\": 1740876909.1278965, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42696243550732055, \"count\": 1, \"min\": 0.42696243550732055, \"max\": 0.42696243550732055}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1279159, \"EndTime\": 1740876909.1279209, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43006334402550717, \"count\": 1, \"min\": 0.43006334402550717, \"max\": 0.43006334402550717}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.127938, \"EndTime\": 1740876909.12796, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46128500834391023, \"count\": 1, \"min\": 0.46128500834391023, \"max\": 0.46128500834391023}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1279802, \"EndTime\": 1740876909.1279857, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4300635875056813, \"count\": 1, \"min\": 0.4300635875056813, \"max\": 0.4300635875056813}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1280026, \"EndTime\": 1740876909.1280074, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.461286009579766, \"count\": 1, \"min\": 0.461286009579766, \"max\": 0.461286009579766}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1280243, \"EndTime\": 1740876909.1280293, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530335365591427, \"count\": 1, \"min\": 0.5530335365591427, \"max\": 0.5530335365591427}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1280463, \"EndTime\": 1740876909.1280515, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5526302878364463, \"count\": 1, \"min\": 0.5526302878364463, \"max\": 0.5526302878364463}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1280682, \"EndTime\": 1740876909.128073, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530348822452662, \"count\": 1, \"min\": 0.5530348822452662, \"max\": 0.5530348822452662}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1280897, \"EndTime\": 1740876909.1280947, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5526408348041607, \"count\": 1, \"min\": 0.5526408348041607, \"max\": 0.5526408348041607}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1281111, \"EndTime\": 1740876909.1281161, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5602098893630557, \"count\": 1, \"min\": 0.5602098893630557, \"max\": 0.5602098893630557}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1281328, \"EndTime\": 1740876909.1281397, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5536510787282471, \"count\": 1, \"min\": 0.5536510787282471, \"max\": 0.5536510787282471}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1281688, \"EndTime\": 1740876909.1281767, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.560209610800792, \"count\": 1, \"min\": 0.560209610800792, \"max\": 0.560209610800792}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1282032, \"EndTime\": 1740876909.128212, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5536566000557225, \"count\": 1, \"min\": 0.5536566000557225, \"max\": 0.5536566000557225}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.128246, \"EndTime\": 1740876909.1282544, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6627257819755186, \"count\": 1, \"min\": 0.6627257819755186, \"max\": 0.6627257819755186}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1282892, \"EndTime\": 1740876909.1282973, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6630963249402025, \"count\": 1, \"min\": 0.6630963249402025, \"max\": 0.6630963249402025}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1283345, \"EndTime\": 1740876909.1283436, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6628382839535201, \"count\": 1, \"min\": 0.6628382839535201, \"max\": 0.6628382839535201}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1283758, \"EndTime\": 1740876909.128384, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6636888165774143, \"count\": 1, \"min\": 0.6636888165774143, \"max\": 0.6636888165774143}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1284153, \"EndTime\": 1740876909.1284232, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6619582602080628, \"count\": 1, \"min\": 0.6619582602080628, \"max\": 0.6619582602080628}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1284556, \"EndTime\": 1740876909.128465, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.663304022255614, \"count\": 1, \"min\": 0.663304022255614, \"max\": 0.663304022255614}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1284995, \"EndTime\": 1740876909.1285098, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.661895552631004, \"count\": 1, \"min\": 0.661895552631004, \"max\": 0.661895552631004}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.1285408, \"EndTime\": 1740876909.1285508, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6632442308554363, \"count\": 1, \"min\": 0.6632442308554363, \"max\": 0.6632442308554363}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:09 INFO 140224006256448] #quality_metric: host=algo-1, epoch=19, validation binary_classification_cross_entropy_objective <loss>=0.4327011448747068\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:09 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=19, criteria=sampled_accuracy, value=0.8140556368960741\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:09 INFO 140224006256448] Epoch 19: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:09 INFO 140224006256448] Saving model for epoch: 19\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:09 INFO 140224006256448] Saved checkpoint to \"/tmp/tmpnm30hy79/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:09 INFO 140224006256448] #progress_metric: host=algo-1, completed 66.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876906.071332, \"EndTime\": 1740876909.135269, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 19, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 66940.0, \"count\": 1, \"min\": 66940, \"max\": 66940}, \"Total Batches Seen\": {\"sum\": 1975.0, \"count\": 1, \"min\": 1975, \"max\": 1975}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 22.0, \"count\": 1, \"min\": 22, \"max\": 22}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:09 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1039.7878993534712 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.4908936, \"EndTime\": 1740876911.490939, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4277044867202498, \"count\": 1, \"min\": 0.4277044867202498, \"max\": 0.4277044867202498}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.4910018, \"EndTime\": 1740876911.4910142, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4250128732158895, \"count\": 1, \"min\": 0.4250128732158895, \"max\": 0.4250128732158895}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.491048, \"EndTime\": 1740876911.491058, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42323019065712164, \"count\": 1, \"min\": 0.42323019065712164, \"max\": 0.42323019065712164}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.4911125, \"EndTime\": 1740876911.4911237, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4250116999732928, \"count\": 1, \"min\": 0.4250116999732928, \"max\": 0.4250116999732928}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.4911547, \"EndTime\": 1740876911.4911654, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4300803605851156, \"count\": 1, \"min\": 0.4300803605851156, \"max\": 0.4300803605851156}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.491197, \"EndTime\": 1740876911.4912062, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4582803552471935, \"count\": 1, \"min\": 0.4582803552471935, \"max\": 0.4582803552471935}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.4912314, \"EndTime\": 1740876911.4912393, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4300813611589754, \"count\": 1, \"min\": 0.4300813611589754, \"max\": 0.4300813611589754}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.4912686, \"EndTime\": 1740876911.491276, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45827830267585884, \"count\": 1, \"min\": 0.45827830267585884, \"max\": 0.45827830267585884}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.491305, \"EndTime\": 1740876911.4913137, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4238775996450078, \"count\": 1, \"min\": 0.4238775996450078, \"max\": 0.4238775996450078}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.4913478, \"EndTime\": 1740876911.4913573, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42561219976643533, \"count\": 1, \"min\": 0.42561219976643533, \"max\": 0.42561219976643533}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.4913847, \"EndTime\": 1740876911.491394, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42387634481831793, \"count\": 1, \"min\": 0.42387634481831793, \"max\": 0.42387634481831793}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.4914246, \"EndTime\": 1740876911.4914336, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42561272018548435, \"count\": 1, \"min\": 0.42561272018548435, \"max\": 0.42561272018548435}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.4914668, \"EndTime\": 1740876911.4914768, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4304638415631578, \"count\": 1, \"min\": 0.4304638415631578, \"max\": 0.4304638415631578}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.491508, \"EndTime\": 1740876911.491517, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45594980986641603, \"count\": 1, \"min\": 0.45594980986641603, \"max\": 0.45594980986641603}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.4915483, \"EndTime\": 1740876911.4915578, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.43046397547568044, \"count\": 1, \"min\": 0.43046397547568044, \"max\": 0.43046397547568044}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.491589, \"EndTime\": 1740876911.4915984, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45595020828633126, \"count\": 1, \"min\": 0.45595020828633126, \"max\": 0.45595020828633126}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.491625, \"EndTime\": 1740876911.4916332, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5410744892050389, \"count\": 1, \"min\": 0.5410744892050389, \"max\": 0.5410744892050389}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.4916627, \"EndTime\": 1740876911.4916723, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421547533815831, \"count\": 1, \"min\": 0.5421547533815831, \"max\": 0.5421547533815831}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.491703, \"EndTime\": 1740876911.4917126, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5410746436266866, \"count\": 1, \"min\": 0.5410746436266866, \"max\": 0.5410746436266866}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.491749, \"EndTime\": 1740876911.4917579, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421552519342856, \"count\": 1, \"min\": 0.5421552519342856, \"max\": 0.5421552519342856}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.4917903, \"EndTime\": 1740876911.4917996, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5438687802869108, \"count\": 1, \"min\": 0.5438687802869108, \"max\": 0.5438687802869108}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.4918368, \"EndTime\": 1740876911.491846, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5582497088235062, \"count\": 1, \"min\": 0.5582497088235062, \"max\": 0.5582497088235062}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.491883, \"EndTime\": 1740876911.4918923, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5438684406799278, \"count\": 1, \"min\": 0.5438684406799278, \"max\": 0.5438684406799278}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.49193, \"EndTime\": 1740876911.4919388, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5582506766732473, \"count\": 1, \"min\": 0.5582506766732473, \"max\": 0.5582506766732473}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.4920015, \"EndTime\": 1740876911.4920123, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6465666865638959, \"count\": 1, \"min\": 0.6465666865638959, \"max\": 0.6465666865638959}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.4920459, \"EndTime\": 1740876911.4920557, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470401753058244, \"count\": 1, \"min\": 0.6470401753058244, \"max\": 0.6470401753058244}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.4920957, \"EndTime\": 1740876911.4921057, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6465668289213524, \"count\": 1, \"min\": 0.6465668289213524, \"max\": 0.6465668289213524}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.4921439, \"EndTime\": 1740876911.4921532, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470453224930108, \"count\": 1, \"min\": 0.6470453224930108, \"max\": 0.6470453224930108}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.4921908, \"EndTime\": 1740876911.4921997, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6481789752398014, \"count\": 1, \"min\": 0.6481789752398014, \"max\": 0.6481789752398014}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.4922361, \"EndTime\": 1740876911.4922445, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575614276526474, \"count\": 1, \"min\": 0.6575614276526474, \"max\": 0.6575614276526474}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.4922807, \"EndTime\": 1740876911.4922895, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6481900284518025, \"count\": 1, \"min\": 0.6481900284518025, \"max\": 0.6481900284518025}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876911.4923282, \"EndTime\": 1740876911.4923387, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.657618759102191, \"count\": 1, \"min\": 0.657618759102191, \"max\": 0.657618759102191}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:11 INFO 140224006256448] #quality_metric: host=algo-1, epoch=20, train binary_classification_cross_entropy_objective <loss>=0.4277044867202498\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1953902, \"EndTime\": 1740876912.1954486, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4324166542614536, \"count\": 1, \"min\": 0.4324166542614536, \"max\": 0.4324166542614536}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1955209, \"EndTime\": 1740876912.1955307, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42562247910925444, \"count\": 1, \"min\": 0.42562247910925444, \"max\": 0.42562247910925444}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.195556, \"EndTime\": 1740876912.1955621, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4250140619487399, \"count\": 1, \"min\": 0.4250140619487399, \"max\": 0.4250140619487399}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1955957, \"EndTime\": 1740876912.195604, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4256194608277842, \"count\": 1, \"min\": 0.4256194608277842, \"max\": 0.4256194608277842}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1956394, \"EndTime\": 1740876912.195648, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4289472370161668, \"count\": 1, \"min\": 0.4289472370161668, \"max\": 0.4289472370161668}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1956785, \"EndTime\": 1740876912.195686, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4614224223580926, \"count\": 1, \"min\": 0.4614224223580926, \"max\": 0.4614224223580926}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.195718, \"EndTime\": 1740876912.195727, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42894740195434927, \"count\": 1, \"min\": 0.42894740195434927, \"max\": 0.42894740195434927}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1957629, \"EndTime\": 1740876912.1957722, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46141510582249473, \"count\": 1, \"min\": 0.46141510582249473, \"max\": 0.46141510582249473}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1958063, \"EndTime\": 1740876912.195816, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42634721189780955, \"count\": 1, \"min\": 0.42634721189780955, \"max\": 0.42634721189780955}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1958485, \"EndTime\": 1740876912.1958585, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42693730643343614, \"count\": 1, \"min\": 0.42693730643343614, \"max\": 0.42693730643343614}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1958954, \"EndTime\": 1740876912.1959047, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42633722641806654, \"count\": 1, \"min\": 0.42633722641806654, \"max\": 0.42633722641806654}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.195968, \"EndTime\": 1740876912.195981, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42693547239066215, \"count\": 1, \"min\": 0.42693547239066215, \"max\": 0.42693547239066215}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1960213, \"EndTime\": 1740876912.1960304, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4296861178354847, \"count\": 1, \"min\": 0.4296861178354847, \"max\": 0.4296861178354847}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1960664, \"EndTime\": 1740876912.1960754, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4608225868701237, \"count\": 1, \"min\": 0.4608225868701237, \"max\": 0.4608225868701237}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.196104, \"EndTime\": 1740876912.196113, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42968631506315264, \"count\": 1, \"min\": 0.42968631506315264, \"max\": 0.42968631506315264}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1961453, \"EndTime\": 1740876912.1961534, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46082349595004257, \"count\": 1, \"min\": 0.46082349595004257, \"max\": 0.46082349595004257}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1961794, \"EndTime\": 1740876912.1961877, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530305734316042, \"count\": 1, \"min\": 0.5530305734316042, \"max\": 0.5530305734316042}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.196212, \"EndTime\": 1740876912.1962175, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5526167573202756, \"count\": 1, \"min\": 0.5526167573202756, \"max\": 0.5526167573202756}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.196242, \"EndTime\": 1740876912.1962507, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530317463253462, \"count\": 1, \"min\": 0.5530317463253462, \"max\": 0.5530317463253462}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1962867, \"EndTime\": 1740876912.1962955, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.552626026322517, \"count\": 1, \"min\": 0.552626026322517, \"max\": 0.552626026322517}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.197196, \"EndTime\": 1740876912.1972136, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5595077609596979, \"count\": 1, \"min\": 0.5595077609596979, \"max\": 0.5595077609596979}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1972513, \"EndTime\": 1740876912.1972623, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5540822892726602, \"count\": 1, \"min\": 0.5540822892726602, \"max\": 0.5540822892726602}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1973011, \"EndTime\": 1740876912.1973112, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5595082658974353, \"count\": 1, \"min\": 0.5595082658974353, \"max\": 0.5595082658974353}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1973464, \"EndTime\": 1740876912.1973565, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5540856238165502, \"count\": 1, \"min\": 0.5540856238165502, \"max\": 0.5540856238165502}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.197404, \"EndTime\": 1740876912.1974154, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6627180986488197, \"count\": 1, \"min\": 0.6627180986488197, \"max\": 0.6627180986488197}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1974561, \"EndTime\": 1740876912.197466, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6631368512115925, \"count\": 1, \"min\": 0.6631368512115925, \"max\": 0.6631368512115925}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1975226, \"EndTime\": 1740876912.1975338, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6628219294164052, \"count\": 1, \"min\": 0.6628219294164052, \"max\": 0.6628219294164052}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1975706, \"EndTime\": 1740876912.1975806, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.663704557963381, \"count\": 1, \"min\": 0.663704557963381, \"max\": 0.663704557963381}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1976187, \"EndTime\": 1740876912.1976285, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6619321282402139, \"count\": 1, \"min\": 0.6619321282402139, \"max\": 0.6619321282402139}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1976633, \"EndTime\": 1740876912.197671, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6631683748253617, \"count\": 1, \"min\": 0.6631683748253617, \"max\": 0.6631683748253617}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1977017, \"EndTime\": 1740876912.1977093, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6619925704916958, \"count\": 1, \"min\": 0.6619925704916958, \"max\": 0.6619925704916958}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.1977296, \"EndTime\": 1740876912.1977375, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6631668676918108, \"count\": 1, \"min\": 0.6631668676918108, \"max\": 0.6631668676918108}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:12 INFO 140224006256448] #quality_metric: host=algo-1, epoch=20, validation binary_classification_cross_entropy_objective <loss>=0.4324166542614536\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:12 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=20, criteria=sampled_accuracy, value=0.8140556368960741\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:12 INFO 140224006256448] Epoch 20: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:12 INFO 140224006256448] Saving model for epoch: 20\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:12 INFO 140224006256448] Saved checkpoint to \"/tmp/tmpdetxc7ku/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:12 INFO 140224006256448] #progress_metric: host=algo-1, completed 70.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876909.135529, \"EndTime\": 1740876912.2036202, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 20, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 70126.0, \"count\": 1, \"min\": 70126, \"max\": 70126}, \"Total Batches Seen\": {\"sum\": 2069.0, \"count\": 1, \"min\": 2069, \"max\": 2069}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 23.0, \"count\": 1, \"min\": 23, \"max\": 23}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:12 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1038.3884833588857 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5596178, \"EndTime\": 1740876914.5596654, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42750855158734063, \"count\": 1, \"min\": 0.42750855158734063, \"max\": 0.42750855158734063}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5597274, \"EndTime\": 1740876914.559739, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4249948289558753, \"count\": 1, \"min\": 0.4249948289558753, \"max\": 0.4249948289558753}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5597742, \"EndTime\": 1740876914.5597847, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42319081464498426, \"count\": 1, \"min\": 0.42319081464498426, \"max\": 0.42319081464498426}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5598154, \"EndTime\": 1740876914.559824, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42499378178407693, \"count\": 1, \"min\": 0.42499378178407693, \"max\": 0.42499378178407693}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5598524, \"EndTime\": 1740876914.5598605, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42947551904035325, \"count\": 1, \"min\": 0.42947551904035325, \"max\": 0.42947551904035325}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5599008, \"EndTime\": 1740876914.559909, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4579727124896402, \"count\": 1, \"min\": 0.4579727124896402, \"max\": 0.4579727124896402}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5599387, \"EndTime\": 1740876914.5599475, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4294763514695478, \"count\": 1, \"min\": 0.4294763514695478, \"max\": 0.4294763514695478}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5599787, \"EndTime\": 1740876914.5601697, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4579709227668719, \"count\": 1, \"min\": 0.4579709227668719, \"max\": 0.4579709227668719}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5602372, \"EndTime\": 1740876914.5602515, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4238385359446208, \"count\": 1, \"min\": 0.4238385359446208, \"max\": 0.4238385359446208}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5602872, \"EndTime\": 1740876914.560297, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42559519951136937, \"count\": 1, \"min\": 0.42559519951136937, \"max\": 0.42559519951136937}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.560335, \"EndTime\": 1740876914.5603456, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4238374506198176, \"count\": 1, \"min\": 0.4238374506198176, \"max\": 0.4238374506198176}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5603805, \"EndTime\": 1740876914.5603895, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4255956700148272, \"count\": 1, \"min\": 0.4255956700148272, \"max\": 0.4255956700148272}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.56043, \"EndTime\": 1740876914.5604413, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4299038911755518, \"count\": 1, \"min\": 0.4299038911755518, \"max\": 0.4299038911755518}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.560477, \"EndTime\": 1740876914.560488, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4556584436632575, \"count\": 1, \"min\": 0.4556584436632575, \"max\": 0.4556584436632575}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5605245, \"EndTime\": 1740876914.5605335, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4299039999040752, \"count\": 1, \"min\": 0.4299039999040752, \"max\": 0.4299039999040752}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5605686, \"EndTime\": 1740876914.5605779, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45565880347776083, \"count\": 1, \"min\": 0.45565880347776083, \"max\": 0.45565880347776083}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5606163, \"EndTime\": 1740876914.5606263, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5410403958006346, \"count\": 1, \"min\": 0.5410403958006346, \"max\": 0.5410403958006346}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5606637, \"EndTime\": 1740876914.560673, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.542149974152229, \"count\": 1, \"min\": 0.542149974152229, \"max\": 0.542149974152229}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5607116, \"EndTime\": 1740876914.5607226, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5410405273003189, \"count\": 1, \"min\": 0.5410405273003189, \"max\": 0.5410405273003189}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5607564, \"EndTime\": 1740876914.5607662, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421504063518797, \"count\": 1, \"min\": 0.5421504063518797, \"max\": 0.5421504063518797}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5608022, \"EndTime\": 1740876914.560812, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5436603195074613, \"count\": 1, \"min\": 0.5436603195074613, \"max\": 0.5436603195074613}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5608482, \"EndTime\": 1740876914.5608566, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5581614046742236, \"count\": 1, \"min\": 0.5581614046742236, \"max\": 0.5581614046742236}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.560885, \"EndTime\": 1740876914.5608912, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.543660072493146, \"count\": 1, \"min\": 0.543660072493146, \"max\": 0.543660072493146}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5609088, \"EndTime\": 1740876914.5609138, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5581623571421209, \"count\": 1, \"min\": 0.5581623571421209, \"max\": 0.5581623571421209}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.560931, \"EndTime\": 1740876914.5609362, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6465544908729858, \"count\": 1, \"min\": 0.6465544908729858, \"max\": 0.6465544908729858}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5609593, \"EndTime\": 1740876914.5609674, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470355450692319, \"count\": 1, \"min\": 0.6470355450692319, \"max\": 0.6470355450692319}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5609977, \"EndTime\": 1740876914.5610063, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6465524502150398, \"count\": 1, \"min\": 0.6465524502150398, \"max\": 0.6465524502150398}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5610435, \"EndTime\": 1740876914.561054, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470407899763673, \"count\": 1, \"min\": 0.6470407899763673, \"max\": 0.6470407899763673}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5610883, \"EndTime\": 1740876914.5610976, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6480152147016821, \"count\": 1, \"min\": 0.6480152147016821, \"max\": 0.6480152147016821}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5611331, \"EndTime\": 1740876914.5611422, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575483199088804, \"count\": 1, \"min\": 0.6575483199088804, \"max\": 0.6575483199088804}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5611851, \"EndTime\": 1740876914.5611959, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6480556128524211, \"count\": 1, \"min\": 0.6480556128524211, \"max\": 0.6480556128524211}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876914.5612311, \"EndTime\": 1740876914.5612407, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6576059499471569, \"count\": 1, \"min\": 0.6576059499471569, \"max\": 0.6576059499471569}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:14 INFO 140224006256448] #quality_metric: host=algo-1, epoch=21, train binary_classification_cross_entropy_objective <loss>=0.42750855158734063\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2675884, \"EndTime\": 1740876915.267643, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43216905604344336, \"count\": 1, \"min\": 0.43216905604344336, \"max\": 0.43216905604344336}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2677107, \"EndTime\": 1740876915.2677205, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42559502117804865, \"count\": 1, \"min\": 0.42559502117804865, \"max\": 0.42559502117804865}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2677534, \"EndTime\": 1740876915.267761, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4250235285277248, \"count\": 1, \"min\": 0.4250235285277248, \"max\": 0.4250235285277248}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2677946, \"EndTime\": 1740876915.2678034, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4255925045180984, \"count\": 1, \"min\": 0.4255925045180984, \"max\": 0.4255925045180984}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2678373, \"EndTime\": 1740876915.2678463, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4286101953526018, \"count\": 1, \"min\": 0.4286101953526018, \"max\": 0.4286101953526018}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.267881, \"EndTime\": 1740876915.26789, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4609911504636572, \"count\": 1, \"min\": 0.4609911504636572, \"max\": 0.4609911504636572}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2679105, \"EndTime\": 1740876915.267918, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4286103606398598, \"count\": 1, \"min\": 0.4286103606398598, \"max\": 0.4286103606398598}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2679605, \"EndTime\": 1740876915.2679706, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4609844431521079, \"count\": 1, \"min\": 0.4609844431521079, \"max\": 0.4609844431521079}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2680044, \"EndTime\": 1740876915.2680135, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42635829242745393, \"count\": 1, \"min\": 0.42635829242745393, \"max\": 0.42635829242745393}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.268046, \"EndTime\": 1740876915.268055, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42691174852027725, \"count\": 1, \"min\": 0.42691174852027725, \"max\": 0.42691174852027725}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2680953, \"EndTime\": 1740876915.2681046, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42634863054071653, \"count\": 1, \"min\": 0.42634863054071653, \"max\": 0.42634863054071653}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2681406, \"EndTime\": 1740876915.2681508, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42691012147928575, \"count\": 1, \"min\": 0.42691012147928575, \"max\": 0.42691012147928575}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2681823, \"EndTime\": 1740876915.268206, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42939578788695887, \"count\": 1, \"min\": 0.42939578788695887, \"max\": 0.42939578788695887}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2682436, \"EndTime\": 1740876915.268253, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4603889566214856, \"count\": 1, \"min\": 0.4603889566214856, \"max\": 0.4603889566214856}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2682831, \"EndTime\": 1740876915.2682922, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42939591128515464, \"count\": 1, \"min\": 0.42939591128515464, \"max\": 0.42939591128515464}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2683256, \"EndTime\": 1740876915.268335, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4603897913483191, \"count\": 1, \"min\": 0.4603897913483191, \"max\": 0.4603897913483191}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2683654, \"EndTime\": 1740876915.2683752, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530283634344969, \"count\": 1, \"min\": 0.5530283634344969, \"max\": 0.5530283634344969}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2684104, \"EndTime\": 1740876915.2684197, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5526040595237542, \"count\": 1, \"min\": 0.5526040595237542, \"max\": 0.5526040595237542}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2684612, \"EndTime\": 1740876915.2684686, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530293665029992, \"count\": 1, \"min\": 0.5530293665029992, \"max\": 0.5530293665029992}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2685037, \"EndTime\": 1740876915.26851, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5526121880962769, \"count\": 1, \"min\": 0.5526121880962769, \"max\": 0.5526121880962769}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2685428, \"EndTime\": 1740876915.2685492, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5588270891812326, \"count\": 1, \"min\": 0.5588270891812326, \"max\": 0.5588270891812326}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2685854, \"EndTime\": 1740876915.2685924, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5544740050638403, \"count\": 1, \"min\": 0.5544740050638403, \"max\": 0.5544740050638403}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.26863, \"EndTime\": 1740876915.2686384, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5588279328967607, \"count\": 1, \"min\": 0.5588279328967607, \"max\": 0.5588279328967607}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.268668, \"EndTime\": 1740876915.2686772, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5544754687374891, \"count\": 1, \"min\": 0.5544754687374891, \"max\": 0.5544754687374891}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2687085, \"EndTime\": 1740876915.268717, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6627119763878394, \"count\": 1, \"min\": 0.6627119763878394, \"max\": 0.6627119763878394}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2687488, \"EndTime\": 1740876915.2687578, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6631694473598921, \"count\": 1, \"min\": 0.6631694473598921, \"max\": 0.6631694473598921}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2687886, \"EndTime\": 1740876915.268797, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6628099173787397, \"count\": 1, \"min\": 0.6628099173787397, \"max\": 0.6628099173787397}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2688253, \"EndTime\": 1740876915.2688346, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6637176999584997, \"count\": 1, \"min\": 0.6637176999584997, \"max\": 0.6637176999584997}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.268867, \"EndTime\": 1740876915.2688775, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6620421523056477, \"count\": 1, \"min\": 0.6620421523056477, \"max\": 0.6620421523056477}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2689123, \"EndTime\": 1740876915.2689226, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6630328413682661, \"count\": 1, \"min\": 0.6630328413682661, \"max\": 0.6630328413682661}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2689588, \"EndTime\": 1740876915.268968, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6619272019119598, \"count\": 1, \"min\": 0.6619272019119598, \"max\": 0.6619272019119598}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.269002, \"EndTime\": 1740876915.2690113, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6630648367575985, \"count\": 1, \"min\": 0.6630648367575985, \"max\": 0.6630648367575985}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:15 INFO 140224006256448] #quality_metric: host=algo-1, epoch=21, validation binary_classification_cross_entropy_objective <loss>=0.43216905604344336\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:15 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=21, criteria=sampled_accuracy, value=0.8140556368960741\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:15 INFO 140224006256448] Epoch 21: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:15 INFO 140224006256448] Saving model for epoch: 21\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:15 INFO 140224006256448] Saved checkpoint to \"/tmp/tmpq2z54f77/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:15 INFO 140224006256448] #progress_metric: host=algo-1, completed 73.33333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876912.2038643, \"EndTime\": 1740876915.27437, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 21, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 73312.0, \"count\": 1, \"min\": 73312, \"max\": 73312}, \"Total Batches Seen\": {\"sum\": 2163.0, \"count\": 1, \"min\": 2163, \"max\": 2163}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 24.0, \"count\": 1, \"min\": 24, \"max\": 24}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:15 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1037.3492825061353 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5827556, \"EndTime\": 1740876917.582802, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4273380186646743, \"count\": 1, \"min\": 0.4273380186646743, \"max\": 0.4273380186646743}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5828626, \"EndTime\": 1740876917.5828714, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42497664520365014, \"count\": 1, \"min\": 0.42497664520365014, \"max\": 0.42497664520365014}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5828955, \"EndTime\": 1740876917.5829034, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4231549625831039, \"count\": 1, \"min\": 0.4231549625831039, \"max\": 0.4231549625831039}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5829377, \"EndTime\": 1740876917.5829458, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4249757025379082, \"count\": 1, \"min\": 0.4249757025379082, \"max\": 0.4249757025379082}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.582981, \"EndTime\": 1740876917.5829895, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42892862889376115, \"count\": 1, \"min\": 0.42892862889376115, \"max\": 0.42892862889376115}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5830224, \"EndTime\": 1740876917.5830302, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.457664619285347, \"count\": 1, \"min\": 0.457664619285347, \"max\": 0.457664619285347}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5830622, \"EndTime\": 1740876917.583071, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42892932650561877, \"count\": 1, \"min\": 0.42892932650561877, \"max\": 0.42892932650561877}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5831032, \"EndTime\": 1740876917.5831115, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45766306375869087, \"count\": 1, \"min\": 0.45766306375869087, \"max\": 0.45766306375869087}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5831401, \"EndTime\": 1740876917.5831485, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42380296724043187, \"count\": 1, \"min\": 0.42380296724043187, \"max\": 0.42380296724043187}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5831792, \"EndTime\": 1740876917.5831883, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42557811631498876, \"count\": 1, \"min\": 0.42557811631498876, \"max\": 0.42557811631498876}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5832198, \"EndTime\": 1740876917.583229, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4238020158281513, \"count\": 1, \"min\": 0.4238020158281513, \"max\": 0.4238020158281513}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5832624, \"EndTime\": 1740876917.5832722, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4255785254418737, \"count\": 1, \"min\": 0.4255785254418737, \"max\": 0.4255785254418737}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5833063, \"EndTime\": 1740876917.583317, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42939148983723147, \"count\": 1, \"min\": 0.42939148983723147, \"max\": 0.42939148983723147}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5833523, \"EndTime\": 1740876917.5833626, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45536243908017743, \"count\": 1, \"min\": 0.45536243908017743, \"max\": 0.45536243908017743}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5834026, \"EndTime\": 1740876917.5834122, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42939158499353974, \"count\": 1, \"min\": 0.42939158499353974, \"max\": 0.42939158499353974}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5834477, \"EndTime\": 1740876917.583457, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45536275802723297, \"count\": 1, \"min\": 0.45536275802723297, \"max\": 0.45536275802723297}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5834906, \"EndTime\": 1740876917.5834992, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5410086166097121, \"count\": 1, \"min\": 0.5410086166097121, \"max\": 0.5410086166097121}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5835395, \"EndTime\": 1740876917.583549, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421473055531298, \"count\": 1, \"min\": 0.5421473055531298, \"max\": 0.5421473055531298}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5835884, \"EndTime\": 1740876917.5835986, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5410087254890379, \"count\": 1, \"min\": 0.5410087254890379, \"max\": 0.5410087254890379}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5836408, \"EndTime\": 1740876917.583651, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421476882895965, \"count\": 1, \"min\": 0.5421476882895965, \"max\": 0.5421476882895965}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5836844, \"EndTime\": 1740876917.5836937, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5434894332547945, \"count\": 1, \"min\": 0.5434894332547945, \"max\": 0.5434894332547945}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.583725, \"EndTime\": 1740876917.5837321, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.558076939350589, \"count\": 1, \"min\": 0.558076939350589, \"max\": 0.558076939350589}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5837643, \"EndTime\": 1740876917.583773, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5434892731026559, \"count\": 1, \"min\": 0.5434892731026559, \"max\": 0.5434892731026559}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5846756, \"EndTime\": 1740876917.5846994, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5580778260686441, \"count\": 1, \"min\": 0.5580778260686441, \"max\": 0.5580778260686441}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5847561, \"EndTime\": 1740876917.5847669, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6465431927579027, \"count\": 1, \"min\": 0.6465431927579027, \"max\": 0.6465431927579027}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5848072, \"EndTime\": 1740876917.5848172, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470312049764383, \"count\": 1, \"min\": 0.6470312049764383, \"max\": 0.6470312049764383}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5848556, \"EndTime\": 1740876917.5848668, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.646539614518785, \"count\": 1, \"min\": 0.646539614518785, \"max\": 0.646539614518785}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5849063, \"EndTime\": 1740876917.5849159, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470358593414133, \"count\": 1, \"min\": 0.6470358593414133, \"max\": 0.6470358593414133}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5849524, \"EndTime\": 1740876917.5849621, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6478998774143052, \"count\": 1, \"min\": 0.6478998774143052, \"max\": 0.6478998774143052}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5849888, \"EndTime\": 1740876917.584997, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575207158329365, \"count\": 1, \"min\": 0.6575207158329365, \"max\": 0.6575207158329365}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5850158, \"EndTime\": 1740876917.5850227, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6479555482279267, \"count\": 1, \"min\": 0.6479555482279267, \"max\": 0.6479555482279267}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876917.5850532, \"EndTime\": 1740876917.5850616, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575787922462883, \"count\": 1, \"min\": 0.6575787922462883, \"max\": 0.6575787922462883}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:17 INFO 140224006256448] #quality_metric: host=algo-1, epoch=22, train binary_classification_cross_entropy_objective <loss>=0.4273380186646743\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2520514, \"EndTime\": 1740876918.2521064, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43195254300035113, \"count\": 1, \"min\": 0.43195254300035113, \"max\": 0.43195254300035113}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2521746, \"EndTime\": 1740876918.2521846, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4255737961647626, \"count\": 1, \"min\": 0.4255737961647626, \"max\": 0.4255737961647626}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2522166, \"EndTime\": 1740876918.2522247, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42503259070272154, \"count\": 1, \"min\": 0.42503259070272154, \"max\": 0.42503259070272154}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2522569, \"EndTime\": 1740876918.2522657, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4255716584262876, \"count\": 1, \"min\": 0.4255716584262876, \"max\": 0.4255716584262876}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2522964, \"EndTime\": 1740876918.252303, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42835692395926567, \"count\": 1, \"min\": 0.42835692395926567, \"max\": 0.42835692395926567}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.252337, \"EndTime\": 1740876918.2523458, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4605695549425932, \"count\": 1, \"min\": 0.4605695549425932, \"max\": 0.4605695549425932}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2523813, \"EndTime\": 1740876918.252388, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4283571320082747, \"count\": 1, \"min\": 0.4283571320082747, \"max\": 0.4283571320082747}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2524068, \"EndTime\": 1740876918.2524118, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46056363584356463, \"count\": 1, \"min\": 0.46056363584356463, \"max\": 0.46056363584356463}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.252429, \"EndTime\": 1740876918.252435, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42636879680795514, \"count\": 1, \"min\": 0.42636879680795514, \"max\": 0.42636879680795514}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2524588, \"EndTime\": 1740876918.252467, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42689249037299987, \"count\": 1, \"min\": 0.42689249037299987, \"max\": 0.42689249037299987}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2524934, \"EndTime\": 1740876918.2525012, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4263594016149138, \"count\": 1, \"min\": 0.4263594016149138, \"max\": 0.4263594016149138}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2525344, \"EndTime\": 1740876918.2525406, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42689104537489125, \"count\": 1, \"min\": 0.42689104537489125, \"max\": 0.42689104537489125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2529485, \"EndTime\": 1740876918.2529652, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.429179390562401, \"count\": 1, \"min\": 0.429179390562401, \"max\": 0.429179390562401}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2530107, \"EndTime\": 1740876918.2530205, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4599854212205197, \"count\": 1, \"min\": 0.4599854212205197, \"max\": 0.4599854212205197}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2530525, \"EndTime\": 1740876918.253061, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42917953333428804, \"count\": 1, \"min\": 0.42917953333428804, \"max\": 0.42917953333428804}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2530942, \"EndTime\": 1740876918.253103, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45998624896584284, \"count\": 1, \"min\": 0.45998624896584284, \"max\": 0.45998624896584284}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.253133, \"EndTime\": 1740876918.2531414, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530231808848123, \"count\": 1, \"min\": 0.5530231808848123, \"max\": 0.5530231808848123}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2531672, \"EndTime\": 1740876918.2531748, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5525903991514907, \"count\": 1, \"min\": 0.5525903991514907, \"max\": 0.5525903991514907}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.253204, \"EndTime\": 1740876918.2532136, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530240546208349, \"count\": 1, \"min\": 0.5530240546208349, \"max\": 0.5530240546208349}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2532444, \"EndTime\": 1740876918.2532535, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5525975698607907, \"count\": 1, \"min\": 0.5525975698607907, \"max\": 0.5525975698607907}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2532835, \"EndTime\": 1740876918.2532933, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5580929030785623, \"count\": 1, \"min\": 0.5580929030785623, \"max\": 0.5580929030785623}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.253325, \"EndTime\": 1740876918.2533343, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5548141166720523, \"count\": 1, \"min\": 0.5548141166720523, \"max\": 0.5548141166720523}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.253367, \"EndTime\": 1740876918.2533765, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5580938530875859, \"count\": 1, \"min\": 0.5580938530875859, \"max\": 0.5580938530875859}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2534223, \"EndTime\": 1740876918.2534318, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5548140938076058, \"count\": 1, \"min\": 0.5548140938076058, \"max\": 0.5548140938076058}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.253462, \"EndTime\": 1740876918.2534719, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6627035301565949, \"count\": 1, \"min\": 0.6627035301565949, \"max\": 0.6627035301565949}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2535002, \"EndTime\": 1740876918.2535088, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6631968230838133, \"count\": 1, \"min\": 0.6631968230838133, \"max\": 0.6631968230838133}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.253539, \"EndTime\": 1740876918.2535481, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6627987345699684, \"count\": 1, \"min\": 0.6627987345699684, \"max\": 0.6627987345699684}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2535794, \"EndTime\": 1740876918.2535877, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.663729639562995, \"count\": 1, \"min\": 0.663729639562995, \"max\": 0.663729639562995}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2536263, \"EndTime\": 1740876918.253636, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6620713142489968, \"count\": 1, \"min\": 0.6620713142489968, \"max\": 0.6620713142489968}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2536721, \"EndTime\": 1740876918.2536821, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6628878874101541, \"count\": 1, \"min\": 0.6628878874101541, \"max\": 0.6628878874101541}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2537205, \"EndTime\": 1740876918.2537303, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.661968920450783, \"count\": 1, \"min\": 0.661968920450783, \"max\": 0.661968920450783}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2537696, \"EndTime\": 1740876918.2537801, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6629332975971227, \"count\": 1, \"min\": 0.6629332975971227, \"max\": 0.6629332975971227}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:18 INFO 140224006256448] #quality_metric: host=algo-1, epoch=22, validation binary_classification_cross_entropy_objective <loss>=0.43195254300035113\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:18 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=22, criteria=sampled_accuracy, value=0.8140556368960741\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:18 INFO 140224006256448] Epoch 22: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:18 INFO 140224006256448] Saving model for epoch: 22\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:18 INFO 140224006256448] Saved checkpoint to \"/tmp/tmpxb1fl56o/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:18 INFO 140224006256448] #progress_metric: host=algo-1, completed 76.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876915.2752352, \"EndTime\": 1740876918.2590623, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 22, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 76498.0, \"count\": 1, \"min\": 76498, \"max\": 76498}, \"Total Batches Seen\": {\"sum\": 2257.0, \"count\": 1, \"min\": 2257, \"max\": 2257}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 25.0, \"count\": 1, \"min\": 25, \"max\": 25}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:18 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1067.714855815915 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5687997, \"EndTime\": 1740876920.568844, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4271888826407638, \"count\": 1, \"min\": 0.4271888826407638, \"max\": 0.4271888826407638}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5689087, \"EndTime\": 1740876920.5689187, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42496043183545684, \"count\": 1, \"min\": 0.42496043183545684, \"max\": 0.42496043183545684}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.568952, \"EndTime\": 1740876920.56896, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.423122081328313, \"count\": 1, \"min\": 0.423122081328313, \"max\": 0.423122081328313}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5689893, \"EndTime\": 1740876920.5689979, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42495959035811887, \"count\": 1, \"min\": 0.42495959035811887, \"max\": 0.42495959035811887}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.569033, \"EndTime\": 1740876920.5690424, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4284247825750439, \"count\": 1, \"min\": 0.4284247825750439, \"max\": 0.4284247825750439}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5690823, \"EndTime\": 1740876920.569091, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4573413752665028, \"count\": 1, \"min\": 0.4573413752665028, \"max\": 0.4573413752665028}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.569119, \"EndTime\": 1740876920.5691273, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42842535803696535, \"count\": 1, \"min\": 0.42842535803696535, \"max\": 0.42842535803696535}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5691633, \"EndTime\": 1740876920.569171, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45734002060863055, \"count\": 1, \"min\": 0.45734002060863055, \"max\": 0.45734002060863055}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5691977, \"EndTime\": 1740876920.5692053, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4237702891164607, \"count\": 1, \"min\": 0.4237702891164607, \"max\": 0.4237702891164607}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5692308, \"EndTime\": 1740876920.569238, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4255628907024521, \"count\": 1, \"min\": 0.4255628907024521, \"max\": 0.4255628907024521}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5692673, \"EndTime\": 1740876920.5692747, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.423769454726835, \"count\": 1, \"min\": 0.423769454726835, \"max\": 0.423769454726835}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.569302, \"EndTime\": 1740876920.5693102, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4255632630335538, \"count\": 1, \"min\": 0.4255632630335538, \"max\": 0.4255632630335538}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5693421, \"EndTime\": 1740876920.5693512, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42891470892831995, \"count\": 1, \"min\": 0.42891470892831995, \"max\": 0.42891470892831995}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5693734, \"EndTime\": 1740876920.5693803, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4550516890393715, \"count\": 1, \"min\": 0.4550516890393715, \"max\": 0.4550516890393715}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5694232, \"EndTime\": 1740876920.5694325, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42891478568673663, \"count\": 1, \"min\": 0.42891478568673663, \"max\": 0.42891478568673663}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5694704, \"EndTime\": 1740876920.56948, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4550519933585952, \"count\": 1, \"min\": 0.4550519933585952, \"max\": 0.4550519933585952}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5695126, \"EndTime\": 1740876920.5695226, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5409786012035469, \"count\": 1, \"min\": 0.5409786012035469, \"max\": 0.5409786012035469}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.569557, \"EndTime\": 1740876920.569567, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421423770294093, \"count\": 1, \"min\": 0.5421423770294093, \"max\": 0.5421423770294093}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.569605, \"EndTime\": 1740876920.5696154, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5409786940978193, \"count\": 1, \"min\": 0.5409786940978193, \"max\": 0.5409786940978193}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5696504, \"EndTime\": 1740876920.5696602, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421427166363924, \"count\": 1, \"min\": 0.5421427166363924, \"max\": 0.5421427166363924}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5696952, \"EndTime\": 1740876920.5697045, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5433419213726278, \"count\": 1, \"min\": 0.5433419213726278, \"max\": 0.5433419213726278}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5697396, \"EndTime\": 1740876920.5697496, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5579869148476375, \"count\": 1, \"min\": 0.5579869148476375, \"max\": 0.5579869148476375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5697858, \"EndTime\": 1740876920.5697958, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5433418375264988, \"count\": 1, \"min\": 0.5433418375264988, \"max\": 0.5433418375264988}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5698373, \"EndTime\": 1740876920.5698476, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5579877204340067, \"count\": 1, \"min\": 0.5579877204340067, \"max\": 0.5579877204340067}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5698838, \"EndTime\": 1740876920.569892, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6465334298111531, \"count\": 1, \"min\": 0.6465334298111531, \"max\": 0.6465334298111531}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5699103, \"EndTime\": 1740876920.5699155, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470284078937026, \"count\": 1, \"min\": 0.6470284078937026, \"max\": 0.6470284078937026}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5699327, \"EndTime\": 1740876920.569938, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6465289660603996, \"count\": 1, \"min\": 0.6465289660603996, \"max\": 0.6465289660603996}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5699549, \"EndTime\": 1740876920.5699599, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470321863983945, \"count\": 1, \"min\": 0.6470321863983945, \"max\": 0.6470321863983945}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5699768, \"EndTime\": 1740876920.5699818, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6478193410961481, \"count\": 1, \"min\": 0.6478193410961481, \"max\": 0.6478193410961481}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5700083, \"EndTime\": 1740876920.570017, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6574974814070546, \"count\": 1, \"min\": 0.6574974814070546, \"max\": 0.6574974814070546}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5700538, \"EndTime\": 1740876920.5700636, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6478682432952823, \"count\": 1, \"min\": 0.6478682432952823, \"max\": 0.6478682432952823}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876920.5701022, \"EndTime\": 1740876920.5701122, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575540268745398, \"count\": 1, \"min\": 0.6575540268745398, \"max\": 0.6575540268745398}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:20 INFO 140224006256448] #quality_metric: host=algo-1, epoch=23, train binary_classification_cross_entropy_objective <loss>=0.4271888826407638\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.255418, \"EndTime\": 1740876921.2554772, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43176243071325704, \"count\": 1, \"min\": 0.43176243071325704, \"max\": 0.43176243071325704}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2555466, \"EndTime\": 1740876921.2555566, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42555401981487806, \"count\": 1, \"min\": 0.42555401981487806, \"max\": 0.42555401981487806}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2555814, \"EndTime\": 1740876921.2555878, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4250403377357025, \"count\": 1, \"min\": 0.4250403377357025, \"max\": 0.4250403377357025}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2556124, \"EndTime\": 1740876921.255619, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4255522393551962, \"count\": 1, \"min\": 0.4255522393551962, \"max\": 0.4255522393551962}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2556522, \"EndTime\": 1740876921.2556608, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42815816367527754, \"count\": 1, \"min\": 0.42815816367527754, \"max\": 0.42815816367527754}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2559733, \"EndTime\": 1740876921.2559817, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.46018458442492505, \"count\": 1, \"min\": 0.46018458442492505, \"max\": 0.46018458442492505}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2560022, \"EndTime\": 1740876921.2560081, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42815836997890894, \"count\": 1, \"min\": 0.42815836997890894, \"max\": 0.42815836997890894}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.256026, \"EndTime\": 1740876921.2560313, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4601792112800073, \"count\": 1, \"min\": 0.4601792112800073, \"max\": 0.4601792112800073}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.25605, \"EndTime\": 1740876921.2560582, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4263778200610316, \"count\": 1, \"min\": 0.4263778200610316, \"max\": 0.4263778200610316}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.256087, \"EndTime\": 1740876921.2560954, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4268744384561765, \"count\": 1, \"min\": 0.4268744384561765, \"max\": 0.4268744384561765}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.256123, \"EndTime\": 1740876921.2561324, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42636870884092454, \"count\": 1, \"min\": 0.42636870884092454, \"max\": 0.42636870884092454}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2561533, \"EndTime\": 1740876921.2561584, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4268731700902802, \"count\": 1, \"min\": 0.4268731700902802, \"max\": 0.4268731700902802}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2561762, \"EndTime\": 1740876921.2561812, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4290196134614735, \"count\": 1, \"min\": 0.4290196134614735, \"max\": 0.4290196134614735}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2561982, \"EndTime\": 1740876921.2562032, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45961104060685476, \"count\": 1, \"min\": 0.45961104060685476, \"max\": 0.45961104060685476}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2562284, \"EndTime\": 1740876921.2562363, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42901972795824356, \"count\": 1, \"min\": 0.42901972795824356, \"max\": 0.42901972795824356}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2562625, \"EndTime\": 1740876921.256271, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4596117528954502, \"count\": 1, \"min\": 0.4596117528954502, \"max\": 0.4596117528954502}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2563, \"EndTime\": 1740876921.2563086, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530182058605233, \"count\": 1, \"min\": 0.5530182058605233, \"max\": 0.5530182058605233}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2563415, \"EndTime\": 1740876921.2563508, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5525835988113158, \"count\": 1, \"min\": 0.5525835988113158, \"max\": 0.5525835988113158}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2563856, \"EndTime\": 1740876921.256395, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530189300176863, \"count\": 1, \"min\": 0.5530189300176863, \"max\": 0.5530189300176863}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2564254, \"EndTime\": 1740876921.2564344, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.552589942909788, \"count\": 1, \"min\": 0.552589942909788, \"max\": 0.552589942909788}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2564726, \"EndTime\": 1740876921.2564821, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5573100839491993, \"count\": 1, \"min\": 0.5573100839491993, \"max\": 0.5573100839491993}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2565215, \"EndTime\": 1740876921.256532, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5550926499625076, \"count\": 1, \"min\": 0.5550926499625076, \"max\": 0.5550926499625076}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2565699, \"EndTime\": 1740876921.2565806, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5573110168535225, \"count\": 1, \"min\": 0.5573110168535225, \"max\": 0.5573110168535225}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2566216, \"EndTime\": 1740876921.2566316, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5550914337834013, \"count\": 1, \"min\": 0.5550914337834013, \"max\": 0.5550914337834013}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2566736, \"EndTime\": 1740876921.2566838, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6626976133265572, \"count\": 1, \"min\": 0.6626976133265572, \"max\": 0.6626976133265572}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2567213, \"EndTime\": 1740876921.256731, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6632230594252423, \"count\": 1, \"min\": 0.6632230594252423, \"max\": 0.6632230594252423}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.25677, \"EndTime\": 1740876921.2567797, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6627898516452504, \"count\": 1, \"min\": 0.6627898516452504, \"max\": 0.6627898516452504}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2568126, \"EndTime\": 1740876921.2568214, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6637425426159212, \"count\": 1, \"min\": 0.6637425426159212, \"max\": 0.6637425426159212}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2568521, \"EndTime\": 1740876921.2568605, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6620764245400491, \"count\": 1, \"min\": 0.6620764245400491, \"max\": 0.6620764245400491}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2568924, \"EndTime\": 1740876921.2569017, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6627720205186924, \"count\": 1, \"min\": 0.6627720205186924, \"max\": 0.6627720205186924}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.256932, \"EndTime\": 1740876921.2569406, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6621398126398312, \"count\": 1, \"min\": 0.6621398126398312, \"max\": 0.6621398126398312}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2569788, \"EndTime\": 1740876921.2569878, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6628157205846963, \"count\": 1, \"min\": 0.6628157205846963, \"max\": 0.6628157205846963}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:21 INFO 140224006256448] #quality_metric: host=algo-1, epoch=23, validation binary_classification_cross_entropy_objective <loss>=0.43176243071325704\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:21 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=23, criteria=sampled_accuracy, value=0.8140556368960741\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:21 INFO 140224006256448] Epoch 23: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:21 INFO 140224006256448] Saving model for epoch: 23\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:21 INFO 140224006256448] Saved checkpoint to \"/tmp/tmp7_239n35/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:21 INFO 140224006256448] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876918.2592888, \"EndTime\": 1740876921.2627413, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 23, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 79684.0, \"count\": 1, \"min\": 79684, \"max\": 79684}, \"Total Batches Seen\": {\"sum\": 2351.0, \"count\": 1, \"min\": 2351, \"max\": 2351}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 26.0, \"count\": 1, \"min\": 26, \"max\": 26}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:21 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1060.7381149258356 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5514317, \"EndTime\": 1740876923.551477, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42705800501626173, \"count\": 1, \"min\": 0.42705800501626173, \"max\": 0.42705800501626173}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5515387, \"EndTime\": 1740876923.5515506, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42494420459344373, \"count\": 1, \"min\": 0.42494420459344373, \"max\": 0.42494420459344373}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5515852, \"EndTime\": 1740876923.551595, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42309223663045364, \"count\": 1, \"min\": 0.42309223663045364, \"max\": 0.42309223663045364}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5516324, \"EndTime\": 1740876923.5516393, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42494344364458214, \"count\": 1, \"min\": 0.42494344364458214, \"max\": 0.42494344364458214}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5516613, \"EndTime\": 1740876923.5516665, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4279644275148936, \"count\": 1, \"min\": 0.4279644275148936, \"max\": 0.4279644275148936}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.551689, \"EndTime\": 1740876923.5517693, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45704055601550686, \"count\": 1, \"min\": 0.45704055601550686, \"max\": 0.45704055601550686}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5518064, \"EndTime\": 1740876923.5518167, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42796489892316575, \"count\": 1, \"min\": 0.42796489892316575, \"max\": 0.42796489892316575}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.551854, \"EndTime\": 1740876923.551864, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4570393440166958, \"count\": 1, \"min\": 0.4570393440166958, \"max\": 0.4570393440166958}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5518994, \"EndTime\": 1740876923.551908, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4237406647408936, \"count\": 1, \"min\": 0.4237406647408936, \"max\": 0.4237406647408936}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5519605, \"EndTime\": 1740876923.551972, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4255471915704099, \"count\": 1, \"min\": 0.4255471915704099, \"max\": 0.4255471915704099}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5520122, \"EndTime\": 1740876923.552022, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42373992264233085, \"count\": 1, \"min\": 0.42373992264233085, \"max\": 0.42373992264233085}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5520554, \"EndTime\": 1740876923.5520642, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42554752785974026, \"count\": 1, \"min\": 0.42554752785974026, \"max\": 0.42554752785974026}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.552094, \"EndTime\": 1740876923.5521026, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42847681829704654, \"count\": 1, \"min\": 0.42847681829704654, \"max\": 0.42847681829704654}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.552132, \"EndTime\": 1740876923.5521407, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45475922514561384, \"count\": 1, \"min\": 0.45475922514561384, \"max\": 0.45475922514561384}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5521731, \"EndTime\": 1740876923.5521824, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4284768840468887, \"count\": 1, \"min\": 0.4284768840468887, \"max\": 0.4284768840468887}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5522115, \"EndTime\": 1740876923.5522199, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45475949870114984, \"count\": 1, \"min\": 0.45475949870114984, \"max\": 0.45475949870114984}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.55226, \"EndTime\": 1740876923.55227, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5409522515018856, \"count\": 1, \"min\": 0.5409522515018856, \"max\": 0.5409522515018856}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5523052, \"EndTime\": 1740876923.5523138, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421310605164347, \"count\": 1, \"min\": 0.5421310605164347, \"max\": 0.5421310605164347}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5523431, \"EndTime\": 1740876923.5523515, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5409523241886378, \"count\": 1, \"min\": 0.5409523241886378, \"max\": 0.5409523241886378}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5523784, \"EndTime\": 1740876923.5523882, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421313551843053, \"count\": 1, \"min\": 0.5421313551843053, \"max\": 0.5421313551843053}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5524166, \"EndTime\": 1740876923.552425, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5432051264131318, \"count\": 1, \"min\": 0.5432051264131318, \"max\": 0.5432051264131318}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.552458, \"EndTime\": 1740876923.5524662, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5579177686340216, \"count\": 1, \"min\": 0.5579177686340216, \"max\": 0.5579177686340216}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5525036, \"EndTime\": 1740876923.5525131, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5432050965542585, \"count\": 1, \"min\": 0.5432050965542585, \"max\": 0.5432050965542585}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5525458, \"EndTime\": 1740876923.553406, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5579184822309327, \"count\": 1, \"min\": 0.5579184822309327, \"max\": 0.5579184822309327}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5534697, \"EndTime\": 1740876923.553485, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6465253268971163, \"count\": 1, \"min\": 0.6465253268971163, \"max\": 0.6465253268971163}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5535426, \"EndTime\": 1740876923.553555, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470241214865601, \"count\": 1, \"min\": 0.6470241214865601, \"max\": 0.6470241214865601}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5535967, \"EndTime\": 1740876923.5536077, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6465206387524058, \"count\": 1, \"min\": 0.6465206387524058, \"max\": 0.6465206387524058}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5536463, \"EndTime\": 1740876923.5536568, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.647026955365079, \"count\": 1, \"min\": 0.647026955365079, \"max\": 0.647026955365079}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.553696, \"EndTime\": 1740876923.5537052, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6477456566353978, \"count\": 1, \"min\": 0.6477456566353978, \"max\": 0.6477456566353978}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5537438, \"EndTime\": 1740876923.553754, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6574837095295606, \"count\": 1, \"min\": 0.6574837095295606, \"max\": 0.6574837095295606}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.553792, \"EndTime\": 1740876923.5538013, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6477788144617727, \"count\": 1, \"min\": 0.6477788144617727, \"max\": 0.6477788144617727}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876923.5538812, \"EndTime\": 1740876923.5538943, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575352278485621, \"count\": 1, \"min\": 0.6575352278485621, \"max\": 0.6575352278485621}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:23 INFO 140224006256448] #quality_metric: host=algo-1, epoch=24, train binary_classification_cross_entropy_objective <loss>=0.42705800501626173\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2118921, \"EndTime\": 1740876924.2119784, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43159492804749294, \"count\": 1, \"min\": 0.43159492804749294, \"max\": 0.43159492804749294}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2120464, \"EndTime\": 1740876924.2120566, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42553471576417, \"count\": 1, \"min\": 0.42553471576417, \"max\": 0.42553471576417}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2120814, \"EndTime\": 1740876924.2120876, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4250475672642274, \"count\": 1, \"min\": 0.4250475672642274, \"max\": 0.4250475672642274}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2121115, \"EndTime\": 1740876924.212117, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4255331578401311, \"count\": 1, \"min\": 0.4255331578401311, \"max\": 0.4255331578401311}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2121363, \"EndTime\": 1740876924.2121415, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42799261408703915, \"count\": 1, \"min\": 0.42799261408703915, \"max\": 0.42799261408703915}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2121618, \"EndTime\": 1740876924.212167, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4598376179334883, \"count\": 1, \"min\": 0.4598376179334883, \"max\": 0.4598376179334883}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2121863, \"EndTime\": 1740876924.2121916, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4279927161916283, \"count\": 1, \"min\": 0.4279927161916283, \"max\": 0.4279927161916283}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2122104, \"EndTime\": 1740876924.2122157, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45983274161030224, \"count\": 1, \"min\": 0.45983274161030224, \"max\": 0.45983274161030224}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2122374, \"EndTime\": 1740876924.2122426, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4263862182943922, \"count\": 1, \"min\": 0.4263862182943922, \"max\": 0.4263862182943922}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2122643, \"EndTime\": 1740876924.2122695, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42685537317312305, \"count\": 1, \"min\": 0.42685537317312305, \"max\": 0.42685537317312305}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2122927, \"EndTime\": 1740876924.2123008, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4263773795277273, \"count\": 1, \"min\": 0.4263773795277273, \"max\": 0.4263773795277273}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2123327, \"EndTime\": 1740876924.212341, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4268542892936383, \"count\": 1, \"min\": 0.4268542892936383, \"max\": 0.4268542892936383}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2123673, \"EndTime\": 1740876924.212375, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4289017873836646, \"count\": 1, \"min\": 0.4289017873836646, \"max\": 0.4289017873836646}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.212405, \"EndTime\": 1740876924.2124128, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45927488245342696, \"count\": 1, \"min\": 0.45927488245342696, \"max\": 0.45927488245342696}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.212447, \"EndTime\": 1740876924.2124555, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42890181565878155, \"count\": 1, \"min\": 0.42890181565878155, \"max\": 0.42890181565878155}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2124817, \"EndTime\": 1740876924.2124898, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45927554299157675, \"count\": 1, \"min\": 0.45927554299157675, \"max\": 0.45927554299157675}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2125187, \"EndTime\": 1740876924.212528, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530138619647718, \"count\": 1, \"min\": 0.5530138619647718, \"max\": 0.5530138619647718}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2125566, \"EndTime\": 1740876924.212564, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5525730202522668, \"count\": 1, \"min\": 0.5525730202522668, \"max\": 0.5525730202522668}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2125914, \"EndTime\": 1740876924.2125976, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530144707524759, \"count\": 1, \"min\": 0.5530144707524759, \"max\": 0.5530144707524759}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2126226, \"EndTime\": 1740876924.212631, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.552578617852743, \"count\": 1, \"min\": 0.552578617852743, \"max\": 0.552578617852743}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2126603, \"EndTime\": 1740876924.212669, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5565195886491856, \"count\": 1, \"min\": 0.5565195886491856, \"max\": 0.5565195886491856}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2127037, \"EndTime\": 1740876924.2127132, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5554051989168584, \"count\": 1, \"min\": 0.5554051989168584, \"max\": 0.5554051989168584}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2127478, \"EndTime\": 1740876924.2127576, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5565204538328581, \"count\": 1, \"min\": 0.5565204538328581, \"max\": 0.5565204538328581}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2127924, \"EndTime\": 1740876924.2128024, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5554030590839302, \"count\": 1, \"min\": 0.5554030590839302, \"max\": 0.5554030590839302}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.212837, \"EndTime\": 1740876924.2128465, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6626942597580514, \"count\": 1, \"min\": 0.6626942597580514, \"max\": 0.6626942597580514}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2128868, \"EndTime\": 1740876924.2128973, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6632435827967363, \"count\": 1, \"min\": 0.6632435827967363, \"max\": 0.6632435827967363}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.212936, \"EndTime\": 1740876924.2129438, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.662779665621622, \"count\": 1, \"min\": 0.662779665621622, \"max\": 0.662779665621622}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.21298, \"EndTime\": 1740876924.2129898, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6637481943231027, \"count\": 1, \"min\": 0.6637481943231027, \"max\": 0.6637481943231027}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.213022, \"EndTime\": 1740876924.2130294, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6624584044404819, \"count\": 1, \"min\": 0.6624584044404819, \"max\": 0.6624584044404819}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2130647, \"EndTime\": 1740876924.213074, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6627308470612913, \"count\": 1, \"min\": 0.6627308470612913, \"max\": 0.6627308470612913}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2130988, \"EndTime\": 1740876924.2131069, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6624821127770062, \"count\": 1, \"min\": 0.6624821127770062, \"max\": 0.6624821127770062}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.21313, \"EndTime\": 1740876924.213138, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6627686156360855, \"count\": 1, \"min\": 0.6627686156360855, \"max\": 0.6627686156360855}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:24 INFO 140224006256448] #quality_metric: host=algo-1, epoch=24, validation binary_classification_cross_entropy_objective <loss>=0.43159492804749294\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:24 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=24, criteria=sampled_accuracy, value=0.8140556368960741\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:24 INFO 140224006256448] Epoch 24: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:24 INFO 140224006256448] Saving model for epoch: 24\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:24 INFO 140224006256448] Saved checkpoint to \"/tmp/tmpcjl0v20_/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:24 INFO 140224006256448] #progress_metric: host=algo-1, completed 83.33333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876921.2629645, \"EndTime\": 1740876924.2193053, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 24, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 82870.0, \"count\": 1, \"min\": 82870, \"max\": 82870}, \"Total Batches Seen\": {\"sum\": 2445.0, \"count\": 1, \"min\": 2445, \"max\": 2445}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 27.0, \"count\": 1, \"min\": 27, \"max\": 27}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:24 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1077.6438879574112 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5164797, \"EndTime\": 1740876926.5165248, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4269427306134817, \"count\": 1, \"min\": 0.4269427306134817, \"max\": 0.4269427306134817}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.516585, \"EndTime\": 1740876926.5165944, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42492752690469066, \"count\": 1, \"min\": 0.42492752690469066, \"max\": 0.42492752690469066}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.516619, \"EndTime\": 1740876926.5166278, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4230650128781381, \"count\": 1, \"min\": 0.4230650128781381, \"max\": 0.4230650128781381}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5166657, \"EndTime\": 1740876926.5166752, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4249268452778864, \"count\": 1, \"min\": 0.4249268452778864, \"max\": 0.4249268452778864}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5167642, \"EndTime\": 1740876926.5167773, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.427541120831986, \"count\": 1, \"min\": 0.427541120831986, \"max\": 0.427541120831986}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5168488, \"EndTime\": 1740876926.5168605, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45673474837224143, \"count\": 1, \"min\": 0.45673474837224143, \"max\": 0.45673474837224143}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5169036, \"EndTime\": 1740876926.516914, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42754151035456023, \"count\": 1, \"min\": 0.42754151035456023, \"max\": 0.42754151035456023}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5169897, \"EndTime\": 1740876926.5170014, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4567337182411131, \"count\": 1, \"min\": 0.4567337182411131, \"max\": 0.4567337182411131}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5170417, \"EndTime\": 1740876926.5170517, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4237136825740073, \"count\": 1, \"min\": 0.4237136825740073, \"max\": 0.4237136825740073}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5171247, \"EndTime\": 1740876926.5171359, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42553061899092287, \"count\": 1, \"min\": 0.42553061899092287, \"max\": 0.42553061899092287}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5171795, \"EndTime\": 1740876926.5171902, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42371302673441186, \"count\": 1, \"min\": 0.42371302673441186, \"max\": 0.42371302673441186}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5172296, \"EndTime\": 1740876926.5172408, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.425530921952925, \"count\": 1, \"min\": 0.425530921952925, \"max\": 0.425530921952925}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5172772, \"EndTime\": 1740876926.517287, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4280728500602669, \"count\": 1, \"min\": 0.4280728500602669, \"max\": 0.4280728500602669}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.517344, \"EndTime\": 1740876926.517355, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4544614807553566, \"count\": 1, \"min\": 0.4544614807553566, \"max\": 0.4544614807553566}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5173955, \"EndTime\": 1740876926.5174057, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4280729046507322, \"count\": 1, \"min\": 0.4280729046507322, \"max\": 0.4280729046507322}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5174446, \"EndTime\": 1740876926.5174541, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45446173696861775, \"count\": 1, \"min\": 0.45446173696861775, \"max\": 0.45446173696861775}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5175164, \"EndTime\": 1740876926.5175273, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5409281762018753, \"count\": 1, \"min\": 0.5409281762018753, \"max\": 0.5409281762018753}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5176024, \"EndTime\": 1740876926.517616, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421221456823283, \"count\": 1, \"min\": 0.5421221456823283, \"max\": 0.5421221456823283}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5176475, \"EndTime\": 1740876926.5176566, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5409282494918369, \"count\": 1, \"min\": 0.5409282494918369, \"max\": 0.5409282494918369}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.517691, \"EndTime\": 1740876926.5177002, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421224089833018, \"count\": 1, \"min\": 0.5421224089833018, \"max\": 0.5421224089833018}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5177326, \"EndTime\": 1740876926.5177433, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5430719591559374, \"count\": 1, \"min\": 0.5430719591559374, \"max\": 0.5430719591559374}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.517771, \"EndTime\": 1740876926.5177794, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5578554311483288, \"count\": 1, \"min\": 0.5578554311483288, \"max\": 0.5578554311483288}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.517816, \"EndTime\": 1740876926.5178268, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5430719769506195, \"count\": 1, \"min\": 0.5430719769506195, \"max\": 0.5430719769506195}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5178933, \"EndTime\": 1740876926.517904, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5578560397867761, \"count\": 1, \"min\": 0.5578560397867761, \"max\": 0.5578560397867761}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5179632, \"EndTime\": 1740876926.5179732, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6465184026545622, \"count\": 1, \"min\": 0.6465184026545622, \"max\": 0.6465184026545622}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.518031, \"EndTime\": 1740876926.5180416, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470195600158576, \"count\": 1, \"min\": 0.6470195600158576, \"max\": 0.6470195600158576}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5181017, \"EndTime\": 1740876926.5181148, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6465143665793875, \"count\": 1, \"min\": 0.6465143665793875, \"max\": 0.6465143665793875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5185702, \"EndTime\": 1740876926.518589, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470215494009907, \"count\": 1, \"min\": 0.6470215494009907, \"max\": 0.6470215494009907}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5186327, \"EndTime\": 1740876926.5186427, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6476733070774067, \"count\": 1, \"min\": 0.6476733070774067, \"max\": 0.6476733070774067}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.518676, \"EndTime\": 1740876926.5186872, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6574609805932911, \"count\": 1, \"min\": 0.6574609805932911, \"max\": 0.6574609805932911}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.5187147, \"EndTime\": 1740876926.5187252, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6476845080757503, \"count\": 1, \"min\": 0.6476845080757503, \"max\": 0.6476845080757503}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876926.518752, \"EndTime\": 1740876926.5187624, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6575062749960391, \"count\": 1, \"min\": 0.6575062749960391, \"max\": 0.6575062749960391}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:26 INFO 140224006256448] #quality_metric: host=algo-1, epoch=25, train binary_classification_cross_entropy_objective <loss>=0.4269427306134817\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.201443, \"EndTime\": 1740876927.2014937, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4314470416804882, \"count\": 1, \"min\": 0.4314470416804882, \"max\": 0.4314470416804882}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2015588, \"EndTime\": 1740876927.2015688, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42551827099103356, \"count\": 1, \"min\": 0.42551827099103356, \"max\": 0.42551827099103356}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.201593, \"EndTime\": 1740876927.2015991, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4250547903348551, \"count\": 1, \"min\": 0.4250547903348551, \"max\": 0.4250547903348551}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2016249, \"EndTime\": 1740876927.2016332, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42551694240961035, \"count\": 1, \"min\": 0.42551694240961035, \"max\": 0.42551694240961035}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2016664, \"EndTime\": 1740876927.201675, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4278233107152132, \"count\": 1, \"min\": 0.4278233107152132, \"max\": 0.4278233107152132}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2017043, \"EndTime\": 1740876927.2017143, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4594562982221299, \"count\": 1, \"min\": 0.4594562982221299, \"max\": 0.4594562982221299}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2017446, \"EndTime\": 1740876927.2017539, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.427823363774692, \"count\": 1, \"min\": 0.427823363774692, \"max\": 0.427823363774692}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2017841, \"EndTime\": 1740876927.2017922, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45945184209859913, \"count\": 1, \"min\": 0.45945184209859913, \"max\": 0.45945184209859913}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2018192, \"EndTime\": 1740876927.2018278, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.426394458396543, \"count\": 1, \"min\": 0.426394458396543, \"max\": 0.426394458396543}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2018614, \"EndTime\": 1740876927.20187, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42683859520740425, \"count\": 1, \"min\": 0.42683859520740425, \"max\": 0.42683859520740425}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2018971, \"EndTime\": 1740876927.201905, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4263858669498829, \"count\": 1, \"min\": 0.4263858669498829, \"max\": 0.4263858669498829}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2019346, \"EndTime\": 1740876927.2019439, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4268376614303924, \"count\": 1, \"min\": 0.4268376614303924, \"max\": 0.4268376614303924}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2019775, \"EndTime\": 1740876927.2019844, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4287898982077357, \"count\": 1, \"min\": 0.4287898982077357, \"max\": 0.4287898982077357}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2020035, \"EndTime\": 1740876927.202011, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4588963347507605, \"count\": 1, \"min\": 0.4588963347507605, \"max\": 0.4588963347507605}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2020338, \"EndTime\": 1740876927.2020392, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42878992142125766, \"count\": 1, \"min\": 0.42878992142125766, \"max\": 0.42878992142125766}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2020712, \"EndTime\": 1740876927.2020802, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.458896917968683, \"count\": 1, \"min\": 0.458896917968683, \"max\": 0.458896917968683}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2021117, \"EndTime\": 1740876927.2021217, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.553008674353492, \"count\": 1, \"min\": 0.553008674353492, \"max\": 0.553008674353492}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2021847, \"EndTime\": 1740876927.202195, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5525559401616869, \"count\": 1, \"min\": 0.5525559401616869, \"max\": 0.5525559401616869}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2022362, \"EndTime\": 1740876927.2022462, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530092018066004, \"count\": 1, \"min\": 0.5530092018066004, \"max\": 0.5530092018066004}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2023044, \"EndTime\": 1740876927.202315, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5525609029683327, \"count\": 1, \"min\": 0.5525609029683327, \"max\": 0.5525609029683327}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2023487, \"EndTime\": 1740876927.2023582, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5557441618920769, \"count\": 1, \"min\": 0.5557441618920769, \"max\": 0.5557441618920769}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2023954, \"EndTime\": 1740876927.202405, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.555674385012156, \"count\": 1, \"min\": 0.555674385012156, \"max\": 0.555674385012156}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2024424, \"EndTime\": 1740876927.2024522, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5557449181641876, \"count\": 1, \"min\": 0.5557449181641876, \"max\": 0.5557449181641876}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2025175, \"EndTime\": 1740876927.202529, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5556715070590442, \"count\": 1, \"min\": 0.5556715070590442, \"max\": 0.5556715070590442}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2030935, \"EndTime\": 1740876927.2031028, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6626904092805452, \"count\": 1, \"min\": 0.6626904092805452, \"max\": 0.6626904092805452}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2031295, \"EndTime\": 1740876927.2031353, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6632685209263122, \"count\": 1, \"min\": 0.6632685209263122, \"max\": 0.6632685209263122}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2031584, \"EndTime\": 1740876927.2031639, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6627618327496865, \"count\": 1, \"min\": 0.6627618327496865, \"max\": 0.6627618327496865}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2031865, \"EndTime\": 1740876927.203192, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6637529234236889, \"count\": 1, \"min\": 0.6637529234236889, \"max\": 0.6637529234236889}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2032142, \"EndTime\": 1740876927.2032208, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6629879488602913, \"count\": 1, \"min\": 0.6629879488602913, \"max\": 0.6629879488602913}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2032475, \"EndTime\": 1740876927.2032535, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.662702359357306, \"count\": 1, \"min\": 0.662702359357306, \"max\": 0.662702359357306}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2032757, \"EndTime\": 1740876927.2032814, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6629084004839203, \"count\": 1, \"min\": 0.6629084004839203, \"max\": 0.6629084004839203}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2033036, \"EndTime\": 1740876927.203309, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6627322288767311, \"count\": 1, \"min\": 0.6627322288767311, \"max\": 0.6627322288767311}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:27 INFO 140224006256448] #quality_metric: host=algo-1, epoch=25, validation binary_classification_cross_entropy_objective <loss>=0.4314470416804882\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:27 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=25, criteria=sampled_accuracy, value=0.8125915080527361\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:27 INFO 140224006256448] Epoch 25: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:27 INFO 140224006256448] Saving model for epoch: 25\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:27 INFO 140224006256448] Saved checkpoint to \"/tmp/tmp4f4c4pmv/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:27 INFO 140224006256448] #progress_metric: host=algo-1, completed 86.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876924.2195249, \"EndTime\": 1740876927.2083592, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 25, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 86056.0, \"count\": 1, \"min\": 86056, \"max\": 86056}, \"Total Batches Seen\": {\"sum\": 2539.0, \"count\": 1, \"min\": 2539, \"max\": 2539}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 28.0, \"count\": 1, \"min\": 28, \"max\": 28}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:27 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1065.903965166303 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.520351, \"EndTime\": 1740876929.5203955, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4268408313271066, \"count\": 1, \"min\": 0.4268408313271066, \"max\": 0.4268408313271066}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.5204542, \"EndTime\": 1740876929.5204637, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4249103847445754, \"count\": 1, \"min\": 0.4249103847445754, \"max\": 0.4249103847445754}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.5204873, \"EndTime\": 1740876929.520496, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4230400680515451, \"count\": 1, \"min\": 0.4230400680515451, \"max\": 0.4230400680515451}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.5205302, \"EndTime\": 1740876929.5205393, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4249097598194699, \"count\": 1, \"min\": 0.4249097598194699, \"max\": 0.4249097598194699}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.5205734, \"EndTime\": 1740876929.5205824, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4271472335841971, \"count\": 1, \"min\": 0.4271472335841971, \"max\": 0.4271472335841971}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.5206153, \"EndTime\": 1740876929.520624, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4564245968661227, \"count\": 1, \"min\": 0.4564245968661227, \"max\": 0.4564245968661227}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.52066, \"EndTime\": 1740876929.52067, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42714755584890524, \"count\": 1, \"min\": 0.42714755584890524, \"max\": 0.42714755584890524}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.5207093, \"EndTime\": 1740876929.5207195, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4564236712410509, \"count\": 1, \"min\": 0.4564236712410509, \"max\": 0.4564236712410509}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.5207608, \"EndTime\": 1740876929.520771, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4236889135830015, \"count\": 1, \"min\": 0.4236889135830015, \"max\": 0.4236889135830015}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.520802, \"EndTime\": 1740876929.5208113, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4255134413922459, \"count\": 1, \"min\": 0.4255134413922459, \"max\": 0.4255134413922459}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.5208423, \"EndTime\": 1740876929.520851, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42368833012855334, \"count\": 1, \"min\": 0.42368833012855334, \"max\": 0.42368833012855334}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.5208793, \"EndTime\": 1740876929.5208883, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42551371630500345, \"count\": 1, \"min\": 0.42551371630500345, \"max\": 0.42551371630500345}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.5209203, \"EndTime\": 1740876929.5209293, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42769506051523787, \"count\": 1, \"min\": 0.42769506051523787, \"max\": 0.42769506051523787}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.5209525, \"EndTime\": 1740876929.5209582, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.454164256633346, \"count\": 1, \"min\": 0.454164256633346, \"max\": 0.454164256633346}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.5209835, \"EndTime\": 1740876929.520992, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42769510062867366, \"count\": 1, \"min\": 0.42769510062867366, \"max\": 0.42769510062867366}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.5210228, \"EndTime\": 1740876929.5210316, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45416446217700396, \"count\": 1, \"min\": 0.45416446217700396, \"max\": 0.45416446217700396}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.5210626, \"EndTime\": 1740876929.5210714, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5409050476392714, \"count\": 1, \"min\": 0.5409050476392714, \"max\": 0.5409050476392714}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.521107, \"EndTime\": 1740876929.5211136, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421140500068061, \"count\": 1, \"min\": 0.5421140500068061, \"max\": 0.5421140500068061}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.521144, \"EndTime\": 1740876929.521153, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5409051082618322, \"count\": 1, \"min\": 0.5409051082618322, \"max\": 0.5409051082618322}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.5211906, \"EndTime\": 1740876929.5212002, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421142719879247, \"count\": 1, \"min\": 0.5421142719879247, \"max\": 0.5421142719879247}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.5212815, \"EndTime\": 1740876929.5216997, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.542935944448009, \"count\": 1, \"min\": 0.542935944448009, \"max\": 0.542935944448009}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.5217445, \"EndTime\": 1740876929.5217566, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5577844762108433, \"count\": 1, \"min\": 0.5577844762108433, \"max\": 0.5577844762108433}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.521814, \"EndTime\": 1740876929.5218248, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5429359905935405, \"count\": 1, \"min\": 0.5429359905935405, \"max\": 0.5429359905935405}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.521862, \"EndTime\": 1740876929.5218723, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.557784985319713, \"count\": 1, \"min\": 0.557784985319713, \"max\": 0.557784985319713}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.5219061, \"EndTime\": 1740876929.521916, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6465123042058974, \"count\": 1, \"min\": 0.6465123042058974, \"max\": 0.6465123042058974}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.521954, \"EndTime\": 1740876929.5219643, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470152772279724, \"count\": 1, \"min\": 0.6470152772279724, \"max\": 0.6470152772279724}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.5219984, \"EndTime\": 1740876929.5220077, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6465097297074899, \"count\": 1, \"min\": 0.6465097297074899, \"max\": 0.6465097297074899}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.5220912, \"EndTime\": 1740876929.5221062, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.647016832905431, \"count\": 1, \"min\": 0.647016832905431, \"max\": 0.647016832905431}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.522151, \"EndTime\": 1740876929.5221612, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6475925771289803, \"count\": 1, \"min\": 0.6475925771289803, \"max\": 0.6475925771289803}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.5221975, \"EndTime\": 1740876929.522207, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6574318552228335, \"count\": 1, \"min\": 0.6574318552228335, \"max\": 0.6574318552228335}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.522235, \"EndTime\": 1740876929.5222437, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6475937980251324, \"count\": 1, \"min\": 0.6475937980251324, \"max\": 0.6475937980251324}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876929.5222714, \"EndTime\": 1740876929.5222778, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6574697850400477, \"count\": 1, \"min\": 0.6574697850400477, \"max\": 0.6574697850400477}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:29 INFO 140224006256448] #quality_metric: host=algo-1, epoch=26, train binary_classification_cross_entropy_objective <loss>=0.4268408313271066\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.1800423, \"EndTime\": 1740876930.180107, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43131595893625285, \"count\": 1, \"min\": 0.43131595893625285, \"max\": 0.43131595893625285}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.1801772, \"EndTime\": 1740876930.180188, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42550384090725185, \"count\": 1, \"min\": 0.42550384090725185, \"max\": 0.42550384090725185}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.180226, \"EndTime\": 1740876930.180235, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4250609817127881, \"count\": 1, \"min\": 0.4250609817127881, \"max\": 0.4250609817127881}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.180271, \"EndTime\": 1740876930.1802793, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42550268180199285, \"count\": 1, \"min\": 0.42550268180199285, \"max\": 0.42550268180199285}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.180314, \"EndTime\": 1740876930.1803234, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42760942272001967, \"count\": 1, \"min\": 0.42760942272001967, \"max\": 0.42760942272001967}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.1803627, \"EndTime\": 1740876930.180372, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4591295664167334, \"count\": 1, \"min\": 0.4591295664167334, \"max\": 0.4591295664167334}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.1804068, \"EndTime\": 1740876930.180417, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4276094204510288, \"count\": 1, \"min\": 0.4276094204510288, \"max\": 0.4276094204510288}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.1804478, \"EndTime\": 1740876930.1804564, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45912558617040317, \"count\": 1, \"min\": 0.45912558617040317, \"max\": 0.45912558617040317}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.180488, \"EndTime\": 1740876930.180497, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.426401562432419, \"count\": 1, \"min\": 0.426401562432419, \"max\": 0.426401562432419}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.1805227, \"EndTime\": 1740876930.1805308, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42682362056581374, \"count\": 1, \"min\": 0.42682362056581374, \"max\": 0.42682362056581374}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.18056, \"EndTime\": 1740876930.1805694, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42639315704301023, \"count\": 1, \"min\": 0.42639315704301023, \"max\": 0.42639315704301023}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.1805987, \"EndTime\": 1740876930.1806076, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4268227625381894, \"count\": 1, \"min\": 0.4268227625381894, \"max\": 0.4268227625381894}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.180644, \"EndTime\": 1740876930.1806507, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4286423853515357, \"count\": 1, \"min\": 0.4286423853515357, \"max\": 0.4286423853515357}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.1806853, \"EndTime\": 1740876930.1806934, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45854561918825565, \"count\": 1, \"min\": 0.45854561918825565, \"max\": 0.45854561918825565}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.1807184, \"EndTime\": 1740876930.180724, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.428642409786822, \"count\": 1, \"min\": 0.428642409786822, \"max\": 0.428642409786822}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.18075, \"EndTime\": 1740876930.1807554, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.458546145943213, \"count\": 1, \"min\": 0.458546145943213, \"max\": 0.458546145943213}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.1807778, \"EndTime\": 1740876930.1807833, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530033343707486, \"count\": 1, \"min\": 0.5530033343707486, \"max\": 0.5530033343707486}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.1808054, \"EndTime\": 1740876930.180811, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5525412011460713, \"count\": 1, \"min\": 0.5525412011460713, \"max\": 0.5525412011460713}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.180833, \"EndTime\": 1740876930.1808388, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5530037488979267, \"count\": 1, \"min\": 0.5530037488979267, \"max\": 0.5530037488979267}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.180859, \"EndTime\": 1740876930.1808646, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5525456015920569, \"count\": 1, \"min\": 0.5525456015920569, \"max\": 0.5525456015920569}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.180886, \"EndTime\": 1740876930.1808913, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5550696818406201, \"count\": 1, \"min\": 0.5550696818406201, \"max\": 0.5550696818406201}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.1809132, \"EndTime\": 1740876930.1809187, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5559127843921041, \"count\": 1, \"min\": 0.5559127843921041, \"max\": 0.5559127843921041}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.1809406, \"EndTime\": 1740876930.1809459, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5550703393243591, \"count\": 1, \"min\": 0.5550703393243591, \"max\": 0.5550703393243591}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.180968, \"EndTime\": 1740876930.1809733, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5559094140679735, \"count\": 1, \"min\": 0.5559094140679735, \"max\": 0.5559094140679735}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.180991, \"EndTime\": 1740876930.1809962, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6626855311247126, \"count\": 1, \"min\": 0.6626855311247126, \"max\": 0.6626855311247126}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.1810174, \"EndTime\": 1740876930.1810353, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6632984168009388, \"count\": 1, \"min\": 0.6632984168009388, \"max\": 0.6632984168009388}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.1810682, \"EndTime\": 1740876930.181078, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6627363641998604, \"count\": 1, \"min\": 0.6627363641998604, \"max\": 0.6627363641998604}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.1811042, \"EndTime\": 1740876930.1811118, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6637589324096635, \"count\": 1, \"min\": 0.6637589324096635, \"max\": 0.6637589324096635}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.1811404, \"EndTime\": 1740876930.1811497, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6633613961332888, \"count\": 1, \"min\": 0.6633613961332888, \"max\": 0.6633613961332888}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.1811793, \"EndTime\": 1740876930.1811872, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6626527836521757, \"count\": 1, \"min\": 0.6626527836521757, \"max\": 0.6626527836521757}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.1812155, \"EndTime\": 1740876930.1812215, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6632142276400878, \"count\": 1, \"min\": 0.6632142276400878, \"max\": 0.6632142276400878}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.1812394, \"EndTime\": 1740876930.1812444, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6626792961123398, \"count\": 1, \"min\": 0.6626792961123398, \"max\": 0.6626792961123398}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:30 INFO 140224006256448] #quality_metric: host=algo-1, epoch=26, validation binary_classification_cross_entropy_objective <loss>=0.43131595893625285\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:30 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=26, criteria=sampled_accuracy, value=0.811127379209398\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:30 INFO 140224006256448] Epoch 26: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:30 INFO 140224006256448] Saving model for epoch: 26\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:30 INFO 140224006256448] Saved checkpoint to \"/tmp/tmpfeurenww/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:30 INFO 140224006256448] #progress_metric: host=algo-1, completed 90.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876927.2086368, \"EndTime\": 1740876930.187501, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 26, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 89242.0, \"count\": 1, \"min\": 89242, \"max\": 89242}, \"Total Batches Seen\": {\"sum\": 2633.0, \"count\": 1, \"min\": 2633, \"max\": 2633}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 29.0, \"count\": 1, \"min\": 29, \"max\": 29}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:30 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1069.494589081354 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5161657, \"EndTime\": 1740876932.51621, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4267505631274924, \"count\": 1, \"min\": 0.4267505631274924, \"max\": 0.4267505631274924}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5162725, \"EndTime\": 1740876932.5162854, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4248933965537007, \"count\": 1, \"min\": 0.4248933965537007, \"max\": 0.4248933965537007}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.516321, \"EndTime\": 1740876932.516331, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42301752128456305, \"count\": 1, \"min\": 0.42301752128456305, \"max\": 0.42301752128456305}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5163605, \"EndTime\": 1740876932.5163713, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42489284974423336, \"count\": 1, \"min\": 0.42489284974423336, \"max\": 0.42489284974423336}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5164003, \"EndTime\": 1740876932.51641, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42678234789810326, \"count\": 1, \"min\": 0.42678234789810326, \"max\": 0.42678234789810326}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.516442, \"EndTime\": 1740876932.516451, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4561466193515843, \"count\": 1, \"min\": 0.4561466193515843, \"max\": 0.4561466193515843}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5164773, \"EndTime\": 1740876932.5164864, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42678260984185523, \"count\": 1, \"min\": 0.42678260984185523, \"max\": 0.42678260984185523}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5165231, \"EndTime\": 1740876932.5165339, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45614581059836495, \"count\": 1, \"min\": 0.45614581059836495, \"max\": 0.45614581059836495}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5165627, \"EndTime\": 1740876932.516572, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42366654189759456, \"count\": 1, \"min\": 0.42366654189759456, \"max\": 0.42366654189759456}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5166032, \"EndTime\": 1740876932.5166125, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4254962678652334, \"count\": 1, \"min\": 0.4254962678652334, \"max\": 0.4254962678652334}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5166419, \"EndTime\": 1740876932.516652, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42366601062077347, \"count\": 1, \"min\": 0.42366601062077347, \"max\": 0.42366601062077347}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5166843, \"EndTime\": 1740876932.5166924, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.425496511863501, \"count\": 1, \"min\": 0.425496511863501, \"max\": 0.425496511863501}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5167606, \"EndTime\": 1740876932.516772, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42734391172048336, \"count\": 1, \"min\": 0.42734391172048336, \"max\": 0.42734391172048336}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5168135, \"EndTime\": 1740876932.5168235, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45390477638920224, \"count\": 1, \"min\": 0.45390477638920224, \"max\": 0.45390477638920224}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5168958, \"EndTime\": 1740876932.5169075, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4273439515323144, \"count\": 1, \"min\": 0.4273439515323144, \"max\": 0.4273439515323144}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.516949, \"EndTime\": 1740876932.5169606, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4539049819328603, \"count\": 1, \"min\": 0.4539049819328603, \"max\": 0.4539049819328603}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.517031, \"EndTime\": 1740876932.517042, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5408849951438253, \"count\": 1, \"min\": 0.5408849951438253, \"max\": 0.5408849951438253}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5170827, \"EndTime\": 1740876932.517094, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421089933010538, \"count\": 1, \"min\": 0.5421089933010538, \"max\": 0.5421089933010538}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5171618, \"EndTime\": 1740876932.517175, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5408850409877519, \"count\": 1, \"min\": 0.5408850409877519, \"max\": 0.5408850409877519}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5172107, \"EndTime\": 1740876932.5172203, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421091929634186, \"count\": 1, \"min\": 0.5421091929634186, \"max\": 0.5421091929634186}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5172513, \"EndTime\": 1740876932.517262, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5428011967817641, \"count\": 1, \"min\": 0.5428011967817641, \"max\": 0.5428011967817641}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5172899, \"EndTime\": 1740876932.5172987, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5577229120398081, \"count\": 1, \"min\": 0.5577229120398081, \"max\": 0.5577229120398081}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.51733, \"EndTime\": 1740876932.5173395, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5428012706749353, \"count\": 1, \"min\": 0.5428012706749353, \"max\": 0.5428012706749353}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5174336, \"EndTime\": 1740876932.5174472, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5577233125709568, \"count\": 1, \"min\": 0.5577233125709568, \"max\": 0.5577233125709568}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5175223, \"EndTime\": 1740876932.517537, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6465067757902683, \"count\": 1, \"min\": 0.6465067757902683, \"max\": 0.6465067757902683}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5176015, \"EndTime\": 1740876932.517612, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470107000738212, \"count\": 1, \"min\": 0.6470107000738212, \"max\": 0.6470107000738212}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5176494, \"EndTime\": 1740876932.5176566, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6465061689614495, \"count\": 1, \"min\": 0.6465061689614495, \"max\": 0.6465061689614495}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5176773, \"EndTime\": 1740876932.517685, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470120476439812, \"count\": 1, \"min\": 0.6470120476439812, \"max\": 0.6470120476439812}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5177202, \"EndTime\": 1740876932.5177298, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6475013814946656, \"count\": 1, \"min\": 0.6475013814946656, \"max\": 0.6475013814946656}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5178134, \"EndTime\": 1740876932.517827, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.657404048468477, \"count\": 1, \"min\": 0.657404048468477, \"max\": 0.657404048468477}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5178978, \"EndTime\": 1740876932.5179088, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6475082424002159, \"count\": 1, \"min\": 0.6475082424002159, \"max\": 0.6475082424002159}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876932.5179527, \"EndTime\": 1740876932.517962, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6574340515088462, \"count\": 1, \"min\": 0.6574340515088462, \"max\": 0.6574340515088462}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:32 INFO 140224006256448] #quality_metric: host=algo-1, epoch=27, train binary_classification_cross_entropy_objective <loss>=0.4267505631274924\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1847467, \"EndTime\": 1740876933.1847997, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4311994577745742, \"count\": 1, \"min\": 0.4311994577745742, \"max\": 0.4311994577745742}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1848683, \"EndTime\": 1740876933.184881, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42549032103788453, \"count\": 1, \"min\": 0.42549032103788453, \"max\": 0.42549032103788453}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1849182, \"EndTime\": 1740876933.1849287, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4250663829582851, \"count\": 1, \"min\": 0.4250663829582851, \"max\": 0.4250663829582851}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1849577, \"EndTime\": 1740876933.184968, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4254893361213092, \"count\": 1, \"min\": 0.4254893361213092, \"max\": 0.4254893361213092}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.185, \"EndTime\": 1740876933.1850104, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42734965642758727, \"count\": 1, \"min\": 0.42734965642758727, \"max\": 0.42734965642758727}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.185079, \"EndTime\": 1740876933.18509, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4589231442741908, \"count\": 1, \"min\": 0.4589231442741908, \"max\": 0.4589231442741908}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1851594, \"EndTime\": 1740876933.185171, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42734960546256157, \"count\": 1, \"min\": 0.42734960546256157, \"max\": 0.42734960546256157}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1852365, \"EndTime\": 1740876933.185246, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45891952305203126, \"count\": 1, \"min\": 0.45891952305203126, \"max\": 0.45891952305203126}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1852787, \"EndTime\": 1740876933.1852882, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42640779447764987, \"count\": 1, \"min\": 0.42640779447764987, \"max\": 0.42640779447764987}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1853611, \"EndTime\": 1740876933.1853833, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4268098149781346, \"count\": 1, \"min\": 0.4268098149781346, \"max\": 0.4268098149781346}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1854799, \"EndTime\": 1740876933.1854951, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4263995931228816, \"count\": 1, \"min\": 0.4263995931228816, \"max\": 0.4263995931228816}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1855626, \"EndTime\": 1740876933.1855767, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4268090581824106, \"count\": 1, \"min\": 0.4268090581824106, \"max\": 0.4268090581824106}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1856096, \"EndTime\": 1740876933.18562, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.428449433335099, \"count\": 1, \"min\": 0.428449433335099, \"max\": 0.428449433335099}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1856701, \"EndTime\": 1740876933.1856809, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4583638258943795, \"count\": 1, \"min\": 0.4583638258943795, \"max\": 0.4583638258943795}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1857104, \"EndTime\": 1740876933.18572, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4284494555013944, \"count\": 1, \"min\": 0.4284494555013944, \"max\": 0.4284494555013944}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.18575, \"EndTime\": 1740876933.1857588, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45836435648916757, \"count\": 1, \"min\": 0.45836435648916757, \"max\": 0.45836435648916757}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1858253, \"EndTime\": 1740876933.1858356, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.552998277139175, \"count\": 1, \"min\": 0.552998277139175, \"max\": 0.552998277139175}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.185912, \"EndTime\": 1740876933.1859248, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5525458354726542, \"count\": 1, \"min\": 0.5525458354726542, \"max\": 0.5525458354726542}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1859674, \"EndTime\": 1740876933.185978, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5529986324980528, \"count\": 1, \"min\": 0.5529986324980528, \"max\": 0.5529986324980528}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1860633, \"EndTime\": 1740876933.1860764, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5525497445948476, \"count\": 1, \"min\": 0.5525497445948476, \"max\": 0.5525497445948476}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1861198, \"EndTime\": 1740876933.1861274, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5544981562026597, \"count\": 1, \"min\": 0.5544981562026597, \"max\": 0.5544981562026597}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1861482, \"EndTime\": 1740876933.1861565, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.556064743946796, \"count\": 1, \"min\": 0.556064743946796, \"max\": 0.556064743946796}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1861842, \"EndTime\": 1740876933.1861932, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.554498641068555, \"count\": 1, \"min\": 0.554498641068555, \"max\": 0.554498641068555}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1862519, \"EndTime\": 1740876933.1862628, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5560610231508448, \"count\": 1, \"min\": 0.5560610231508448, \"max\": 0.5560610231508448}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.186292, \"EndTime\": 1740876933.1863017, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6626767462902153, \"count\": 1, \"min\": 0.6626767462902153, \"max\": 0.6626767462902153}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1863332, \"EndTime\": 1740876933.186342, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6633237078458638, \"count\": 1, \"min\": 0.6633237078458638, \"max\": 0.6633237078458638}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1863716, \"EndTime\": 1740876933.1863806, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6627037465834164, \"count\": 1, \"min\": 0.6627037465834164, \"max\": 0.6627037465834164}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1864197, \"EndTime\": 1740876933.1864293, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6637596810021128, \"count\": 1, \"min\": 0.6637596810021128, \"max\": 0.6637596810021128}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1864672, \"EndTime\": 1740876933.1864762, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6636647343810097, \"count\": 1, \"min\": 0.6636647343810097, \"max\": 0.6636647343810097}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1865127, \"EndTime\": 1740876933.1865218, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6625977676050904, \"count\": 1, \"min\": 0.6625977676050904, \"max\": 0.6625977676050904}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.186559, \"EndTime\": 1740876933.1865695, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6634837675234234, \"count\": 1, \"min\": 0.6634837675234234, \"max\": 0.6634837675234234}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1866066, \"EndTime\": 1740876933.186617, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6626224753448241, \"count\": 1, \"min\": 0.6626224753448241, \"max\": 0.6626224753448241}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:33 INFO 140224006256448] #quality_metric: host=algo-1, epoch=27, validation binary_classification_cross_entropy_objective <loss>=0.4311994577745742\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:33 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=27, criteria=sampled_accuracy, value=0.811127379209398\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:33 INFO 140224006256448] Epoch 27: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:33 INFO 140224006256448] Saving model for epoch: 27\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:33 INFO 140224006256448] Saved checkpoint to \"/tmp/tmphme8qwxj/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:33 INFO 140224006256448] #progress_metric: host=algo-1, completed 93.33333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876930.1877258, \"EndTime\": 1740876933.1924808, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 27, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 92428.0, \"count\": 1, \"min\": 92428, \"max\": 92428}, \"Total Batches Seen\": {\"sum\": 2727.0, \"count\": 1, \"min\": 2727, \"max\": 2727}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 30.0, \"count\": 1, \"min\": 30, \"max\": 30}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:33 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1060.2595712785119 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4693327, \"EndTime\": 1740876935.4693902, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4266703335413972, \"count\": 1, \"min\": 0.4266703335413972, \"max\": 0.4266703335413972}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4694502, \"EndTime\": 1740876935.469463, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.424875996521498, \"count\": 1, \"min\": 0.424875996521498, \"max\": 0.424875996521498}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4694972, \"EndTime\": 1740876935.4695077, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42299681732279076, \"count\": 1, \"min\": 0.42299681732279076, \"max\": 0.42299681732279076}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4695373, \"EndTime\": 1740876935.4695475, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42487551365224413, \"count\": 1, \"min\": 0.42487551365224413, \"max\": 0.42487551365224413}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4695847, \"EndTime\": 1740876935.4695947, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4264434154541865, \"count\": 1, \"min\": 0.4264434154541865, \"max\": 0.4264434154541865}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4696314, \"EndTime\": 1740876935.4696407, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4558413045305304, \"count\": 1, \"min\": 0.4558413045305304, \"max\": 0.4558413045305304}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4696794, \"EndTime\": 1740876935.46969, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4264436262759282, \"count\": 1, \"min\": 0.4264436262759282, \"max\": 0.4264436262759282}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4697273, \"EndTime\": 1740876935.4697373, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.455840594251272, \"count\": 1, \"min\": 0.455840594251272, \"max\": 0.455840594251272}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.469775, \"EndTime\": 1740876935.4697847, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4236460249307863, \"count\": 1, \"min\": 0.4236460249307863, \"max\": 0.4236460249307863}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4698205, \"EndTime\": 1740876935.46983, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42547870300601814, \"count\": 1, \"min\": 0.42547870300601814, \"max\": 0.42547870300601814}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4698613, \"EndTime\": 1740876935.4698703, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42364553452141296, \"count\": 1, \"min\": 0.42364553452141296, \"max\": 0.42364553452141296}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4699023, \"EndTime\": 1740876935.4699116, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4254789192566458, \"count\": 1, \"min\": 0.4254789192566458, \"max\": 0.4254789192566458}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4699392, \"EndTime\": 1740876935.4699473, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4270159771440905, \"count\": 1, \"min\": 0.4270159771440905, \"max\": 0.4270159771440905}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4699771, \"EndTime\": 1740876935.4699862, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4536170716680808, \"count\": 1, \"min\": 0.4536170716680808, \"max\": 0.4536170716680808}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4700253, \"EndTime\": 1740876935.4700346, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4270160054949399, \"count\": 1, \"min\": 0.4270160054949399, \"max\": 0.4270160054949399}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4700649, \"EndTime\": 1740876935.4700735, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4536172488608894, \"count\": 1, \"min\": 0.4536172488608894, \"max\": 0.4536172488608894}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4701009, \"EndTime\": 1740876935.4701095, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5408664428305581, \"count\": 1, \"min\": 0.5408664428305581, \"max\": 0.5408664428305581}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.470143, \"EndTime\": 1740876935.470152, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5421037070740634, \"count\": 1, \"min\": 0.5421037070740634, \"max\": 0.5421037070740634}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4701848, \"EndTime\": 1740876935.4701934, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5408664907857182, \"count\": 1, \"min\": 0.5408664907857182, \"max\": 0.5408664907857182}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.470229, \"EndTime\": 1740876935.470239, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.542103885020884, \"count\": 1, \"min\": 0.542103885020884, \"max\": 0.542103885020884}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4702706, \"EndTime\": 1740876935.4702797, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5426711083061706, \"count\": 1, \"min\": 0.5426711083061706, \"max\": 0.5426711083061706}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4703114, \"EndTime\": 1740876935.4703202, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5576383568379488, \"count\": 1, \"min\": 0.5576383568379488, \"max\": 0.5576383568379488}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4703486, \"EndTime\": 1740876935.4703574, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5426711861202039, \"count\": 1, \"min\": 0.5426711861202039, \"max\": 0.5426711861202039}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4703882, \"EndTime\": 1740876935.4703953, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5576386527122387, \"count\": 1, \"min\": 0.5576386527122387, \"max\": 0.5576386527122387}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4704297, \"EndTime\": 1740876935.4704368, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6465011424161753, \"count\": 1, \"min\": 0.6465011424161753, \"max\": 0.6465011424161753}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.470467, \"EndTime\": 1740876935.470475, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.64700540811634, \"count\": 1, \"min\": 0.64700540811634, \"max\": 0.64700540811634}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4704945, \"EndTime\": 1740876935.470502, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6465025883094937, \"count\": 1, \"min\": 0.6465025883094937, \"max\": 0.6465025883094937}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.470528, \"EndTime\": 1740876935.4705362, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470066682211135, \"count\": 1, \"min\": 0.6470066682211135, \"max\": 0.6470066682211135}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4705653, \"EndTime\": 1740876935.4705746, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6474152763458387, \"count\": 1, \"min\": 0.6474152763458387, \"max\": 0.6474152763458387}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4705987, \"EndTime\": 1740876935.4706042, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6573639368422796, \"count\": 1, \"min\": 0.6573639368422796, \"max\": 0.6573639368422796}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4706233, \"EndTime\": 1740876935.4706311, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6474225956906554, \"count\": 1, \"min\": 0.6474225956906554, \"max\": 0.6474225956906554}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876935.4706604, \"EndTime\": 1740876935.4706662, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6573863177266323, \"count\": 1, \"min\": 0.6573863177266323, \"max\": 0.6573863177266323}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:35 INFO 140224006256448] #quality_metric: host=algo-1, epoch=28, train binary_classification_cross_entropy_objective <loss>=0.4266703335413972\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1273873, \"EndTime\": 1740876936.1274426, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4310957966576907, \"count\": 1, \"min\": 0.4310957966576907, \"max\": 0.4310957966576907}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1275105, \"EndTime\": 1740876936.1275194, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42547741850857157, \"count\": 1, \"min\": 0.42547741850857157, \"max\": 0.42547741850857157}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.127782, \"EndTime\": 1740876936.1277936, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4250717310570344, \"count\": 1, \"min\": 0.4250717310570344, \"max\": 0.4250717310570344}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1278229, \"EndTime\": 1740876936.1278293, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4254765681606086, \"count\": 1, \"min\": 0.4254765681606086, \"max\": 0.4254765681606086}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1278486, \"EndTime\": 1740876936.127854, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42706228018156084, \"count\": 1, \"min\": 0.42706228018156084, \"max\": 0.42706228018156084}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.127872, \"EndTime\": 1740876936.1278772, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45870930052431924, \"count\": 1, \"min\": 0.45870930052431924, \"max\": 0.45870930052431924}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1278946, \"EndTime\": 1740876936.1279006, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4270621951816721, \"count\": 1, \"min\": 0.4270621951816721, \"max\": 0.4270621951816721}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1279266, \"EndTime\": 1740876936.1279323, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45870602471238525, \"count\": 1, \"min\": 0.45870602471238525, \"max\": 0.45870602471238525}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1279647, \"EndTime\": 1740876936.1279702, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4264139336687929, \"count\": 1, \"min\": 0.4264139336687929, \"max\": 0.4264139336687929}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.127996, \"EndTime\": 1740876936.1280015, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4267967419254309, \"count\": 1, \"min\": 0.4267967419254309, \"max\": 0.4267967419254309}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1280289, \"EndTime\": 1740876936.1280365, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4264058920160743, \"count\": 1, \"min\": 0.4264058920160743, \"max\": 0.4264058920160743}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.128067, \"EndTime\": 1740876936.1280732, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4267960586101035, \"count\": 1, \"min\": 0.4267960586101035, \"max\": 0.4267960586101035}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1281013, \"EndTime\": 1740876936.128109, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4282224785705611, \"count\": 1, \"min\": 0.4282224785705611, \"max\": 0.4282224785705611}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1281326, \"EndTime\": 1740876936.1281402, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45817218535466564, \"count\": 1, \"min\": 0.45817218535466564, \"max\": 0.45817218535466564}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1281693, \"EndTime\": 1740876936.1281776, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42822245937140757, \"count\": 1, \"min\": 0.42822245937140757, \"max\": 0.42822245937140757}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1282072, \"EndTime\": 1740876936.128216, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45817264421443465, \"count\": 1, \"min\": 0.45817264421443465, \"max\": 0.45817264421443465}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1282473, \"EndTime\": 1740876936.128257, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.552993859588489, \"count\": 1, \"min\": 0.552993859588489, \"max\": 0.552993859588489}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1282854, \"EndTime\": 1740876936.1282935, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5525465130282355, \"count\": 1, \"min\": 0.5525465130282355, \"max\": 0.5525465130282355}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.12832, \"EndTime\": 1740876936.1283278, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.552994176374522, \"count\": 1, \"min\": 0.552994176374522, \"max\": 0.552994176374522}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1283565, \"EndTime\": 1740876936.1283653, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5525499847588043, \"count\": 1, \"min\": 0.5525499847588043, \"max\": 0.5525499847588043}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.128395, \"EndTime\": 1740876936.128404, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5540229893708124, \"count\": 1, \"min\": 0.5540229893708124, \"max\": 0.5540229893708124}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.128434, \"EndTime\": 1740876936.1284432, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5562970470718898, \"count\": 1, \"min\": 0.5562970470718898, \"max\": 0.5562970470718898}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1284735, \"EndTime\": 1740876936.1284823, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5540233234360836, \"count\": 1, \"min\": 0.5540233234360836, \"max\": 0.5540233234360836}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1285138, \"EndTime\": 1740876936.1285236, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5562930117588964, \"count\": 1, \"min\": 0.5562930117588964, \"max\": 0.5562930117588964}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1285603, \"EndTime\": 1740876936.1285672, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6626627101381561, \"count\": 1, \"min\": 0.6626627101381561, \"max\": 0.6626627101381561}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1285865, \"EndTime\": 1740876936.1285932, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6633462836068685, \"count\": 1, \"min\": 0.6633462836068685, \"max\": 0.6633462836068685}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1286266, \"EndTime\": 1740876936.128636, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6626672798857682, \"count\": 1, \"min\": 0.6626672798857682, \"max\": 0.6626672798857682}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1286736, \"EndTime\": 1740876936.1286833, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6637571301327617, \"count\": 1, \"min\": 0.6637571301327617, \"max\": 0.6637571301327617}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1287203, \"EndTime\": 1740876936.12873, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6639114843455101, \"count\": 1, \"min\": 0.6639114843455101, \"max\": 0.6639114843455101}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1287587, \"EndTime\": 1740876936.1287673, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6625502809424002, \"count\": 1, \"min\": 0.6625502809424002, \"max\": 0.6625502809424002}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1287963, \"EndTime\": 1740876936.1288054, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6637579680885438, \"count\": 1, \"min\": 0.6637579680885438, \"max\": 0.6637579680885438}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1288366, \"EndTime\": 1740876936.1288466, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6625718285014653, \"count\": 1, \"min\": 0.6625718285014653, \"max\": 0.6625718285014653}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:36 INFO 140224006256448] #quality_metric: host=algo-1, epoch=28, validation binary_classification_cross_entropy_objective <loss>=0.4310957966576907\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:36 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=28, criteria=sampled_accuracy, value=0.811127379209398\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:36 INFO 140224006256448] Epoch 28: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:36 INFO 140224006256448] Saving model for epoch: 28\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:36 INFO 140224006256448] Saved checkpoint to \"/tmp/tmp0mcicpgc/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:36 INFO 140224006256448] #progress_metric: host=algo-1, completed 96.66666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876933.1927795, \"EndTime\": 1740876936.134055, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 28, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 95614.0, \"count\": 1, \"min\": 95614, \"max\": 95614}, \"Total Batches Seen\": {\"sum\": 2821.0, \"count\": 1, \"min\": 2821, \"max\": 2821}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 31.0, \"count\": 1, \"min\": 31, \"max\": 31}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:36 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1083.1710942384327 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4364703, \"EndTime\": 1740876938.4365163, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42659889603626266, \"count\": 1, \"min\": 0.42659889603626266, \"max\": 0.42659889603626266}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4365776, \"EndTime\": 1740876938.4365897, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4248589870674862, \"count\": 1, \"min\": 0.4248589870674862, \"max\": 0.4248589870674862}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4366288, \"EndTime\": 1740876938.4366384, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4229780198048369, \"count\": 1, \"min\": 0.4229780198048369, \"max\": 0.4229780198048369}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4366705, \"EndTime\": 1740876938.4366794, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42485854355765623, \"count\": 1, \"min\": 0.42485854355765623, \"max\": 0.42485854355765623}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4367082, \"EndTime\": 1740876938.436717, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4261334126392246, \"count\": 1, \"min\": 0.4261334126392246, \"max\": 0.4261334126392246}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4367485, \"EndTime\": 1740876938.4367578, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4555448317060284, \"count\": 1, \"min\": 0.4555448317060284, \"max\": 0.4555448317060284}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4367917, \"EndTime\": 1740876938.4368007, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4261335940545002, \"count\": 1, \"min\": 0.4261335940545002, \"max\": 0.4261335940545002}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4368312, \"EndTime\": 1740876938.4368408, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4555442153766591, \"count\": 1, \"min\": 0.4555442153766591, \"max\": 0.4555442153766591}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4368734, \"EndTime\": 1740876938.4368827, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42362736931788175, \"count\": 1, \"min\": 0.42362736931788175, \"max\": 0.42362736931788175}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4369142, \"EndTime\": 1740876938.436942, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4254616084994582, \"count\": 1, \"min\": 0.4254616084994582, \"max\": 0.4254616084994582}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.436979, \"EndTime\": 1740876938.4369903, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42362691856953705, \"count\": 1, \"min\": 0.42362691856953705, \"max\": 0.42362691856953705}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4370232, \"EndTime\": 1740876938.437034, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42546180092330826, \"count\": 1, \"min\": 0.42546180092330826, \"max\": 0.42546180092330826}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4370675, \"EndTime\": 1740876938.437077, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4267136896810224, \"count\": 1, \"min\": 0.4267136896810224, \"max\": 0.4267136896810224}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.437107, \"EndTime\": 1740876938.437117, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.4533336972375975, \"count\": 1, \"min\": 0.4533336972375975, \"max\": 0.4533336972375975}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4371505, \"EndTime\": 1740876938.4371598, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.42671372059551244, \"count\": 1, \"min\": 0.42671372059551244, \"max\": 0.42671372059551244}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4372344, \"EndTime\": 1740876938.4372475, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.45333386477905313, \"count\": 1, \"min\": 0.45333386477905313, \"max\": 0.45333386477905313}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4373305, \"EndTime\": 1740876938.4373457, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5408492070221584, \"count\": 1, \"min\": 0.5408492070221584, \"max\": 0.5408492070221584}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.437416, \"EndTime\": 1740876938.4374282, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5420993893000237, \"count\": 1, \"min\": 0.5420993893000237, \"max\": 0.5420993893000237}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4375184, \"EndTime\": 1740876938.4375315, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5408492450243608, \"count\": 1, \"min\": 0.5408492450243608, \"max\": 0.5408492450243608}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.437571, \"EndTime\": 1740876938.437581, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.542099548245743, \"count\": 1, \"min\": 0.542099548245743, \"max\": 0.542099548245743}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.437612, \"EndTime\": 1740876938.4376223, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5425485747287275, \"count\": 1, \"min\": 0.5425485747287275, \"max\": 0.5425485747287275}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4376755, \"EndTime\": 1740876938.4376864, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5575560485917055, \"count\": 1, \"min\": 0.5575560485917055, \"max\": 0.5575560485917055}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.437717, \"EndTime\": 1740876938.4377275, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5425486640037426, \"count\": 1, \"min\": 0.5425486640037426, \"max\": 0.5425486640037426}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.437806, \"EndTime\": 1740876938.4378183, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.5575562410155556, \"count\": 1, \"min\": 0.5575562410155556, \"max\": 0.5575562410155556}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4378862, \"EndTime\": 1740876938.4378967, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6464952973155264, \"count\": 1, \"min\": 0.6464952973155264, \"max\": 0.6464952973155264}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.437962, \"EndTime\": 1740876938.437974, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6469996154949229, \"count\": 1, \"min\": 0.6469996154949229, \"max\": 0.6469996154949229}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.438038, \"EndTime\": 1740876938.4380488, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6464984514983224, \"count\": 1, \"min\": 0.6464984514983224, \"max\": 0.6464984514983224}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4380915, \"EndTime\": 1740876938.438102, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6470008719804391, \"count\": 1, \"min\": 0.6470008719804391, \"max\": 0.6470008719804391}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4382744, \"EndTime\": 1740876938.4382935, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6473337712731262, \"count\": 1, \"min\": 0.6473337712731262, \"max\": 0.6473337712731262}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4383364, \"EndTime\": 1740876938.4383464, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6573050937495754, \"count\": 1, \"min\": 0.6573050937495754, \"max\": 0.6573050937495754}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4384143, \"EndTime\": 1740876938.4384253, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6473386035849217, \"count\": 1, \"min\": 0.6473386035849217, \"max\": 0.6473386035849217}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876938.4384913, \"EndTime\": 1740876938.4385018, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.6573211270597146, \"count\": 1, \"min\": 0.6573211270597146, \"max\": 0.6573211270597146}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:38 INFO 140224006256448] #quality_metric: host=algo-1, epoch=29, train binary_classification_cross_entropy_objective <loss>=0.42659889603626266\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.103374, \"EndTime\": 1740876939.1034281, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 0}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.43100329304160345, \"count\": 1, \"min\": 0.43100329304160345, \"max\": 0.43100329304160345}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.1034975, \"EndTime\": 1740876939.103507, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 1}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4254595702773132, \"count\": 1, \"min\": 0.4254595702773132, \"max\": 0.4254595702773132}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.103539, \"EndTime\": 1740876939.1035485, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 2}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42507658940283133, \"count\": 1, \"min\": 0.42507658940283133, \"max\": 0.42507658940283133}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.1035845, \"EndTime\": 1740876939.103594, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 3}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.425458828142761, \"count\": 1, \"min\": 0.425458828142761, \"max\": 0.425458828142761}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.1036305, \"EndTime\": 1740876939.1036403, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 4}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4267502345941077, \"count\": 1, \"min\": 0.4267502345941077, \"max\": 0.4267502345941077}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.1036797, \"EndTime\": 1740876939.1036892, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 5}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.458356048840904, \"count\": 1, \"min\": 0.458356048840904, \"max\": 0.458356048840904}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.1037273, \"EndTime\": 1740876939.1037376, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 6}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42675013859834016, \"count\": 1, \"min\": 0.42675013859834016, \"max\": 0.42675013859834016}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.1037743, \"EndTime\": 1740876939.1037838, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 7}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.45835301895267266, \"count\": 1, \"min\": 0.45835301895267266, \"max\": 0.45835301895267266}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.10382, \"EndTime\": 1740876939.10383, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 8}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42641945133097525, \"count\": 1, \"min\": 0.42641945133097525, \"max\": 0.42641945133097525}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.1038985, \"EndTime\": 1740876939.1039124, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 9}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4267786797108797, \"count\": 1, \"min\": 0.4267786797108797, \"max\": 0.4267786797108797}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.103976, \"EndTime\": 1740876939.1039875, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 10}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42641156571501343, \"count\": 1, \"min\": 0.42641156571501343, \"max\": 0.42641156571501343}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.1040244, \"EndTime\": 1740876939.1040332, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 11}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.426778089424178, \"count\": 1, \"min\": 0.426778089424178, \"max\": 0.426778089424178}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.1041033, \"EndTime\": 1740876939.1041174, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 12}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4279606241083774, \"count\": 1, \"min\": 0.4279606241083774, \"max\": 0.4279606241083774}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.1041503, \"EndTime\": 1740876939.104159, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 13}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.4578414296684991, \"count\": 1, \"min\": 0.4578414296684991, \"max\": 0.4578414296684991}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.1041973, \"EndTime\": 1740876939.1042066, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 14}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.42796062672644375, \"count\": 1, \"min\": 0.42796062672644375, \"max\": 0.42796062672644375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.1042376, \"EndTime\": 1740876939.1042438, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 15}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.457841799426742, \"count\": 1, \"min\": 0.457841799426742, \"max\": 0.457841799426742}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.1042717, \"EndTime\": 1740876939.10428, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 16}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5529888042768308, \"count\": 1, \"min\": 0.5529888042768308, \"max\": 0.5529888042768308}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.1043146, \"EndTime\": 1740876939.1043234, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 17}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.552539075276164, \"count\": 1, \"min\": 0.552539075276164, \"max\": 0.552539075276164}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.1043599, \"EndTime\": 1740876939.1043696, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 18}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5529890723668289, \"count\": 1, \"min\": 0.5529890723668289, \"max\": 0.5529890723668289}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.104397, \"EndTime\": 1740876939.104403, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 19}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5525421522023214, \"count\": 1, \"min\": 0.5525421522023214, \"max\": 0.5525421522023214}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.1044385, \"EndTime\": 1740876939.1044486, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 20}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5536147148333391, \"count\": 1, \"min\": 0.5536147148333391, \"max\": 0.5536147148333391}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.1044836, \"EndTime\": 1740876939.1044939, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 21}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5565110471203247, \"count\": 1, \"min\": 0.5565110471203247, \"max\": 0.5565110471203247}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.104523, \"EndTime\": 1740876939.1045318, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 22}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5536148904183249, \"count\": 1, \"min\": 0.5536148904183249, \"max\": 0.5536148904183249}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.1045651, \"EndTime\": 1740876939.1045718, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 23}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.5565069035939206, \"count\": 1, \"min\": 0.5565069035939206, \"max\": 0.5565069035939206}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.104608, \"EndTime\": 1740876939.104618, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 24}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6626441852240053, \"count\": 1, \"min\": 0.6626441852240053, \"max\": 0.6626441852240053}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.1046438, \"EndTime\": 1740876939.10465, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 25}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6633656651523417, \"count\": 1, \"min\": 0.6633656651523417, \"max\": 0.6633656651523417}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.1046808, \"EndTime\": 1740876939.1046898, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 26}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6626306278290197, \"count\": 1, \"min\": 0.6626306278290197, \"max\": 0.6626306278290197}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.1047196, \"EndTime\": 1740876939.104729, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 27}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6637476000220325, \"count\": 1, \"min\": 0.6637476000220325, \"max\": 0.6637476000220325}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.104766, \"EndTime\": 1740876939.1047747, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 28}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6640141877737087, \"count\": 1, \"min\": 0.6640141877737087, \"max\": 0.6640141877737087}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.104806, \"EndTime\": 1740876939.1048157, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 29}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6625062921909427, \"count\": 1, \"min\": 0.6625062921909427, \"max\": 0.6625062921909427}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.1048827, \"EndTime\": 1740876939.1048946, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 30}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6639068268054051, \"count\": 1, \"min\": 0.6639068268054051, \"max\": 0.6639068268054051}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876939.104924, \"EndTime\": 1740876939.1049328, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"model\": 31}, \"Metrics\": {\"validation_binary_classification_cross_entropy_objective\": {\"sum\": 0.6625211139374562, \"count\": 1, \"min\": 0.6625211139374562, \"max\": 0.6625211139374562}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] #quality_metric: host=algo-1, epoch=29, validation binary_classification_cross_entropy_objective <loss>=0.43100329304160345\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=29, criteria=sampled_accuracy, value=0.811127379209398\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] Epoch 29: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] Saving model for epoch: 29\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] Saved checkpoint to \"/tmp/tmp97dcgco4/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876936.1342, \"EndTime\": 1740876939.1110463, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 29, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 98800.0, \"count\": 1, \"min\": 98800, \"max\": 98800}, \"Total Batches Seen\": {\"sum\": 2915.0, \"count\": 1, \"min\": 2915, \"max\": 2915}, \"Max Records Seen Between Resets\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Max Batches Seen Between Resets\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}, \"Reset Count\": {\"sum\": 32.0, \"count\": 1, \"min\": 32, \"max\": 32}, \"Number of Records Since Last Reset\": {\"sum\": 3186.0, \"count\": 1, \"min\": 3186, \"max\": 3186}, \"Number of Batches Since Last Reset\": {\"sum\": 94.0, \"count\": 1, \"min\": 94, \"max\": 94}}}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] #throughput_metric: host=algo-1, train throughput=1070.2067905607219 records/second\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 WARNING 140224006256448] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 WARNING 140224006256448] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] #early_stopping_criteria_metric: host=algo-1, epoch=29, criteria=sampled_accuracy, value=0.811127379209398\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] Epoch 29: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] #validation_score (algo-1) : ('binary_classification_cross_entropy_objective', 0.43100329304160345)\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] #validation_score (algo-1) : ('binary_classification_accuracy', 0.8096632503660323)\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] #validation_score (algo-1) : ('binary_f_1.000', 0.8491879350348028)\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] #validation_score (algo-1) : ('precision', 0.8375286041189931)\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] #validation_score (algo-1) : ('recall', 0.8611764705882353)\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] #validation_score (algo-1) : ('roc_auc_score', 0.8753032375740994)\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] #validation_score (algo-1) : ('binary_balanced_accuracy', 0.5)\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] #validation_score (algo-1) : ('binary_log_loss', 0.5869141277791744)\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] #quality_metric: host=algo-1, validation binary_classification_cross_entropy_objective <loss>=0.43100329304160345\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] #quality_metric: host=algo-1, validation binary_classification_accuracy <score>=0.8096632503660323\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] #quality_metric: host=algo-1, validation binary_f_1.000 <score>=0.8491879350348028\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] #quality_metric: host=algo-1, validation precision <score>=0.8375286041189931\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] #quality_metric: host=algo-1, validation recall <score>=0.8611764705882353\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] #quality_metric: host=algo-1, validation roc_auc_score <score>=0.8753032375740994\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] #quality_metric: host=algo-1, validation binary_balanced_accuracy <score>=0.5\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] #quality_metric: host=algo-1, validation binary_log_loss <score>=0.5869141277791744\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] Best model found for hyperparameters: {\"optimizer\": \"adam\", \"learning_rate\": 0.0010342773147247286, \"l1\": 0.004265073434536369, \"wd\": 0.008154580793546683, \"lr_scheduler_step\": 10, \"lr_scheduler_factor\": 0.99, \"lr_scheduler_minimum_lr\": 1e-05}\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] Saved checkpoint to \"/tmp/tmpt1m7v8h1/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/02/2025 00:55:39 INFO 140224006256448] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1740876847.905478, \"EndTime\": 1740876939.935003, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 671.0855960845947, \"count\": 1, \"min\": 671.0855960845947, \"max\": 671.0855960845947}, \"epochs\": {\"sum\": 30.0, \"count\": 1, \"min\": 30, \"max\": 30}, \"check_early_stopping.time\": {\"sum\": 25.113821029663086, \"count\": 31, \"min\": 0.6682872772216797, \"max\": 1.1701583862304688}, \"update.time\": {\"sum\": 90441.64633750916, \"count\": 30, \"min\": 2923.0103492736816, \"max\": 3308.229923248291}, \"finalize.time\": {\"sum\": 818.1025981903076, \"count\": 1, \"min\": 818.1025981903076, \"max\": 818.1025981903076}, \"setuptime\": {\"sum\": 1.9936561584472656, \"count\": 1, \"min\": 1.9936561584472656, \"max\": 1.9936561584472656}, \"totaltime\": {\"sum\": 92142.42815971375, \"count\": 1, \"min\": 92142.42815971375, \"max\": 92142.42815971375}}}\u001b[0m\n",
      "\n",
      "2025-03-02 00:55:48 Uploading - Uploading generated training model\n",
      "2025-03-02 00:56:01 Completed - Training job completed\n",
      "Training seconds: 240\n",
      "Billable seconds: 240\n"
     ]
    }
   ],
   "source": [
    "# cell 17\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "linear_learner_small = sagemaker.estimator.Estimator(\n",
    "    image_uri=sagemaker.image_uris.retrieve(\"linear-learner\", sess.boto_region_name),\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    output_path=f's3://{bucket}/{prefix}/output',\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "\n",
    "\n",
    "linear_learner_small.set_hyperparameters(\n",
    "    predictor_type='binary_classifier',  # Logistic regression for binary classification\n",
    "    loss='logistic',  \n",
    "    optimizer=\"auto\",  \n",
    "    use_bias=True,  # Include an intercept (bias term) in the model\n",
    "    epochs=30,  # Number of passes over the data (Can't be tuned)\n",
    "    \n",
    "    mini_batch_size=best_mini_batch_size,      \n",
    "    learning_rate=best_learning_rate, \n",
    "    wd=best_weight_decay,  # For L2 regularization (weight decay)\n",
    "    l1=best_L1  # For L1 regularization (sparsity)\n",
    ")\n",
    "\n",
    "linear_learner_small.fit({'train': s3_input_train_small, 'validation': s3_input_validation_small}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_small = test_data[variables_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: linear-learner-2025-03-02-00-56-42-273\n",
      "INFO:sagemaker:Creating endpoint-config with name linear-learner-2025-03-02-00-56-42-273\n",
      "INFO:sagemaker:Creating endpoint with name linear-learner-2025-03-02-00-56-42-273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "# cell 18\n",
    "linear_learner_small_predictor = linear_learner_small.deploy(initial_instance_count=1,\n",
    "                           instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 19\n",
    "linear_learner_small_predictor.serializer = sagemaker.serializers.CSVSerializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use a simple function to:\n",
    "1. Loop over our test dataset\n",
    "1. Split it into mini-batches of rows \n",
    "1. Convert those mini-batches to CSV string payloads (notice, we drop the target variable from our dataset first)\n",
    "1. Retrieve mini-batch predictions by invoking the XGBoost endpoint\n",
    "1. Collect predictions and convert from the CSV output our model provides into a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the raw prediction output\n",
    "raw_predictions_small = linear_learner_small_predictor.predict(test_data_small.drop(['MATH_Proficient'], axis=1).to_numpy())\n",
    "\n",
    "# Decode and parse JSON\n",
    "parsed_predictions_small = json.loads(raw_predictions_small.decode(\"utf-8\"))\n",
    "\n",
    "# Extract the scores\n",
    "predictions_small = np.array([pred[\"score\"] for pred in parsed_predictions_small[\"predictions\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predicted values for the test set\n",
    "predicted_values_small = predictions_small\n",
    "predicted_values_small = pd.DataFrame(predicted_values_small, columns=['Predicted Values'])\n",
    "predicted_values_small.to_csv('predicted_values_small.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: linear-learner-2025-03-02-00-56-42-273\n",
      "INFO:sagemaker:Deleting endpoint with name: linear-learner-2025-03-02-00-56-42-273\n"
     ]
    }
   ],
   "source": [
    "# Clean up\n",
    "linear_learner_small_predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of students not proficient in Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students who are NOT proficient in Math:  1607 ( 35.3 %)\n"
     ]
    }
   ],
   "source": [
    "#print(\"Students who are proficient: \", proficient_n)\n",
    "print(\"Students who are NOT proficient in Math: \", not_proficient_n, \"(\", not_proficient_p, \"%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model performance (model with all the predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested threshold: 0.65\n"
     ]
    }
   ],
   "source": [
    "suggested_threshold = (100 - not_proficient_p)/100\n",
    "print(\"Suggested threshold:\", round(suggested_threshold, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Adjust the threhold for the FINAL PREDICTIONS if necessary!!*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will predict as Math_proficient if the probability is above this threhold. (If the threshold is above 0.5, it will reduce the number of students predicted as \"Math proficient\" for both students that are actually proficient and not proficient in Math.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.66\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.66\n",
    "\n",
    "print(\"Threshold:\", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in the real values\n",
    "real_values = pd.read_csv('real_values.csv', usecols=[0], header=None)\n",
    "real_values = real_values.values.ravel()\n",
    "\n",
    "# Read in the predicted values (using the full model)\n",
    "predicted_values_full = pd.read_csv('predicted_values_full.csv', usecols=[0], header=None)\n",
    "predicted_values_full = predicted_values_full.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL USING ALL FEATURES \n",
      "\n",
      "predictions    0    1\n",
      "actuals              \n",
      "0.0          181   45\n",
      "1.0           96  361\n",
      "\n",
      "Accuracy: 79.4\n",
      "F1 Score: 83.7\n",
      "Precision: 88.9\n",
      "Recall: 79.0\n",
      "Specificity: 80.1\n"
     ]
    }
   ],
   "source": [
    "cm = pd.crosstab(index=real_values, \n",
    "                 columns=np.round( (predicted_values_full >= threshold).astype(int) ), \n",
    "                 rownames=['actuals'], \n",
    "                 colnames=['predictions'])\n",
    "\n",
    "TN = cm.loc[0.0, 0.0]\n",
    "FP = cm.loc[0.0, 1.0]\n",
    "FN = cm.loc[1.0, 0.0]\n",
    "TP = cm.loc[1.0, 1.0]\n",
    "\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN) * 100\n",
    "precision = TP / (TP + FP) * 100 if (TP + FP) > 0 else 0\n",
    "recall = TP / (TP + FN) * 100 if (TP + FN) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "specificity = TN / (TN + FP) * 100 if (TN + FP) > 0 else 0\n",
    "\n",
    "print(\"MODEL USING ALL FEATURES \\n\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nAccuracy: {:.1f}\".format(accuracy))\n",
    "print(\"F1 Score: {:.1f}\".format(f1_score))\n",
    "print(\"Precision: {:.1f}\".format(precision))\n",
    "print(\"Recall: {:.1f}\".format(recall))\n",
    "print(\"Specificity: {:.1f}\".format(specificity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performance (model with 20 predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the predicted values (using 20 predictors)\n",
    "predicted_values_small = pd.read_csv('predicted_values_small.csv', usecols=[0], header=None)\n",
    "predicted_values_small = predicted_values_small.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL USING 20 FEATURES \n",
      "\n",
      "predictions    0    1\n",
      "actuals              \n",
      "0.0          182   44\n",
      "1.0          120  337\n",
      "\n",
      "Accuracy: 76.0\n",
      "F1 Score: 80.4\n",
      "Precision: 88.5\n",
      "Recall: 73.7\n",
      "Specificity: 80.5\n"
     ]
    }
   ],
   "source": [
    "cm_small = pd.crosstab(index=real_values, \n",
    "                       columns=np.round( (predicted_values_small >= threshold).astype(int) ), \n",
    "                       rownames=['actuals'], \n",
    "                       colnames=['predictions'])\n",
    "\n",
    "TN_small = cm_small.loc[0.0, 0.0]\n",
    "FP_small = cm_small.loc[0.0, 1.0]\n",
    "FN_small = cm_small.loc[1.0, 0.0]\n",
    "TP_small = cm_small.loc[1.0, 1.0]\n",
    "\n",
    "accuracy_small = (TP_small + TN_small) / (TP_small + TN_small + FP_small + FN_small) * 100\n",
    "precision_small = TP_small / (TP_small + FP_small) * 100 if (TP_small + FP_small) > 0 else 0\n",
    "recall_small = TP_small / (TP_small + FN_small) * 100 if (TP_small + FN_small) > 0 else 0\n",
    "f1_score_small = 2 * (precision_small * recall_small) / (precision_small + recall_small) if (precision_small + recall_small) > 0 else 0\n",
    "specificity_small = TN_small / (TN_small + FP_small) * 100 if (TN_small + FP_small) > 0 else 0\n",
    "\n",
    "print(\"MODEL USING 20 FEATURES \\n\")\n",
    "print(cm_small)\n",
    "\n",
    "print(\"\\nAccuracy: {:.1f}\".format(accuracy_small))\n",
    "print(\"F1 Score: {:.1f}\".format(f1_score_small))\n",
    "print(\"Precision: {:.1f}\".format(precision_small))\n",
    "print(\"Recall: {:.1f}\".format(recall_small))\n",
    "print(\"Specificity: {:.1f}\".format(specificity_small))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 20 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|    | Variable_name   | Variable_label                                                                                                                                        |\n",
       "|---:|:----------------|:------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
       "|  0 | ST268Q04JA      | Agree/disagree: Mathematics is easy for me.                                                                                                           |\n",
       "|  1 | ST004D01T       | Student (Standardized) Gender                                                                                                                         |\n",
       "|  2 | ST255Q01JA      | How many books are there in your [home]?                                                                                                              |\n",
       "|  3 | ST263Q02JA      | Agree/disagree: Your intelligence is something about you that you cannot change very much.                                                            |\n",
       "|  4 | ST268Q01JA      | Agree/disagree: Mathematics is one of my favourite subjects.                                                                                          |\n",
       "|  5 | SC032Q04TA      | Last school yr, teachers monitored by? Observation of classes by inspectors or other persons external to the school                                   |\n",
       "|  6 | ST259Q01JA      | Now think about where you would place your family on this scale. Where would you say your family stands at this time?                                 |\n",
       "|  7 | ST251Q04JA      | How many of these items are there at your [home]: Rooms with a [flush toilet]                                                                         |\n",
       "|  8 | ST253Q01JA      | How many [digital devices] with screens are there in your [home]?                                                                                     |\n",
       "|  9 | ST251Q06JA      | How many of these items are there at your [home]: Musical instruments (e.g. guitar, piano, [country-specific example])                                |\n",
       "| 10 | ST059Q02JA      | Total number of [class periods] per week for all subjects, including mathematics                                                                      |\n",
       "| 11 | SC001Q01TA      | Which of the following definitions best describes the community in which your school is located?                                                      |\n",
       "| 12 | IC173Q04JA      | How often use [digital resources] in lessons in: [Computer science], [information technology], [informatics] or similar lessons.                      |\n",
       "| 13 | EXERPRAC        | Exercise or practice a sport before or after school                                                                                                   |\n",
       "| 14 | ST230Q01JA      | How many siblings (including brothers, sisters, step-brothers, and step-sisters) do you have?                                                         |\n",
       "| 15 | IC174Q02JA      | How often used [digital resources] to: Write or edit text for a school assignment (e.g. using [GoogleÂ® Docsâ„¢], [MicrosoftÂ® Word])                     |\n",
       "| 16 | FL171Q01JA      | How often: Checked that you were given the right change when you bought something with cash                                                           |\n",
       "| 17 | ST349Q01JA_1    | During COVID closures, which of the following digital devices did you use most often for your school work? My own laptop, desktop computer, or tablet |\n",
       "| 18 | SC211Q03JA      | Percentage [15-year-old modal grade] students who: Students from socioeconomically disadvantaged homes                                                |\n",
       "| 19 | IC180Q08JA      | Agree/disagree: I share made-up information on social networks without flagging its inaccuracy.                                                       |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Filter the DataFrame to only include rows where Variable_name is in top_20_features\n",
    "top_20_dictionary = dictionary[dictionary[\"Variable_name\"].isin(top_20_features)]\n",
    "top_20_table = top_20_dictionary.set_index(\"Variable_name\").loc[top_20_features].reset_index()\n",
    "display(Markdown(top_20_table.to_markdown()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
